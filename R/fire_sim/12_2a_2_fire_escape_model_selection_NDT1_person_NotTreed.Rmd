---
title: "12_2a_2_fire_escape_model_selection_NDT1_person_NotTreed"
author: "Cora Skaien"
date: "19/11/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

#Load relevant libraries
library(sf)
library(tidyverse)
library(ggplot2)
library(ggcorrplot)
library(RPostgreSQL)
library(rpostgis)
library(dplyr)
library(lme4)
library(arm)
library(ggpubr)
library(mgcv)
library(nlme)
library(purrr)
library(tidyr)
library(caret)
library(pROC)
library(keyring)
library(ggcorrplot) 
library(kableExtra)
library(data.table)
library(DBI)
library(here)
library(AICcmodavg)
library(rje)
library(base)
library(car)
library(visreg)

source(here::here("R/functions/R_Postgres.R"))
```

<!--
Copyright 2021 Province of British Columbia

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and limitations under the License.
-->

#=================================
#  Script Name: 12_2a_2_fire_escape_model_selection_NDT1_person_NotTreed.R
#  Script Version: 1.0
#  Script Purpose: Model selection for escape by NDT.
#  Script Author: Cora Skaien, Ecological Modeling Specialist, Forest Analysis and Inventory Branch, B.C. Ministry of Forests, Lands, and Natural Resource Operations.
#=================================

Load in the prepped data.

```{r}
Escape_data_person_nt<-read.csv(file="D:\\Fire\\fire_data\\raw_data\\ClimateBC_Data\\escape_data_person_notrees_NDT_Oct.csv")

head(Escape_data_person_nt)

```

################ PART 1: Person Caused Fires ################

We will make a loop that does something very similar to our last loop, but with the selected climate variable plus other variables of interest. For person caused fires without trees, the variables of interest include:

1. Climate variable(s)
2. vegtype2
3. slope
4. aspect (cos)
5. elevation
6. Various distance to infrastructure variables (dist_mun, dist_dam, dist_nat, dist_pow, dist_mine) - no interactions
7. Land use (bclcs_level_5_2)
8. windspeed (wind_atfire)
9. roads_km (road density, which may relate to ability to fight fires)
10. Tdif_atfire (temperature difference from the month prior to the month of the fire)

Interactions of interest: two-way interactions between climate (1) and vegtype (5); two-way interactions between topography measures (6-8). 

This will be done separately for trees and non-treed areas. 

##We will do each loop separately for each NDT zone given the large number of possible models for each zone.

First we will create the variable lists that contain all of our variables of interest.

```{r}
##Create variable lists to be used in the model loop.
variables_all<-c(climate1 = "climate1", climate2 = "climate2", proj_height_1 = "proj_height_1", proj_age_1 = "proj_age_1", live_stand_volume_125 = "live_stand_volume_125", slope = "slope", aspect = "aspect", elevation ="elevation", vegtype2 = "vegtype2", bclcs_level_5_2 = "bclcs_level_5_2", dist_mun = "dist_mun", dist_dam ="dist_dam", dist_nat = "dist_nat", dist_pow = "dist_pow", dist_mine = "dist_mine", wind_atfire = "wind_atfire", roads_km="roads_km") 

variables_all_c1<-c(climate1 = "climate1", proj_height_1 = "proj_height_1", proj_age_1 = "proj_age_1", live_stand_volume_125 = "live_stand_volume_125", slope = "slope", aspect = "aspect", elevation ="elevation", vegtype2 = "vegtype2", bclcs_level_5_2 = "bclcs_level_5_2", dist_mun = "dist_mun", dist_dam ="dist_dam", dist_nat = "dist_nat", dist_pow = "dist_pow", dist_mine = "dist_mine", wind_atfire = "wind_atfire", roads_km="roads_km") 

vars.clim<-c("climate1")
vars.clim.vegtype<-c("climate1", "vegtype2")
vars.oth<-c("proj_height_1", "proj_age_1", "live_stand_volume_125") 
vars.topo<-c("slope", "aspect", "elevation", "wind_atfire")
vars.infra<-c("dist_mun", "dist_dam", "dist_nat", "dist_pow", "dist_mine", "roads_km")

#Also for later with 2 climate variables
vars.clim.vegtype2<-c("climate1", "climate2","vegtype2")
vars.clim.vegtype2b<-c("climate1", "climate2")

##Create interaction for climate and vegtype
inputs.me <- c(vars.clim.vegtype)
inputs.me2 <- c(vars.clim.vegtype2)
inputs.me2b <- c(vars.clim.vegtype2b)
```

Now, we will generate two-way interactions for each of these lists. 

```{r}

#####1a. For those with one climate variable
#get the names of all possible two-way interactions for climate variable(s) and vegtype.
twoway.ints <- NULL
for (i in 1:(length(inputs.me)-1)) {
  for (j in (i+1):length(inputs.me)) {
     twoway.ints <- cbind(twoway.ints, paste(inputs.me[i], inputs.me[j], sep=":"))
  }
}
twoway.ints
length(twoway.ints)#1

#
#Create function to determine Powerset for any vector of variable names
## or use rje package
#powerSet <- function(x) {
#   z.list <- NULL
#   for(i in 1:length(x)) {
#      z.list <- append(z.list, combn(x, m=i, simplify=F))
#   }    
#   return(z.list)
#}


#Get variables on own
#complete list of models using non-climate vars
mods.me.tmp <- powerSet(vars.clim.vegtype) 
#add climate vars to all of the above
mods.me.climate <- list()
for (i in 1: length(mods.me.tmp)) {
   mods.me.climate[[i]] <- c(mods.me.tmp[[i]])
}

mods.me.climate
mods.me.climate<-mods.me.climate[-1]

#complete list of two-way interactions
mods.twoway <- powerSet(twoway.ints)
length(mods.twoway) #2
mods.twoway
mods.twoway<-mods.twoway[-1]

#Finding models in mods.me that accommodate/allow interaction terms in each mods.twoway to be added
mods.inter <- list()
counter <- 0
for (i in 1: length(mods.twoway)) {
   s1 <- unique(unlist( strsplit(mods.twoway[[i]], split=':', fixed=TRUE) ) )
   for (j in 1: length(mods.me.climate)) {
      if (all(s1 %in% mods.me.climate[[j]])==TRUE) {
        counter <- counter + 1
        both <-  c(mods.me.climate[[j]], mods.twoway[[i]])
        mods.inter[[counter]] <- both
      }
   }
}

length(mods.inter) #1
mods.inter


#####1b. For those with two climate variables
#get the names of all possible two-way interactions for climate variable(s) and vegtype.
twoway.ints2 <- NULL
for (i in 1:(length(inputs.me2)-1)) {
  for (j in (i+1):length(inputs.me2)) {
     twoway.ints2 <- cbind(twoway.ints2, paste(inputs.me2[i], inputs.me2[j], sep=":"))
  }
}
twoway.ints2
length(twoway.ints2) #3

#Get variables on own
#complete list of models using non-climate vars
mods.me.tmp <- powerSet(vars.clim.vegtype2) 
#add climate vars to all of the above
mods.me.climate2 <- list()
for (i in 1: length(mods.me.tmp)) {
   mods.me.climate2[[i]] <- c(mods.me.tmp[[i]])
}

mods.me.climate2
mods.me.climate2<-mods.me.climate2[-1]

#complete list of two-way interactions
mods.twoway2 <- powerSet(twoway.ints2)
length(mods.twoway2) #8
mods.twoway2
mods.twoway2<-mods.twoway2[-1]

#Finding models in mods.me that accommodate/allow interaction terms in each mods.twoway to be added
mods.inter2 <- list()
counter <- 0
for (i in 1: length(mods.twoway2)) {
   s1 <- unique(unlist( strsplit(mods.twoway2[[i]], split=':', fixed=TRUE) ) )
   for (j in 1: length(mods.me.climate2)) {
      if (all(s1 %in% mods.me.climate2[[j]])==TRUE) {
        counter <- counter + 1
        both <-  c(mods.me.climate2[[j]], mods.twoway2[[i]])
        mods.inter2[[counter]] <- both
      }
   }
}

length(mods.inter2) #10
#mods.inter2
mods.inter2


####1c. Two variables, no variation in vegtype
#get the names of all possible two-way interactions for climate variable(s) and vegtype.
twoway.ints2b <- NULL
for (i in 1:(length(inputs.me2b)-1)) {
  for (j in (i+1):length(inputs.me2b)) {
     twoway.ints2b <- cbind(twoway.ints2b, paste(inputs.me2b[i], inputs.me2b[j], sep=":"))
  }
}
twoway.ints2b
length(twoway.ints2b) #1

#Get variables on own
#complete list of models using non-climate vars
mods.me.tmp <- powerSet(vars.clim.vegtype2b) 
#add climate vars to all of the above
mods.me.climate2b <- list()
for (i in 1: length(mods.me.tmp)) {
   mods.me.climate2b[[i]] <- c(mods.me.tmp[[i]])
}

mods.me.climate2b
mods.me.climate2b<-mods.me.climate2b[-1]

#complete list of two-way interactions
mods.twoway2b <- powerSet(twoway.ints2b)
length(mods.twoway2b) #2
mods.twoway2b
mods.twoway2b<-mods.twoway2b[-1]

#Finding models in mods.me that accommodate/allow interaction terms in each mods.twoway to be added
mods.inter2b <- list()
counter <- 0
for (i in 1: length(mods.twoway2b)) {
   s1 <- unique(unlist( strsplit(mods.twoway2b[[i]], split=':', fixed=TRUE) ) )
   for (j in 1: length(mods.me.climate2b)) {
      if (all(s1 %in% mods.me.climate2b[[j]])==TRUE) {
        counter <- counter + 1
        both <-  c(mods.me.climate2b[[j]], mods.twoway2b[[i]])
        mods.inter2b[[counter]] <- both
      }
   }
}

length(mods.inter2b)
#mods.inter2b


#########2. Now for topography data, get all possible two-way interactions

#get the names of all possible two-way interactions
twoway.intsT <- NULL
for (i in 1:(length(vars.topo)-1)) {
  for (j in (i+1):length(vars.topo)) {
     twoway.intsT <- cbind(twoway.intsT, paste(vars.topo[i], vars.topo[j], sep=":"))
  }
}
twoway.intsT
length(twoway.intsT) #6

#complete list of models using non-climate vars (topo)
mods.me.tmp <- powerSet(vars.topo) 
#add climate vars to all of the above
mods.meT <- list()
for (i in 1: length(mods.me.tmp)) {
   mods.meT[[i]] <- c(mods.me.tmp[[i]])
}

mods.meT
mods.meT<-mods.meT[-1]

#complete list of two-way interactions
mods.twowayT <- powerSet(twoway.intsT)
length(mods.twowayT) #64
mods.twowayT
mods.twowayT<-mods.twowayT[-1]

#Finding models in mods.me that accommodate/allow interaction terms in each mods.twoway to be added

mods.interT <- list()
counter <- 0
for (i in 1: length(mods.twowayT)) {
   s1 <- unique(unlist( strsplit(mods.twowayT[[i]], split=':', fixed=TRUE) ) )
   for (j in 1: length(mods.meT)) {
      if (all(s1 %in% mods.meT[[j]])==TRUE) {
        counter <- counter + 1
        both <-  c(mods.meT[[j]], mods.twowayT[[i]])
        mods.interT[[counter]] <- both
      }
   }
}

length(mods.interT) #97
#mods.interT

#########3. Now for distance to infrastructure data, get all possible two-way interactions

#get the names of all possible two-way interactions
twoway.intsI <- NULL
for (i in 1:(length(vars.infra)-1)) {
  for (j in (i+1):length(vars.infra)) {
     twoway.intsI <- cbind(twoway.intsI, paste(vars.infra[i], vars.infra[j], sep=":"))
  }
}
twoway.intsI
length(twoway.intsI) #15

#complete list of models using non-climate vars (infra)
mods.me.tmp <- powerSet(vars.infra) 
#add climate vars to all of the above
mods.meI <- list()
for (i in 1: length(mods.me.tmp)) {
   mods.meI[[i]] <- c(mods.me.tmp[[i]])
}

mods.meI
mods.meI<-mods.meI[-1]

#complete list of two-way interactions
mods.twowayI <- powerSet(twoway.intsI)
length(mods.twowayI) #32768 -
#mods.twowayI

#Finding models in mods.me that accommodate/allow interaction terms in each mods.twoway to be added

mods.interI <- list()
counter <- 0
for (i in 1: length(mods.twowayI)) {
   s1 <- unique(unlist( strsplit(mods.twowayI[[i]], split=':', fixed=TRUE) ) )
   for (j in 1: length(mods.meI)) {
      if (all(s1 %in% mods.meI[[j]])==TRUE) {
        counter <- counter + 1
        both <-  c(mods.meI[[j]], mods.twowayI[[i]])
        mods.interI[[counter]] <- both
      }
   }
}

length(mods.interI) #80136
#mods.interI


#the list of all possible model RHSs. 
#all.poss.mods <- c(1, vars.clim, twoway.ints, mods.me.oth, mods.me2, mods.inter2)
#all.poss.mods

all.poss.mods.clim.vegtype<-c(1, mods.me.climate, twoway.ints)
all.poss.mods.clim.vegtype 

all.poss.mods.clim.vegtype2<-c(1, mods.me.climate2, mods.inter2)
all.poss.mods.clim.vegtype2

all.poss.mods.clim.vegtype2b<-c(1, mods.me.climate2b, mods.inter2b)
all.poss.mods.clim.vegtype2b

all.poss.mods.topo<-c(1, mods.interT)
all.poss.mods.topo

all.poss.mods.infra<-c(1, mods.meI) #I don't think we want interactions here actually... we will in the next stage when we include bclcs_level_5_2 after some initial pattern exploration


#If need to determine which ones are character(0), try this:
biglist <- list(list("A","B","C"), "foo", "", character(0), integer(0))
lapply(biglist, function(x) {length(x) == 0L} ) 


##Check and rid of any duplicated models
duplicated(all.poss.mods.clim.vegtype) #None duplicated
duplicated(all.poss.mods.clim.vegtype2)
duplicated(all.poss.mods.clim.vegtype2b)
duplicated(all.poss.mods.topo)
duplicated(all.poss.mods.infra)

```

############### Part 1 of 4 Model Series: person Caused Fires, No Trees ##########

Because of the large number of models with all variables included, we will test the climate and vegtype first, then the topography variables, then the infrastructure variables. Then we will test the top models together in additional combinations, with determining best AIC model from there. 

Select NDT: NDT1
- NDT1 has two climate variables; NDTs 2-5 have only 1

```{r}
zones1<-c("NDT1") #Do one zone at a time
prop<-0.75

#Create empty table
table.glm.climate.simple <- data.frame (matrix (ncol = 5, nrow = 0))
colnames (table.glm.climate.simple) <- c ("model", "edf", "aic", "auc.valid", "NDT")

########### 1. Climate and vegtype ############
for (g in 1:100){

for (h in 1:length(zones1)) {
  dat2<- Escape_data_person_nt %>% dplyr::filter(ntrl_ds ==zones1[h])

#for (i in 1: length(all.poss.mods.clim.vegtype2)){
#  print(paste((all.poss.mods.clim.vegtype2[i]), (zones1[h]), sep=" "))
  
for (i in 1: length(zones1)){
  print(paste((all.poss.mods.clim.vegtype2[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(escape, escape, variables_all[i])
  model_dat<- dat2 %>% dplyr::select(escape, veg_escape, !!variables_all)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$veg_escape, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="escape") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.aic, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.clim.vegtype2, big.mod, df.train=dat1, df.test=Valid)

#terms in each model
x1.1 <- unlist(sapply(mods.fit, '[', 1))
x1.1
#Aic for models
x3.1 <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3.1
#auc from validation data
x4.1 <- unlist(sapply(mods.fit, '[', 4))
x4.1
#combining all as df
tab.sum.climate <- cbind.data.frame(model=x1.1, edf=x3.1[,1], aic=x3.1[,2], auc.valid=x4.1)
tab.sum.climate$NDT<-c("NDT1")
tab.sum.climate 

table.glm.climate.simple<-rbind(table.glm.climate.simple, tab.sum.climate)

}
}
}

```

Now that we have run the model 100 times, we want the average AIC and AUC for each variable combination.

```{r}
head(table.glm.climate.simple)
table(table.glm.climate.simple$model) # 100 per model

AIC_person_NDT1_escape_ntreed_climate<-table.glm.climate.simple

AIC_person_NDT1_escape_ntreed_summary_climate<- AIC_person_NDT1_escape_ntreed_climate %>%
  group_by(model) %>%
  summarise(meanAIC=mean(aic),
            meanAUC=mean(auc.valid),
            sdAUC=sd(auc.valid),
            )

AIC_person_NDT1_escape_ntreed_summary_climate2<- AIC_person_NDT1_escape_ntreed_summary_climate %>%
  mutate(deltaAIC=meanAIC-min(meanAIC))

head(AIC_person_NDT1_escape_ntreed_summary_climate2)
```

#Now repeat for topography

```{r}
########### 2. topo ############
#Create empty table
table.glm.topo.simple <- data.frame (matrix (ncol = 5, nrow = 0))
colnames (table.glm.topo.simple) <- c ("model", "edf", "aic", "auc.valid", "NDT")

#
for (g in 1:100){

for (h in 1:length(zones1)) {
  dat2<- Escape_data_person_nt %>% dplyr::filter(ntrl_ds ==zones1[h])

#for (i in 1: length(all.poss.mods.topo)){
#  print(paste((all.poss.mods.topo[i]), (zones1[h]), sep=" "))
  
for (i in 1: length(zones1)){
  print(paste((all.poss.mods.topo[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(escape, escape, variables_all[i])
  model_dat<- dat2 %>% dplyr::select(escape, escape, !!variables_all)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$escape, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="escape") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.aic, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.topo, big.mod, df.train=dat1, df.test=Valid)

#terms in each model
x1.1 <- unlist(sapply(mods.fit, '[', 1))
x1.1
#Aic for models
x3.1 <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3.1
#auc from validation data
x4.1 <- unlist(sapply(mods.fit, '[', 4))
x4.1
#combining all as df
tab.sum.topo <- cbind.data.frame(model=x1.1, edf=x3.1[,1], aic=x3.1[,2], auc.valid=x4.1)
tab.sum.topo$NDT<-c("NDT1")
tab.sum.topo 

table.glm.topo.simple<-rbind(table.glm.topo.simple, tab.sum.topo)

}
}
}
```

Now that we have run the model 100 times, we want the average AIC and AUC for each variable combination.

```{r}
head(table.glm.topo.simple)
table(table.glm.topo.simple$model) # 100 per model

AIC_person_NDT1_escape_ntreed_ntopo<-table.glm.topo.simple

AIC_person_NDT1_escape_ntreed_summary_ntopo<- AIC_person_NDT1_escape_ntreed_ntopo %>%
  group_by(model) %>%
  summarise(meanAIC=mean(aic),
            meanAUC=mean(auc.valid),
            sdAUC=sd(auc.valid),
            )

AIC_person_NDT1_escape_ntreed_summary_ntopo2<- AIC_person_NDT1_escape_ntreed_summary_ntopo %>%
  mutate(deltaAIC=meanAIC-min(meanAIC))

head(AIC_person_NDT1_escape_ntreed_summary_ntopo2)
```

#Now repeat for infrastructure

```{r}
########### 3. Distance to Infrastructure ############
#Create empty table
table.glm.infra.simple <- data.frame (matrix (ncol = 5, nrow = 0))
colnames (table.glm.infra.simple) <- c ("model", "edf", "aic", "auc.valid", "NDT")

#
for (g in 1:100){

for (h in 1:length(zones1)) {
  dat2<- Escape_data_person_nt %>% dplyr::filter(ntrl_ds ==zones1[h])

#for (i in 1: length(all.poss.mods.infra)){
#  print(paste((all.poss.mods.infra[i]), (zones1[h]), sep=" "))
  
for (i in 1: length(zones1)){
  print(paste((all.poss.mods.infra[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(escape, escape, variables_all[i])
  model_dat<- dat2 %>% dplyr::select(escape, escape, !!variables_all)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$escape, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="escape") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.aic, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.infra, big.mod, df.train=dat1, df.test=Valid)

#terms in each model
x1.1 <- unlist(sapply(mods.fit, '[', 1))
x1.1
#Aic for models
x3.1 <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3.1
#auc from validation data
x4.1 <- unlist(sapply(mods.fit, '[', 4))
x4.1
#combining all as df
tab.sum.infra <- cbind.data.frame(model=x1.1, edf=x3.1[,1], aic=x3.1[,2], auc.valid=x4.1)
tab.sum.infra$NDT<-c("NDT1")
tab.sum.infra 

table.glm.infra.simple<-rbind(table.glm.infra.simple, tab.sum.infra)

}
}
}
```

Now that we have run the model 100 times, we want the average AIC and AUC for each variable combination.

```{r}
head(table.glm.infra.simple)
table(table.glm.infra.simple$model) # 100 per model

AIC_person_NDT1_escape_ntreed_infra<-table.glm.infra.simple

AIC_person_NDT1_escape_ntreed_summary_infra<- AIC_person_NDT1_escape_ntreed_infra %>%
  group_by(model) %>%
  summarise(meanAIC=mean(aic),
            meanAUC=mean(auc.valid),
            sdAUC=sd(auc.valid),
            )

AIC_person_NDT1_escape_ntreed_summary_infra2<- AIC_person_NDT1_escape_ntreed_summary_infra %>%
  mutate(deltaAIC=meanAIC-min(meanAIC))

head(AIC_person_NDT1_escape_ntreed_summary_infra2)

```

#Now combine the datatables and save to computer

```{r}
NDT1_l_models_ntreed<-rbind(AIC_person_NDT1_escape_ntreed_summary_climate2, AIC_person_NDT1_escape_ntreed_summary_ntopo2, AIC_person_NDT1_escape_ntreed_summary_infra2)
NDT1_l_models_ntreed
NDT1_l_models_ntreed$NDT<-"NDT1"

write.csv(NDT1_l_models_ntreed, file="D:\\Fire\\fire_data\\raw_data\\NDT1_person_models_notrees_escape.csv")
```


################################ STAGE TWO ########################

#STAGE TWO: PUT TOGETHER MORE VARIABLES
Now choose the top variables and create final model. The below code will need to be updated manually, depending on what the results of the above analyses are. From the top models, we will re-create two-way interactions for the variables selected from each model, plus the other variables listed as needed to be included. We will assess each set to ensure only interactions that make sense are investigated ultimately, given that sample sizes will be an issues.

Top Models:
1. climate1 + climate2 
2. slope + aspect + elevation + aspect:elevation
3. dist_mun

#Additional Variables:
1. bclcs_level_5_2 (land use) (to be added to final investigated model)
**We will leave vegtype2 in final model selection to test.
2. Tdif_atfire

#Interactions to investigate:
1. elevation*climate1
2. elevation*climate2
3. wind_atfire*climate1
4. wind_atfire*climate2
5. wind_atfire*vegtype2
6. Tdif_atfire*climate1
7. Tdif_atfire*climate2
8. Tdif_atfire*wind_atfire
9. bclcs_level_5_2*dist_mun
10. bclcs_level_5_2*dist_dam
11. bclcs_level_5_2*roads_km
12. dist_mun*roads_km
13. dist_dam*roads_km

#Next investigation
Because there would be far too many models to investigate including all variables and their interactions, we will start with the above and make educated guesses for what may need to be enhanced. We will seek the best model from the above informed progress.

```{r}
escape_person_nt_NDT1<-subset(Escape_data_person_nt, Escape_data_person_nt$ntrl_ds=="NDT1") #Only 124 observations - likely cannot use all interactions effectively

#Divide data into training and valid
prop<-0.75
# Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(escape_person_nt_NDT1$escape, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- escape_person_nt_NDT1[ trainIndex,]
   Valid <- escape_person_nt_NDT1[-trainIndex,]

#Run model using dat1
#Start without additional interactions
model.NDT1.E<-glm(escape ~ climate1 + climate2 + slope + aspect + elevation + aspect:elevation + dist_mun, family = binomial, data = dat1)

AIC(model.NDT1.E) #81.8

#Determine AUC of full model
mod.valid <- predict.glm(model.NDT1.E, newdata=Valid, type="response")
   roc_obj <- roc(Valid[,"escape"], mod.valid)
   mod.auc <- auc(roc_obj)
   mod.auc #0.73- good
   
Anova(model.NDT1.E, type=3)
Anova(model.NDT1.E, type=3, singular.ok = TRUE)

#Remove least significant
model.NDT1.E<-glm(escape ~ climate1 + climate2 + slope + aspect + elevation + aspect:elevation, family = binomial, data = dat1)

AIC(model.NDT1.E) #80.0

#Determine AUC of full model
mod.valid <- predict.glm(model.NDT1.E, newdata=Valid, type="response")
   roc_obj <- roc(Valid[,"escape"], mod.valid)
   mod.auc <- auc(roc_obj)
   mod.auc #0.69- not as good
   
Anova(model.NDT1.E, type=3)
#Anova(model.NDT1.E, type=3, singular.ok = TRUE)

#Remove least significant
model.NDT1.E<-glm(escape ~ climate1 + climate2 + aspect + elevation + aspect:elevation, family = binomial, data = dat1)

AIC(model.NDT1.E) #78.9

#Determine AUC of full model
mod.valid <- predict.glm(model.NDT1.E, newdata=Valid, type="response")
   roc_obj <- roc(Valid[,"escape"], mod.valid)
   mod.auc <- auc(roc_obj)
   mod.auc #0.39- VERY BAD
   
Anova(model.NDT1.E, type=3)
#Anova(model.NDT1.E, type=3, singular.ok = TRUE)

#Go back
model.NDT1.E<-glm(escape ~ climate1 + climate2 + slope + aspect + elevation + aspect:elevation + dist_mun + climate1:elevation, family = binomial, data = dat1)

AIC(model.NDT1.E) #81.5

#Determine AUC of full model
mod.valid <- predict.glm(model.NDT1.E, newdata=Valid, type="response")
   roc_obj <- roc(Valid[,"escape"], mod.valid)
   mod.auc <- auc(roc_obj)
   mod.auc #0.74- good
   
Anova(model.NDT1.E, type=3)
#Anova(model.NDT1.E, type=3, singular.ok = TRUE)

#Add
model.NDT1.E<-glm(escape ~ climate1 + climate2 + slope + aspect + elevation + aspect:elevation + dist_mun + climate1:elevation + climate2:elevation, family = binomial, data = dat1)

AIC(model.NDT1.E) #82.9

#Determine AUC of full model
mod.valid <- predict.glm(model.NDT1.E, newdata=Valid, type="response")
   roc_obj <- roc(Valid[,"escape"], mod.valid)
   mod.auc <- auc(roc_obj)
   mod.auc #0.74- good
   
Anova(model.NDT1.E, type=3)
#Anova(model.NDT1.E, type=3, singular.ok = TRUE)

#
model.NDT1.E<-glm(escape ~ climate1 + climate2 + slope + aspect + elevation + aspect:elevation + dist_mun + Tdif_atfire + bclcs_level_5_2 + climate1:elevation, family = binomial, data = dat1)

AIC(model.NDT1.E) #64.8

#Determine AUC of full model
mod.valid <- predict.glm(model.NDT1.E, newdata=Valid, type="response")
   roc_obj <- roc(Valid[,"escape"], mod.valid)
   mod.auc <- auc(roc_obj)
   mod.auc #0.85- very good
   
Anova(model.NDT1.E, type=3)
#Anova(model.NDT1.E, type=3, singular.ok = TRUE)

#
model.NDT1.E<-glm(escape ~ climate1  + slope + aspect + elevation + aspect:elevation + dist_mun + Tdif_atfire + bclcs_level_5_2 + climate1:elevation, family = binomial, data = dat1)

AIC(model.NDT1.E) #63.2

#Determine AUC of full model
mod.valid <- predict.glm(model.NDT1.E, newdata=Valid, type="response")
   roc_obj <- roc(Valid[,"escape"], mod.valid)
   mod.auc <- auc(roc_obj)
   mod.auc #0.87- very good
   
Anova(model.NDT1.E, type=3)
#Anova(model.NDT1.E, type=3, singular.ok = TRUE)

#
model.NDT1.E<-glm(escape ~ climate1 + slope + aspect + elevation + dist_mun + Tdif_atfire + bclcs_level_5_2 + climate1:elevation, family = binomial, data = dat1)

AIC(model.NDT1.E) #62.6

#Determine AUC of full model
mod.valid <- predict.glm(model.NDT1.E, newdata=Valid, type="response")
   roc_obj <- roc(Valid[,"escape"], mod.valid)
   mod.auc <- auc(roc_obj)
   mod.auc #0.84- very good
   
Anova(model.NDT1.E, type=3)
#Anova(model.NDT1.E, type=3, singular.ok = TRUE)

```

Remove NAs and run multiple times.

```{r}
#Remove NAs to ensure all same data used so we can compare AICs
NDT1_escape_nt<-escape_person_nt_NDT1 %>% drop_na(climate1, dist_mun,slope, aspect, elevation, Tdif_atfire, bclcs_level_5_2) #122 observations

#Run Model again with this data; but uses all data here
model.NDT1.E<-glm(escape ~ climate1 + slope + aspect + elevation + dist_mun + Tdif_atfire + bclcs_level_5_2 + climate1:elevation, family = binomial, data = NDT1_escape_nt)

#Anova(model.NDT1.E, type=3)
Anova(model.NDT1.E, type=3, singular.ok = TRUE)

# model diagnostic plots
binnedplot (fitted(model.NDT1.E), 
            residuals(model.NDT1.E), 
            nclass = NULL, 
            xlab = "Expected Values", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))


NDT1_escape_nt$resids<-resid(model.NDT1.E)

binnedplot (NDT1_escape_nt$live_stand_volume_125, 
            NDT1_escape_nt$resids, 
            nclass = NULL, 
            xlab = "live stand volume", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))

binnedplot (NDT1_escape_nt$climate1, 
            NDT1_escape_nt$resids, 
            nclass = NULL, 
            xlab = "", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))

# Diagnostic plots look good

#Partial Residuals
#climate1 + slope + aspect + elevation + dist_mun + Tdif_atfire + bclcs_level_5_2 + climate1:elevation

visreg(model.NDT1.E, "climate1", by="elevation")
visreg(model.NDT1.E, "Tdif_atfire")
visreg(model.NDT1.E, "dist_mun")

visreg(model.NDT1.E, "slope")
visreg(model.NDT1.E, "elevation")
visreg(model.NDT1.E, "aspect")

visreg(model.NDT1.E, "bclcs_level_5_2", ylim = c(-50,50))

```

We should repeat the above several times and take the mean of the coefficients.

```{r}
summary(model.NDT1.E)

#Create a new blank table and get AUC too
top_mod_ntable_NDT1_person_nt_ALL <- data.frame (matrix (ncol = 15, nrow = 0))
colnames (top_mod_ntable_NDT1_person_nt_ALL ) <- c ("CAUSE", "NDT", "TREED", "Model_terms", "intercept", "coef_climate_1", "coef_slope", "coef_aspect", "coef_elevation", "coef_dist_mun", "coef_Tdif_atfire", "coef_bclcs_level_5_2OP", "coef_bclcs_level_5_2SP", "coef_climate1:elevation", "AUC")

NDT1_escape_nt$escape_land<-paste(NDT1_escape_nt$escape, NDT1_escape_nt$bclcs_level_5_2)
```

Let's run it 500 times to get good mean values.

```{r}

for (g in 1:500){

prop<-0.75
# Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(NDT1_escape_nt$escape_land, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- NDT1_escape_nt[ trainIndex,]
   Valid <- NDT1_escape_nt[-trainIndex,]
   
#Model   
model.NDT1.E<-glm(escape ~ climate1 + slope + aspect + elevation + dist_mun + Tdif_atfire + bclcs_level_5_2 + climate1:elevation, family = binomial, data = dat1) 

mod.valid <- predict.glm(model.NDT1.E, newdata=Valid, type="response")
   roc_obj <- roc(Valid[,"escape"], mod.valid)
   mod.auc <- auc(roc_obj)

# create model table (only do this once) and add the relevant data
top_mod_ntable_NDT1_person_nt <- data.frame (matrix (ncol = 15, nrow = 0))
colnames (top_mod_ntable_NDT1_person_nt ) <- c ("CAUSE", "NDT", "TREED", "Model_terms", "intercept", "coef_climate_1", "coef_slope", "coef_aspect", "coef_elevation", "coef_dist_mun", "coef_Tdif_atfire", "coef_bclcs_level_5_2OP", "coef_bclcs_level_5_2SP", "coef_climate1:elevation", "AUC")

##Add data for NDT1
top_mod_ntable_NDT1_person_nt[1,1]<-"person"
top_mod_ntable_NDT1_person_nt[1,2]<-"NDT1"
top_mod_ntable_NDT1_person_nt[1,3]<-"N"
top_mod_ntable_NDT1_person_nt[1,4]<-"escape ~ climate1 + slope + aspect + elevation + dist_mun + Tdif_atfire + bclcs_level_5_2 + climate1:elevation" 
top_mod_ntable_NDT1_person_nt[1,5]<- coef(model.NDT1.E)[1] #Intercept
top_mod_ntable_NDT1_person_nt[1,6]<- coef(model.NDT1.E)[2] #C
top_mod_ntable_NDT1_person_nt[1,7]<- coef(model.NDT1.E)[3] #C
top_mod_ntable_NDT1_person_nt[1,8]<- coef(model.NDT1.E)[4] #co
top_mod_ntable_NDT1_person_nt[1,9]<- coef(model.NDT1.E)[5] #co
top_mod_ntable_NDT1_person_nt[1,10]<- coef(model.NDT1.E)[6] #c
top_mod_ntable_NDT1_person_nt[1,11]<- coef(model.NDT1.E)[7] #l
top_mod_ntable_NDT1_person_nt[1,12]<- coef(model.NDT1.E)[8] #co
top_mod_ntable_NDT1_person_nt[1,13]<- coef(model.NDT1.E)[9] #c
top_mod_ntable_NDT1_person_nt[1,14]<- coef(model.NDT1.E)[10] #coeff
top_mod_ntable_NDT1_person_nt[1,15]<- mod.auc

top_mod_ntable_NDT1_person_nt_ALL<-rbind(top_mod_ntable_NDT1_person_nt_ALL, top_mod_ntable_NDT1_person_nt)

}

```

Check.
```{r}
head(top_mod_ntable_NDT1_person_nt_ALL)

```

#Save coefficient table

```{r}
write.csv(top_mod_ntable_NDT1_person_nt_ALL, file="D:\\Fire\\fire_data\\raw_data\\top_mod_escape_NDT1_person_nt_ALL.csv")
```


#Get Mean Values

```{r}
names(top_mod_ntable_NDT1_person_nt_ALL)

top_mod_ntable_NDT1_escape_person_nt_means<-top_mod_ntable_NDT1_person_nt_ALL %>% summarise_each(funs( mean( .,na.rm = TRUE)))
top_mod_ntable_NDT1_escape_person_nt_means

top_mod_ntable_NDT1_escape_person_nt_means[1,1]<-"person"
top_mod_ntable_NDT1_escape_person_nt_means[1,2]<-"NDT1"
top_mod_ntable_NDT1_escape_person_nt_means[1,3]<-"Not Treed"
top_mod_ntable_NDT1_escape_person_nt_means[1,4]<- "escape ~ climate1 + slope + aspect + elevation + dist_mun + Tdif_atfire + bclcs_level_5_2 + climate1:elevation" 
top_mod_ntable_NDT1_escape_person_nt_means
```
Save table.

```{r}
write.csv(top_mod_ntable_NDT1_escape_person_nt_means, file="D:\\Fire\\fire_data\\raw_data\\top_mod_escape_NDT1_person_nt_Means.csv")
```

Standard deviation.

```{r}
top_mod_ntable_NDT1_escape_person_nt_sd<-top_mod_ntable_NDT1_person_nt_ALL %>% summarise_each(funs( sd( .,na.rm = TRUE)))
top_mod_ntable_NDT1_escape_person_nt_sd

top_mod_ntable_NDT1_escape_person_nt_sd[1,1]<-"person"
top_mod_ntable_NDT1_escape_person_nt_sd[1,2]<-"NDT1"
top_mod_ntable_NDT1_escape_person_nt_sd[1,3]<-"Not Treed"
top_mod_ntable_NDT1_escape_person_nt_sd[1,4]<-"escape ~ climate1 + slope + aspect + elevation + dist_mun + Tdif_atfire + bclcs_level_5_2 + climate1:elevation" 
top_mod_ntable_NDT1_escape_person_nt_sd
```

Save sd coefficient table.

```{r}
write.csv(top_mod_ntable_NDT1_escape_person_nt_sd, file="D:\\Fire\\fire_data\\raw_data\\top_mod_escape_NDT1_person_nt_SD.csv")
```

