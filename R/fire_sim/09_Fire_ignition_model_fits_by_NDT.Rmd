---
title: "09_Fire ignition model fit by BEC zone"
author: "Elizabeth Kleynhans and Cora Skaien"
contributor: "Peter Ott"
date: "20/04/2021"
output: html_document
editor_options: 
  chunk_output_type: console
---

editor_options:
  chunk_output_type: console
  
<style> 
p.caption {
  font-size: 1.2em;
}
</style>


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library (kableExtra)
library (data.table)
library (DBI)
library (RPostgreSQL)
library (dplyr)
library (ggplot2)
library (here)
library(ggpubr)
library(arm)
library(tidyr)
library(AICcmodavg)
library(keyring)
library(caret)
library(pROC)
library(rje)

source(here::here("R/functions/R_Postgres.R"))
```

<!--
Copyright 2021 Province of British Columbia

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and limitations under the License.
-->

## Introduction

Here, we are running a glm for each separate bec zone to develop a predictive equation so that we can extrapolate fire ignitions into the future. The data that we include in these glms is both vegetation and climate date. The top climate variable for each BEC zone was determined in the script "08_ignition_climate_variable_selection.R". 

Firstly, in each BEC zone, we split the data into treed and non-treed then run a glm with climate and vegetation for areas that are classified as treed in the VRI and another separate analysis for areas that are classified as not treed. The fixed effects we include in these analyses are slightly different, i.e. no age, volume or height data in the non-treed areas, which is why we split the analyses up.  

# climate variable selection
In the script "08_ignition_climate_variable_selection.R", we performed an AIC and ROC analysis for each BEC zone including presence/available fire ignition points and a variety of climate variables. For this analysis, we split the data into a training and a validation data set where 75% of the data was used for training and 25% was used for validation. We then fit the model and extracted the AIC and AUC values. This was repeated 100 times and at the end we calculated the average AIC and AUC values. We then also used a different subset of non-fire locations from the initial pruned numbers and repeated the previous step 3-5 times to get consistent results per BEC zone. The climate variable that consistently resulted in the lowest average AIC value is used in this analysis. We will load tables for person and lightning caused is a summary of which climate variables fitted best for each BEC zone. 

Note: Some climate variables resulted in delta AIC values that were very similar and had much less than 2 points difference. Also, the variable with the smallest AIC value did not always have the best AUC value. Regardless of these two issues, we decided to take the climate variable with the smallest average AIC for simplicity. Results will be loaded in for each AIC table. These files were manipulated manually and then saved on to the drive before being uploaded (i.e., it is a simplified table from that generated in the last file, 06_ignition_climate_variable_selection; code for uploading not included prior).


```{r, AIC table, echo = F, message = F, eval = T}

climate_variables_lightning<-read.csv("D:/Fire/fire_data/raw_data/ClimateBC_Data/Final_Selected_Climate_Variables_Lightning_NDT.csv")
climate_variables_person<-read.csv("D://Fire//fire_data//raw_data//ClimateBC_Data//Final_Selected_Climate_Variables_Person_NDT.csv")

head(climate_variables_lightning) 
head(climate_variables_person) 

kable (climate_variables_lightning,
       caption = "<b>Table 1. Top candidate climate variables for lightning caused fires as selected through an AIC analysis for each BEC zone.<b>",
       digits = 2) %>%
  kable_styling (position = "left",
                 bootstrap_options = c("striped", "hover"),
                 fixed_thead = T,
                 full_width = F,
                 font_size = 11)

kable (climate_variables_person,
       caption = "<b>Table 2. Top candidate climate variables for person caused fires as selected through an AIC analysis for each BEC zone.<b>",
       digits = 2) %>%
  kable_styling (position = "left",
                 bootstrap_options = c("striped", "hover"),
                 fixed_thead = T,
                 full_width = F,
                 font_size = 11)

```

## Pull in the data for both lightning and person caused fires. Note, below seems to not be working and currently I am bringing it in from my local computer.

```{r}
connKyle <- dbConnect(drv = RPostgreSQL::PostgreSQL(), 
                      host = key_get('dbhost', keyring = 'postgreSQL'),
                      user = key_get('dbuser', keyring = 'postgreSQL'),
                      dbname = key_get('dbname', keyring = 'postgreSQL'),
                      password = key_get('dbpass', keyring = 'postgreSQL'),
                      port = "5432")
dat_lightning_ <- sf::st_read  (dsn = connKyle, # connKyle
                               query = "SELECT * FROM Data_Lightning")
dbDisconnect (connKyle)

head(dat_lightning_)

```


```{r}
connKyle <- dbConnect(drv = RPostgreSQL::PostgreSQL(), 
                      host = key_get('dbhost', keyring = 'postgreSQL'),
                      user = key_get('dbuser', keyring = 'postgreSQL'),
                      dbname = key_get('dbname', keyring = 'postgreSQL'),
                      password = key_get('dbpass', keyring = 'postgreSQL'),
                      port = "5432")
dat_person_ <- sf::st_read  (dsn = connKyle, # connKyle
                               query = "SELECT * FROM Data_Person")
dbDisconnect (connKyle)

head(dat_person_)

```

When doing the below analyses, it was noticed that disturbed areas often get eliminated when NAs are removed from the final data used for the model. Here, we investigate what variables are missing.

```{r}
dat_Disturbed<-subset(dat_lightning_, dat_lightning_$vegtype=="D")
head(dat_Disturbed)
dat_Disturbed$live_stand_volume_125
table(dat_Disturbed$live_stand_volume_125)
## We see that live_stand_volume does not exist for most disturbed sites (and when it does, it is 0, and one that is 3.103)

hist(dat_Disturbed$proj_age_1) #All under 15 years, as expected given the classification of disturbed if below 15 years

hist(dat_Disturbed$proj_height_1) #When not NA, Mostly all 0-5 m, a small number ~7 m.

##Change all NA for this vegtype to 0
dat_lightning_ <- within(dat_lightning_, live_stand_volume_125[is.na(live_stand_volume_125) & vegtype == 'D'] <- 0)
dat_person_ <- within(dat_person_, live_stand_volume_125[is.na(live_stand_volume_125) & vegtype == 'D'] <- 0)
##Because there will be no effect of stand volume on disturbed veg type, an interaction between these two variables should be included when both are in the model.

```

Now we will create additional columns that have the climate1 and climate2 variables indicated as the top variables for climate. 

```{r}
#View top variable
climate_variables_lightning
names(dat_lightning_)
unique(dat_lightning_$ntrl_ds)
dat_lightning_$ntrl_ds<-as.factor(dat_lightning_$ntrl_ds)
dat_lightning_$ntrl_ds_numeric<-as.numeric(dat_lightning_$ntrl_ds)
table(dat_lightning_$ntrl_ds_numeric)

dat_lightning_$ntrl_ds_codes<-paste(dat_lightning_$ntrl_ds, dat_lightning_$ntrl_ds_numeric)
unique(dat_lightning_$ntrl_ds_codes)

## Create empty vector
dat_lightning_$climate1<-0
head(dat_lightning_)

dat_lightning_<-dat_lightning_ %>%
    mutate(climate1 = case_when(ntrl_ds_numeric == 1 ~ tmax07, # NDT1
                                ntrl_ds_numeric == 2 ~ tave08, #NDT2
                                ntrl_ds_numeric == 3 ~ tave07, #NDT3
                                ntrl_ds_numeric == 4 ~ tmax07, # NDT4
                                ntrl_ds_numeric == 5 ~ tmax07, # NDT5
                                TRUE ~ NA_real_))

#Repeat for climate 2
dat_lightning_$climate2<-0
dat_lightning_$ppt07<-as.numeric(dat_lightning_$ppt07)
dat_lightning_$ppt08<-as.numeric(dat_lightning_$ppt08)

#Perform mutate to get the applicable variable for each row
dat_lightning_<-dat_lightning_ %>%
    mutate(climate2 = case_when(ntrl_ds_numeric == 1 ~ ppt07, # NDT1
                                ntrl_ds_numeric == 2 ~ ppt08, #NDT2
                                ntrl_ds_numeric == 3 ~ ppt07, #NDT3
                                ntrl_ds_numeric == 4 ~ ppt07, # NDT4
                                ntrl_ds_numeric == 5 ~ ppt07, # NDT5
                                TRUE ~ NA_real_))

head(dat_lightning_)

##Change vegtype to factor
dat_lightning_$vegtype<-as.factor(dat_lightning_$vegtype)

#create new column
dat_lightning_$fire_veg<-paste(dat_lightning_$fire_pres, dat_lightning_$vegtype)

```

Repeat for person-caused fires.

```{r}
#View top variable
climate_variables_person
names(dat_person_)
unique(dat_person_$ntrl_ds)
dat_person_$ntrl_ds<-as.factor(dat_person_$ntrl_ds)
dat_person_$ntrl_ds_numeric<-as.numeric(dat_person_$ntrl_ds)
table(dat_person_$ntrl_ds_numeric)

dat_person_$ntrl_ds_codes<-paste(dat_person_$ntrl_ds, dat_person_$ntrl_ds_numeric)
unique(dat_person_$ntrl_ds_codes)
#Compare codes to lightning
unique(dat_lightning_$ntrl_ds_codes) #they are the same

## Create empty vector
dat_person_$climate1<-0
head(dat_person_)

dat_person_<-dat_person_ %>%
    mutate(climate1 = case_when(ntrl_ds_numeric == 1 ~ tmax08, # NDT1
                                ntrl_ds_numeric == 2 ~ mean_tave08_tave09, #NDT2
                                ntrl_ds_numeric == 3 ~ mean_tmax05_tmax06_tmax07_tmax08_tmax09, #NDT3
                                ntrl_ds_numeric == 4 ~ tmax08, # NDT4
                                ntrl_ds_numeric == 5 ~ tave08, # NDT5
                                TRUE ~ NA_real_))

#Repeat for climate 2
dat_person_$climate2<-0

#Perform mutate to get the applicable variable for each row
dat_person_<-dat_person_ %>%
    mutate(climate2 = case_when(ntrl_ds_numeric == 1 ~ ppt08, # NDT1
                                #ntrl_ds_numeric == 2 ~ , #NDT2
                                #ntrl_ds_numeric == 3 ~ , #NDT3
                                ntrl_ds_numeric == 4 ~ ppt08, # NDT4
                                ntrl_ds_numeric == 5 ~ ppt08, # NDT5
                                TRUE ~ NA_real_))

head(dat_person_)

##Change vegtype to factor
dat_person_$vegtype<-as.factor(dat_person_$vegtype)

##Create new variable for fire presence by vegtype
dat_person_$fire_veg<-paste(dat_person_$fire_pres, dat_person_$vegtype)
str(dat_person_$fire_veg)
str(dat_person_$fire_pres)
table(dat_person_$fire_pres)

```

Add some transformations to some of the variables.

```{r}
#Before transformations, must convert degrees to radians
dat_lightning_$aspect_radians<-(dat_lightning_$aspect*pi)/180
hist(dat_lightning_$aspect_radians)

dat_lightning_$aspect_cos<-cos(dat_lightning_$aspect_radians) #try cos because I hypothesize that southern aspects would be most likely to have higher likelihood of fire. 180 degrees is -1 with cos, and north is plus 1.
```

Check values for percent dead.

```{r}
hist(dat_lightning_$stand_percentage_dead)
min(dat_lightning_$stand_percentage_dead) #NA
table(dat_lightning_$stand_percentage_dead) # There are 9 cases with 0. A few thousand with NA
dat_lightning_$stand_percentage_dead

#Not an accurate measure. Do not use.

```

View plots.

```{r}
p <- ggplot(dat_lightning_, aes(aspect, as.numeric(fire_pres))) +
  geom_smooth(method="glm", formula=y~x,
              method.args=list(family="binomial"),
              alpha=0.3, size=1) +
  geom_point(position=position_jitter(height=0.03, width=0)) +
  xlab("aspect") + ylab("Pr (ignition)")
p

p <- ggplot(dat_lightning_, aes(aspect_cos, as.numeric(fire_pres))) +
  geom_smooth(method="glm", formula=y~x,
              method.args=list(family="binomial"),
              alpha=0.3, size=1) +
  geom_point(position=position_jitter(height=0.03, width=0)) +
  xlab("aspect_cos") + ylab("Pr (ignition)")
p
##Seems to be minimal relationship with aspect overall

p <- ggplot(dat_lightning_, aes(slope, as.numeric(fire_pres))) +
  geom_smooth(method="glm", formula=y~x,
              method.args=list(family="binomial"),
              alpha=0.3, size=1) +
  geom_point(position=position_jitter(height=0.03, width=0)) +
  xlab("slope") + ylab("Pr (ignition)")
p
#positive association

ggplot(dat_lightning_, aes(x = slope)) +
  geom_histogram(fill = "white", colour = "black") +
  facet_grid(fire_pres ~ .)
##Seeing distribution of ignitions by slope makes me believe that slope is not a big factor for ignitions despite seemingly positive trend prior.


#
p <- ggplot(dat_lightning_, aes(aspect_cos*slope, as.numeric(fire_pres))) +
  geom_smooth(method="glm", formula=y~x,
              method.args=list(family="binomial"),
              alpha=0.3, size=1) +
  geom_point(position=position_jitter(height=0.03, width=0)) +
  xlab("aspect_cos*slope") + ylab("Pr (ignition)")
p

p <- ggplot(dat_lightning_, aes(elevation, as.numeric(fire_pres))) +
  geom_smooth(method="glm", formula=y~x,
              method.args=list(family="binomial"),
              alpha=0.3, size=1) +
  geom_point(position=position_jitter(height=0.03, width=0)) +
  xlab("elevation") + ylab("Pr (ignition)")
p
```

#Inspect each of the top climate variables for each group. Currently here, combined for all NDTs.

```{r}
p <- ggplot(dat_lightning_, aes(tmax07, as.numeric(fire_pres))) +
  geom_smooth(method="glm", formula=y~x,
              method.args=list(family="binomial"),
              alpha=0.3, size=1) +
  geom_point(position=position_jitter(height=0.03, width=0)) +
  xlab("tmax07") + ylab("Pr (ignition)")
p

p <- ggplot(dat_lightning_, aes(tave07, as.numeric(fire_pres))) +
  geom_smooth(method="glm", formula=y~x,
              method.args=list(family="binomial"),
              alpha=0.3, size=1) +
  geom_point(position=position_jitter(height=0.03, width=0)) +
  xlab("tave07") + ylab("Pr (ignition)")
p

p <- ggplot(dat_lightning_, aes(tave08, as.numeric(fire_pres))) +
  geom_smooth(method="glm", formula=y~x,
              method.args=list(family="binomial"),
              alpha=0.3, size=1) +
  geom_point(position=position_jitter(height=0.03, width=0)) +
  xlab("tave08") + ylab("Pr (ignition)")
p

p <- ggplot(dat_lightning_, aes(ppt08, as.numeric(fire_pres))) +
  geom_smooth(method="glm", formula=y~x,
              method.args=list(family="binomial"),
              alpha=0.3, size=1) +
  geom_point(position=position_jitter(height=0.03, width=0)) +
  xlab("ppt08") + ylab("Pr (ignition)")
p

p <- ggplot(dat_lightning_, aes(ppt07, as.numeric(fire_pres))) +
  geom_smooth(method="glm", formula=y~x,
              method.args=list(family="binomial"),
              alpha=0.3, size=1) +
  geom_point(position=position_jitter(height=0.03, width=0)) +
  xlab("ppt07") + ylab("Pr (ignition)")
p
```

#VRI variables

```{r}
p <- ggplot(dat_lightning_, aes(proj_age_1, as.numeric(fire_pres))) +
  geom_smooth(method="glm", formula=y~x,
              method.args=list(family="binomial"),
              alpha=0.3, size=1) +
  geom_point(position=position_jitter(height=0.03, width=0)) +
  xlab("proj_age_1") + ylab("Pr (ignition)")
p

p <- ggplot(dat_lightning_, aes(proj_height_1, as.numeric(fire_pres))) +
  geom_smooth(method="glm", formula=y~x,
              method.args=list(family="binomial"),
              alpha=0.3, size=1) +
  geom_point(position=position_jitter(height=0.03, width=0)) +
  xlab("proj_height_1") + ylab("Pr (ignition)")
p

p <- ggplot(dat_lightning_, aes(live_stand_volume_125, as.numeric(fire_pres))) +
  geom_smooth(method="glm", formula=y~x,
              method.args=list(family="binomial"),
              alpha=0.3, size=1) +
  geom_point(position=position_jitter(height=0.03, width=0)) +
  xlab("live_stand_volume_125") + ylab("Pr (ignition)")
p
```

Repeat for Person-caused fires

```{r}
##########Repeat for person-caused fires
dat_person_$aspect_radians<-(dat_person_$aspect*pi)/180
hist(dat_person_$aspect_radians)

dat_person_$aspect_cos<-cos(dat_person_$aspect_radians)
```
 
 View plots.

```{r}
p <- ggplot(dat_person_, aes(aspect, as.numeric(fire_pres))) +
  geom_smooth(method="glm", formula=y~x,
              method.args=list(family="binomial"),
              alpha=0.3, size=1) +
  geom_point(position=position_jitter(height=0.03, width=0)) +
  xlab("aspect") + ylab("Pr (ignition)")
p

p <- ggplot(dat_person_, aes(aspect_cos, as.numeric(fire_pres))) +
  geom_smooth(method="glm", formula=y~x,
              method.args=list(family="binomial"),
              alpha=0.3, size=1) +
  geom_point(position=position_jitter(height=0.03, width=0)) +
  xlab("aspect_cos") + ylab("Pr (ignition)")
p

##Seems to be minimal relationship with aspect overall

p <- ggplot(dat_person_, aes(slope, as.numeric(fire_pres))) +
  geom_smooth(method="glm", formula=y~x,
              method.args=list(family="binomial"),
              alpha=0.3, size=1) +
  geom_point(position=position_jitter(height=0.03, width=0)) +
  xlab("slope") + ylab("Pr (ignition)")
p
#strong negative correlation

ggplot(dat_person_, aes(x = slope)) +
  geom_histogram(fill = "white", colour = "black") +
  facet_grid(fire_pres ~ .)


p <- ggplot(dat_person_, aes(elevation, as.numeric(fire_pres))) +
  geom_smooth(method="glm", formula=y~x,
              method.args=list(family="binomial"),
              alpha=0.3, size=1) +
  geom_point(position=position_jitter(height=0.03, width=0)) +
  xlab("elevation") + ylab("Pr (ignition)")
p

p <- ggplot(dat_person_, aes(roads_km, as.numeric(fire_pres))) +
  geom_smooth(method="glm", formula=y~x,
              method.args=list(family="binomial"),
              alpha=0.3, size=1) +
  geom_point(position=position_jitter(height=0.03, width=0)) +
  xlab("Road Density") + ylab("Pr (ignition)")
p
```


Make cos(aspect in degrees) to be the default aspect.

```{r}
##cos makes more sense for aspect, so make this the default in analyses
dat_person_$aspect_degrees<-dat_person_$aspect
dat_person_$aspect<-dat_person_$aspect_cos

dat_lightning_$aspect_degrees<-dat_lightning_$aspect
dat_lightning_$aspect<-dat_lightning_$aspect_cos

```

#Repeat for top climate variables

```{r}
p <- ggplot(dat_person_, aes(tmax08, as.numeric(fire_pres))) +
  geom_smooth(method="glm", formula=y~x,
              method.args=list(family="binomial"),
              alpha=0.3, size=1) +
  geom_point(position=position_jitter(height=0.03, width=0)) +
  xlab("tmax08") + ylab("Pr (ignition)")
p

p <- ggplot(dat_person_, aes(tave08, as.numeric(fire_pres))) +
  geom_smooth(method="glm", formula=y~x,
              method.args=list(family="binomial"),
              alpha=0.3, size=1) +
  geom_point(position=position_jitter(height=0.03, width=0)) +
  xlab("tave08") + ylab("Pr (ignition)")
p

p <- ggplot(dat_person_, aes(mean_tmax05_tmax06_tmax07_tmax08_tmax09, as.numeric(fire_pres))) +
  geom_smooth(method="glm", formula=y~x,
              method.args=list(family="binomial"),
              alpha=0.3, size=1) +
  geom_point(position=position_jitter(height=0.03, width=0)) +
  xlab("mean_tmax05-09") + ylab("Pr (ignition)")
p

p <- ggplot(dat_person_, aes(mean_tave08_tave09, as.numeric(fire_pres))) +
  geom_smooth(method="glm", formula=y~x,
              method.args=list(family="binomial"),
              alpha=0.3, size=1) +
  geom_point(position=position_jitter(height=0.03, width=0)) +
  xlab("mean_tave08_tave09") + ylab("Pr (ignition)")
p

p <- ggplot(dat_person_, aes(ppt08, as.numeric(fire_pres))) +
  geom_smooth(method="glm", formula=y~x,
              method.args=list(family="binomial"),
              alpha=0.3, size=1) +
  geom_point(position=position_jitter(height=0.03, width=0)) +
  xlab("ppt08") + ylab("Pr (ignition)")
p
```

#VRI variables

```{r}
p <- ggplot(dat_person_, aes(proj_age_1, as.numeric(fire_pres))) +
  geom_smooth(method="glm", formula=y~x,
              method.args=list(family="binomial"),
              alpha=0.3, size=1) +
  geom_point(position=position_jitter(height=0.03, width=0)) +
  xlab("proj_age_1") + ylab("Pr (ignition)")
p

p <- ggplot(dat_person_, aes(proj_height_1, as.numeric(fire_pres))) +
  geom_smooth(method="glm", formula=y~x,
              method.args=list(family="binomial"),
              alpha=0.3, size=1) +
  geom_point(position=position_jitter(height=0.03, width=0)) +
  xlab("proj_height_1") + ylab("Pr (ignition)")
p

p <- ggplot(dat_person_, aes(live_stand_volume_125, as.numeric(fire_pres))) +
  geom_smooth(method="glm", formula=y~x,
              method.args=list(family="binomial"),
              alpha=0.3, size=1) +
  geom_point(position=position_jitter(height=0.03, width=0)) +
  xlab("live_stand_volume_125") + ylab("Pr (ignition)")
p
```

Save data.

```{r}
write.csv(dat_lightning_, "D:\\Fire\\fire_data\\raw_data\\ClimateBC_Data\\Lightning_data_Sept.csv")

write.csv(dat_person_, "D:\\Fire\\fire_data\\raw_data\\ClimateBC_Data\\Person_data_Sept.csv")

#Can read the data in
dat_lightning_<-read.csv("D:\\Fire\\fire_data\\raw_data\\ClimateBC_Data\\Lightning_data_Sept.csv")

dat_person_<-read.csv("D:\\Fire\\fire_data\\raw_data\\ClimateBC_Data\\Person_data_Sept.csv")
```

#Before sub-seeting data by treed and not treed, assess vegtype and land use type for both lightning and person-casued fires.

Assess landuse type distribution
```{r}
table(dat_lightning_$bclcs_level_5)
table(dat_lightning_$bclcs_level_5, dat_lightning_$fire)

```
BP: unspecified -> seems to be old code for urban. Combine with urban.
BR: bedrock
BU: Burned Area
CL: closed (Cover of bryoids is greater than 50% of the polygon) --> this one confuses me... closed canopy? Closed what?
DE: dense (Tree, shrub, or herb cover is between 61% and 100% for the polygon)
ES: Exposed Soil (Any exposed soil not covered by the other categories, such as areas of recent disturbance that include mud slides, debris torrents, avalanches, or disturbances such as pipeline rights-of-way or cultivated fields where vegetation cover is less than 5%)
GL: glacier
LS: Pond or lake sediments (Exposed sediments related to dried lakes or ponds)
MI: Open Pit Mine
MN: Moraine (debris)
MU: Mudflat (fine-textured sediments)
MZ: Rubbly Mine Spoils (Discarded overburden or waste rock, moved to extract ore during mining.)
OP: Open (Cover of bryoids is less than or equal to 50% of the polygon)
OT: Other (A Non-Vegetated polygon where none of the above categories can be reliably chosen)
PN: Snow Cover (Snow or ice that is not part of a glacier but is found during summer months on the landscape)
RS: River Sediments
RZ:  Road Surface
SP: sparse (Cover is between 10% and 25% for treed polygons, or cover is between 20% and 25% for shrub or herb polygons)
TA: Talus (Rock fragments of any size accumulated on or at the foot of slopes as a result of successive rock falls. This is a type of colluvium)
TS: unspecified. Seems to be old code for TZ. Tailings. An area containing the solid waste material produced in the mining and milling of ore
UR: Urban

#Change some of the classifications
```{r}
dat_lightning_$bclcs_level_5_2<-dat_lightning_$bclcs_level_5
#Change BP to UR since UR is the updated code for BP
dat_lightning_$bclcs_level_5_2[dat_lightning_$bclcs_level_5_2=="BP"] <- "UR"

#Make various snow/glacier categories into one
dat_lightning_$bclcs_level_5_2[dat_lightning_$bclcs_level_5_2=="GL"] <- "SNOW"
dat_lightning_$bclcs_level_5_2[dat_lightning_$bclcs_level_5_2=="PN"] <- "SNOW"

#Make various rock categories (or road)
dat_lightning_$bclcs_level_5_2[dat_lightning_$bclcs_level_5_2=="MI"] <- "ROCK"
dat_lightning_$bclcs_level_5_2[dat_lightning_$bclcs_level_5_2=="MN"] <- "ROCK"
dat_lightning_$bclcs_level_5_2[dat_lightning_$bclcs_level_5_2=="MZ"] <- "ROCK"
dat_lightning_$bclcs_level_5_2[dat_lightning_$bclcs_level_5_2=="RZ"] <- "ROCK"
dat_lightning_$bclcs_level_5_2[dat_lightning_$bclcs_level_5_2=="TA"] <- "ROCK"
dat_lightning_$bclcs_level_5_2[dat_lightning_$bclcs_level_5_2=="TS"] <- "ROCK"
dat_lightning_$bclcs_level_5_2[dat_lightning_$bclcs_level_5_2=="OT"] <- "ROCK"
dat_lightning_$bclcs_level_5_2[dat_lightning_$bclcs_level_5_2=="GP"] <- "ROCK"

#Categories for soil, sediments and mud
dat_lightning_$bclcs_level_5_2[dat_lightning_$bclcs_level_5_2=="ES"] <- "SOIL"
dat_lightning_$bclcs_level_5_2[dat_lightning_$bclcs_level_5_2=="LS"] <- "SOIL"
dat_lightning_$bclcs_level_5_2[dat_lightning_$bclcs_level_5_2=="MU"] <- "SOIL"
dat_lightning_$bclcs_level_5_2[dat_lightning_$bclcs_level_5_2=="RS"] <- "SOIL"

#Combine CL and Op categories
dat_lightning_$bclcs_level_5_2[dat_lightning_$bclcs_level_5_2=="CL"] <- "OP"

#For comparison to determine which categories need changing
table(dat_lightning_$bclcs_level_5)
table(dat_lightning_$bclcs_level_5_2) #Rock and Snow categories are very small and this may be a problem. They may need to be combined later as "inflammable surface"

table(dat_lightning_$bclcs_level_5_2, dat_lightning_$ntrl_ds)
#Given how sparse rock, snow and soil is between these, let's make them all unvegetated
dat_lightning_$bclcs_level_5_2[dat_lightning_$bclcs_level_5_2=="SOIL"] <- "UNVEG"
dat_lightning_$bclcs_level_5_2[dat_lightning_$bclcs_level_5_2=="SNOW"] <- "UNVEG"
dat_lightning_$bclcs_level_5_2[dat_lightning_$bclcs_level_5_2=="ROCK"] <- "UNVEG"

#Check again
table(dat_lightning_$bclcs_level_5_2, dat_lightning_$ntrl_ds)

table(dat_lightning_$bclcs_level_5_2, dat_lightning_$vegtype)
#Still have 6 unspecified; for some reason, dense "DE" from level 5 corresponds to 542 open polygons from vegtype?? I see in definition that bryoids can be considered dense too. Use vegtype to refine. Unsure what the "OP" definition really means with bryoids... what is the remainder? Rock? Trees?

#Create disturbed category if disturbed in last 16 years; add burn to this category
dat_lightning_$bclcs_level_5_2[which(dat_lightning_$vegtype =="D")]<-"DIST" 
dat_lightning_$bclcs_level_5_2[dat_lightning_$bclcs_level_5_2=="BU"] <- "DIST"
```


```{r}
#Get the OP category in vegtype from DE in bclcs_type_5 into OP, and get the S from the former into SP in the latter.
#OP: Open (Cover of bryoids is less than or equal to 50% of the polygon)--> what is the remainder? Rock? Trees? Confusing.
# note: there are also many "open" designations in vegtype that come out as TB, TC and TM in the bclcs_type_5. This suggests our designations prior may not have been accurate?
table(dat_lightning_$bclcs_level_4, dat_lightning_$vegtype)
table(dat_lightning_$bclcs_level_5_2, dat_lightning_$vegtype)
#BY: a bryoid polygon --> open seems good
#EL: Exposed Land --> open seems good, but maybe disturbed possible too?
#HE: Herb --> open seems good
#HF: Herb-Forb --> open seems good
#HG: Herb-Graminoids --> open seems good
#RO: Rock/Rubble--> actually I think this should be its own category of rock
#SI: Snow/Ice--> also should be own category and not open


#Repeat vegtype classification with new information
dat_lightning_$vegtype2<-"OP" #setting anything that is not one of the categories below to Open.
dat_lightning_ <- dat_lightning_ %>%
  mutate(vegtype2 = if_else(bclcs_level_4=="TC","TC", # Treed coniferous
                           if_else(bclcs_level_4=="TM", "TM", # Treed mixed
                                   if_else(bclcs_level_4== "TB","TB", #Treed broadleaf
                                           if_else(bclcs_level_4=="SL", "S", # shrub
                                                   if_else(bclcs_level_4=="ST", "S", 
                                                           if_else(bclcs_level_4=="RO","RO",
                                                                   if_else(bclcs_level_4=="SI", "SI",                                         vegtype2))))))))
dat_lightning_$vegtype2[which(dat_lightning_$proj_age_1 <16)]<-"D" #
table(dat_lightning_$vegtype2) #D: Disturbed; OP: Open; RO: Rock; S: Shurb; SI: Snow/Ice; TB: Treed Broadleaf; TC: Treed Conifer; TM: Treed Mixed.


table(dat_lightning_$bclcs_level_5_2, dat_lightning_$vegtype2)
#Still have 6 unspecified; for some reason, dense "DE" from level 5 corresponds to 542 open polygons from vegtype?? I see in definition that bryoids can be considered dense too. Use vegtype to refine. Unsure what the "OP" definition really means with bryoids... what is the remainder? Rock? Trees?

# Urban plots were also put into open; create as own category
#Need bclcs_level_5_2 to be a factor prior to being able to succeed. Make other changes first in case this makes that not possible.
dat_lightning_$bclcs_level_5_2 <-as.factor(dat_lightning_$bclcs_level_5_2)
dat_lightning_$vegtype2[which(dat_lightning_$bclcs_level_5_2 =="UR")]<-"UR" #

#Inspect
table(dat_lightning_$vegtype2) #SI category is too small. Combine with Rock.
dat_lightning_$vegtype2[dat_lightning_$vegtype2=="SI"] <- "RO"

#We still have discrepenacies between open and dense in vegtype (derived from bclcs_level_4) and bclcs_level_5. Play them out for now.

```


#Repeat for person-caused fires
Note, there are different landuse types for the person-caused fires compared to the lightning caused fires.

Assess landuse type distribution
```{r}
table(dat_person_$bclcs_level_5)
table(dat_person_$bclcs_level_5, dat_person_$fire)

```
AP: airport
BE: Beach (An area with sorted sediments reworked in recent time by wave action, which may be formed at the edge of fresh or salt water bodies)
BP: unspecified -> seems to be old code for urban. Combine with urban.
BR: bedrock
BU: Burned Area
CB: cutbank (Part of a road corridor created upslope of the road surface, created by excavation into the hillside)
CL: closed (Cover of bryoids is greater than 50% of the polygon) --> this one confuses me... closed canopy? Closed what?
DE: dense (Tree, shrub, or herb cover is between 61% and 100% for the polygon)
ES: Exposed Soil (Any exposed soil not covered by the other categories, such as areas of recent disturbance that include mud slides, debris torrents, avalanches, or disturbances such as pipeline rights-of-way or cultivated fields where vegetation cover is less than 5%)
GL: glacier
GP: Gravel Pit.
LL: Landing (A compacted area adjacent to a road used for sorting and loading logs)
LS: Pond or lake sediments (Exposed sediments related to dried lakes or ponds)
MI: Open Pit Mine
MN: Moraine (debris)
MU: Mudflat (fine-textured sediments)
MZ: Rubbly Mine Spoils (Discarded overburden or waste rock, moved to extract ore during mining.)
OP: Open (Cover of bryoids is less than or equal to 50% of the polygon)
OT: Other (A Non-Vegetated polygon where none of the above categories can be reliably chosen)
PN: Snow Cover (Snow or ice that is not part of a glacier but is found during summer months on the landscape)
RM: Reservoir Margin (Land exposed by a drained or fluctuating reservoir. It is found above "normal" water levels and may consist of a range of substrates including gravel, cobbles, fine sediments, or bedrock)
RN: Railway Surface (A roadbed with fixed rails, which may contain single or multiple rail lines)
RP: not specified
RS: River Sediments
RT: Not specified
RZ:  Road Surface
SP: sparse (Cover is between 10% and 25% for treed polygons, or cover is between 20% and 25% for shrub or herb polygons)
TA: Talus (Rock fragments of any size accumulated on or at the foot of slopes as a result of successive rock falls. This is a type of colluvium)
TS: unspecified. Seems to be old code for TZ. Tailings. An area containing the solid waste material produced in the mining and milling of ore
TZ: Tailings (An area containing the solid waste material produced in the mining and milling of ore)
UR: Urban

#Change some of the classifications
```{r}
dat_person_$bclcs_level_5_2<-dat_person_$bclcs_level_5
#Change BP to UR since UR is the updated code for BP
dat_person_$bclcs_level_5_2[dat_person_$bclcs_level_5_2=="BP"] <- "UR"
#We will also make airport as urban
dat_person_$bclcs_level_5_2[dat_person_$bclcs_level_5_2=="AP"] <- "UR"

#Make various snow/glacier categories into one
dat_person_$bclcs_level_5_2[dat_person_$bclcs_level_5_2=="GL"] <- "SNOW"
dat_person_$bclcs_level_5_2[dat_person_$bclcs_level_5_2=="PN"] <- "SNOW"

#Make various rock categories (or road)
dat_person_$bclcs_level_5_2[dat_person_$bclcs_level_5_2=="MI"] <- "ROCK"
dat_person_$bclcs_level_5_2[dat_person_$bclcs_level_5_2=="MN"] <- "ROCK"
dat_person_$bclcs_level_5_2[dat_person_$bclcs_level_5_2=="MZ"] <- "ROCK"
dat_person_$bclcs_level_5_2[dat_person_$bclcs_level_5_2=="TA"] <- "ROCK"
dat_person_$bclcs_level_5_2[dat_person_$bclcs_level_5_2=="TS"] <- "ROCK"
dat_person_$bclcs_level_5_2[dat_person_$bclcs_level_5_2=="OT"] <- "ROCK"
dat_person_$bclcs_level_5_2[dat_person_$bclcs_level_5_2=="GP"] <- "ROCK"
dat_person_$bclcs_level_5_2[dat_person_$bclcs_level_5_2=="TZ"] <- "ROCK"

#Road related ones will be separate for person caused fires; we will add railroad to this category
dat_person_$bclcs_level_5_2[dat_person_$bclcs_level_5_2=="RZ"] <- "ROAD"
dat_person_$bclcs_level_5_2[dat_person_$bclcs_level_5_2=="CB"] <- "ROAD"
dat_person_$bclcs_level_5_2[dat_person_$bclcs_level_5_2=="LL"] <- "ROAD"
dat_person_$bclcs_level_5_2[dat_person_$bclcs_level_5_2=="RN"] <- "ROAD"

#Water adjacent ones
dat_person_$bclcs_level_5_2[dat_person_$bclcs_level_5_2=="BE"] <- "BEACH"
dat_person_$bclcs_level_5_2[dat_person_$bclcs_level_5_2=="RM"] <- "BEACH"
dat_person_$bclcs_level_5_2[dat_person_$bclcs_level_5_2=="BE"] <- "BEACH"

#Categories for soil, sediments and mud
dat_person_$bclcs_level_5_2[dat_person_$bclcs_level_5_2=="ES"] <- "SOIL"
dat_person_$bclcs_level_5_2[dat_person_$bclcs_level_5_2=="LS"] <- "SOIL"
dat_person_$bclcs_level_5_2[dat_person_$bclcs_level_5_2=="MU"] <- "SOIL"
dat_person_$bclcs_level_5_2[dat_person_$bclcs_level_5_2=="RS"] <- "SOIL"

#Combine CL and Op categories
dat_person_$bclcs_level_5_2[dat_person_$bclcs_level_5_2=="CL"] <- "OP"

#For comparison to determine which categories need changing
table(dat_person_$bclcs_level_5)
table(dat_person_$bclcs_level_5_2) #Rock and Snow categories are very small and this may be a problem. They may need to be combined later as "inflammable surface"

table(dat_person_$bclcs_level_5_2, dat_person_$ntrl_ds)
#Given how sparse rock, snow and soil is between these, let's make them all unvegetated
dat_person_$bclcs_level_5_2[dat_person_$bclcs_level_5_2=="SOIL"] <- "UNVEG"
dat_person_$bclcs_level_5_2[dat_person_$bclcs_level_5_2=="SNOW"] <- "UNVEG"
dat_person_$bclcs_level_5_2[dat_person_$bclcs_level_5_2=="ROCK"] <- "UNVEG"

#Check again
table(dat_person_$bclcs_level_5_2, dat_person_$ntrl_ds)

table(dat_person_$bclcs_level_5_2, dat_person_$vegtype)
#Still have 6 unspecified; for some reason, dense "DE" from level 5 corresponds to 542 open polygons from vegtype?? I see in definition that bryoids can be considered dense too. Use vegtype to refine. Unsure what the "OP" definition really means with bryoids... what is the remainder? Rock? Trees?

#GP is unspecified and there are only 4, so remove; and yet, when do so, we lost MANY more...
dat_person<-subset(dat_person_,dat_person_$bclcs_level_5!="RP")
dat_person<-subset(dat_person,dat_person$bclcs_level_5!="RT")

#Create disturbed category if disturbed in last 16 years; add burn to this category
dat_person$bclcs_level_5_2[which(dat_person$vegtype =="D")]<-"DIST" 
dat_person$bclcs_level_5_2[dat_person$bclcs_level_5_2=="BU"] <- "DIST"

#Check
table(dat_person$bclcs_level_5_2) #I do not know what the 22 unspecified are
```


```{r}
#Get the OP category in vegtype from DE in bclcs_type_5 into OP, and get the S from the former into SP in the latter.
#OP: Open (Cover of bryoids is less than or equal to 50% of the polygon)--> what is the remainder? Rock? Trees? Confusing.
# note: there are also many "open" designations in vegtype that come out as TB, TC and TM in the bclcs_type_5. This suggests our designations prior may not have been accurate?
table(dat_person$bclcs_level_4, dat_person$vegtype)
table(dat_person$bclcs_level_5_2, dat_person$vegtype)
#BY: a bryoid polygon --> open seems good
#EL: Exposed Land --> open seems good, but maybe disturbed possible too?
#HE: Herb --> open seems good
#HF: Herb-Forb --> open seems good
#HG: Herb-Graminoids --> open seems good
#RO: Rock/Rubble--> actually I think this should be its own category of rock
#SI: Snow/Ice--> also should be own category and not open


#Repeat vegtype classification with new information
dat_person$vegtype2<-"OP" #setting anything that is not one of the categories below to Open.
dat_person <- dat_person %>%
  mutate(vegtype2 = if_else(bclcs_level_4=="TC","TC", # Treed coniferous
                           if_else(bclcs_level_4=="TM", "TM", # Treed mixed
                                   if_else(bclcs_level_4== "TB","TB", #Treed broadleaf
                                           if_else(bclcs_level_4=="SL", "S", # shrub
                                                   if_else(bclcs_level_4=="ST", "S", 
                                                           if_else(bclcs_level_4=="RO","RO",
                                                                   if_else(bclcs_level_4=="SI", "SI",                                         vegtype2))))))))
dat_person$vegtype2[which(dat_person$proj_age_1 <16)]<-"D" #
table(dat_person$vegtype2) #D: Disturbed; OP: Open; RO: Rock; S: Shurb; SI: Snow/Ice; TB: Treed Broadleaf; TC: Treed Conifer; TM: Treed Mixed.


table(dat_person$bclcs_level_5_2, dat_person$vegtype2)
#Still have 6 unspecified; for some reason, dense "DE" from level 5 corresponds to 542 open polygons from vegtype?? I see in definition that bryoids can be considered dense too. Use vegtype to refine. Unsure what the "OP" definition really means with bryoids... what is the remainder? Rock? Trees?

# Urban plots were also put into open; create as own category
#Need bclcs_level_5_2 to be a factor prior to being able to succeed. Make other changes first in case this makes that not possible.
dat_person$bclcs_level_5_2 <-as.factor(dat_person$bclcs_level_5_2)
dat_person$vegtype2[which(dat_person$bclcs_level_5_2 =="UR")]<-"UR" #

#Inspect
table(dat_person$vegtype2) #SI category is too small. Combine with Rock.
dat_person$vegtype2[dat_person$vegtype2=="SI"] <- "RO"

#We still have discrepancies between open and dense in vegtype (derived from bclcs_level_4) and bclcs_level_5. Play them out for now.

head(dat_person)

```

##Save data files

```{r}

write.csv(dat_lightning_, file="D:\\Fire\\fire_data\\raw_data\\ClimateBC_Data\\data_lightning_Sept.csv")

write.csv(dat_person, file="D:\\Fire\\fire_data\\raw_data\\ClimateBC_Data\\data_person_Sept.csv")

```


## Examining correlation between stand level variables
```{r}
# Examining the relationship between some stand level variables. Volume and height are fairly correlated (0.67) but age and volume are not (0.28) and neither are age and height (0.44). Because volume and height are very close to 0.7 in correlation I will leave out this combination of variables from my treed models. 
table(dat_lightning_$bclcs_level_2) ##What is L? It is Land, exclude and do not use.
dat_lightning_$fire_pres<-as.numeric(dat_lightning_$fire)

dat_lightning_t<- dat_lightning_ %>% dplyr::filter(bclcs_level_2=="T")
dat_lightning_nt<- dat_lightning_ %>% dplyr::filter(bclcs_level_2=="N")
dat_lightning_l<- dat_lightning_ %>% dplyr::filter(bclcs_level_2=="L")

table(dat_lightning_$vegtype)
table(dat_lightning_t$vegtype) #either disturbed, open, treed broadleaf, treed conifer, or treed mixed broadleaf and conifer
table(dat_lightning_nt$vegtype) #either disturbed, open or shrub

ggscatter(dat_lightning_t, x = "live_stand_volume_125", y = "proj_age_1", 
          add = "reg.line", conf.int = TRUE, 
          cor.coef = TRUE, cor.method = "kendall",
          xlab = "live stand volume", ylab = "Stand age")

ggscatter(dat_lightning_t, x = "live_stand_volume_125", y = "proj_height_1", 
          add = "reg.line", conf.int = TRUE, 
          cor.coef = TRUE, cor.method = "kendall",
          xlab = "live stand volume", ylab = "Stand height")

ggscatter(dat_lightning_t, x = "proj_age_1", y = "proj_height_1", 
          add = "reg.line", conf.int = TRUE, 
          cor.coef = TRUE, cor.method = "kendall",
          xlab = "proj_age_1", ylab = "Stand height")

ggscatter(dat_lightning_t, x = "elevation", y = "roads_km", 
          add = "reg.line", conf.int = TRUE, 
          cor.coef = TRUE, cor.method = "kendall",
          xlab = "Elevation", ylab = "Road Density") #minor negative relationship

ggscatter(dat_lightning_nt, x = "elevation", y = "roads_km", 
          add = "reg.line", conf.int = TRUE, 
          cor.coef = TRUE, cor.method = "kendall",
          xlab = "Elevation", ylab = "Road Density") #minor negative relationship

##Note that some no tree areas also have tree attributes. This is likely because the majority of the polygon has no trees, but part of the polygon might have trees which are given attributes.
hist(dat_lightning_nt$proj_height_1)
hist(dat_lightning_nt$proj_age_1)
hist(dat_lightning_nt$live_stand_volume_125) #Pretty much all NAs. Can likely assume 0.
dat_lightning_nt$proj_height_1 #Also many NAs. 
dat_lightning_nt$proj_age_1 # Also many NAs. 

hist(dat_lightning_l$proj_height_1)
hist(dat_lightning_l$proj_age_1)
hist(dat_lightning_l$live_stand_volume_125)
## This is ok. Still exclude from models, because majority of polygon will not be treed

head(dat_lightning_t)

```

#Repeat for person caused fires
## Examining correlation between stand level variables
```{r}
# Examining the relationship between some stand level variables. Volume and height are fairly correlated (0.67) but age and volume are not (0.28) and neither are age and height (0.44). Because volume and height are very close to 0.7 in correlation I will leave out this combination of variables from my treed models. 
dat_person_<-dat_person

table(dat_person_$bclcs_level_2) ##What is L? It is Land, exclude and do not use.
dat_person_$fire_pres<-as.numeric(dat_person_$fire)

dat_person_t<- dat_person_ %>% dplyr::filter(bclcs_level_2=="T")
dat_person_nt<- dat_person_ %>% dplyr::filter(bclcs_level_2=="N")
dat_person_l<- dat_person_ %>% dplyr::filter(bclcs_level_2=="L")

table(dat_person_$vegtype)
table(dat_person_t$vegtype) #either disturbed, open, treed broadleaf, treed conifer, or treed mixed broadleaf and conifer
table(dat_person_nt$vegtype) #either disturbed, open or shrub
table(dat_person_$vegtype2)

ggscatter(dat_person_t, x = "live_stand_volume_125", y = "proj_age_1", 
          add = "reg.line", conf.int = TRUE, 
          cor.coef = TRUE, cor.method = "kendall",
          xlab = "live stand volume", ylab = "Stand age")

ggscatter(dat_person_t, x = "live_stand_volume_125", y = "proj_height_1", 
          add = "reg.line", conf.int = TRUE, 
          cor.coef = TRUE, cor.method = "kendall",
          xlab = "live stand volume", ylab = "Stand height")

ggscatter(dat_person_t, x = "proj_age_1", y = "proj_height_1", 
          add = "reg.line", conf.int = TRUE, 
          cor.coef = TRUE, cor.method = "kendall",
          xlab = "proj_age_1", ylab = "Stand height")

ggscatter(dat_person_t, x = "elevation", y = "roads_km", 
          add = "reg.line", conf.int = TRUE, 
          cor.coef = TRUE, cor.method = "kendall",
          xlab = "Elevation", ylab = "Road Density") #No relationship

ggscatter(dat_person_nt, x = "elevation", y = "roads_km", 
          add = "reg.line", conf.int = TRUE, 
          cor.coef = TRUE, cor.method = "kendall",
          xlab = "Elevation", ylab = "Road Density") #No relationship

##Note that some no tree areas also have tree attributes. This is likely because the majority of the polygon has no trees, but part of the polygon might have trees which are given attributes.
hist(dat_person_nt$proj_height_1)
hist(dat_person_nt$proj_age_1)
hist(dat_person_nt$live_stand_volume_125) #Pretty much all NAs. Can likely assume 0.
dat_person_nt$proj_height_1 #Also many NAs. 
dat_person_nt$proj_age_1 # Also many NAs. 

hist(dat_person_l$proj_height_1)
hist(dat_person_l$proj_age_1)
hist(dat_person_l$live_stand_volume_125)
## This is ok. Still exclude from models, because majority of polygon will not be treed

```

Save the prepped data

```{r}
write.csv(dat_lightning_t, file="D:\\Fire\\fire_data\\raw_data\\ClimateBC_Data\\data_lightning_trees_NDT.csv")

write.csv(dat_lightning_nt, file="D:\\Fire\\fire_data\\raw_data\\ClimateBC_Data\\data_lightning_notrees_NDT.csv")

write.csv(dat_person_t, file="D:\\Fire\\fire_data\\raw_data\\ClimateBC_Data\\data_person_trees_NDT.csv")

write.csv(dat_person_nt, file="D:\\Fire\\fire_data\\raw_data\\ClimateBC_Data\\data_person_notrees_NDT.csv")

```

#Load data back in if starting from here
Note: depending where your geometry column was located when saved as a csv (and turned into a dataframe), you may need to manually correct column headings on the csv file before loading back in. This has been performed for the below files.

```{r}
dat_lightning_t<-read.csv(file="D:\\Fire\\fire_data\\raw_data\\ClimateBC_Data\\data_lightning_trees_NDT.csv")
head(dat_lightning_t)

dat_lightning_nt<-read.csv(file="D:\\Fire\\fire_data\\raw_data\\ClimateBC_Data\\data_lightning_notrees_NDT.csv")
head(dat_lightning_nt)

dat_person_t<-read.csv(file="D:\\Fire\\fire_data\\raw_data\\ClimateBC_Data\\data_person_trees_NDT.csv")
head(dat_person_t)

dat_person_nt<-read.csv(file="D:\\Fire\\fire_data\\raw_data\\ClimateBC_Data\\data_person_notrees_NDT.csv")
head(dat_person_nt)
```


#################### ANALYSES #########################

Now, we will make a loop that does something very similar to our last loop, but with the selected climate variable plus other variables of interest. For lightning caused fires with trees, the variables of interest include:

1. Climate variable(s)
2. Projected Height (proj_height_1)
3. projected age (proj_age_1)  
4. live_stand_volume_125
5. vegtype2 (with additional categories)
6. slope
7. aspect (cos)
8. elevation
9. Various distance to infrastructure variables (dist_mun, dist_dam, dist_nat, dist_pow, dist_mine, dist_any) - no interactions
10. Some measure of death or mountain pine beetle damage -- TBD

Variables to be added after initial model selection for next round model selection:
1. bclcs_level_5_2 (land use) (to be added to final investigated model)

Interactions of interest: two-way interactions between climate (1) and vegtype (6); two-way interactions between topography measures (7-9); interactions between VRI variables.

This will be done separately for trees and non-treed areas. 

Consider modelling by landuse type spread_data_lightning$bclcs_level_5.

First, let's do this for treed areas (with the lightning-caused fires dataset).

##We will do each loop separately for each NDT zone given the large number of possible models for each zone.

First we will create the variable lists that contain all of our variables of interest.

```{r}
##Create variable lists to be used in the model loop.
variables_all<-c(climate1 = "climate1", climate2 = "climate2", proj_height_1 = "proj_height_1", proj_age_1 = "proj_age_1", live_stand_volume_125 = "live_stand_volume_125", slope = "slope", aspect = "aspect", elevation ="elevation", vegtype2 = "vegtype2", dist_mun = "dist_mun", dist_dam = "dist_dam", dist_nat = "dist_nat", dist_pow = "dist_pow", dist_mine = "dist_mine", dist_any = "dist_any") #heatload="heatload",

variables_all_c1<-c(climate1 = "climate1", proj_height_1 = "proj_height_1", proj_age_1 = "proj_age_1", live_stand_volume_125 = "live_stand_volume_125", slope = "slope", aspect = "aspect", elevation ="elevation", vegtype2 = "vegtype2", dist_mun = "dist_mun", dist_dam = "dist_dam", dist_nat = "dist_nat", dist_pow = "dist_pow", dist_mine = "dist_mine", dist_any = "dist_any") #heatload="heatload",

vars.clim<-c("climate1")
vars.clim.vegtype<-c("climate1", "vegtype2")
vars.clim.vegtype2<-c("climate1", "climate2","vegtype2")
vars.clim.vegtype2b<-c("climate1", "climate2")

vars.oth<-c("proj_height_1", "proj_age_1", "live_stand_volume_125") 
vars.topo<-c("slope", "aspect", "elevation")
vars.heatload<-c("heatload")
vars.infra<-c("dist_mun", "dist_dam", "dist_nat", "dist_pow", "dist_mine", "dist_any")


##Create interaction for climate and vegtype
inputs.me <- c(vars.clim.vegtype)
inputs.me2 <- c(vars.clim.vegtype2)
inputs.me2b <- c(vars.clim.vegtype2b)
```

Now, we will generate two-way interactions for each of these lists. 

```{r}

#####1a. For those with one climate variable
#get the names of all possible two-way interactions for climate variable(s) and vegtype.
twoway.ints <- NULL
for (i in 1:(length(inputs.me)-1)) {
  for (j in (i+1):length(inputs.me)) {
     twoway.ints <- cbind(twoway.ints, paste(inputs.me[i], inputs.me[j], sep=":"))
  }
}
twoway.ints
length(twoway.ints)

#
#Create function to determine Powerset for any vector of variable names
## or use rje package
#powerSet <- function(x) {
#   z.list <- NULL
#   for(i in 1:length(x)) {
#      z.list <- append(z.list, combn(x, m=i, simplify=F))
#   }    
#   return(z.list)
#}


#Get variables on own
#complete list of models using non-climate vars
mods.me.tmp <- powerSet(vars.clim.vegtype) 
#add climate vars to all of the above
mods.me.climate <- list()
for (i in 1: length(mods.me.tmp)) {
   mods.me.climate[[i]] <- c(mods.me.tmp[[i]])
}

mods.me.climate


#####1b. For those with two climate variables
#get the names of all possible two-way interactions for climate variable(s) and vegtype.
twoway.ints2 <- NULL
for (i in 1:(length(inputs.me2)-1)) {
  for (j in (i+1):length(inputs.me2)) {
     twoway.ints2 <- cbind(twoway.ints2, paste(inputs.me2[i], inputs.me2[j], sep=":"))
  }
}
twoway.ints2
length(twoway.ints2)

#Get variables on own
#complete list of models using non-climate vars
mods.me.tmp <- powerSet(vars.clim.vegtype2) 
#add climate vars to all of the above
mods.me.climate2 <- list()
for (i in 1: length(mods.me.tmp)) {
   mods.me.climate2[[i]] <- c(mods.me.tmp[[i]])
}

mods.me.climate2

#complete list of two-way interactions
mods.twoway2 <- powerSet(twoway.ints2)
length(mods.twoway2) #7
mods.twoway2

#Finding models in mods.me that accommodate/allow interaction terms in each mods.twoway to be added
mods.inter2 <- list()
counter <- 0
for (i in 1: length(mods.twoway2)) {
   s1 <- unique(unlist( strsplit(mods.twoway2[[i]], split=':', fixed=TRUE) ) )
   for (j in 1: length(mods.me.climate2)) {
      if (all(s1 %in% mods.me.climate2[[j]])==TRUE) {
        counter <- counter + 1
        both <-  c(mods.me.climate2[[j]], mods.twoway2[[i]])
        mods.inter2[[counter]] <- both
      }
   }
}

length(mods.inter2)
mods.inter2


####1c. Two variables, no variation in vegtype
#get the names of all possible two-way interactions for climate variable(s) and vegtype.
twoway.ints2b <- NULL
for (i in 1:(length(inputs.me2b)-1)) {
  for (j in (i+1):length(inputs.me2b)) {
     twoway.ints2b <- cbind(twoway.ints2b, paste(inputs.me2b[i], inputs.me2b[j], sep=":"))
  }
}
twoway.ints2b
length(twoway.ints2b)

#Get variables on own
#complete list of models using non-climate vars
mods.me.tmp <- powerSet(vars.clim.vegtype2b) 
#add climate vars to all of the above
mods.me.climate2b <- list()
for (i in 1: length(mods.me.tmp)) {
   mods.me.climate2b[[i]] <- c(mods.me.tmp[[i]])
}

mods.me.climate2b

#complete list of two-way interactions
mods.twoway2b <- powerSet(twoway.ints2b)
length(mods.twoway2b) #7
mods.twoway2b

#Finding models in mods.me that accommodate/allow interaction terms in each mods.twoway to be added
mods.inter2b <- list()
counter <- 0
for (i in 1: length(mods.twoway2b)) {
   s1 <- unique(unlist( strsplit(mods.twoway2b[[i]], split=':', fixed=TRUE) ) )
   for (j in 1: length(mods.me.climate2b)) {
      if (all(s1 %in% mods.me.climate2b[[j]])==TRUE) {
        counter <- counter + 1
        both <-  c(mods.me.climate2b[[j]], mods.twoway2b[[i]])
        mods.inter2b[[counter]] <- both
      }
   }
}

length(mods.inter2b)
mods.inter2b




#########2. Now for topography data, get all possible two-way interactions

#get the names of all possible two-way interactions
twoway.intsT <- NULL
for (i in 1:(length(vars.topo)-1)) {
  for (j in (i+1):length(vars.topo)) {
     twoway.intsT <- cbind(twoway.intsT, paste(vars.topo[i], vars.topo[j], sep=":"))
  }
}
twoway.intsT
length(twoway.intsT)

#complete list of models using non-climate vars (topo)
mods.me.tmp <- powerSet(vars.topo) 
#add climate vars to all of the above
mods.meT <- list()
for (i in 1: length(mods.me.tmp)) {
   mods.meT[[i]] <- c(mods.me.tmp[[i]])
}

mods.meT

#complete list of two-way interactions
mods.twowayT <- powerSet(twoway.intsT)
length(mods.twowayT) #7
mods.twowayT

#Finding models in mods.me that accommodate/allow interaction terms in each mods.twoway to be added

mods.interT <- list()
counter <- 0
for (i in 1: length(mods.twowayT)) {
   s1 <- unique(unlist( strsplit(mods.twowayT[[i]], split=':', fixed=TRUE) ) )
   for (j in 1: length(mods.meT)) {
      if (all(s1 %in% mods.meT[[j]])==TRUE) {
        counter <- counter + 1
        both <-  c(mods.meT[[j]], mods.twowayT[[i]])
        mods.interT[[counter]] <- both
      }
   }
}

length(mods.interT)
mods.interT
mods.interTb<-c(mods.interT,vars.heatload)
mods.interTb

####3.For other VRI data, get without interactions

#complete list of models using VRI - no interactions
mods.me.tmp <- powerSet(vars.oth) 
#add climate vars to all of the above
mods.me.oth <- list()
for (i in 1: length(mods.me.tmp)) {
   mods.me.oth[[i]] <- c(mods.me.tmp[[i]])
}

mods.me.oth


#########4. Now for distance to infrastructure data, get all possible two-way interactions

#get the names of all possible two-way interactions
twoway.intsI <- NULL
for (i in 1:(length(vars.infra)-1)) {
  for (j in (i+1):length(vars.infra)) {
     twoway.intsI <- cbind(twoway.intsI, paste(vars.infra[i], vars.infra[j], sep=":"))
  }
}
twoway.intsI
length(twoway.intsI)

#complete list of models using non-climate vars (infra)
mods.me.tmp <- powerSet(vars.infra) 
#add climate vars to all of the above
mods.meI <- list()
for (i in 1: length(mods.me.tmp)) {
   mods.meI[[i]] <- c(mods.me.tmp[[i]])
}

mods.meI

#complete list of two-way interactions
mods.twowayI <- powerSet(twoway.intsI)
length(mods.twowayI) #32768
mods.twowayI

#Finding models in mods.me that accommodate/allow interaction terms in each mods.twoway to be added

mods.interI <- list()
counter <- 0
for (i in 1: length(mods.twowayI)) {
   s1 <- unique(unlist( strsplit(mods.twowayI[[i]], split=':', fixed=TRUE) ) )
   for (j in 1: length(mods.meI)) {
      if (all(s1 %in% mods.meI[[j]])==TRUE) {
        counter <- counter + 1
        both <-  c(mods.meI[[j]], mods.twowayI[[i]])
        mods.interI[[counter]] <- both
      }
   }
}

length(mods.interI)
mods.interI


#the list of all possible model RHSs. 
#all.poss.mods <- c(1, vars.clim, twoway.ints, mods.me.oth, mods.me2, mods.inter2)
#all.poss.mods

all.poss.mods.clim.vegtype<-c(1, mods.me.climate, twoway.ints)
all.poss.mods.clim.vegtype 
all.poss.mods.clim.vegtype<-all.poss.mods.clim.vegtype [-2] #Use this line only if there is an odd character(0) added to list
all.poss.mods.clim.vegtype2<-c(1, mods.inter2)
all.poss.mods.clim.vegtype2
all.poss.mods.clim.vegtype2<-all.poss.mods.clim.vegtype2[-2]
#all.poss.mods.clim.vegtype2<-all.poss.mods.clim.vegtype2[-9]
all.poss.mods.clim.vegtype2b<-c(1, mods.inter2b)
#all.poss.mods.clim.vegtype2b<-c(1, mods.me.climate2b, mods.inter2b)
all.poss.mods.clim.vegtype2b
all.poss.mods.clim.vegtype2b<-all.poss.mods.clim.vegtype2b[-2]
#all.poss.mods.clim.vegtype2b<-all.poss.mods.clim.vegtype2b[-5]

all.poss.mods.VRI<-c(1, mods.me.oth)
all.poss.mods.VRI
all.poss.mods.VRI<-all.poss.mods.VRI[-2]
#all.poss.mods.topo<-c(1, mods.meT, mods.interT)
all.poss.mods.topo<-c(1, mods.interT)
all.poss.mods.topo
#all.poss.mods.topo<-all.poss.mods.topo[-10]
all.poss.mods.topo<-all.poss.mods.topo[-2]
all.poss.mods.infra<-c(1, mods.meI) #I don't think we want interactions here actually...
#all.poss.mods.infra<-c(1, mods.meI, mods.interI)
all.poss.mods.infra<-all.poss.mods.infra[-2] #See if have future errors to see if need to remove

#If need to determine which ones are character(0), try this:
biglist <- list(list("A","B","C"), "foo", "", character(0), integer(0))
lapply(biglist, function(x) {length(x) == 0L} ) 


##Check and rid of any duplicated models
duplicated(all.poss.mods.clim.vegtype) #None duplicated
duplicated(all.poss.mods.clim.vegtype2)
duplicated(all.poss.mods.clim.vegtype2b)
duplicated(all.poss.mods.VRI)
duplicated(all.poss.mods.topo)
duplicated(all.poss.mods.infra)


```

Let's work with one NDT at a time. 

Because of the large number of models with all variables included, we will test the climate and vegtype first, then the VRI variables, then the topography variables. Then we will test the top models together, with determining best AIC model from there. Or perhaps we will just combine the top models for each together, and eliminate models if the intercept was the best predictor.


############### Part 1 of 4 Model Series: Lightning Caused Fires, Trees ##########

Select first NDT: NDT4 

```{r}
zones1<-c("NDT4") #Do one zone at a time

prop<-0.75

#Create empty table
table.glm.climate.simple <- data.frame (matrix (ncol = 5, nrow = 0))
colnames (table.glm.climate.simple) <- c ("model", "edf", "aic", "auc.valid", "NDT")

########### 1. Climate and vegtype ############
for (g in 1:100){

for (h in 1:length(zones1)) {
  dat2<- dat_lightning_t %>% dplyr::filter(ntrl_ds ==zones1[h])

#for (i in 1: length(all.poss.mods.clim.vegtype2)){
#  print(paste((all.poss.mods.clim.vegtype2[i]), (zones1[h]), sep=" "))
  
for (i in 1: length(zones1)){
  print(paste((all.poss.mods.clim.vegtype2[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, variables_all[i])
  model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, !!variables_all)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="fire_pres") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.aic, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.clim.vegtype2, big.mod, df.train=dat1, df.test=Valid)

#terms in each model
x1.1 <- unlist(sapply(mods.fit, '[', 1))
x1.1
#Aic for models
x3.1 <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3.1
#auc from validation data
x4.1 <- unlist(sapply(mods.fit, '[', 4))
x4.1
#combining all as df
tab.sum.climate <- cbind.data.frame(model=x1.1, edf=x3.1[,1], aic=x3.1[,2], auc.valid=x4.1)
tab.sum.climate$NDT<-c("NDT4")
tab.sum.climate 

table.glm.climate.simple<-rbind(table.glm.climate.simple, tab.sum.climate)

}
}
}


```

Now that we have run the model 100 times, we want the average AIC and AUC for each variable combination.

```{r}
head(table.glm.climate.simple)
table(table.glm.climate.simple$model) # 100 per model

AIC_lightning_NDT4_treed_climate<-table.glm.climate.simple

AIC_lightning_NDT4_treed_summary_climate<- AIC_lightning_NDT4_treed_climate %>%
  group_by(model) %>%
  summarise(meanAIC=mean(aic),
            meanAUC=mean(auc.valid),
            sdAUC=sd(auc.valid),
            )

AIC_lightning_NDT4_treed_summary_climate2<- AIC_lightning_NDT4_treed_summary_climate %>%
  mutate(deltaAIC=meanAIC-min(meanAIC))

head(AIC_lightning_NDT4_treed_summary_climate2)
```

#Now repeat for VRI data

```{r}
########### 2. VRI ############
#Create empty table
table.glm.VRI.simple <- data.frame (matrix (ncol = 5, nrow = 0))
colnames (table.glm.VRI.simple) <- c ("model", "edf", "aic", "auc.valid", "NDT")

####
for (g in 1:100){

for (h in 1:length(zones1)) {
  dat2<- dat_lightning_t %>% dplyr::filter(ntrl_ds ==zones1[h])

#for (i in 1: length(all.poss.mods.VRI)){
#  print(paste((all.poss.mods.VRI[i]), (zones1[h]), sep=" "))
  
for (i in 1: length(zones1)){
  print(paste((all.poss.mods.VRI[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, variables_all[i])
  model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, !!variables_all)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="fire_pres") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.aic, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.VRI, big.mod, df.train=dat1, df.test=Valid)

#terms in each model
x1.1 <- unlist(sapply(mods.fit, '[', 1))
x1.1
#Aic for models
x3.1 <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3.1
#auc from validation data
x4.1 <- unlist(sapply(mods.fit, '[', 4))
x4.1
#combining all as df
tab.sum.VRI <- cbind.data.frame(model=x1.1, edf=x3.1[,1], aic=x3.1[,2], auc.valid=x4.1)
tab.sum.VRI$NDT<-c("NDT4")
tab.sum.VRI 

table.glm.VRI.simple<-rbind(table.glm.VRI.simple, tab.sum.VRI)

}
}
}
```

Now that we have run the model 100 times, we want the average AIC and AUC for each variable combination.

```{r}
head(table.glm.VRI.simple)
table(table.glm.VRI.simple$model) # 100 per model

AIC_lightning_NDT4_treed_VRI<-table.glm.VRI.simple

AIC_lightning_NDT4_treed_summary_VRI<- AIC_lightning_NDT4_treed_VRI %>%
  group_by(model) %>%
  summarise(meanAIC=mean(aic),
            meanAUC=mean(auc.valid),
            sdAUC=sd(auc.valid),
            )

AIC_lightning_NDT4_treed_summary_VRI2<- AIC_lightning_NDT4_treed_summary_VRI %>%
  mutate(deltaAIC=meanAIC-min(meanAIC))

head(AIC_lightning_NDT4_treed_summary_VRI2)
```


#Now repeat for topography

```{r}
########### 3. topo ############
#Create empty table
table.glm.topo.simple <- data.frame (matrix (ncol = 5, nrow = 0))
colnames (table.glm.topo.simple) <- c ("model", "edf", "aic", "auc.valid", "NDT")

#
for (g in 1:100){

for (h in 1:length(zones1)) {
  dat2<- dat_lightning_t %>% dplyr::filter(ntrl_ds ==zones1[h])

#for (i in 1: length(all.poss.mods.topo)){
#  print(paste((all.poss.mods.topo[i]), (zones1[h]), sep=" "))
  
for (i in 1: length(zones1)){
  print(paste((all.poss.mods.topo[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, variables_all[i])
  model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, !!variables_all)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="fire_pres") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.aic, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.topo, big.mod, df.train=dat1, df.test=Valid)

#terms in each model
x1.1 <- unlist(sapply(mods.fit, '[', 1))
x1.1
#Aic for models
x3.1 <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3.1
#auc from validation data
x4.1 <- unlist(sapply(mods.fit, '[', 4))
x4.1
#combining all as df
tab.sum.topo <- cbind.data.frame(model=x1.1, edf=x3.1[,1], aic=x3.1[,2], auc.valid=x4.1)
tab.sum.topo$NDT<-c("NDT4")
tab.sum.topo 

table.glm.topo.simple<-rbind(table.glm.topo.simple, tab.sum.topo)

}
}
}
```

Now that we have run the model 100 times, we want the average AIC and AUC for each variable combination.

```{r}
head(table.glm.topo.simple)
table(table.glm.topo.simple$model) # 100 per model

AIC_lightning_NDT4_treed_topo<-table.glm.topo.simple

AIC_lightning_NDT4_treed_summary_topo<- AIC_lightning_NDT4_treed_topo %>%
  group_by(model) %>%
  summarise(meanAIC=mean(aic),
            meanAUC=mean(auc.valid),
            sdAUC=sd(auc.valid),
            )

AIC_lightning_NDT4_treed_summary_topo2<- AIC_lightning_NDT4_treed_summary_topo %>%
  mutate(deltaAIC=meanAIC-min(meanAIC))

head(AIC_lightning_NDT4_treed_summary_topo2)
```


#Now repeat for infrastructure

```{r}
########### 4. Distance to Infrastructure ############
#Create empty table
table.glm.infra.simple <- data.frame (matrix (ncol = 5, nrow = 0))
colnames (table.glm.infra.simple) <- c ("model", "edf", "aic", "auc.valid", "NDT")

#
for (g in 1:100){

for (h in 1:length(zones1)) {
  dat2<- dat_lightning_t %>% dplyr::filter(ntrl_ds ==zones1[h])

#for (i in 1: length(all.poss.mods.infra)){
#  print(paste((all.poss.mods.infra[i]), (zones1[h]), sep=" "))
  
for (i in 1: length(zones1)){
  print(paste((all.poss.mods.infra[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, variables_all[i])
  model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, !!variables_all)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="fire_pres") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.aic, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.infra, big.mod, df.train=dat1, df.test=Valid)

#terms in each model
x1.1 <- unlist(sapply(mods.fit, '[', 1))
x1.1
#Aic for models
x3.1 <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3.1
#auc from validation data
x4.1 <- unlist(sapply(mods.fit, '[', 4))
x4.1
#combining all as df
tab.sum.infra <- cbind.data.frame(model=x1.1, edf=x3.1[,1], aic=x3.1[,2], auc.valid=x4.1)
tab.sum.infra$NDT<-c("NDT4")
tab.sum.infra 

table.glm.infra.simple<-rbind(table.glm.infra.simple, tab.sum.infra)

}
}
}
```

Now that we have run the model 100 times, we want the average AIC and AUC for each variable combination.

```{r}
head(table.glm.infra.simple)
table(table.glm.infra.simple$model) # 100 per model

AIC_lightning_NDT4_treed_infra<-table.glm.infra.simple

AIC_lightning_NDT4_treed_summary_infra<- AIC_lightning_NDT4_treed_infra %>%
  group_by(model) %>%
  summarise(meanAIC=mean(aic),
            meanAUC=mean(auc.valid),
            sdAUC=sd(auc.valid),
            )

AIC_lightning_NDT4_treed_summary_infra2<- AIC_lightning_NDT4_treed_summary_infra %>%
  mutate(deltaAIC=meanAIC-min(meanAIC))

head(AIC_lightning_NDT4_treed_summary_infra2)
```

#Now combine the datatables and save to computer

```{r}
NDT4_l_models_treed<-rbind(AIC_lightning_NDT4_treed_summary_climate2, AIC_lightning_NDT4_treed_summary_VRI2, AIC_lightning_NDT4_treed_summary_topo2, AIC_lightning_NDT4_treed_summary_infra2)
NDT4_l_models_treed
NDT4_l_models_treed$NDT<-"NDT4"

write.csv(NDT4_l_models_treed, file="D:\\Fire\\fire_data\\raw_data\\NDT4_lightning_models_treed.csv")
```


Now choose the top variables and create final model. The below code will need to be updated manually, depending on what the results of the above analyses are. From the top models, we will re-create two-way interactions for the variables selected from each model, plus the other variables listed as needed to be included. We will assess each set to ensure only interactions that make sense are investigated ultimately, given that sample sizes will be an issues. 

######## UPDATE BELOW #########

Top Models:
1. climate1 + climate2 + vegtype2 + climate1:climate2
2. proj_height_1 + live_stand_volume_125
3. slope + aspect + elevation + slope:aspect
4. dist_mun + dist_dam + dist_nat + dist_pow + dist_any. 

Additional Variabes:
1. bclcs_level_5_2 (land use) (to be added to final investigated model)

We want to include interactions between variables from within each list. This will make for many models.

```{r}
##Create variable lists to be used in the model loop.
variables_all_NDT4<-c(climate1 = "climate1", climate2 = "climate2", vegtype2 = "vegtype2", proj_height_1 = "proj_height_1", live_stand_volume_125 = "live_stand_volume_125", slope = "slope", aspect = "aspect", elevation ="elevation", dist_mun = "dist_mun", dist_dam = "dist_dam", dist_nat = "dist_nat", dist_pow = "dist_pow", dist_any = "dist_any", bclcs_level_5_2 = "bclcs_level_5_2")

variables_all_NDT4<-c(climate1 = "climate1", climate2 = "climate2", vegtype2 = "vegtype2", proj_height_1 = "proj_height_1", live_stand_volume_125 = "live_stand_volume_125", slope = "slope", aspect = "aspect", elevation ="elevation", dist_any = "dist_any", bclcs_level_5_2 = "bclcs_level_5_2")

variables_all_NDT4<-c("climate1", "climate2", "vegtype2", "proj_height_1", "live_stand_volume_125","slope", "aspect", "elevation", "dist_any", "bclcs_level_5_2")

#Too many permutations to be able to include two-way interactions and all possibole models, so need to divide into what we think may have interactions and which not.
variables_clim_VRI_NDT4<-c(climate1 = "climate1", climate2 = "climate2", vegtype2 = "vegtype2", proj_height_1 = "proj_height_1", live_stand_volume_125 = "live_stand_volume_125")

#treat slope, aspect and elevation as their own thing.And we have already done this analysis with them.
#slope = "slope", aspect = "aspect", elevation ="elevation")

variables_all_infra_landuse_NDT4<-c(dist_mun = "dist_mun", dist_dam = "dist_dam", dist_nat = "dist_nat", dist_pow = "dist_pow", dist_any = "dist_any", bclcs_level_5_2 = "bclcs_level_5_2") #I don't think it makes sense to have interactions between the distance elements, but maybe with land use and each distance element?

##
inputs.me.NDT4 <- c(variables_all_NDT4)
#inputs.me.clim_VRI_DEM_NDT4 <- c(variables_clim_VRI_DEM_NDT4)
inputs.me.clim_VRI_NDT4 <- c(variables_clim_VRI_NDT4)
inputs.me.infra_landuse_NDT4 <- c(variables_all_infra_landuse_NDT4)

```

Before the next step, you may need to clear much of the workspace. Many elements below are from previous files, or from code that follows that I ran before. So you will likely need to modify to suit your needs.

```{r}
#First remove the AIC tables from this section. Note, you may not have created them all yet, and may need to remove some sections.
rm(AIC_lightning_NDT1_treed, AIC_lightning_NDT1_treed_climate, AIC_lightning_NDT1_treed_infra, AIC_lightning_NDT1_treed_summary, AIC_lightning_NDT1_treed_summary_climate, AIC_lightning_NDT1_treed_summary_climate2, AIC_lightning_NDT1_treed_summary_infra, AIC_lightning_NDT1_treed_summary_infra2, AIC_lightning_NDT1_treed_summary_topo, AIC_lightning_NDT1_treed_summary_topo2, AIC_lightning_NDT1_treed_summary_VRI, AIC_lightning_NDT1_treed_summary_VRI2, AIC_lightning_NDT1_treed_topo, AIC_lightning_NDT1_treed_VRI, AIC_lightning_NDT1_treed_infra, AIC_lightning_NDT2_treed_climate, 
   
   AIC_lightning_NDT2_treed, AIC_lightning_NDT2_treed_climate, AIC_lightning_NDT2_treed_infra, AIC_lightning_NDT2_treed_summary, AIC_lightning_NDT2_treed_summary_climate, AIC_lightning_NDT2_treed_summary_climate2, AIC_lightning_NDT2_treed_summary_infra, AIC_lightning_NDT2_treed_summary_infra2, AIC_lightning_NDT2_treed_summary_topo, AIC_lightning_NDT2_treed_summary_topo2, AIC_lightning_NDT2_treed_summary_VRI, AIC_lightning_NDT2_treed_summary_VRI2, AIC_lightning_NDT2_treed_topo, AIC_lightning_NDT2_treed_VRI, AIC_lightning_NDT2_treed_infra, AIC_lightning_NDT2_treed_climate,
   
   AIC_lightning_NDT3_treed, AIC_lightning_NDT3_treed_climate, AIC_lightning_NDT3_treed_infra, AIC_lightning_NDT3_treed_summary, AIC_lightning_NDT3_treed_summary_climate, AIC_lightning_NDT3_treed_summary_climate2, AIC_lightning_NDT3_treed_summary_infra, AIC_lightning_NDT3_treed_summary_infra2, AIC_lightning_NDT3_treed_summary_topo, AIC_lightning_NDT3_treed_summary_topo2, AIC_lightning_NDT3_treed_summary_VRI, AIC_lightning_NDT3_treed_summary_VRI2, AIC_lightning_NDT3_treed_topo, AIC_lightning_NDT3_treed_VRI, AIC_lightning_NDT3_treed_infra, AIC_lightning_NDT2_treed_climate,
   
   AIC_lightning_NDT4_treed, AIC_lightning_NDT4_treed_climate, AIC_lightning_NDT4_treed_infra, AIC_lightning_NDT4_treed_summary, AIC_lightning_NDT4_treed_summary_climate, AIC_lightning_NDT4_treed_summary_climate2, AIC_lightning_NDT4_treed_summary_infra, AIC_lightning_NDT4_treed_summary_infra2, AIC_lightning_NDT4_treed_summary_topo, AIC_lightning_NDT4_treed_summary_topo2, AIC_lightning_NDT4_treed_summary_VRI, AIC_lightning_NDT4_treed_summary_VRI2, AIC_lightning_NDT4_treed_topo, AIC_lightning_NDT4_treed_VRI, AIC_lightning_NDT4_treed_infra, AIC_lightning_NDT4_treed_climate,
   
   AIC_lightning_NDT5_treed, AIC_lightning_NDT5_treed_climate, AIC_lightning_NDT5_treed_infra, AIC_lightning_NDT5_treed_summary, AIC_lightning_NDT5_treed_summary_climate, AIC_lightning_NDT5_treed_summary_climate2, AIC_lightning_NDT5_treed_summary_infra, AIC_lightning_NDT5_treed_summary_infra2, AIC_lightning_NDT5_treed_summary_topo, AIC_lightning_NDT5_treed_summary_topo2, AIC_lightning_NDT5_treed_summary_VRI, AIC_lightning_NDT5_treed_summary_VRI2, AIC_lightning_NDT5_treed_topo, AIC_lightning_NDT5_treed_VRI, AIC_lightning_NDT5_treed_infra, AIC_lightning_NDT2_treed_climate)

#Now, remove any elements created prior that are also not needed
rm(dat_lightning___, dat_Disturbed, dist.cut.corr, filenames, fire_veg_data_B, fire_veg_data_lighnight_5x, fire_veg_data_lighnight_NA_5x, fire_veg_data_lighnight_NA_5x_, fire_veg_data_NA_5x, fire_veg_data_person_5x, fire_veg_data_person_NA_5x, fire_veg_data_person_NA_5x_, fire_veg_data_unknown_5x, ignition_pres_abs3, ignition_pres_abs4, table.glm.climate.simple180, table.glm.climate.simple1800)
```

Now, we will generate two-way interactions for each of these lists. We cannot make two-way interactions between them all because apparently it will be >2 GB in size.  


DO NOT RUN THIS NEXT CHUNK! The mods.twoway.NDT4 is >2 GB and will not run successfully. You will likely need to skip to the subsequent chunk.
```{r}
twoway.ints <- NULL
for (i in 1:(length(inputs.me.NDT4)-1)) {
  for (j in (i+1):length(inputs.me.NDT4)) {
     twoway.ints <- cbind(twoway.ints, paste(inputs.me.NDT4[i], inputs.me.NDT4[j], sep=":"))
  }
}
twoway.ints
length(twoway.ints) #45

#Create function to determine Powerset for any vector of variable names
## or use rje package
#powerSet <- function(x) {
#   z.list <- NULL
#   for(i in 1:length(x)) {
#      z.list <- append(z.list, combn(x, m=i, simplify=F))
#   }    
#   return(z.list)
#}

#Get variables on own
#complete list of models using non-climate vars
mods.me.tmp <- powerSet(variables_all_NDT4) 
#add climate vars to all of the above
mods.me.NDT4 <- list()
for (i in 1: length(mods.me.tmp)) {
   mods.me.NDT4[[i]] <- c(mods.me.tmp[[i]])
}

mods.me.NDT4
length(mods.me.NDT4) #1024 with only dist_any

## DO NOT RUN BELOW ####
#complete list of two-way interactions
mods.twoway.NDT4 <- powerSet(twoway.ints) #Too large > 2 GB, so cannot perform, with all distances to infrastructure; also too large for smaller subset of data.
length(mods.twoway.NDT4) #
mods.twoway.NDT4
```

Actually skip to chunk after this one, unless you go back and add DEM back in... but it will also be > 2 GB and unable to write.

```{r}

###########Try with subset: ############## 
twoway.ints <- NULL
for (i in 1:(length(inputs.me.clim_VRI_DEM_NDT4)-1)) {
  for (j in (i+1):length(inputs.me.clim_VRI_DEM_NDT4)) {
     twoway.ints <- cbind(twoway.ints, paste(inputs.me.clim_VRI_DEM_NDT4[i], inputs.me.clim_VRI_DEM_NDT4[j], sep=":"))
  }
}
twoway.ints
length(twoway.ints) #28

#Create function to determine Powerset for any vector of variable names
## or use rje package
#powerSet <- function(x) {
#   z.list <- NULL
#   for(i in 1:length(x)) {
#      z.list <- append(z.list, combn(x, m=i, simplify=F))
#   }    
#   return(z.list)
#}

#Get variables on own
#complete list of models using non-climate vars
mods.me.tmp <- powerSet(variables_clim_VRI_DEM_NDT4) 
#add climate vars to all of the above
mods.me.clim_VRI_DEM_NDT4 <- list()
for (i in 1: length(mods.me.tmp)) {
   mods.me.clim_VRI_DEM_NDT4[[i]] <- c(mods.me.tmp[[i]])
}

mods.me.clim_VRI_DEM_NDT4
length(mods.me.clim_VRI_DEM_NDT4) #256


##Continue from here

#complete list of two-way interactions
mods.twoway.NDT4 <- powerSet(twoway.ints) # File still too large > 2 GB
length(mods.twoway.NDT4) #
mods.twoway.NDT4

#Finding models in mods.me that accommodate/allow interaction terms in each mods.twoway to be added
mods.inter.NDT4 <- list()
counter <- 0
for (i in 1: length(mods.twoway.NDT4)) {
   s1 <- unique(unlist( strsplit(mods.twoway.NDT4[[i]], split=':', fixed=TRUE) ) )
   for (j in 1: length(mods.me.NDT4)) {
      if (all(s1 %in% mods.me.NDT4[[j]])==TRUE) {
        counter <- counter + 1
        both <-  c(mods.me.clim_VRI_DEM_NDT4[[j]], mods.twoway.NDT4[[i]])
        mods.inter.NDT4[[counter]] <- both
      }
   }
}

length(mods.inter.NDT4)
mods.inter.NDT4
```

RUN FROM HERE
```{r}
####Reduce further; remove DEM
twoway.ints <- NULL
for (i in 1:(length(inputs.me.clim_VRI_NDT4)-1)) {
  for (j in (i+1):length(inputs.me.clim_VRI_NDT4)) {
     twoway.ints <- cbind(twoway.ints, paste(inputs.me.clim_VRI_NDT4[i], inputs.me.clim_VRI_NDT4[j], sep=":"))
  }
}
twoway.ints
length(twoway.ints) #10

#Create function to determine Powerset for any vector of variable names
## or use rje package
#powerSet <- function(x) {
#   z.list <- NULL
#   for(i in 1:length(x)) {
#      z.list <- append(z.list, combn(x, m=i, simplify=F))
#   }    
#   return(z.list)
#}

#Get variables on own
#complete list of models using non-climate vars
mods.me.tmp <- powerSet(variables_clim_VRI_NDT4) 
#add climate vars to all of the above
mods.me.clim_VRI_NDT4 <- list()
for (i in 1: length(mods.me.tmp)) {
   mods.me.clim_VRI_NDT4[[i]] <- c(mods.me.tmp[[i]])
}

mods.me.clim_VRI_NDT4
length(mods.me.clim_VRI_NDT4) #32


##Continue from here

#complete list of two-way interactions
mods.twoway.NDT4 <- powerSet(twoway.ints) # Works now!
length(mods.twoway.NDT4) #1024
mods.twoway.NDT4

#Finding models in mods.me that accommodate/allow interaction terms in each mods.twoway to be added
mods.inter.NDT4 <- list()
counter <- 0
for (i in 1: length(mods.twoway.NDT4)) {
   s1 <- unique(unlist( strsplit(mods.twoway.NDT4[[i]], split=':', fixed=TRUE) ) )
   for (j in 1: length(mods.me.clim_VRI_NDT4)) {
      if (all(s1 %in% mods.me.clim_VRI_NDT4[[j]])==TRUE) {
        counter <- counter + 1
        both <-  c(mods.me.clim_VRI_NDT4[[j]], mods.twoway.NDT4[[i]])
        mods.inter.NDT4[[counter]] <- both
      }
   }
}

length(mods.inter.NDT4) #1450: this number is manageable for analyses
mods.inter.NDT4

##Subset 2: Infrastructure and land use ########
#inputs.me.infra_landuse_NDT4
twoway.ints <- NULL
for (i in 1:(length(inputs.me.infra_landuse_NDT4)-1)) {
  for (j in (i+1):length(inputs.me.infra_landuse_NDT4)) {
     twoway.ints <- cbind(twoway.ints, paste(inputs.me.infra_landuse_NDT4[i], inputs.me.infra_landuse_NDT4[j], sep=":"))
  }
}
twoway.ints
length(twoway.ints) #15
#Review. If we do not want interactions between the different distance measurements, but only those between land use and distance, subset those.
twoway.ints
twoway.ints_dist<-twoway.ints[c(5,9,12,14,15)]
twoway.ints_dist


#Create function to determine Powerset for any vector of variable names
## or use rje package
#powerSet <- function(x) {
#   z.list <- NULL
#   for(i in 1:length(x)) {
#      z.list <- append(z.list, combn(x, m=i, simplify=F))
#   }    
#   return(z.list)
#}

#Get variables on own
#complete list of models using non-climate vars
mods.me.tmp <- powerSet(variables_all_infra_landuse_NDT4) 
#add climate vars to all of the above
mods.me.infra_landuse_NDT4 <- list()
for (i in 1: length(mods.me.tmp)) {
   mods.me.infra_landuse_NDT4[[i]] <- c(mods.me.tmp[[i]])
}

mods.me.infra_landuse_NDT4
length(mods.me.infra_landuse_NDT4) #64


#complete list of two-way interactions
mods.twoway.NDT4b <- powerSet(twoway.ints) #
#Or use subset of interactions
mods.twoway.NDT4b <- powerSet(twoway.ints_dist) 
length(mods.twoway.NDT4b) #32768 if use all interactions; 32 if use subset
mods.twoway.NDT4b

#Finding models in mods.me that accommodate/allow interaction terms in each mods.twoway to be added
mods.inter.NDT4b <- list()
counter <- 0
for (i in 1: length(mods.twoway.NDT4b)) {
   s1 <- unique(unlist( strsplit(mods.twoway.NDT4b[[i]], split=':', fixed=TRUE) ) )
   for (j in 1: length(mods.me.infra_landuse_NDT4)) {
      if (all(s1 %in% mods.me.infra_landuse_NDT4[[j]])==TRUE) {
        counter <- counter + 1
        both <-  c(mods.me.infra_landuse_NDT4[[j]], mods.twoway.NDT4b[[i]])
        mods.inter.NDT4b[[counter]] <- both
      }
   }
}

length(mods.inter.NDT4b) #40069 if use all interactions - this is too many to handle; 275 with subset of interactions
mods.inter.NDT4b
```

Make final list of variables to assess.

```{r}
## 1. climate and VRI
#the list of all possible model RHSs. 
all.poss.mods.clim_VRI_NDT4<-c(1, mods.me.clim_VRI_NDT4, mods.inter.NDT4)
all.poss.mods.clim_VRI_NDT4
length(mods.me.clim_VRI_NDT4) #32
all.poss.mods.clim_VRI_NDT4[2]
all.poss.mods.clim_VRI_NDT4[34] #character 0
all.poss.mods.clim_VRI_NDT4<-all.poss.mods.clim_VRI_NDT4[-34]
all.poss.mods.clim_VRI_NDT4<-all.poss.mods.clim_VRI_NDT4[-2] #Use this line only if there is an odd character(0) added to list

##Check and rid of any duplicated models
duplicated(all.poss.mods.clim_VRI_NDT4) #Need to remove #33-63
all.poss.mods.clim_VRI_NDT4b<-all.poss.mods.clim_VRI_NDT4[-(33:63)]
duplicated(all.poss.mods.clim_VRI_NDT4b) 


##2. Infrastructure and land use
all.poss.mods.infra_landuse_NDT4<-c(1,mods.me.infra_landuse_NDT4, mods.inter.NDT4b)

##Check and rid of any duplicated models
duplicated(all.poss.mods.infra_landuse_NDT4) #Need to remove #66-129
all.poss.mods.infra_landuse_NDT4b<-all.poss.mods.infra_landuse_NDT4[-(66:129)]
duplicated(all.poss.mods.infra_landuse_NDT4b) 
all.poss.mods.infra_landuse_NDT4b[2]
all.poss.mods.infra_landuse_NDT4b<-all.poss.mods.infra_landuse_NDT4b[-2] #There is probably another one that needs removing...
all.poss.mods.infra_landuse_NDT4[66] #It was removed! Yay!
duplicated(all.poss.mods.infra_landuse_NDT4b)

###########Using a subset of interactions interactions
all.poss.mods.infra_landuse_NDT4<-c(1,mods.me.infra_landuse_NDT4, mods.inter.NDT4b)

##Check and rid of any duplicated models
duplicated(all.poss.mods.infra_landuse_NDT4) #Need to remove #66-119
all.poss.mods.infra_landuse_NDT4b<-all.poss.mods.infra_landuse_NDT4[-(66:128)]
duplicated(all.poss.mods.infra_landuse_NDT4b) 
all.poss.mods.infra_landuse_NDT4b[2]
all.poss.mods.infra_landuse_NDT4b<-all.poss.mods.infra_landuse_NDT4b[-2] #There is probably another one that needs removing...
duplicated(all.poss.mods.infra_landuse_NDT4b)
length(all.poss.mods.infra_landuse_NDT4b)#276


#If need to determine which ones are character(0), try this:
biglist <- list(list("A","B","C"), "foo", "", character(0), integer(0))
lapply(biglist, function(x) {length(x) == 0L} ) 

#Below does not work
lapply(biglist, all.poss.mods.infra_landuse_NDT4b {length(all.poss.mods.infra_landuse_NDT4b) == 0L} ) 


#Proceed with 
  ## all.poss.mods.clim_VRI_NDT4b
  ## all.poss.mods.infra_landuse_NDT4b

```


#all.poss.mods.clim_VRI_NDT4b
We cannot run the model 100 times without R crashing. Instead, we will run it 25 times, then save the output, then run that another 3 times (for a total of 100 runs). Then we will combine all 100 runs, and calculate the deltaAIC from that.

```{r}
zones1<-"NDT4"

#Create empty table
table.glm.clim_VRI.simple <- data.frame (matrix (ncol = 5, nrow = 0))
colnames (table.glm.clim_VRI.simple) <- c ("model", "edf", "aic", "auc.valid", "NDT")

#
for (g in 1:25){

for (h in 1:length(zones1)) {
  dat2<- dat_lightning_t %>% dplyr::filter(ntrl_ds ==zones1[h])

#for (i in 1: length(all.poss.mods.topo)){
#  print(paste((all.poss.mods.topo[i]), (zones1[h]), sep=" "))
  
for (i in 1: length(zones1)){
  print(paste((all.poss.mods.clim_VRI_NDT4b[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, variables_all[i])
  model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, !!variables_clim_VRI_NDT4)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="fire_pres") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.aic, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.clim_VRI_NDT4b, big.mod, df.train=dat1, df.test=Valid)

#terms in each model
x1.1 <- unlist(sapply(mods.fit, '[', 1))
x1.1
#Aic for models
x3.1 <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3.1
#auc from validation data
x4.1 <- unlist(sapply(mods.fit, '[', 4))
x4.1
#combining all as df
tab.sum.clim_VRI <- cbind.data.frame(model=x1.1, edf=x3.1[,1], aic=x3.1[,2], auc.valid=x4.1)
tab.sum.clim_VRI$NDT<-c("NDT4")
tab.sum.clim_VRI 

table.glm.clim_VRI.simple<-rbind(table.glm.clim_VRI.simple, tab.sum.clim_VRI)

}
}
}
```

For the below chunks, they will need to be run in specific order, with repeating the previous chunk in between. DO NOT RUN THIS CHUNK MORE THAN ONCE! RUN EACH ONE ONCE, AFTER EACH SUBSEQUENT RUN OF THE ABOVE.

```{r}
table.glm.clim_VRI.simple_run1<-table.glm.clim_VRI.simple
head(table.glm.clim_VRI.simple_run1)
```

STOP! RUN the model x25 again.
```{r}
table.glm.clim_VRI.simple_run2<-table.glm.clim_VRI.simple
head(table.glm.clim_VRI.simple_run2)
```

STOP! RUN the model x25 again.
```{r}
table.glm.clim_VRI.simple_run3<-table.glm.clim_VRI.simple
```

STOP! RUN the model x25 again.
```{r}
table.glm.clim_VRI.simple_run4<-table.glm.clim_VRI.simple
```

Now that we have run the model 100 times, we want the average AIC and AUC for each variable combination. First, combine the 4 runs back together.

```{r}
table.glm.clim_VRI.simple<-rbind(table.glm.clim_VRI.simple_run1, table.glm.clim_VRI.simple_run2, table.glm.clim_VRI.simple_run3, table.glm.clim_VRI.simple_run4)
```

Now determine deltaAIC.

```{r}
head(table.glm.clim_VRI.simple)
table(table.glm.clim_VRI.simple$model) # 100 per model

AIC_lightning_NDT4_treed_clim_VRI<-table.glm.clim_VRI.simple

AIC_lightning_NDT4_treed_summary_clim_VRI<- AIC_lightning_NDT4_treed_clim_VRI %>%
  group_by(model) %>%
  summarise(meanAIC=mean(aic),
            meanAUC=mean(auc.valid),
            sdAUC=sd(auc.valid),
            )

AIC_lightning_NDT4_treed_summary_clim_VRI2<- AIC_lightning_NDT4_treed_summary_clim_VRI %>%
  mutate(deltaAIC=meanAIC-min(meanAIC))

head(AIC_lightning_NDT4_treed_summary_clim_VRI2)
```

Save file.
```{r}
write.csv(AIC_lightning_NDT4_treed_summary_clim_VRI2, file="D:\\Fire\\fire_data\\raw_data\\AIC_lightning_NDT4_treed_summary_clim_VRI2.csv")
```

#Assessing models, all had low AUC (~0.55), so these models are barely performing better than 50-50.

#Now repeat for all.poss.mods.infra_landuse_NDT4b

```{r}
########### 2. Distance to Infrastructure ############
#Create empty table
table.glm.infra.lu.simple <- data.frame (matrix (ncol = 5, nrow = 0))
colnames (table.glm.infra.lu.simple) <- c ("model", "edf", "aic", "auc.valid", "NDT")

#
for (g in 1:25){

for (h in 1:length(zones1)) {
  dat2<- dat_lightning_t %>% dplyr::filter(ntrl_ds ==zones1[h])

#for (i in 1: length(all.poss.mods.infra)){
#  print(paste((all.poss.mods.infra[i]), (zones1[h]), sep=" "))
  
for (i in 1: length(zones1)){
  print(paste((all.poss.mods.infra_landuse_NDT4b[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, variables_all[i])
  model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, !!variables_all_infra_landuse_NDT4)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="fire_pres") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.aic, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.infra_landuse_NDT4b, big.mod, df.train=dat1, df.test=Valid)

#terms in each model
x1.1 <- unlist(sapply(mods.fit, '[', 1))
x1.1
#Aic for models
x3.1 <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3.1
#auc from validation data
x4.1 <- unlist(sapply(mods.fit, '[', 4))
x4.1
#combining all as df
tab.sum.infra.lu <- cbind.data.frame(model=x1.1, edf=x3.1[,1], aic=x3.1[,2], auc.valid=x4.1)
tab.sum.infra.lu$NDT<-c("NDT4")
tab.sum.infra.lu 

table.glm.infra.lu.simple<-rbind(table.glm.infra.lu.simple, tab.sum.infra.lu)

}
}
}
```

Now that we have run the model 100 times, we want the average AIC and AUC for each variable combination.

For the below chunks, they will need to be run in specific order, with repeating the previous chunk in between. DO NOT RUN THIS CHUNK MORE THAN ONCE! RUN EACH ONE ONCE, AFTER EACH SUBSEQUENT RUN OF THE ABOVE.

```{r}
#Check that it ran correctly
table.glm.infra.lu.simple

table.glm.infra.lu.simple_run1<-table.glm.infra.lu.simple
head(table.glm.infra.lu.simple_run1)

```

STOP! RUN the model x25 again.
```{r}
table.glm.infra.lu.simple_run2<-table.glm.infra.lu.simple
head(table.glm.infra.lu.simple_run2)
```

STOP! RUN the model x25 again.
```{r}
table.glm.infra.lu.simple_run3<-table.glm.infra.lu.simple
head(table.glm.infra.lu.simple_run3)
```

STOP! RUN the model x25 again.
```{r}
table.glm.infra.lu.simple_run4<-table.glm.infra.lu.simple
```

Now that we have run the model 100 times, we want the average AIC and AUC for each variable combination. First, combine the 4 runs back together.

```{r}
table.glm.infra.lu.simple<-rbind(table.glm.infra.lu.simple_run1, table.glm.infra.lu.simple_run2, table.glm.infra.lu.simple_run3, table.glm.infra.lu.simple_run4)
```

Now determine deltaAIC.

```{r}
head(table.glm.infra.lu.simple)
table(table.glm.infra.lu.simple$model) # 100 per model

AIC_lightning_NDT4_treed_infra<-table.glm.infra.lu.simple

AIC_lightning_NDT4_treed_summary_infra<- AIC_lightning_NDT4_treed_infra %>%
  group_by(model) %>%
  summarise(meanAIC=mean(aic),
            meanAUC=mean(auc.valid),
            sdAUC=sd(auc.valid),
            )

AIC_lightning_NDT4_treed_summary_infra2<- AIC_lightning_NDT4_treed_summary_infra %>%
  mutate(deltaAIC=meanAIC-min(meanAIC))

head(AIC_lightning_NDT4_treed_summary_infra2)
```

Save to computer.

```{r}
write.csv(AIC_lightning_NDT4_treed_summary_infra2, file="D:\\Fire\\fire_data\\raw_data\\AIC_lightning_NDT4_treed_summary_infra.csv")
```

##Top variables
1. Top models have live_stand_volume and proj_height with various combinations of interactions with climate 1 and climate 2. Vegtype 2 is not included, but this is important. So we should explore interactions between climate 1, climate 2, live stand volume and projected age, and add vegtype 2 with no interactions separately.

2. Infrastructure and landuse: distance to any and distance to municipality best model. Land use not found important, but I think it is useful to have in model. Try full model with these 3 variables first. AUC low for all (<0.57). No interactions found to be important.

3. DEM: slope + aspect + elevation + slope:aspect was the top model. Include elements of these in but not interactions with other variables unless we have a reason to expect an interaction (perhaps try landuse*elevation, for example; or with slope or aspect)

Create variable lists.

```{r}
##Create variable lists to be used in the model loop.
variables_all_NDT4<-c(climate1 = "climate1", climate2 = "climate2", vegtype2 = "vegtype2", proj_height_1 = "proj_height_1", live_stand_volume_125 = "live_stand_volume_125", slope = "slope", aspect = "aspect", elevation ="elevation", dist_mun = "dist_mun", dist_any = "dist_any", bclcs_level_5_2 = "bclcs_level_5_2", slope = "slope", aspect = "aspect", elevation ="elevation")

#Too many permutations to be able to include two-way interactions and all possible models, so need to divide into what we think may have interactions and which not.
variables_clim_VRI_NDT4<-c(climate1 = "climate1", climate2 = "climate2", proj_height_1 = "proj_height_1", live_stand_volume_125 = "live_stand_volume_125")

variables_DEM_NDT4<-c(slope = "slope", aspect = "aspect", elevation ="elevation")

#treat slope, aspect and elevation as their own thing.And we have already done this analysis with them.
#slope = "slope", aspect = "aspect", elevation ="elevation")

##
inputs.me.NDT4 <- c(variables_all_NDT4)
#inputs.me.clim_VRI_DEM_NDT4 <- c(variables_clim_VRI_DEM_NDT4)
inputs.me.clim_VRI_NDT4 <- c(variables_clim_VRI_NDT4)
inputs.me.DEM_NDT4 <- c(variables_DEM_NDT4)

```

Form for full model given above constraints.

```{r}
twoway.ints <- NULL
for (i in 1:(length(inputs.me.clim_VRI_NDT4)-1)) {
  for (j in (i+1):length(inputs.me.clim_VRI_NDT4)) {
     twoway.ints <- cbind(twoway.ints, paste(inputs.me.clim_VRI_NDT4[i], inputs.me.clim_VRI_NDT4[j], sep=":"))
  }
}
twoway.ints
length(twoway.ints) #6


twoway.ints.DEM <- NULL
for (i in 1:(length(inputs.me.DEM_NDT4)-1)) {
  for (j in (i+1):length(inputs.me.DEM_NDT4)) {
     twoway.ints.DEM <- cbind(twoway.ints.DEM, paste(inputs.me.DEM_NDT4[i], inputs.me.DEM_NDT4[j], sep=":"))
  }
}
twoway.ints.DEM #3
length(twoway.ints.DEM) #3

#Create function to determine Powerset for any vector of variable names
## or use rje package
#powerSet <- function(x) {
#   z.list <- NULL
#   for(i in 1:length(x)) {
#      z.list <- append(z.list, combn(x, m=i, simplify=F))
#   }    
#   return(z.list)
#}

#Get variables on own and all possible combinations
#complete list of models using all variables
mods.me.tmp <- powerSet(variables_all_NDT4) 
#add climate vars to all of the above
mods.me_NDT4 <- list()
for (i in 1: length(mods.me.tmp)) {
   mods.me_NDT4[[i]] <- c(mods.me.tmp[[i]])
}

mods.me_NDT4
length(mods.me_NDT4) #16384


#complete list of two-way interactions
mods.twoway.NDT4.a <- powerSet(twoway.ints) 
length(mods.twoway.NDT4.a) #64
mods.twoway.NDT4.a

mods.twoway.NDT4.b <- powerSet(twoway.ints.DEM) 
length(mods.twoway.NDT4.b) #8
mods.twoway.NDT4.b

mods.twoway.NDT4<-c(mods.twoway.NDT4.a, mods.twoway.NDT4.b)
mods.twoway.NDT4
length(mods.twoway.NDT4) #72

#Finding models in mods.me that accommodate/allow interaction terms in each mods.twoway to be added
mods.inter.NDT4 <- list()
counter <- 0
for (i in 1: length(mods.twoway.NDT4)) {
   s1 <- unique(unlist( strsplit(mods.twoway.NDT4[[i]], split=':', fixed=TRUE) ) )
   for (j in 1: length(mods.me_NDT4)) {
      if (all(s1 %in% mods.me_NDT4[[j]])==TRUE) {
        counter <- counter + 1
        both <-  c(mods.me_NDT4[[j]], mods.twoway.NDT4[[i]])
        mods.inter.NDT4[[counter]] <- both
      }
   }
}

length(mods.inter.NDT4) #187392.... very large...
mods.inter.NDT4

```

Make final list of variables to assess.

```{r}
## 1. climate and VRI
#the list of all possible model RHSs. 
all.poss.mods.NDT4<-c(1, mods.me_NDT4, mods.inter.NDT4)
all.poss.mods.NDT4
length(all.poss.mods.NDT4) #203,777
#all.poss.mods.clim_VRI_NDT4<-all.poss.mods.clim_VRI_NDT4[-34]
#all.poss.mods.clim_VRI_NDT4<-all.poss.mods.clim_VRI_NDT4[-2] #Use this line only if there is an odd character(0) added to list
length(mods.me_NDT4)
all.poss.mods.NDT4[16386]
all.poss.mods.NDT4<-all.poss.mods.NDT4[-16386]
all.poss.mods.NDT4[2]
all.poss.mods.NDT4<-all.poss.mods.NDT4[-2]

##Check and rid of any duplicated models
duplicated(all.poss.mods.NDT4) #



#If need to determine which ones are character(0), try this:
biglist <- list(list("A","B","C"), "foo", "", character(0), integer(0))
lapply(biglist, function(x) {length(x) == 0L} ) 

#Below does not work
lapply(biglist, all.poss.mods.infra_landuse_NDT4b {length(all.poss.mods.infra_landuse_NDT4b) == 0L} )

```

#Run model selection
Because there are nearly 200,000 models to go through each time, we will do only 2 rounds at a time. 5 was too many.
##Need to determine which ones are character(0) before proceeding.

```{r}
########### Full Model ############
zones1<-"NDT4"
prop<-0.75

#Create empty table
table.glm.NDT4.simple <- data.frame (matrix (ncol = 5, nrow = 0))
colnames (table.glm.NDT4.simple) <- c ("model", "edf", "aic", "auc.valid", "NDT")

#
for (g in 1:2){

for (h in 1:length(zones1)) {
  dat2<- dat_lightning_t %>% dplyr::filter(ntrl_ds ==zones1[h])

#for (i in 1: length(all.poss.mods.infra)){
#  print(paste((all.poss.mods.infra[i]), (zones1[h]), sep=" "))
  
for (i in 1: length(zones1)){
  print(paste((all.poss.mods.NDT4[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, variables_all[i])
  model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, !!variables_all_NDT4)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="fire_pres") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.aic, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.NDT4, big.mod, df.train=dat1, df.test=Valid)

#terms in each model
x1.1 <- unlist(sapply(mods.fit, '[', 1))
x1.1
#Aic for models
x3.1 <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3.1
#auc from validation data
x4.1 <- unlist(sapply(mods.fit, '[', 4))
x4.1
#combining all as df
tab.sum.NDT4 <- cbind.data.frame(model=x1.1, edf=x3.1[,1], aic=x3.1[,2], auc.valid=x4.1)
tab.sum.NDT4$NDT<-c("NDT4")
tab.sum.NDT4 

table.glm.NDT4.simple<-rbind(table.glm.NDT4.simple, tab.sum.NDT4)

}
}
}
```

Now that we have run the model 5 times, we want the average AIC and AUC for each variable combination. Save the first round, but consider doing more than 5 runds, depending on how long it takes to run.


Now determine deltaAIC.

```{r}
head(table.glm.NDT4.simple)
table(table.glm.NDT4.simple$model) # 5 per model

AIC_lightning_NDT4_treed_<-table.glm.NDT4.simple

AIC_lightning_NDT4_treed_summary_<- AIC_lightning_NDT4_treed_ %>%
  group_by(model) %>%
  summarise(meanAIC=mean(aic),
            meanAUC=mean(auc.valid),
            sdAUC=sd(auc.valid),
            )

AIC_lightning_NDT4_treed_summary_2<- AIC_lightning_NDT4_treed_summary_ %>%
  mutate(deltaAIC=meanAIC-min(meanAIC))

head(AIC_lightning_NDT4_treed_summary_2)
```

Save to computer.

```{r}
write.csv(AIC_lightning_NDT4_treed_summary_2, file="D:\\Fire\\fire_data\\raw_data\\AIC_lightning_NDT4_treed_summary.csv")
```


For the below chunks, they will need to be run in specific order, with repeating the previous chunk in between. DO NOT RUN THIS CHUNK MORE THAN ONCE! RUN EACH ONE ONCE, AFTER EACH SUBSEQUENT RUN OF THE ABOVE.

```{r}
#Check that it ran correctly
table.glm.NDT4.simple

table.glm.NDT4.simple_run1<-table.glm.NDT4.simple
head(table.glm.NDT4.simple_run1)

```

STOP! RUN the model x25 again.
```{r}
table.glm.NDT4.simple_run2<-table.glm.NDT4.simple
head(table.glm.NDT4.simple_run2)
```

STOP! RUN the model x25 again.
```{r}
table.glm.NDT4.simple_run3<-table.glm.NDT4.simple
head(table.glm.NDT4.simple_run3)
```

STOP! RUN the model x25 again.
```{r}
table.glm.NDT4.simple_run4<-table.glm.NDT4.simple
```

Now that we have run the model 100 times, we want the average AIC and AUC for each variable combination. First, combine the 4 runs back together.

```{r}
table.glm.NDT4.simple<-rbind(table.glm.NDT4.simple_run1, table.glm.NDT4.simple_run2, table.glm.NDT4.simple_run3, table.glm.NDT4.simple_run4)
```

Now determine deltaAIC.

```{r}
head(table.glm.NDT4.simple)
table(table.glm.NDT4.simple$model) # 100 per model

AIC_lightning_NDT4_treed_<-table.glm.NDT4.simple

AIC_lightning_NDT4_treed_summary_<- AIC_lightning_NDT4_treed_ %>%
  group_by(model) %>%
  summarise(meanAIC=mean(aic),
            meanAUC=mean(auc.valid),
            sdAUC=sd(auc.valid),
            )

AIC_lightning_NDT4_treed_summary_2<- AIC_lightning_NDT4_treed_summary_ %>%
  mutate(deltaAIC=meanAIC-min(meanAIC))

head(AIC_lightning_NDT4_treed_summary_2)
```

Save to computer.

```{r}
write.csv(AIC_lightning_NDT4_treed_summary_2, file="D:\\Fire\\fire_data\\raw_data\\AIC_lightning_NDT4_treed_summary.csv")
```








```{r}

```






#Now combine the datatables and save to computer

```{r}
NDT4_l_models_treed<-rbind(AIC_lightning_NDT4_treed_summary_climate2, AIC_lightning_NDT4_treed_summary_VRI2, AIC_lightning_NDT4_treed_summary_topo2, AIC_lightning_NDT4_treed_summary_infra2)
NDT4_l_models_treed
NDT4_l_models_treed$NDT<-"NDT4"

write.csv(NDT4_l_models_treed, file="D:\\Fire\\fire_data\\raw_data\\NDT4_lightning_models_treed.csv")
```









#Because we cannot make two-way interactions with all, we will first widdle down the possible variables manually.

1. climate1 + climate2 + vegtype2 + climate1:climate2
2. proj_height_1 + live_stand_volume_125
3. slope + aspect + elevation + slope:aspect
4. dist_mun + dist_dam + dist_nat + dist_pow + dist_any1. 

Additional Variabes:
1. bclcs_level_5_2 (land use) (to be added to final investigated model)


```{r}
##### TOP MODEL####
NDT4_t<-dat_lightning_t %>%
  filter(ntrl_ds=="NDT4")
str(NDT4_t) #7288 observations
str(NDT4_t$bclcs_level_5_2)
str(NDT4_t$vegtype2)
NDT4_t$vegtype2<-as.factor(NDT4_t$vegtype2)

table(NDT4_t$fire_pres)

#Remove NAs to ensure all same data used so we can compare AICs
NDT4_t2<-NDT4_t %>% drop_na(live_stand_volume_125, vegtype2, climate1, climate2, proj_height_1, slope, aspect, elevation, dist_mun, dist_dam, dist_nat, dist_pow, dist_mine, dist_any)

#Had to remove some because would not converge

glm_best_NDT4<- glm(fire_pres ~ scale(climate1)*scale(climate2) +
               vegtype2+
               scale(live_stand_volume_125) +
               scale(proj_height_1) +
               scale(slope)*scale(aspect) +
                 scale(elevation) +
                 scale(dist_mun) + 
                 scale(dist_dam) + 
                 scale(dist_nat) + 
                 scale(dist_pow) + 
                 scale(dist_any) +
                 bclcs_level_5_2, 
           data= NDT4_t2,
           family = binomial,
           na.action=na.omit)

summary(glm_best_NDT4) #AIC 8282

# model diagnostic plots
binnedplot (fitted(glm_best_NDT4), 
            residuals(glm_best_NDT4), 
            nclass = NULL, 
            xlab = "Expected Values", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))


NDT4_t2$resids<-resid(glm_best_NDT4)

binnedplot (NDT4_t2$live_stand_volume_125, 
            NDT4_t2$resids, 
            nclass = NULL, 
            xlab = "live stand volume", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))

binnedplot (NDT4_t2$climate1, 
            NDT4_t2$resids, 
            nclass = NULL, 
            xlab = "", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))

# Diagnostic plots look good

# Looking at effect of forest height at the average amount of rainfall in September
plot(NDT4_t2$live_stand_volume_125,NDT4_t2$fire_pres)
curve(invlogit(coef(glm_best_NDT4)[1] +coef(glm_best_NDT4)[2]*mean(NDT4_t2$climate1) + coef(glm_best_NDT4)[3]*x), add=TRUE)

# looking at effect of climate1 at the average forest height.
plot(NDT4_t2$climate1,NDT4_t2$fire_pres)
curve(invlogit(coef(glm_best_NDT4)[1] +coef(glm_best_NDT4)[2]*x + coef(glm_best_NDT4)[3]*mean(NDT4_t2$live_stand_volume_125)), add=TRUE)


# create model table (only do this once) and add the relevant data
top_mod_table <- data.frame (matrix (ncol = 16, nrow = 0))
colnames (top_mod_table) <- c ("ZONE", "TREED", "Model_terms", "intercept", "coef_climate_1", "coef_climate_2", "coef_climate_interaction", "coef_stand_height", "coef_live_stand_volume_125", "coef_proj_age", "coef_vegtypeD", "coef_vegtypeOP", "coef_vegtypeS", "coef_vegtypeTB", "coef_vegtypeTC", "coef_vegtypeTM")



##STILL NEED TO ADD DATA FOR TABLE

##Add data for NDT4
top_mod_table[1,1]<-"NDT4"
top_mod_table[1,2]<-"Y"
top_mod_table[1,3]<-"fire_pres ~ ppt09 + proj_height_1" ######### UPDATE
top_mod_table[1,4]<- coef(glm_best_NDT4)[1] #Intercept
top_mod_table[1,5]<- coef(glm_best_NDT4)[2] #Climate variable 1
#top_mod_table[1,6]<- coef(glm_best_NDT4)[2] #Climate variable 2
#top_mod_table[1,7]<- coef(glm_best_NDT4)[3] #Interaction climate variables
#top_mod_table[1,8]<- coef(glm_best_NDT4)[3] #coef_stand_height
#top_mod_table[1,9]<- coef(glm_best_NDT4)[3] #live_stand_volume_125
#top_mod_table[1,10]<- coef(glm_best_NDT4)[4] #proj_age_1
#top_mod_table[1,11]<- coef(glm_best_NDT4)[4] #coefficient vegtypeD
#top_mod_table[1,12]<- coef(glm_best_NDT4)[4] #coefficient vegtypeOP
#top_mod_table[1,13]<- coef(glm_best_NDT4)[4] #coefficient vegtypeS
#top_mod_table[1,14]<- coef(glm_best_NDT4)[4] #coefficient vegtypeTB
#top_mod_table[1,15]<- coef(glm_best_NDT4)[4] #coefficient vegtypeTC
#top_mod_table[1,16]<- coef(glm_best_NDT4)[5] #coefficient vegtypeTM
top_mod_table ##Determine if better way to represent categories for vegtype, and if each climate variable should have its own column

########################## NDT4 Model Selection Complete ###################

```
 


############### Now choose the next NDT zone and repeat ########
Note: currently doing  those with one climate variable)
Models complete above: NDT4
Models to still do henceforth:NDT1, NDT2, NDT3, NDT5


Select next zone: NDT1

```{r}
zones1<-c("NDT1") #Do one zone at a time

prop<-0.75

#Create empty table
table.glm.climate.simple <- data.frame (matrix (ncol = 5, nrow = 0))
colnames (table.glm.climate.simple) <- c ("model", "edf", "aic", "auc.valid", "NDT")

########### 1. Climate and vegtype ############
for (g in 1:100){

for (h in 1:length(zones1)) {
  dat2<- dat_lightning_t %>% dplyr::filter(ntrl_ds ==zones1[h])

#for (i in 1: length(all.poss.mods.clim.vegtype2)){
#  print(paste((all.poss.mods.clim.vegtype2[i]), (zones1[h]), sep=" "))
  
for (i in 1: length(zones1)){
  print(paste((all.poss.mods.clim.vegtype2[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, variables_all[i])
  model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, !!variables_all)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="fire_pres") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.aic, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.clim.vegtype2, big.mod, df.train=dat1, df.test=Valid)

#terms in each model
x1.1 <- unlist(sapply(mods.fit, '[', 1))
x1.1
#Aic for models
x3.1 <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3.1
#auc from validation data
x4.1 <- unlist(sapply(mods.fit, '[', 4))
x4.1
#combining all as df
tab.sum.climate <- cbind.data.frame(model=x1.1, edf=x3.1[,1], aic=x3.1[,2], auc.valid=x4.1)
tab.sum.climate$NDT<-c("NDT1")
tab.sum.climate 

table.glm.climate.simple<-rbind(table.glm.climate.simple, tab.sum.climate)

}
}
}


```

Now that we have run the model 100 times, we want the average AIC and AUC for each variable combination.

```{r}
head(table.glm.climate.simple)
table(table.glm.climate.simple$model) # 100 per model

AIC_lightning_NDT1_treed_climate<-table.glm.climate.simple

AIC_lightning_NDT1_treed_summary_climate<- AIC_lightning_NDT1_treed_climate %>%
  group_by(model) %>%
  summarise(meanAIC=mean(aic),
            meanAUC=mean(auc.valid),
            sdAUC=sd(auc.valid),
            )

AIC_lightning_NDT1_treed_summary_climate2<- AIC_lightning_NDT1_treed_summary_climate %>%
  mutate(deltaAIC=meanAIC-min(meanAIC))

head(AIC_lightning_NDT1_treed_summary_climate2)
```

#Now repeat for VRI data

```{r}
########### 2. VRI ############
#Create empty table
table.glm.VRI.simple <- data.frame (matrix (ncol = 5, nrow = 0))
colnames (table.glm.VRI.simple) <- c ("model", "edf", "aic", "auc.valid", "NDT")

####
for (g in 1:100){

for (h in 1:length(zones1)) {
  dat2<- dat_lightning_t %>% dplyr::filter(ntrl_ds ==zones1[h])

#for (i in 1: length(all.poss.mods.VRI)){
#  print(paste((all.poss.mods.VRI[i]), (zones1[h]), sep=" "))
  
for (i in 1: length(zones1)){
  print(paste((all.poss.mods.VRI[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, variables_all[i])
  model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, !!variables_all)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="fire_pres") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.aic, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.VRI, big.mod, df.train=dat1, df.test=Valid)

#terms in each model
x1.1 <- unlist(sapply(mods.fit, '[', 1))
x1.1
#Aic for models
x3.1 <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3.1
#auc from validation data
x4.1 <- unlist(sapply(mods.fit, '[', 4))
x4.1
#combining all as df
tab.sum.VRI <- cbind.data.frame(model=x1.1, edf=x3.1[,1], aic=x3.1[,2], auc.valid=x4.1)
tab.sum.VRI$NDT<-c("NDT1")
tab.sum.VRI 

table.glm.VRI.simple<-rbind(table.glm.VRI.simple, tab.sum.VRI)

}
}
}
```

Now that we have run the model 100 times, we want the average AIC and AUC for each variable combination.

```{r}
head(table.glm.VRI.simple)
table(table.glm.VRI.simple$model) # 100 per model

AIC_lightning_NDT1_treed_VRI<-table.glm.VRI.simple

AIC_lightning_NDT1_treed_summary_VRI<- AIC_lightning_NDT1_treed_VRI %>%
  group_by(model) %>%
  summarise(meanAIC=mean(aic),
            meanAUC=mean(auc.valid),
            sdAUC=sd(auc.valid),
            )

AIC_lightning_NDT1_treed_summary_VRI2<- AIC_lightning_NDT1_treed_summary_VRI %>%
  mutate(deltaAIC=meanAIC-min(meanAIC))

head(AIC_lightning_NDT1_treed_summary_VRI2)
```


#Now repeat for topography

```{r}
########### 3. topo ############
#Create empty table
table.glm.topo.simple <- data.frame (matrix (ncol = 5, nrow = 0))
colnames (table.glm.topo.simple) <- c ("model", "edf", "aic", "auc.valid", "NDT")

#
for (g in 1:100){

for (h in 1:length(zones1)) {
  dat2<- dat_lightning_t %>% dplyr::filter(ntrl_ds ==zones1[h])

#for (i in 1: length(all.poss.mods.topo)){
#  print(paste((all.poss.mods.topo[i]), (zones1[h]), sep=" "))
  
for (i in 1: length(zones1)){
  print(paste((all.poss.mods.topo[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, variables_all[i])
  model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, !!variables_all)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="fire_pres") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.aic, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.topo, big.mod, df.train=dat1, df.test=Valid)

#terms in each model
x1.1 <- unlist(sapply(mods.fit, '[', 1))
x1.1
#Aic for models
x3.1 <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3.1
#auc from validation data
x4.1 <- unlist(sapply(mods.fit, '[', 4))
x4.1
#combining all as df
tab.sum.topo <- cbind.data.frame(model=x1.1, edf=x3.1[,1], aic=x3.1[,2], auc.valid=x4.1)
tab.sum.topo$NDT<-c("NDT1")
tab.sum.topo 

table.glm.topo.simple<-rbind(table.glm.topo.simple, tab.sum.topo)

}
}
}
```

Now that we have run the model 100 times, we want the average AIC and AUC for each variable combination.

```{r}
head(table.glm.topo.simple)
table(table.glm.topo.simple$model) # 100 per model

AIC_lightning_NDT1_treed_topo<-table.glm.topo.simple

AIC_lightning_NDT1_treed_summary_topo<- AIC_lightning_NDT1_treed_topo %>%
  group_by(model) %>%
  summarise(meanAIC=mean(aic),
            meanAUC=mean(auc.valid),
            sdAUC=sd(auc.valid),
            )

AIC_lightning_NDT1_treed_summary_topo2<- AIC_lightning_NDT1_treed_summary_topo %>%
  mutate(deltaAIC=meanAIC-min(meanAIC))

head(AIC_lightning_NDT1_treed_summary_topo2)
```


#Now repeat for infrastructure

```{r}
########### 4. infra ############
#Create empty table
table.glm.infra.simple <- data.frame (matrix (ncol = 5, nrow = 0))
colnames (table.glm.infra.simple) <- c ("model", "edf", "aic", "auc.valid", "NDT")

#
for (g in 1:100){

for (h in 1:length(zones1)) {
  dat2<- dat_lightning_t %>% dplyr::filter(ntrl_ds ==zones1[h])

#for (i in 1: length(all.poss.mods.infra)){
#  print(paste((all.poss.mods.infra[i]), (zones1[h]), sep=" "))
  
for (i in 1: length(zones1)){
  print(paste((all.poss.mods.infra[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, variables_all[i])
  model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, !!variables_all)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="fire_pres") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.aic, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.infra, big.mod, df.train=dat1, df.test=Valid)

#terms in each model
x1.1 <- unlist(sapply(mods.fit, '[', 1))
x1.1
#Aic for models
x3.1 <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3.1
#auc from validation data
x4.1 <- unlist(sapply(mods.fit, '[', 4))
x4.1
#combining all as df
tab.sum.infra <- cbind.data.frame(model=x1.1, edf=x3.1[,1], aic=x3.1[,2], auc.valid=x4.1)
tab.sum.infra$NDT<-c("NDT1")
tab.sum.infra 

table.glm.infra.simple<-rbind(table.glm.infra.simple, tab.sum.infra)

}
}
}
```

Now that we have run the model 100 times, we want the average AIC and AUC for each variable combination.

```{r}
head(table.glm.infra.simple)
table(table.glm.infra.simple$model) # 100 per model

AIC_lightning_NDT1_treed_infra<-table.glm.infra.simple

AIC_lightning_NDT1_treed_summary_infra<- AIC_lightning_NDT1_treed_infra %>%
  group_by(model) %>%
  summarise(meanAIC=mean(aic),
            meanAUC=mean(auc.valid),
            sdAUC=sd(auc.valid),
            )

AIC_lightning_NDT1_treed_summary_infra2<- AIC_lightning_NDT1_treed_summary_infra %>%
  mutate(deltaAIC=meanAIC-min(meanAIC))

head(AIC_lightning_NDT1_treed_summary_infra2)
```

#Now combine the datatables and save to computer

```{r}
NDT1_l_models_treed<-rbind(AIC_lightning_NDT1_treed_summary_climate2, AIC_lightning_NDT1_treed_summary_VRI2, AIC_lightning_NDT1_treed_summary_topo2, AIC_lightning_NDT1_treed_summary_infra2)
NDT1_l_models_treed
NDT1_l_models_treed$NDT<-"NDT1"

write.csv(NDT1_l_models_treed, file="D:\\Fire\\fire_data\\raw_data\\NDT1_lightning_models_treed.csv")
```

Now choose the top variables and create final model. The below code will need to be updated manually, depending on what the results of the above analyses are.

######## UPDATE BELOW #########

```{r}
##### TOP MODEL####
NDT1_t<-dat_lightning_t %>%
  filter(ntrl_ds=="NDT1")

NDT1_t2<-NDT1_t %>% drop_na(live_stand_volume_125, vegtype, climate1, climate2, proj_height_1)

glm_best_NDT1<- glm(fire_pres ~ scale(climate1)*scale(climate2) +
             scale(live_stand_volume_125) +
               scale(proj_height_1) +
               vegtype, 
           data= NDT1_t2,
           family = binomial,
           na.action=na.omit)

summary(glm_best_NDT1)

# model diagnostic plots
binnedplot (fitted(glm_best_NDT1), 
            residuals(glm_best_NDT1), 
            nclass = NULL, 
            xlab = "Expected Values", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))


NDT1_t2$resids<-resid(glm_best_NDT1)

binnedplot (NDT1_t2$live_stand_volume_125, 
            NDT1_t2$resids, 
            nclass = NULL, 
            xlab = "live stand volume", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))

binnedplot (NDT1_t2$climate1, 
            NDT1_t2$resids, 
            nclass = NULL, 
            xlab = "", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))

# Diagnostic plots look good

# Looking at effect of forest height at the average amount of rainfall in September
plot(NDT1_t2$live_stand_volume_125,NDT1_t2$fire_pres)
curve(invlogit(coef(glm_best_NDT1)[1] +coef(glm_best_NDT1)[2]*mean(NDT1_t2$climate1) + coef(glm_best_NDT1)[3]*x), add=TRUE)

# looking at effect of climate1 at the average forest height.
plot(NDT1_t2$climate1,NDT1_t2$fire_pres)
curve(invlogit(coef(glm_best_NDT1)[1] +coef(glm_best_NDT1)[2]*x + coef(glm_best_NDT1)[3]*mean(NDT1_t2$live_stand_volume_125)), add=TRUE)


# create model table (only do this once) and add the relevant data
top_mod_table <- data.frame (matrix (ncol = 16, nrow = 0))
colnames (top_mod_table) <- c ("ZONE", "TREED", "Model_terms", "intercept", "coef_climate_1", "coef_climate_2", "coef_climate_interaction", "coef_stand_height", "coef_live_stand_volume_125", "coef_proj_age", "coef_vegtypeD", "coef_vegtypeOP", "coef_vegtypeS", "coef_vegtypeTB", "coef_vegtypeTC", "coef_vegtypeTM")



##STILL NEED TO ADD DATA FOR TABLE

##Add data for NDT1
top_mod_table[1,1]<-"NDT1"
top_mod_table[1,2]<-"Y"
top_mod_table[1,3]<-"fire_pres ~ ppt09 + proj_height_1" ######### UPDATE
top_mod_table[1,4]<- coef(glm_best_NDT1)[1] #Intercept
top_mod_table[1,5]<- coef(glm_best_NDT1)[2] #Climate variable 1
#top_mod_table[1,6]<- coef(glm_best_NDT1)[2] #Climate variable 2
#top_mod_table[1,7]<- coef(glm_best_NDT1)[3] #Interaction climate variables
#top_mod_table[1,8]<- coef(glm_best_NDT1)[3] #coef_stand_height
#top_mod_table[1,9]<- coef(glm_best_NDT1)[3] #live_stand_volume_125
#top_mod_table[1,10]<- coef(glm_best_NDT1)[4] #proj_age_1
#top_mod_table[1,11]<- coef(glm_best_NDT1)[4] #coefficient vegtypeD
#top_mod_table[1,12]<- coef(glm_best_NDT1)[4] #coefficient vegtypeOP
#top_mod_table[1,13]<- coef(glm_best_NDT1)[4] #coefficient vegtypeS
#top_mod_table[1,14]<- coef(glm_best_NDT1)[4] #coefficient vegtypeTB
#top_mod_table[1,15]<- coef(glm_best_NDT1)[4] #coefficient vegtypeTC
#top_mod_table[1,16]<- coef(glm_best_NDT1)[5] #coefficient vegtypeTM
top_mod_table ##Determine if better way to represent categories for vegtype, and if each climate variable should have its own column

########################## NDT1 Model Selection Complete ###################



```



############### Now choose the next NDT zone and repeat ########
Note: currently doing  those with one climate variable)
Models complete above: NDT4, NDT1
Models to still do henceforth:NDT2, NDT3, NDT5


Select next zone: NDT2

```{r}
zones1<-c("NDT2") #Do one zone at a time

prop<-0.75

#Create empty table
table.glm.climate.simple <- data.frame (matrix (ncol = 5, nrow = 0))
colnames (table.glm.climate.simple) <- c ("model", "edf", "aic", "auc.valid", "NDT")

########### 1. Climate and vegtype ############
for (g in 1:100){

for (h in 1:length(zones1)) {
  dat2<- dat_lightning_t %>% dplyr::filter(ntrl_ds ==zones1[h])

#for (i in 1: length(all.poss.mods.clim.vegtype2)){
#  print(paste((all.poss.mods.clim.vegtype2[i]), (zones1[h]), sep=" "))
  
for (i in 1: length(zones1)){
  print(paste((all.poss.mods.clim.vegtype2[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, variables_all[i])
  model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, !!variables_all)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="fire_pres") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.aic, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.clim.vegtype2, big.mod, df.train=dat1, df.test=Valid)

#terms in each model
x1.1 <- unlist(sapply(mods.fit, '[', 1))
x1.1
#Aic for models
x3.1 <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3.1
#auc from validation data
x4.1 <- unlist(sapply(mods.fit, '[', 4))
x4.1
#combining all as df
tab.sum.climate <- cbind.data.frame(model=x1.1, edf=x3.1[,1], aic=x3.1[,2], auc.valid=x4.1)
tab.sum.climate$NDT<-c("NDT2")
tab.sum.climate 

table.glm.climate.simple<-rbind(table.glm.climate.simple, tab.sum.climate)

}
}
}


```

Now that we have run the model 100 times, we want the average AIC and AUC for each variable combination.

```{r}
head(table.glm.climate.simple)
table(table.glm.climate.simple$model) # 100 per model

AIC_lightning_NDT2_treed_climate<-table.glm.climate.simple

AIC_lightning_NDT2_treed_summary_climate<- AIC_lightning_NDT2_treed_climate %>%
  group_by(model) %>%
  summarise(meanAIC=mean(aic),
            meanAUC=mean(auc.valid),
            sdAUC=sd(auc.valid),
            )

AIC_lightning_NDT2_treed_summary_climate2<- AIC_lightning_NDT2_treed_summary_climate %>%
  mutate(deltaAIC=meanAIC-min(meanAIC))

head(AIC_lightning_NDT2_treed_summary_climate2)
```

#Now repeat for VRI data

```{r}
########### 2. VRI ############
#Create empty table
table.glm.VRI.simple <- data.frame (matrix (ncol = 5, nrow = 0))
colnames (table.glm.VRI.simple) <- c ("model", "edf", "aic", "auc.valid", "NDT")

####
for (g in 1:100){

for (h in 1:length(zones1)) {
  dat2<- dat_lightning_t %>% dplyr::filter(ntrl_ds ==zones1[h])

#for (i in 1: length(all.poss.mods.VRI)){
#  print(paste((all.poss.mods.VRI[i]), (zones1[h]), sep=" "))
  
for (i in 1: length(zones1)){
  print(paste((all.poss.mods.VRI[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, variables_all[i])
  model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, !!variables_all)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="fire_pres") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.aic, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.VRI, big.mod, df.train=dat1, df.test=Valid)

#terms in each model
x1.1 <- unlist(sapply(mods.fit, '[', 1))
x1.1
#Aic for models
x3.1 <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3.1
#auc from validation data
x4.1 <- unlist(sapply(mods.fit, '[', 4))
x4.1
#combining all as df
tab.sum.VRI <- cbind.data.frame(model=x1.1, edf=x3.1[,1], aic=x3.1[,2], auc.valid=x4.1)
tab.sum.VRI$NDT<-c("NDT2")
tab.sum.VRI 

table.glm.VRI.simple<-rbind(table.glm.VRI.simple, tab.sum.VRI)

}
}
}
```

Now that we have run the model 100 times, we want the average AIC and AUC for each variable combination.

```{r}
head(table.glm.VRI.simple)
table(table.glm.VRI.simple$model) # 100 per model

AIC_lightning_NDT2_treed_VRI<-table.glm.VRI.simple

AIC_lightning_NDT2_treed_summary_VRI<- AIC_lightning_NDT2_treed_VRI %>%
  group_by(model) %>%
  summarise(meanAIC=mean(aic),
            meanAUC=mean(auc.valid),
            sdAUC=sd(auc.valid),
            )

AIC_lightning_NDT2_treed_summary_VRI2<- AIC_lightning_NDT2_treed_summary_VRI %>%
  mutate(deltaAIC=meanAIC-min(meanAIC))

head(AIC_lightning_NDT2_treed_summary_VRI2)
```


#Now repeat for topography

```{r}
########### 3. topo ############
#Create empty table
table.glm.topo.simple <- data.frame (matrix (ncol = 5, nrow = 0))
colnames (table.glm.topo.simple) <- c ("model", "edf", "aic", "auc.valid", "NDT")

#
for (g in 1:100){

for (h in 1:length(zones1)) {
  dat2<- dat_lightning_t %>% dplyr::filter(ntrl_ds ==zones1[h])

#for (i in 1: length(all.poss.mods.topo)){
#  print(paste((all.poss.mods.topo[i]), (zones1[h]), sep=" "))
  
for (i in 1: length(zones1)){
  print(paste((all.poss.mods.topo[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, variables_all[i])
  model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, !!variables_all)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="fire_pres") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.aic, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.topo, big.mod, df.train=dat1, df.test=Valid)

#terms in each model
x1.1 <- unlist(sapply(mods.fit, '[', 1))
x1.1
#Aic for models
x3.1 <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3.1
#auc from validation data
x4.1 <- unlist(sapply(mods.fit, '[', 4))
x4.1
#combining all as df
tab.sum.topo <- cbind.data.frame(model=x1.1, edf=x3.1[,1], aic=x3.1[,2], auc.valid=x4.1)
tab.sum.topo$NDT<-c("NDT2")
tab.sum.topo 

table.glm.topo.simple<-rbind(table.glm.topo.simple, tab.sum.topo)

}
}
}
```

Now that we have run the model 100 times, we want the average AIC and AUC for each variable combination.

```{r}
head(table.glm.topo.simple)
table(table.glm.topo.simple$model) # 100 per model

AIC_lightning_NDT2_treed_topo<-table.glm.topo.simple

AIC_lightning_NDT2_treed_summary_topo<- AIC_lightning_NDT2_treed_topo %>%
  group_by(model) %>%
  summarise(meanAIC=mean(aic),
            meanAUC=mean(auc.valid),
            sdAUC=sd(auc.valid),
            )

AIC_lightning_NDT2_treed_summary_topo2<- AIC_lightning_NDT2_treed_summary_topo %>%
  mutate(deltaAIC=meanAIC-min(meanAIC))

head(AIC_lightning_NDT2_treed_summary_topo2)
```


#Now repeat for infrastructure

```{r}
########### 4. infra ############
#Create empty table
table.glm.infra.simple <- data.frame (matrix (ncol = 5, nrow = 0))
colnames (table.glm.infra.simple) <- c ("model", "edf", "aic", "auc.valid", "NDT")

#
for (g in 1:100){

for (h in 1:length(zones1)) {
  dat2<- dat_lightning_t %>% dplyr::filter(ntrl_ds ==zones1[h])

#for (i in 1: length(all.poss.mods.infra)){
#  print(paste((all.poss.mods.infra[i]), (zones1[h]), sep=" "))
  
for (i in 1: length(zones1)){
  print(paste((all.poss.mods.infra[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, variables_all[i])
  model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, !!variables_all)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="fire_pres") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.aic, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.infra, big.mod, df.train=dat1, df.test=Valid)

#terms in each model
x1.1 <- unlist(sapply(mods.fit, '[', 1))
x1.1
#Aic for models
x3.1 <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3.1
#auc from validation data
x4.1 <- unlist(sapply(mods.fit, '[', 4))
x4.1
#combining all as df
tab.sum.infra <- cbind.data.frame(model=x1.1, edf=x3.1[,1], aic=x3.1[,2], auc.valid=x4.1)
tab.sum.infra$NDT<-c("NDT2")
tab.sum.infra 

table.glm.infra.simple<-rbind(table.glm.infra.simple, tab.sum.infra)

}
}
}
```

Now that we have run the model 100 times, we want the average AIC and AUC for each variable combination.

```{r}
head(table.glm.infra.simple)
table(table.glm.infra.simple$model) # 100 per model

AIC_lightning_NDT2_treed_infra<-table.glm.infra.simple

AIC_lightning_NDT2_treed_summary_infra<- AIC_lightning_NDT2_treed_infra %>%
  group_by(model) %>%
  summarise(meanAIC=mean(aic),
            meanAUC=mean(auc.valid),
            sdAUC=sd(auc.valid),
            )

AIC_lightning_NDT2_treed_summary_infra2<- AIC_lightning_NDT2_treed_summary_infra %>%
  mutate(deltaAIC=meanAIC-min(meanAIC))

head(AIC_lightning_NDT2_treed_summary_infra2)
```

#Now combine the datatables and save to computer
```{r}
NDT2_l_models_treed<-rbind(AIC_lightning_NDT2_treed_summary_climate2, AIC_lightning_NDT2_treed_summary_VRI2, AIC_lightning_NDT2_treed_summary_topo2, AIC_lightning_NDT2_treed_summary_infra2)
NDT2_l_models_treed
NDT2_l_models_treed$NDT<-"NDT2"

write.csv(NDT2_l_models_treed, file="D:\\Fire\\fire_data\\raw_data\\NDT2_lightning_models_treed.csv")
```




Now choose the top variables and create final model. The below code will need to be updated manually, depending on what the results of the above analyses are.

######## UPDATE BELOW #########

```{r}
##### TOP MODEL####
NDT2_t<-dat_lightning_t %>%
  filter(ntrl_ds=="NDT2")

NDT2_t2<-NDT2_t %>% drop_na(live_stand_volume_125, vegtype, climate1, climate2, proj_height_1)

glm_best_NDT2<- glm(fire_pres ~ scale(climate1)*scale(climate2) +
             scale(live_stand_volume_125) +
               scale(proj_height_1) +
               vegtype, 
           data= NDT2_t2,
           family = binomial,
           na.action=na.omit)

summary(glm_best_NDT2)

# model diagnostic plots
binnedplot (fitted(glm_best_NDT2), 
            residuals(glm_best_NDT2), 
            nclass = NULL, 
            xlab = "Expected Values", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))


NDT2_t2$resids<-resid(glm_best_NDT2)

binnedplot (NDT2_t2$live_stand_volume_125, 
            NDT2_t2$resids, 
            nclass = NULL, 
            xlab = "live stand volume", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))

binnedplot (NDT2_t2$climate1, 
            NDT2_t2$resids, 
            nclass = NULL, 
            xlab = "", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))

# Diagnostic plots look good

# Looking at effect of forest height at the average amount of rainfall in September
plot(NDT2_t2$live_stand_volume_125,NDT2_t2$fire_pres)
curve(invlogit(coef(glm_best_NDT2)[1] +coef(glm_best_NDT2)[2]*mean(NDT2_t2$climate1) + coef(glm_best_NDT2)[3]*x), add=TRUE)

# looking at effect of climate1 at the average forest height.
plot(NDT2_t2$climate1,NDT2_t2$fire_pres)
curve(invlogit(coef(glm_best_NDT2)[1] +coef(glm_best_NDT2)[2]*x + coef(glm_best_NDT2)[3]*mean(NDT2_t2$live_stand_volume_125)), add=TRUE)


# create model table (only do this once) and add the relevant data
top_mod_table <- data.frame (matrix (ncol = 16, nrow = 0))
colnames (top_mod_table) <- c ("ZONE", "TREED", "Model_terms", "intercept", "coef_climate_1", "coef_climate_2", "coef_climate_interaction", "coef_stand_height", "coef_live_stand_volume_125", "coef_proj_age", "coef_vegtypeD", "coef_vegtypeOP", "coef_vegtypeS", "coef_vegtypeTB", "coef_vegtypeTC", "coef_vegtypeTM")



##STILL NEED TO ADD DATA FOR TABLE

##Add data for NDT2
top_mod_table[1,1]<-"NDT2"
top_mod_table[1,2]<-"Y"
top_mod_table[1,3]<-"fire_pres ~ ppt09 + proj_height_1" ######### UPDATE
top_mod_table[1,4]<- coef(glm_best_NDT2)[1] #Intercept
top_mod_table[1,5]<- coef(glm_best_NDT2)[2] #Climate variable 1
#top_mod_table[1,6]<- coef(glm_best_NDT2)[2] #Climate variable 2
#top_mod_table[1,7]<- coef(glm_best_NDT2)[3] #Interaction climate variables
#top_mod_table[1,8]<- coef(glm_best_NDT2)[3] #coef_stand_height
#top_mod_table[1,9]<- coef(glm_best_NDT2)[3] #live_stand_volume_125
#top_mod_table[1,10]<- coef(glm_best_NDT2)[4] #proj_age_1
#top_mod_table[1,11]<- coef(glm_best_NDT2)[4] #coefficient vegtypeD
#top_mod_table[1,12]<- coef(glm_best_NDT2)[4] #coefficient vegtypeOP
#top_mod_table[1,13]<- coef(glm_best_NDT2)[4] #coefficient vegtypeS
#top_mod_table[1,14]<- coef(glm_best_NDT2)[4] #coefficient vegtypeTB
#top_mod_table[1,15]<- coef(glm_best_NDT2)[4] #coefficient vegtypeTC
#top_mod_table[1,16]<- coef(glm_best_NDT2)[5] #coefficient vegtypeTM
top_mod_table ##Determine if better way to represent categories for vegtype, and if each climate variable should have its own column

########################## NDT2 Model Selection Complete ###################



```






############### Now choose the next NDT zone and repeat ########
Note: currently doing  those with one climate variable)
Models complete above: NDT4, NDT1, NDT2
Models to still do henceforth: NDT3, NDT5


Select next zone: NDT3

```{r}
zones1<-c("NDT3") #Do one zone at a time

prop<-0.75

#Create empty table
table.glm.climate.simple <- data.frame (matrix (ncol = 5, nrow = 0))
colnames (table.glm.climate.simple) <- c ("model", "edf", "aic", "auc.valid", "NDT")

########### 1. Climate and vegtype ############
for (g in 1:100){

for (h in 1:length(zones1)) {
  dat2<- dat_lightning_t %>% dplyr::filter(ntrl_ds ==zones1[h])

#for (i in 1: length(all.poss.mods.clim.vegtype2)){
#  print(paste((all.poss.mods.clim.vegtype2[i]), (zones1[h]), sep=" "))
  
for (i in 1: length(zones1)){
  print(paste((all.poss.mods.clim.vegtype2[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, variables_all[i])
  model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, !!variables_all)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="fire_pres") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.aic, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.clim.vegtype2, big.mod, df.train=dat1, df.test=Valid)

#terms in each model
x1.1 <- unlist(sapply(mods.fit, '[', 1))
x1.1
#Aic for models
x3.1 <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3.1
#auc from validation data
x4.1 <- unlist(sapply(mods.fit, '[', 4))
x4.1
#combining all as df
tab.sum.climate <- cbind.data.frame(model=x1.1, edf=x3.1[,1], aic=x3.1[,2], auc.valid=x4.1)
tab.sum.climate$NDT<-c("NDT3")
tab.sum.climate 

table.glm.climate.simple<-rbind(table.glm.climate.simple, tab.sum.climate)

}
}
}


```

Now that we have run the model 100 times, we want the average AIC and AUC for each variable combination.

```{r}
head(table.glm.climate.simple)
table(table.glm.climate.simple$model) # 100 per model

AIC_lightning_NDT3_treed_climate<-table.glm.climate.simple

AIC_lightning_NDT3_treed_summary_climate<- AIC_lightning_NDT3_treed_climate %>%
  group_by(model) %>%
  summarise(meanAIC=mean(aic),
            meanAUC=mean(auc.valid),
            sdAUC=sd(auc.valid),
            )

AIC_lightning_NDT3_treed_summary_climate2<- AIC_lightning_NDT3_treed_summary_climate %>%
  mutate(deltaAIC=meanAIC-min(meanAIC))

head(AIC_lightning_NDT3_treed_summary_climate2)
```

#Now repeat for VRI data

```{r}
########### 2. VRI ############
#Create empty table
table.glm.VRI.simple <- data.frame (matrix (ncol = 5, nrow = 0))
colnames (table.glm.VRI.simple) <- c ("model", "edf", "aic", "auc.valid", "NDT")

####
for (g in 1:100){

for (h in 1:length(zones1)) {
  dat2<- dat_lightning_t %>% dplyr::filter(ntrl_ds ==zones1[h])

#for (i in 1: length(all.poss.mods.VRI)){
#  print(paste((all.poss.mods.VRI[i]), (zones1[h]), sep=" "))
  
for (i in 1: length(zones1)){
  print(paste((all.poss.mods.VRI[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, variables_all[i])
  model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, !!variables_all)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="fire_pres") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.aic, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.VRI, big.mod, df.train=dat1, df.test=Valid)

#terms in each model
x1.1 <- unlist(sapply(mods.fit, '[', 1))
x1.1
#Aic for models
x3.1 <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3.1
#auc from validation data
x4.1 <- unlist(sapply(mods.fit, '[', 4))
x4.1
#combining all as df
tab.sum.VRI <- cbind.data.frame(model=x1.1, edf=x3.1[,1], aic=x3.1[,2], auc.valid=x4.1)
tab.sum.VRI$NDT<-c("NDT3")
tab.sum.VRI 

table.glm.VRI.simple<-rbind(table.glm.VRI.simple, tab.sum.VRI)

}
}
}
```

Now that we have run the model 100 times, we want the average AIC and AUC for each variable combination.

```{r}
head(table.glm.VRI.simple)
table(table.glm.VRI.simple$model) # 100 per model

AIC_lightning_NDT3_treed_VRI<-table.glm.VRI.simple

AIC_lightning_NDT3_treed_summary_VRI<- AIC_lightning_NDT3_treed_VRI %>%
  group_by(model) %>%
  summarise(meanAIC=mean(aic),
            meanAUC=mean(auc.valid),
            sdAUC=sd(auc.valid),
            )

AIC_lightning_NDT3_treed_summary_VRI2<- AIC_lightning_NDT3_treed_summary_VRI %>%
  mutate(deltaAIC=meanAIC-min(meanAIC))

head(AIC_lightning_NDT3_treed_summary_VRI2)
```


#Now repeat for topography

```{r}
########### 3. topo ############
#Create empty table
table.glm.topo.simple <- data.frame (matrix (ncol = 5, nrow = 0))
colnames (table.glm.topo.simple) <- c ("model", "edf", "aic", "auc.valid", "NDT")

#
for (g in 1:100){

for (h in 1:length(zones1)) {
  dat2<- dat_lightning_t %>% dplyr::filter(ntrl_ds ==zones1[h])

#for (i in 1: length(all.poss.mods.topo)){
#  print(paste((all.poss.mods.topo[i]), (zones1[h]), sep=" "))
  
for (i in 1: length(zones1)){
  print(paste((all.poss.mods.topo[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, variables_all[i])
  model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, !!variables_all)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="fire_pres") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.aic, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.topo, big.mod, df.train=dat1, df.test=Valid)

#terms in each model
x1.1 <- unlist(sapply(mods.fit, '[', 1))
x1.1
#Aic for models
x3.1 <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3.1
#auc from validation data
x4.1 <- unlist(sapply(mods.fit, '[', 4))
x4.1
#combining all as df
tab.sum.topo <- cbind.data.frame(model=x1.1, edf=x3.1[,1], aic=x3.1[,2], auc.valid=x4.1)
tab.sum.topo$NDT<-c("NDT3")
tab.sum.topo 

table.glm.topo.simple<-rbind(table.glm.topo.simple, tab.sum.topo)

}
}
}
```

Now that we have run the model 100 times, we want the average AIC and AUC for each variable combination.

```{r}
head(table.glm.topo.simple)
table(table.glm.topo.simple$model) # 100 per model

AIC_lightning_NDT3_treed_topo<-table.glm.topo.simple

AIC_lightning_NDT3_treed_summary_topo<- AIC_lightning_NDT3_treed_topo %>%
  group_by(model) %>%
  summarise(meanAIC=mean(aic),
            meanAUC=mean(auc.valid),
            sdAUC=sd(auc.valid),
            )

AIC_lightning_NDT3_treed_summary_topo2<- AIC_lightning_NDT3_treed_summary_topo %>%
  mutate(deltaAIC=meanAIC-min(meanAIC))

head(AIC_lightning_NDT3_treed_summary_topo2)
```


#Now repeat for infrastructure

```{r}
########### 4. infra ############
#Create empty table
table.glm.infra.simple <- data.frame (matrix (ncol = 5, nrow = 0))
colnames (table.glm.infra.simple) <- c ("model", "edf", "aic", "auc.valid", "NDT")

#
for (g in 1:100){

for (h in 1:length(zones1)) {
  dat2<- dat_lightning_t %>% dplyr::filter(ntrl_ds ==zones1[h])

#for (i in 1: length(all.poss.mods.infra)){
#  print(paste((all.poss.mods.infra[i]), (zones1[h]), sep=" "))
  
for (i in 1: length(zones1)){
  print(paste((all.poss.mods.infra[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, variables_all[i])
  model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, !!variables_all)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="fire_pres") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.aic, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.infra, big.mod, df.train=dat1, df.test=Valid)

#terms in each model
x1.1 <- unlist(sapply(mods.fit, '[', 1))
x1.1
#Aic for models
x3.1 <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3.1
#auc from validation data
x4.1 <- unlist(sapply(mods.fit, '[', 4))
x4.1
#combining all as df
tab.sum.infra <- cbind.data.frame(model=x1.1, edf=x3.1[,1], aic=x3.1[,2], auc.valid=x4.1)
tab.sum.infra$NDT<-c("NDT3")
tab.sum.infra 

table.glm.infra.simple<-rbind(table.glm.infra.simple, tab.sum.infra)

}
}
}
```

Now that we have run the model 100 times, we want the average AIC and AUC for each variable combination.

```{r}
head(table.glm.infra.simple)
table(table.glm.infra.simple$model) # 100 per model

AIC_lightning_NDT3_treed_infra<-table.glm.infra.simple

AIC_lightning_NDT3_treed_summary_infra<- AIC_lightning_NDT3_treed_infra %>%
  group_by(model) %>%
  summarise(meanAIC=mean(aic),
            meanAUC=mean(auc.valid),
            sdAUC=sd(auc.valid),
            )

AIC_lightning_NDT3_treed_summary_infra2<- AIC_lightning_NDT3_treed_summary_infra %>%
  mutate(deltaAIC=meanAIC-min(meanAIC))

head(AIC_lightning_NDT3_treed_summary_infra2)
```

#Now combine the datatables and save to computer
```{r}
NDT3_l_models_treed<-rbind(AIC_lightning_NDT3_treed_summary_climate2, AIC_lightning_NDT3_treed_summary_VRI2, AIC_lightning_NDT3_treed_summary_topo2, AIC_lightning_NDT3_treed_summary_infra2)
NDT3_l_models_treed
NDT3_l_models_treed$NDT<-"NDT3"

write.csv(NDT3_l_models_treed, file="D:\\Fire\\fire_data\\raw_data\\NDT3_lightning_models_treed.csv")
```






Now choose the top variables and create final model. The below code will need to be updated manually, depending on what the results of the above analyses are.

######## UPDATE BELOW #########

```{r}
##### TOP MODEL####
NDT3_t<-dat_lightning_t %>%
  filter(ntrl_ds=="NDT3")

NDT3_t2<-NDT3_t %>% drop_na(live_stand_volume_125, vegtype, climate1, climate2, proj_height_1)

glm_best_NDT3<- glm(fire_pres ~ scale(climate1)*scale(climate2) +
             scale(live_stand_volume_125) +
               scale(proj_height_1) +
               vegtype, 
           data= NDT3_t2,
           family = binomial,
           na.action=na.omit)

summary(glm_best_NDT3)

# model diagnostic plots
binnedplot (fitted(glm_best_NDT3), 
            residuals(glm_best_NDT3), 
            nclass = NULL, 
            xlab = "Expected Values", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))


NDT3_t2$resids<-resid(glm_best_NDT3)

binnedplot (NDT3_t2$live_stand_volume_125, 
            NDT3_t2$resids, 
            nclass = NULL, 
            xlab = "live stand volume", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))

binnedplot (NDT3_t2$climate1, 
            NDT3_t2$resids, 
            nclass = NULL, 
            xlab = "", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))

# Diagnostic plots look good

# Looking at effect of forest height at the average amount of rainfall in September
plot(NDT3_t2$live_stand_volume_125,NDT3_t2$fire_pres)
curve(invlogit(coef(glm_best_NDT3)[1] +coef(glm_best_NDT3)[2]*mean(NDT3_t2$climate1) + coef(glm_best_NDT3)[3]*x), add=TRUE)

# looking at effect of climate1 at the average forest height.
plot(NDT3_t2$climate1,NDT3_t2$fire_pres)
curve(invlogit(coef(glm_best_NDT3)[1] +coef(glm_best_NDT3)[2]*x + coef(glm_best_NDT3)[3]*mean(NDT3_t2$live_stand_volume_125)), add=TRUE)


# create model table (only do this once) and add the relevant data
top_mod_table <- data.frame (matrix (ncol = 16, nrow = 0))
colnames (top_mod_table) <- c ("ZONE", "TREED", "Model_terms", "intercept", "coef_climate_1", "coef_climate_2", "coef_climate_interaction", "coef_stand_height", "coef_live_stand_volume_125", "coef_proj_age", "coef_vegtypeD", "coef_vegtypeOP", "coef_vegtypeS", "coef_vegtypeTB", "coef_vegtypeTC", "coef_vegtypeTM")



##STILL NEED TO ADD DATA FOR TABLE

##Add data for NDT3
top_mod_table[1,1]<-"NDT3"
top_mod_table[1,2]<-"Y"
top_mod_table[1,3]<-"fire_pres ~ ppt09 + proj_height_1" ######### UPDATE
top_mod_table[1,4]<- coef(glm_best_NDT3)[1] #Intercept
top_mod_table[1,5]<- coef(glm_best_NDT3)[2] #Climate variable 1
#top_mod_table[1,6]<- coef(glm_best_NDT3)[2] #Climate variable 2
#top_mod_table[1,7]<- coef(glm_best_NDT3)[3] #Interaction climate variables
#top_mod_table[1,8]<- coef(glm_best_NDT3)[3] #coef_stand_height
#top_mod_table[1,9]<- coef(glm_best_NDT3)[3] #live_stand_volume_125
#top_mod_table[1,10]<- coef(glm_best_NDT3)[4] #proj_age_1
#top_mod_table[1,11]<- coef(glm_best_NDT3)[4] #coefficient vegtypeD
#top_mod_table[1,12]<- coef(glm_best_NDT3)[4] #coefficient vegtypeOP
#top_mod_table[1,13]<- coef(glm_best_NDT3)[4] #coefficient vegtypeS
#top_mod_table[1,14]<- coef(glm_best_NDT3)[4] #coefficient vegtypeTB
#top_mod_table[1,15]<- coef(glm_best_NDT3)[4] #coefficient vegtypeTC
#top_mod_table[1,16]<- coef(glm_best_NDT3)[5] #coefficient vegtypeTM
top_mod_table ##Determine if better way to represent categories for vegtype, and if each climate variable should have its own column

########################## NDT3 Model Selection Complete ###################



```



############### Now choose the next NDT zone and repeat ########
Note: currently doing  those with one climate variable)
Models complete above: NDT4, NDT1, NDT2, NDT3
Models to still do henceforth: NDT5


Select next zone: NDT5

```{r}
zones1<-c("NDT5") #Do one zone at a time

prop<-0.75

#Create empty table
table.glm.climate.simple <- data.frame (matrix (ncol = 5, nrow = 0))
colnames (table.glm.climate.simple) <- c ("model", "edf", "aic", "auc.valid", "NDT")

########### 1. Climate and vegtype ############
for (g in 1:100){

for (h in 1:length(zones1)) {
  dat2<- dat_lightning_t %>% dplyr::filter(ntrl_ds ==zones1[h])

#for (i in 1: length(all.poss.mods.clim.vegtype2)){
#  print(paste((all.poss.mods.clim.vegtype2[i]), (zones1[h]), sep=" "))
  
for (i in 1: length(zones1)){
  print(paste((all.poss.mods.clim.vegtype2[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, variables_all[i])
  model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, !!variables_all)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="fire_pres") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.aic, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.clim.vegtype2, big.mod, df.train=dat1, df.test=Valid)

#terms in each model
x1.1 <- unlist(sapply(mods.fit, '[', 1))
x1.1
#Aic for models
x3.1 <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3.1
#auc from validation data
x4.1 <- unlist(sapply(mods.fit, '[', 4))
x4.1
#combining all as df
tab.sum.climate <- cbind.data.frame(model=x1.1, edf=x3.1[,1], aic=x3.1[,2], auc.valid=x4.1)
tab.sum.climate$NDT<-c("NDT5")
tab.sum.climate 

table.glm.climate.simple<-rbind(table.glm.climate.simple, tab.sum.climate)

}
}
}


```

Now that we have run the model 100 times, we want the average AIC and AUC for each variable combination.

```{r}
head(table.glm.climate.simple)
table(table.glm.climate.simple$model) # 100 per model

AIC_lightning_NDT5_treed_climate<-table.glm.climate.simple

AIC_lightning_NDT5_treed_summary_climate<- AIC_lightning_NDT5_treed_climate %>%
  group_by(model) %>%
  summarise(meanAIC=mean(aic),
            meanAUC=mean(auc.valid),
            sdAUC=sd(auc.valid),
            )

AIC_lightning_NDT5_treed_summary_climate2<- AIC_lightning_NDT5_treed_summary_climate %>%
  mutate(deltaAIC=meanAIC-min(meanAIC))

head(AIC_lightning_NDT5_treed_summary_climate2)
```

#Now repeat for VRI data

This shouldn't be needed anymore because we are removing this variable from all analyses.
For VRI, remove stand_percentage_dead because only 9 records have any values.

```{r}
table(dat2$stand_percentage_dead)

vars.oth2<-c("proj_height_1", "proj_age_1", "live_stand_volume_125") 

#complete list of models using VRI - no interactions
mods.me.tmp2 <- powerSet(vars.oth2) 
#add climate vars to all of the above
mods.me.oth2 <- list()
for (i in 1: length(mods.me.tmp2)) {
   mods.me.oth2[[i]] <- c(mods.me.tmp2[[i]])
}

mods.me.oth2

all.poss.mods.VRIb<-c(1, mods.me.oth2)
all.poss.mods.VRIb
all.poss.mods.VRIb<-all.poss.mods.VRIb[-2]
```


```{r}
########### 2. VRI ############
#Create empty table
table.glm.VRI.simple <- data.frame (matrix (ncol = 5, nrow = 0))
colnames (table.glm.VRI.simple) <- c ("model", "edf", "aic", "auc.valid", "NDT")

####
for (g in 1:100){

for (h in 1:length(zones1)) {
  dat2<- dat_lightning_t %>% dplyr::filter(ntrl_ds ==zones1[h])

#for (i in 1: length(all.poss.mods.VRIb)){
#  print(paste((all.poss.mods.VRIb[i]), (zones1[h]), sep=" "))
  
for (i in 1: length(zones1)){
  print(paste((all.poss.mods.VRIb[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, variables_all[i])
  model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, !!variables_all)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="fire_pres") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.aic, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.VRIb, big.mod, df.train=dat1, df.test=Valid)

#terms in each model
x1.1 <- unlist(sapply(mods.fit, '[', 1))
x1.1
#Aic for models
x3.1 <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3.1
#auc from validation data
x4.1 <- unlist(sapply(mods.fit, '[', 4))
x4.1
#combining all as df
tab.sum.VRI <- cbind.data.frame(model=x1.1, edf=x3.1[,1], aic=x3.1[,2], auc.valid=x4.1)
tab.sum.VRI$NDT<-c("NDT5")
tab.sum.VRI 

table.glm.VRI.simple<-rbind(table.glm.VRI.simple, tab.sum.VRI)

}
}
}
```

Now that we have run the model 100 times, we want the average AIC and AUC for each variable combination.

```{r}
head(table.glm.VRI.simple)
table(table.glm.VRI.simple$model) # 100 per model

AIC_lightning_NDT5_treed_VRI<-table.glm.VRI.simple

AIC_lightning_NDT5_treed_summary_VRI<- AIC_lightning_NDT5_treed_VRI %>%
  group_by(model) %>%
  summarise(meanAIC=mean(aic),
            meanAUC=mean(auc.valid),
            sdAUC=sd(auc.valid),
            )

AIC_lightning_NDT5_treed_summary_VRI2<- AIC_lightning_NDT5_treed_summary_VRI %>%
  mutate(deltaAIC=meanAIC-min(meanAIC))

head(AIC_lightning_NDT5_treed_summary_VRI2)
```


#Now repeat for topography

```{r}
########### 3. topo ############
#Create empty table
table.glm.topo.simple <- data.frame (matrix (ncol = 5, nrow = 0))
colnames (table.glm.topo.simple) <- c ("model", "edf", "aic", "auc.valid", "NDT")

#
for (g in 1:100){

for (h in 1:length(zones1)) {
  dat2<- dat_lightning_t %>% dplyr::filter(ntrl_ds ==zones1[h])

#for (i in 1: length(all.poss.mods.topo)){
#  print(paste((all.poss.mods.topo[i]), (zones1[h]), sep=" "))
  
for (i in 1: length(zones1)){
  print(paste((all.poss.mods.topo[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, variables_all[i])
  model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, !!variables_all)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="fire_pres") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.aic, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.topo, big.mod, df.train=dat1, df.test=Valid)

#terms in each model
x1.1 <- unlist(sapply(mods.fit, '[', 1))
x1.1
#Aic for models
x3.1 <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3.1
#auc from validation data
x4.1 <- unlist(sapply(mods.fit, '[', 4))
x4.1
#combining all as df
tab.sum.topo <- cbind.data.frame(model=x1.1, edf=x3.1[,1], aic=x3.1[,2], auc.valid=x4.1)
tab.sum.topo$NDT<-c("NDT5")
tab.sum.topo 

table.glm.topo.simple<-rbind(table.glm.topo.simple, tab.sum.topo)

}
}
}
```

Now that we have run the model 100 times, we want the average AIC and AUC for each variable combination.

```{r}
head(table.glm.topo.simple)
table(table.glm.topo.simple$model) # 100 per model

AIC_lightning_NDT5_treed_topo<-table.glm.topo.simple

AIC_lightning_NDT5_treed_summary_topo<- AIC_lightning_NDT5_treed_topo %>%
  group_by(model) %>%
  summarise(meanAIC=mean(aic),
            meanAUC=mean(auc.valid),
            sdAUC=sd(auc.valid),
            )

AIC_lightning_NDT5_treed_summary_topo2<- AIC_lightning_NDT5_treed_summary_topo %>%
  mutate(deltaAIC=meanAIC-min(meanAIC))

head(AIC_lightning_NDT5_treed_summary_topo2)
```


#Now repeat for infrastructure

```{r}
########### 4. infra ############
#Create empty table
table.glm.infra.simple <- data.frame (matrix (ncol = 5, nrow = 0))
colnames (table.glm.infra.simple) <- c ("model", "edf", "aic", "auc.valid", "NDT")

#
for (g in 1:100){

for (h in 1:length(zones1)) {
  dat2<- dat_lightning_t %>% dplyr::filter(ntrl_ds ==zones1[h])

#for (i in 1: length(all.poss.mods.infra)){
#  print(paste((all.poss.mods.infra[i]), (zones1[h]), sep=" "))
  
for (i in 1: length(zones1)){
  print(paste((all.poss.mods.infra[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, variables_all[i])
  model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, !!variables_all)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="fire_pres") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.aic, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.infra, big.mod, df.train=dat1, df.test=Valid)

#terms in each model
x1.1 <- unlist(sapply(mods.fit, '[', 1))
x1.1
#Aic for models
x3.1 <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3.1
#auc from validation data
x4.1 <- unlist(sapply(mods.fit, '[', 4))
x4.1
#combining all as df
tab.sum.infra <- cbind.data.frame(model=x1.1, edf=x3.1[,1], aic=x3.1[,2], auc.valid=x4.1)
tab.sum.infra$NDT<-c("NDT5")
tab.sum.infra 

table.glm.infra.simple<-rbind(table.glm.infra.simple, tab.sum.infra)

}
}
}
```

Now that we have run the model 100 times, we want the average AIC and AUC for each variable combination.

```{r}
head(table.glm.infra.simple)
table(table.glm.infra.simple$model) # 100 per model

AIC_lightning_NDT5_treed_infra<-table.glm.infra.simple

AIC_lightning_NDT5_treed_summary_infra<- AIC_lightning_NDT5_treed_infra %>%
  group_by(model) %>%
  summarise(meanAIC=mean(aic),
            meanAUC=mean(auc.valid),
            sdAUC=sd(auc.valid),
            )

AIC_lightning_NDT5_treed_summary_infra2<- AIC_lightning_NDT5_treed_summary_infra %>%
  mutate(deltaAIC=meanAIC-min(meanAIC))

head(AIC_lightning_NDT5_treed_summary_infra2)
```

#Now combine the datatables and save to computer
```{r}
NDT5_l_models_treed<-rbind(AIC_lightning_NDT5_treed_summary_climate2, AIC_lightning_NDT5_treed_summary_VRI2, AIC_lightning_NDT5_treed_summary_topo2, AIC_lightning_NDT5_treed_summary_infra2)
NDT5_l_models_treed
NDT5_l_models_treed$NDT<-"NDT5"

write.csv(NDT5_l_models_treed, file="D:\\Fire\\fire_data\\raw_data\\NDT5_lightning_models_treed.csv")
```




Now choose the top variables and create final model. The below code will need to be updated manually, depending on what the results of the above analyses are.

######## UPDATE BELOW #########

```{r}
##### TOP MODEL####
NDT5_t<-dat_lightning_t %>%
  filter(ntrl_ds=="NDT5")

NDT5_t2<-NDT5_t %>% drop_na(live_stand_volume_125, vegtype, climate1, climate2, proj_height_1)

glm_best_NDT5<- glm(fire_pres ~ scale(climate1)*scale(climate2) +
             scale(live_stand_volume_125) +
               scale(proj_height_1) +
               vegtype, 
           data= NDT5_t2,
           family = binomial,
           na.action=na.omit)

summary(glm_best_NDT5)

# model diagnostic plots
binnedplot (fitted(glm_best_NDT5), 
            residuals(glm_best_NDT5), 
            nclass = NULL, 
            xlab = "Expected Values", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))


NDT5_t2$resids<-resid(glm_best_NDT5)

binnedplot (NDT5_t2$live_stand_volume_125, 
            NDT5_t2$resids, 
            nclass = NULL, 
            xlab = "live stand volume", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))

binnedplot (NDT5_t2$climate1, 
            NDT5_t2$resids, 
            nclass = NULL, 
            xlab = "", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))

# Diagnostic plots look good

# Looking at effect of forest height at the average amount of rainfall in September
plot(NDT5_t2$live_stand_volume_125,NDT5_t2$fire_pres)
curve(invlogit(coef(glm_best_NDT5)[1] +coef(glm_best_NDT5)[2]*mean(NDT5_t2$climate1) + coef(glm_best_NDT5)[3]*x), add=TRUE)

# looking at effect of climate1 at the average forest height.
plot(NDT5_t2$climate1,NDT5_t2$fire_pres)
curve(invlogit(coef(glm_best_NDT5)[1] +coef(glm_best_NDT5)[2]*x + coef(glm_best_NDT5)[3]*mean(NDT5_t2$live_stand_volume_125)), add=TRUE)


# create model table (only do this once) and add the relevant data
top_mod_table <- data.frame (matrix (ncol = 16, nrow = 0))
colnames (top_mod_table) <- c ("ZONE", "TREED", "Model_terms", "intercept", "coef_climate_1", "coef_climate_2", "coef_climate_interaction", "coef_stand_height", "coef_live_stand_volume_125", "coef_proj_age", "coef_vegtypeD", "coef_vegtypeOP", "coef_vegtypeS", "coef_vegtypeTB", "coef_vegtypeTC", "coef_vegtypeTM")



##STILL NEED TO ADD DATA FOR TABLE

##Add data for NDT5
top_mod_table[1,1]<-"NDT5"
top_mod_table[1,2]<-"Y"
top_mod_table[1,3]<-"fire_pres ~ ppt09 + proj_height_1" ######### UPDATE
top_mod_table[1,4]<- coef(glm_best_NDT5)[1] #Intercept
top_mod_table[1,5]<- coef(glm_best_NDT5)[2] #Climate variable 1
#top_mod_table[1,6]<- coef(glm_best_NDT5)[2] #Climate variable 2
#top_mod_table[1,7]<- coef(glm_best_NDT5)[3] #Interaction climate variables
#top_mod_table[1,8]<- coef(glm_best_NDT5)[3] #coef_stand_height
#top_mod_table[1,9]<- coef(glm_best_NDT5)[3] #live_stand_volume_125
#top_mod_table[1,10]<- coef(glm_best_NDT5)[4] #proj_age_1
#top_mod_table[1,11]<- coef(glm_best_NDT5)[4] #coefficient vegtypeD
#top_mod_table[1,12]<- coef(glm_best_NDT5)[4] #coefficient vegtypeOP
#top_mod_table[1,13]<- coef(glm_best_NDT5)[4] #coefficient vegtypeS
#top_mod_table[1,14]<- coef(glm_best_NDT5)[4] #coefficient vegtypeTB
#top_mod_table[1,15]<- coef(glm_best_NDT5)[4] #coefficient vegtypeTC
#top_mod_table[1,16]<- coef(glm_best_NDT5)[5] #coefficient vegtypeTM
top_mod_table ##Determine if better way to represent categories for vegtype, and if each climate variable should have its own column

########################## NDT5 Model Selection Complete ###################



```






############### Part 2 of 4 Model Series: Lightning Caused Fires, No Trees ##########

Because these areas are predominately not full of trees, we will ignore the VRI. Some locations will still have some VRI attributes because trees may exist on <50% of the plot, but many plots will have no VRI attributes. So we will ignore the VRI results for this section.

For lightning caused fires with no trees, the variables of interest include:

1. Climate variable(s)
2. vegtype2 (with additional categories)
3. slope
4. aspect (cos)
5. elevation
6. Various distance to infrastructure variables (dist_mun, dist_dam, dist_nat, dist_pow, dist_mine, dist_any) - no interactions

Variables to be added after initial model selection for next round model selection:
1. Wind Speed (to be added to final investigated model)
2. distance to infrastructure (to be added to final investigated model)
3. Road density (to be added to final investigated model) --> not for lightning, just for person caused fires for ignitions
4. bclcs_level_5_2 (land use) (to be added to final investigated model)


Interactions of interest: two-way interactions between climate (1) and vegtype (5); two-way interactions between topography measures (6-8).

===

Select first NDT: NDT4 

```{r}
zones1<-c("NDT4") #Do one zone at a time

filenames<-list()
prop<-0.75

########### 1. Climate and vegtype ############
#for (g in 1:100){

for (h in 1:length(zones1)) {
  dat2<- dat_lightning_nt %>% dplyr::filter(ntrl_ds ==zones1[h])

for (i in 1: length(all.poss.mods.clim.vegtype2)){
  print(paste((all.poss.mods.clim.vegtype2[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, variables_all[i])
  model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, !!variables_all)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="fire_pres") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.aic, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.clim.vegtype2, big.mod, df.train=dat1, df.test=Valid)

}
}
}


```

Now extract elements from the output .

```{r}
#terms in each model
x1 <- unlist(sapply(mods.fit, '[', 1))
x1
#Aic for models
x3 <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3
#auc from validation data
x4 <- unlist(sapply(mods.fit, '[', 4))
x4
#combining all as df
tab.sum.climate.nt <- cbind.data.frame(model=x1, edf=x3[,1], aic=x3[,2], auc.valid=x4)
tab.sum.climate.nt$NDT<-c("NDT4 No trees")
tab.sum.climate.nt$delta.aic<- tab.sum.climate.nt$aic - (min(tab.sum.climate.nt$aic))
tab.sum.climate.nt 

```


#Now repeat for topography

```{r}

########### 2. Topography ############
#for (g in 1:100){

for (h in 1:length(zones1)) {
 dat2<- dat_lightning_nt %>% dplyr::filter(ntrl_ds ==zones1[h])

for (i in 1: length(all.poss.mods.topo)){
  print(paste((all.poss.mods.topo[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, variables_all[i])
  model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, !!variables_all)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="fire_pres") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.aic, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.topo, big.mod, df.train=dat1, df.test=Valid)

}
}
}


```

Now extract elements from the output .

```{r}
#terms in each model
x1c <- unlist(sapply(mods.fit, '[', 1))
x1c
#Aic for models
x3c <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3c
#auc from validation data
x4c <- unlist(sapply(mods.fit, '[', 4))
x4c
#combining all as df
tab.sum.topo.nt <- cbind.data.frame(model=x1c, edf=x3c[,1], aic=x3c[,2], auc.valid=x4c)
tab.sum.topo.nt$NDT<-c("NDT4 No trees")
tab.sum.topo.nt$delta.aic<- tab.sum.topo.nt$aic - (min(tab.sum.topo.nt$aic))
tab.sum.topo.nt

```


```{r}
write.csv(tab.sum.topo, file="D:\\Fire\\fire_data\\raw_data\\NDT4_tab.sum.topo_NT.csv")

```

#Now combine the datatables and save to computer

```{r}
NDT4_l_models_nt<-rbind(tab.sum.climate.nt, tab.sum.topo.nt)
NDT4_l_models_nt

write.csv(NDT4_l_models_nt, file="D:\\Fire\\fire_data\\raw_data\\NDT4_lightning_models_nt.csv")
```

Now choose the top variables and create final model. The below code will need to be updated manually, depending on what the results of the above analyses are.

######## UPDATE BELOW #########

```{r}
##### TOP MODEL####
NDT4_t<-dat_lightning_nt %>%
  filter(ntrl_ds=="NDT4")

NDT4_t2<-NDT4_t %>% drop_na(live_stand_volume_125, vegtype, climate1, climate2, proj_height_1)

glm_best_NDT4<- glm(fire_pres ~ scale(climate1)*scale(climate2) +
             scale(live_stand_volume_125) +
               scale(proj_height_1) +
               vegtype, 
           data= NDT4_t2,
           family = binomial,
           na.action=na.omit)

summary(glm_best_NDT4)

# model diagnostic plots
binnedplot (fitted(glm_best_NDT4), 
            residuals(glm_best_NDT4), 
            nclass = NULL, 
            xlab = "Expected Values", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))


NDT4_t2$resids<-resid(glm_best_NDT4)

binnedplot (NDT4_t2$live_stand_volume_125, 
            NDT4_t2$resids, 
            nclass = NULL, 
            xlab = "live stand volume", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))

binnedplot (NDT4_t2$climate1, 
            NDT4_t2$resids, 
            nclass = NULL, 
            xlab = "", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))

# Diagnostic plots look good

# Looking at effect of forest height at the average amount of rainfall in September
plot(NDT4_t2$live_stand_volume_125,NDT4_t2$fire_pres)
curve(invlogit(coef(glm_best_NDT4)[1] +coef(glm_best_NDT4)[2]*mean(NDT4_t2$climate1) + coef(glm_best_NDT4)[3]*x), add=TRUE)

# looking at effect of climate1 at the average forest height.
plot(NDT4_t2$climate1,NDT4_t2$fire_pres)
curve(invlogit(coef(glm_best_NDT4)[1] +coef(glm_best_NDT4)[2]*x + coef(glm_best_NDT4)[3]*mean(NDT4_t2$live_stand_volume_125)), add=TRUE)


# create model table (only do this once) and add the relevant data
top_mod_table <- data.frame (matrix (ncol = 16, nrow = 0))
colnames (top_mod_table) <- c ("ZONE", "TREED", "Model_terms", "intercept", "coef_climate_1", "coef_climate_2", "coef_climate_interaction", "coef_stand_height", "coef_live_stand_volume_125", "coef_proj_age", "coef_vegtypeD", "coef_vegtypeOP", "coef_vegtypeS", "coef_vegtypeTB", "coef_vegtypeTC", "coef_vegtypeTM")



##STILL NEED TO ADD DATA FOR TABLE

##Add data for NDT4
top_mod_table[1,1]<-"NDT4"
top_mod_table[1,2]<-"Y"
top_mod_table[1,3]<-"fire_pres ~ ppt09 + proj_height_1" ######### UPDATE
top_mod_table[1,4]<- coef(glm_best_NDT4)[1] #Intercept
top_mod_table[1,5]<- coef(glm_best_NDT4)[2] #Climate variable 1
#top_mod_table[1,6]<- coef(glm_best_NDT4)[2] #Climate variable 2
#top_mod_table[1,7]<- coef(glm_best_NDT4)[3] #Interaction climate variables
#top_mod_table[1,8]<- coef(glm_best_NDT4)[3] #coef_stand_height
#top_mod_table[1,9]<- coef(glm_best_NDT4)[3] #live_stand_volume_125
#top_mod_table[1,10]<- coef(glm_best_NDT4)[4] #proj_age_1
#top_mod_table[1,11]<- coef(glm_best_NDT4)[4] #coefficient vegtypeD
#top_mod_table[1,12]<- coef(glm_best_NDT4)[4] #coefficient vegtypeOP
#top_mod_table[1,13]<- coef(glm_best_NDT4)[4] #coefficient vegtypeS
#top_mod_table[1,14]<- coef(glm_best_NDT4)[4] #coefficient vegtypeTB
#top_mod_table[1,15]<- coef(glm_best_NDT4)[4] #coefficient vegtypeTC
#top_mod_table[1,16]<- coef(glm_best_NDT4)[5] #coefficient vegtypeTM
top_mod_table ##Determine if better way to represent categories for vegtype, and if each climate variable should have its own column

########################## NDT4 Model Selection Complete ###################

```
 
############### Now choose the next NDT zone and repeat ########
Note: currently doing  those with one climate variable)
Models complete above: NDT4
Models to still do henceforth:NDT1, NDT2, NDT3, NDT5


Select next zone: NDT1


```{r}
zones1<-c("NDT1") #Do one zone at a time

filenames<-list()
prop<-0.75

########### 1. Climate and vegtype ############
#for (g in 1:100){

for (h in 1:length(zones1)) {
  dat2<- dat_lightning_nt %>% dplyr::filter(ntrl_ds ==zones1[h])

for (i in 1: length(all.poss.mods.clim.vegtype2)){
  print(paste((all.poss.mods.clim.vegtype2[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, variables_all[i])
  model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, !!variables_all)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="fire_pres") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.aic, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.clim.vegtype2, big.mod, df.train=dat1, df.test=Valid)

}
}
}


```

Now extract elements from the output .

```{r}
#terms in each model
x1.1 <- unlist(sapply(mods.fit, '[', 1))
x1.1
#Aic for models
x3.1 <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3.1
#auc from validation data
x4.1 <- unlist(sapply(mods.fit, '[', 4))
x4.1
#combining all as df
tab.sum.climate.nt <- cbind.data.frame(model=x1.1, edf=x3.1[,1], aic=x3.1[,2], auc.valid=x4.1)
tab.sum.climate.nt$NDT<-c("NDT1 No trees")
tab.sum.climate.nt$delta.aic<- tab.sum.climate.nt$aic - (min(tab.sum.climate.nt$aic))
tab.sum.climate.nt 

```


#Now repeat for topography

```{r}

########### 2. Topography ############
#for (g in 1:100){

for (h in 1:length(zones1)) {
 dat2<- dat_lightning_nt %>% dplyr::filter(ntrl_ds ==zones1[h])

for (i in 1: length(all.poss.mods.topo)){
  print(paste((all.poss.mods.topo[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, variables_all[i])
  model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, !!variables_all)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="fire_pres") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.aic, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.topo, big.mod, df.train=dat1, df.test=Valid)

}
}
}


```


Now extract elements from the output.

```{r}
#terms in each model
x1.1c <- unlist(sapply(mods.fit, '[', 1))
x1.1c
#Aic for models
x3.1c <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3.1c
#auc from validation data
x4.1c <- unlist(sapply(mods.fit, '[', 4))
x4.1c
#combining all as df
tab.sum.topo.nt <- cbind.data.frame(model=x1.1c, edf=x3.1c[,1], aic=x3.1c[,2], auc.valid=x4.1c)
tab.sum.topo.nt$NDT<-c("NDT1 No trees")
tab.sum.topo.nt$delta.aic<- tab.sum.topo.nt$aic - (min(tab.sum.topo.nt$aic))
tab.sum.topo.nt

```


```{r}
write.csv(tab.sum.topo, file="D:\\Fire\\fire_data\\raw_data\\NDT1_tab.sum.topo_NT.csv")

```

#Now combine the datatables and save to computer

```{r}
NDT1_l_models_nt<-rbind(tab.sum.climate.nt, tab.sum.topo.nt)
NDT1_l_models_nt

write.csv(NDT1_l_models_nt, file="D:\\Fire\\fire_data\\raw_data\\NDT1_lightning_models_nt.csv")
```

Now choose the top variables and create final model. The below code will need to be updated manually, depending on what the results of the above analyses are.

######## UPDATE BELOW #########

```{r}
##### TOP MODEL####
NDT1_t<-dat_lightning_nt %>%
  filter(ntrl_ds=="NDT1")

NDT1_t2<-NDT1_t %>% drop_na(live_stand_volume_125, vegtype, climate1, climate2, proj_height_1)

glm_best_NDT1<- glm(fire_pres ~ scale(climate1)*scale(climate2) +
             scale(live_stand_volume_125) +
               scale(proj_height_1) +
               vegtype, 
           data= NDT1_t2,
           family = binomial,
           na.action=na.omit)

summary(glm_best_NDT1)

# model diagnostic plots
binnedplot (fitted(glm_best_NDT1), 
            residuals(glm_best_NDT1), 
            nclass = NULL, 
            xlab = "Expected Values", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))


NDT1_t2$resids<-resid(glm_best_NDT1)

binnedplot (NDT1_t2$live_stand_volume_125, 
            NDT1_t2$resids, 
            nclass = NULL, 
            xlab = "live stand volume", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))

binnedplot (NDT1_t2$climate1, 
            NDT1_t2$resids, 
            nclass = NULL, 
            xlab = "", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))

# Diagnostic plots look good

# Looking at effect of forest height at the average amount of rainfall in September
plot(NDT1_t2$live_stand_volume_125,NDT1_t2$fire_pres)
curve(invlogit(coef(glm_best_NDT1)[1] +coef(glm_best_NDT1)[2]*mean(NDT1_t2$climate1) + coef(glm_best_NDT1)[3]*x), add=TRUE)

# looking at effect of climate1 at the average forest height.
plot(NDT1_t2$climate1,NDT1_t2$fire_pres)
curve(invlogit(coef(glm_best_NDT1)[1] +coef(glm_best_NDT1)[2]*x + coef(glm_best_NDT1)[3]*mean(NDT1_t2$live_stand_volume_125)), add=TRUE)


# create model table (only do this once) and add the relevant data
top_mod_table <- data.frame (matrix (ncol = 16, nrow = 0))
colnames (top_mod_table) <- c ("ZONE", "TREED", "Model_terms", "intercept", "coef_climate_1", "coef_climate_2", "coef_climate_interaction", "coef_stand_height", "coef_live_stand_volume_125", "coef_proj_age", "coef_vegtypeD", "coef_vegtypeOP", "coef_vegtypeS", "coef_vegtypeTB", "coef_vegtypeTC", "coef_vegtypeTM")



##STILL NEED TO ADD DATA FOR TABLE

##Add data for NDT1
top_mod_table[1,1]<-"NDT1"
top_mod_table[1,2]<-"Y"
top_mod_table[1,3]<-"fire_pres ~ ppt09 + proj_height_1" ######### UPDATE
top_mod_table[1,4]<- coef(glm_best_NDT1)[1] #Intercept
top_mod_table[1,5]<- coef(glm_best_NDT1)[2] #Climate variable 1
#top_mod_table[1,6]<- coef(glm_best_NDT1)[2] #Climate variable 2
#top_mod_table[1,7]<- coef(glm_best_NDT1)[3] #Interaction climate variables
#top_mod_table[1,8]<- coef(glm_best_NDT1)[3] #coef_stand_height
#top_mod_table[1,9]<- coef(glm_best_NDT1)[3] #live_stand_volume_125
#top_mod_table[1,10]<- coef(glm_best_NDT1)[4] #proj_age_1
#top_mod_table[1,11]<- coef(glm_best_NDT1)[4] #coefficient vegtypeD
#top_mod_table[1,12]<- coef(glm_best_NDT1)[4] #coefficient vegtypeOP
#top_mod_table[1,13]<- coef(glm_best_NDT1)[4] #coefficient vegtypeS
#top_mod_table[1,14]<- coef(glm_best_NDT1)[4] #coefficient vegtypeTB
#top_mod_table[1,15]<- coef(glm_best_NDT1)[4] #coefficient vegtypeTC
#top_mod_table[1,16]<- coef(glm_best_NDT1)[5] #coefficient vegtypeTM
top_mod_table ##Determine if better way to represent categories for vegtype, and if each climate variable should have its own column

########################## NDT1 Model Selection Complete ###################



```



############### Now choose the next NDT zone and repeat ########
Note: currently doing  those with one climate variable)
Models complete above: NDT4, NDT1
Models to still do henceforth:NDT2, NDT3, NDT5


Select next zone: NDT2


```{r}
zones1<-c("NDT2") #Do one zone at a time

filenames<-list()
prop<-0.75

########### 1. Climate and vegtype ############
#for (g in 1:100){

for (h in 1:length(zones1)) {
  dat2<- dat_lightning_nt %>% dplyr::filter(ntrl_ds ==zones1[h])

for (i in 1: length(all.poss.mods.clim.vegtype2)){
  print(paste((all.poss.mods.clim.vegtype2[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, variables_all[i])
  model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, !!variables_all)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="fire_pres") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.aic, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.clim.vegtype2, big.mod, df.train=dat1, df.test=Valid)

}
}
}


```

Now extract elements from the output .

```{r}
#terms in each model
x1.2 <- unlist(sapply(mods.fit, '[', 1))
x1.2
#Aic for models
x3.2 <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3.2
#auc from validation data
x4.2 <- unlist(sapply(mods.fit, '[', 4))
x4.2
#combining all as df
tab.sum.climate.nt <- cbind.data.frame(model=x1.2, edf=x3.2[,1], aic=x3.2[,2], auc.valid=x4.2)
tab.sum.climate.nt$NDT<-c("NDT2 No trees")
tab.sum.climate.nt$delta.aic<- tab.sum.climate.nt$aic - (min(tab.sum.climate.nt$aic))
tab.sum.climate.nt 

```


#Now repeat for topography

```{r}

########### 2. Topography ############
#for (g in 1:100){

for (h in 1:length(zones1)) {
 dat2<- dat_lightning_nt %>% dplyr::filter(ntrl_ds ==zones1[h])

for (i in 1: length(all.poss.mods.topo)){
  print(paste((all.poss.mods.topo[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, variables_all[i])
  model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, !!variables_all)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="fire_pres") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.aic, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.topo, big.mod, df.train=dat1, df.test=Valid)

}
}
}


```

Now extract elements from the output .

```{r}
#terms in each model
x1.2c <- unlist(sapply(mods.fit, '[', 1))
x1.2c
#Aic for models
x3.2c <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3.2c
#auc from validation data
x4.2c <- unlist(sapply(mods.fit, '[', 4))
x4.2c
#combining all as df
tab.sum.topo.nt <- cbind.data.frame(model=x1.2c, edf=x3.2c[,1], aic=x3.2c[,2], auc.valid=x4.2c)
tab.sum.topo.nt$NDT<-c("NDT2 No trees")
tab.sum.topo.nt$delta.aic<- tab.sum.topo.nt$aic - (min(tab.sum.topo.nt$aic))
tab.sum.topo.nt

```

#Now combine the datatables and save to computer

```{r}
NDT2_l_models_nt<-rbind(tab.sum.climate.nt, tab.sum.topo.nt)
NDT2_l_models_nt

write.csv(NDT2_l_models_nt, file="D:\\Fire\\fire_data\\raw_data\\NDT2_lightning_models_nt.csv")
```

Now choose the top variables and create final model. The below code will need to be updated manually, depending on what the results of the above analyses are.

######## UPDATE BELOW #########

```{r}
##### TOP MODEL####
NDT2_t<-dat_lightning_nt %>%
  filter(ntrl_ds=="NDT2")

NDT2_t2<-NDT2_t %>% drop_na(live_stand_volume_125, vegtype, climate1, climate2, proj_height_1)

glm_best_NDT2<- glm(fire_pres ~ scale(climate1)*scale(climate2) +
             scale(live_stand_volume_125) +
               scale(proj_height_1) +
               vegtype, 
           data= NDT2_t2,
           family = binomial,
           na.action=na.omit)

summary(glm_best_NDT2)

# model diagnostic plots
binnedplot (fitted(glm_best_NDT2), 
            residuals(glm_best_NDT2), 
            nclass = NULL, 
            xlab = "Expected Values", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))


NDT2_t2$resids<-resid(glm_best_NDT2)

binnedplot (NDT2_t2$live_stand_volume_125, 
            NDT2_t2$resids, 
            nclass = NULL, 
            xlab = "live stand volume", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))

binnedplot (NDT2_t2$climate1, 
            NDT2_t2$resids, 
            nclass = NULL, 
            xlab = "", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))

# Diagnostic plots look good

# Looking at effect of forest height at the average amount of rainfall in September
plot(NDT2_t2$live_stand_volume_125,NDT2_t2$fire_pres)
curve(invlogit(coef(glm_best_NDT2)[1] +coef(glm_best_NDT2)[2]*mean(NDT2_t2$climate1) + coef(glm_best_NDT2)[3]*x), add=TRUE)

# looking at effect of climate1 at the average forest height.
plot(NDT2_t2$climate1,NDT2_t2$fire_pres)
curve(invlogit(coef(glm_best_NDT2)[1] +coef(glm_best_NDT2)[2]*x + coef(glm_best_NDT2)[3]*mean(NDT2_t2$live_stand_volume_125)), add=TRUE)


# create model table (only do this once) and add the relevant data
top_mod_table <- data.frame (matrix (ncol = 16, nrow = 0))
colnames (top_mod_table) <- c ("ZONE", "TREED", "Model_terms", "intercept", "coef_climate_1", "coef_climate_2", "coef_climate_interaction", "coef_stand_height", "coef_live_stand_volume_125", "coef_proj_age", "coef_vegtypeD", "coef_vegtypeOP", "coef_vegtypeS", "coef_vegtypeTB", "coef_vegtypeTC", "coef_vegtypeTM")



##STILL NEED TO ADD DATA FOR TABLE

##Add data for NDT2
top_mod_table[1,1]<-"NDT2"
top_mod_table[1,2]<-"Y"
top_mod_table[1,3]<-"fire_pres ~ ppt09 + proj_height_1" ######### UPDATE
top_mod_table[1,4]<- coef(glm_best_NDT2)[1] #Intercept
top_mod_table[1,5]<- coef(glm_best_NDT2)[2] #Climate variable 1
#top_mod_table[1,6]<- coef(glm_best_NDT2)[2] #Climate variable 2
#top_mod_table[1,7]<- coef(glm_best_NDT2)[3] #Interaction climate variables
#top_mod_table[1,8]<- coef(glm_best_NDT2)[3] #coef_stand_height
#top_mod_table[1,9]<- coef(glm_best_NDT2)[3] #live_stand_volume_125
#top_mod_table[1,10]<- coef(glm_best_NDT2)[4] #proj_age_1
#top_mod_table[1,11]<- coef(glm_best_NDT2)[4] #coefficient vegtypeD
#top_mod_table[1,12]<- coef(glm_best_NDT2)[4] #coefficient vegtypeOP
#top_mod_table[1,13]<- coef(glm_best_NDT2)[4] #coefficient vegtypeS
#top_mod_table[1,14]<- coef(glm_best_NDT2)[4] #coefficient vegtypeTB
#top_mod_table[1,15]<- coef(glm_best_NDT2)[4] #coefficient vegtypeTC
#top_mod_table[1,16]<- coef(glm_best_NDT2)[5] #coefficient vegtypeTM
top_mod_table ##Determine if better way to represent categories for vegtype, and if each climate variable should have its own column

########################## NDT2 Model Selection Complete ###################



```


############### Now choose the next NDT zone and repeat ########
Note: currently doing  those with one climate variable)
Models complete above: NDT4, NDT1, NDT2
Models to still do henceforth: NDT3, NDT5


Select next zone: NDT3


```{r}
zones1<-c("NDT3") #Do one zone at a time

filenames<-list()
prop<-0.75

########### 1. Climate and vegtype ############
#for (g in 1:100){

for (h in 1:length(zones1)) {
  dat2<- dat_lightning_nt %>% dplyr::filter(ntrl_ds ==zones1[h])

for (i in 1: length(all.poss.mods.clim.vegtype2)){
  print(paste((all.poss.mods.clim.vegtype2[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, variables_all[i])
  model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, !!variables_all)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="fire_pres") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.aic, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.clim.vegtype2, big.mod, df.train=dat1, df.test=Valid)

}
}
}


```

Now extract elements from the output .

```{r}
#terms in each model
x1.3 <- unlist(sapply(mods.fit, '[', 1))
x1.3
#Aic for models
x3.3 <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3.3
#auc from validation data
x4.3 <- unlist(sapply(mods.fit, '[', 4))
x4.3
#combining all as df
tab.sum.climate.nt <- cbind.data.frame(model=x1.3, edf=x3.3[,1], aic=x3.3[,2], auc.valid=x4.3)
tab.sum.climate.nt$NDT<-c("NDT3 No trees")
tab.sum.climate.nt$delta.aic<- tab.sum.climate.nt$aic - (min(tab.sum.climate.nt$aic))
tab.sum.climate.nt 

```

#Now repeat for topography

```{r}

########### 2. Topography ############
#for (g in 1:100){

for (h in 1:length(zones1)) {
 dat2<- dat_lightning_nt %>% dplyr::filter(ntrl_ds ==zones1[h])

for (i in 1: length(all.poss.mods.topo)){
  print(paste((all.poss.mods.topo[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, variables_all[i])
  model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, !!variables_all)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="fire_pres") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.aic, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.topo, big.mod, df.train=dat1, df.test=Valid)

}
}
}


```

Now extract elements from the output .

```{r}
#terms in each model
x1.3c <- unlist(sapply(mods.fit, '[', 1))
x1.3c
#Aic for models
x3.3c <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3.3c
#auc from validation data
x4.3c <- unlist(sapply(mods.fit, '[', 4))
x4.3c
#combining all as df
tab.sum.topo.nt <- cbind.data.frame(model=x1.3c, edf=x3.3c[,1], aic=x3.3c[,2], auc.valid=x4.3c)
tab.sum.topo.nt$NDT<-c("NDT3 No trees")
tab.sum.topo.nt$delta.aic<- tab.sum.topo.nt$aic - (min(tab.sum.topo.nt$aic))
tab.sum.topo.nt

```

#Now combine the datatables and save to computer

```{r}
NDT3_l_models_nt<-rbind(tab.sum.climate.nt, tab.sum.topo.nt)
NDT3_l_models_nt

write.csv(NDT3_l_models_nt, file="D:\\Fire\\fire_data\\raw_data\\NDT3_lightning_models_nt.csv")
```

Now choose the top variables and create final model. The below code will need to be updated manually, depending on what the results of the above analyses are.

######## UPDATE BELOW #########

```{r}
##### TOP MODEL####
NDT3_t<-dat_lightning_nt %>%
  filter(ntrl_ds=="NDT3")

NDT3_t2<-NDT3_t %>% drop_na(live_stand_volume_125, vegtype, climate1, climate2, proj_height_1)

glm_best_NDT3<- glm(fire_pres ~ scale(climate1)*scale(climate2) +
             scale(live_stand_volume_125) +
               scale(proj_height_1) +
               vegtype, 
           data= NDT3_t2,
           family = binomial,
           na.action=na.omit)

summary(glm_best_NDT3)

# model diagnostic plots
binnedplot (fitted(glm_best_NDT3), 
            residuals(glm_best_NDT3), 
            nclass = NULL, 
            xlab = "Expected Values", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))


NDT3_t2$resids<-resid(glm_best_NDT3)

binnedplot (NDT3_t2$live_stand_volume_125, 
            NDT3_t2$resids, 
            nclass = NULL, 
            xlab = "live stand volume", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))

binnedplot (NDT3_t2$climate1, 
            NDT3_t2$resids, 
            nclass = NULL, 
            xlab = "", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))

# Diagnostic plots look good

# Looking at effect of forest height at the average amount of rainfall in September
plot(NDT3_t2$live_stand_volume_125,NDT3_t2$fire_pres)
curve(invlogit(coef(glm_best_NDT3)[1] +coef(glm_best_NDT3)[2]*mean(NDT3_t2$climate1) + coef(glm_best_NDT3)[3]*x), add=TRUE)

# looking at effect of climate1 at the average forest height.
plot(NDT3_t2$climate1,NDT3_t2$fire_pres)
curve(invlogit(coef(glm_best_NDT3)[1] +coef(glm_best_NDT3)[2]*x + coef(glm_best_NDT3)[3]*mean(NDT3_t2$live_stand_volume_125)), add=TRUE)


# create model table (only do this once) and add the relevant data
top_mod_table <- data.frame (matrix (ncol = 16, nrow = 0))
colnames (top_mod_table) <- c ("ZONE", "TREED", "Model_terms", "intercept", "coef_climate_1", "coef_climate_2", "coef_climate_interaction", "coef_stand_height", "coef_live_stand_volume_125", "coef_proj_age", "coef_vegtypeD", "coef_vegtypeOP", "coef_vegtypeS", "coef_vegtypeTB", "coef_vegtypeTC", "coef_vegtypeTM")



##STILL NEED TO ADD DATA FOR TABLE

##Add data for NDT3
top_mod_table[1,1]<-"NDT3"
top_mod_table[1,2]<-"Y"
top_mod_table[1,3]<-"fire_pres ~ ppt09 + proj_height_1" ######### UPDATE
top_mod_table[1,4]<- coef(glm_best_NDT3)[1] #Intercept
top_mod_table[1,5]<- coef(glm_best_NDT3)[2] #Climate variable 1
#top_mod_table[1,6]<- coef(glm_best_NDT3)[2] #Climate variable 2
#top_mod_table[1,7]<- coef(glm_best_NDT3)[3] #Interaction climate variables
#top_mod_table[1,8]<- coef(glm_best_NDT3)[3] #coef_stand_height
#top_mod_table[1,9]<- coef(glm_best_NDT3)[3] #live_stand_volume_125
#top_mod_table[1,10]<- coef(glm_best_NDT3)[4] #proj_age_1
#top_mod_table[1,11]<- coef(glm_best_NDT3)[4] #coefficient vegtypeD
#top_mod_table[1,12]<- coef(glm_best_NDT3)[4] #coefficient vegtypeOP
#top_mod_table[1,13]<- coef(glm_best_NDT3)[4] #coefficient vegtypeS
#top_mod_table[1,14]<- coef(glm_best_NDT3)[4] #coefficient vegtypeTB
#top_mod_table[1,15]<- coef(glm_best_NDT3)[4] #coefficient vegtypeTC
#top_mod_table[1,16]<- coef(glm_best_NDT3)[5] #coefficient vegtypeTM
top_mod_table ##Determine if better way to represent categories for vegtype, and if each climate variable should have its own column

########################## NDT3 Model Selection Complete ###################

```

############### Now choose the next NDT zone and repeat ########
Note: currently doing  those with one climate variable)
Models complete above: NDT4, NDT1, NDT2, NDT3
Models to still do henceforth: NDT5

Select next zone: NDT5

```{r}
zones1<-c("NDT5") #Do one zone at a time

filenames<-list()
prop<-0.75

########### 1. Climate and vegtype ############
#for (g in 1:100){

for (h in 1:length(zones1)) {
  dat2<- dat_lightning_nt %>% dplyr::filter(ntrl_ds ==zones1[h])

for (i in 1: length(all.poss.mods.clim.vegtype2)){
  print(paste((all.poss.mods.clim.vegtype2[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, variables_all[i])
  model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, !!variables_all)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="fire_pres") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.aic, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.clim.vegtype2, big.mod, df.train=dat1, df.test=Valid)

}
}
}


```

Now extract elements from the output .

```{r}
#terms in each model
x1.5 <- unlist(sapply(mods.fit, '[', 1))
x1.5
#Aic for models
x3.5 <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3.5
#auc from validation data
x4.5 <- unlist(sapply(mods.fit, '[', 4))
x4.5
#combining all as df
tab.sum.climate.nt <- cbind.data.frame(model=x1.5, edf=x3.5[,1], aic=x3.5[,2], auc.valid=x4.5)
tab.sum.climate.nt$NDT<-c("NDT5 No trees")
tab.sum.climate.nt$delta.aic<- tab.sum.climate.nt$aic - (min(tab.sum.climate.nt$aic))
tab.sum.climate.nt 

```


#Now repeat for topography

```{r}

########### 2. Topography ############
#for (g in 1:100){

for (h in 1:length(zones1)) {
 dat2<- dat_lightning_nt %>% dplyr::filter(ntrl_ds ==zones1[h])

for (i in 1: length(all.poss.mods.topo)){
  print(paste((all.poss.mods.topo[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, variables_all[i])
  model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, !!variables_all)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="fire_pres") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.aic, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.topo, big.mod, df.train=dat1, df.test=Valid)

}
}
}


```

Now extract elements from the output .

```{r}
#terms in each model
x1.5c <- unlist(sapply(mods.fit, '[', 1))
x1.5c
#Aic for models
x3.5c <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3.5c
#auc from validation data
x4.5c <- unlist(sapply(mods.fit, '[', 4))
x4.5c
#combining all as df
tab.sum.topo.nt <- cbind.data.frame(model=x1.5c, edf=x3.5c[,1], aic=x3.5c[,2], auc.valid=x4.5c)
tab.sum.topo.nt$NDT<-c("NDT5 No trees")
tab.sum.topo.nt$delta.aic<- tab.sum.topo.nt$aic - (min(tab.sum.topo.nt$aic))
tab.sum.topo.nt

```

#Now combine the datatables and save to computer

```{r}
NDT5_l_models_nt<-rbind(tab.sum.climate.nt, tab.sum.topo.nt)
NDT5_l_models_nt

write.csv(NDT5_l_models_nt, file="D:\\Fire\\fire_data\\raw_data\\NDT5_lightning_models_nt.csv")
```

Now choose the top variables and create final model. The below code will need to be updated manually, depending on what the results of the above analyses are.

######## UPDATE BELOW #########

```{r}
##### TOP MODEL####
NDT5_t<-dat_lightning_nt %>%
  filter(ntrl_ds=="NDT5")

NDT5_t2<-NDT5_t %>% drop_na(live_stand_volume_125, vegtype, climate1, climate2, proj_height_1)

glm_best_NDT5<- glm(fire_pres ~ scale(climate1)*scale(climate2) +
             scale(live_stand_volume_125) +
               scale(proj_height_1) +
               vegtype, 
           data= NDT5_t2,
           family = binomial,
           na.action=na.omit)

summary(glm_best_NDT5)

# model diagnostic plots
binnedplot (fitted(glm_best_NDT5), 
            residuals(glm_best_NDT5), 
            nclass = NULL, 
            xlab = "Expected Values", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))


NDT5_t2$resids<-resid(glm_best_NDT5)

binnedplot (NDT5_t2$live_stand_volume_125, 
            NDT5_t2$resids, 
            nclass = NULL, 
            xlab = "live stand volume", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))

binnedplot (NDT5_t2$climate1, 
            NDT5_t2$resids, 
            nclass = NULL, 
            xlab = "", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))

# Diagnostic plots look good

# Looking at effect of forest height at the average amount of rainfall in September
plot(NDT5_t2$live_stand_volume_125,NDT5_t2$fire_pres)
curve(invlogit(coef(glm_best_NDT5)[1] +coef(glm_best_NDT5)[2]*mean(NDT5_t2$climate1) + coef(glm_best_NDT5)[3]*x), add=TRUE)

# looking at effect of climate1 at the average forest height.
plot(NDT5_t2$climate1,NDT5_t2$fire_pres)
curve(invlogit(coef(glm_best_NDT5)[1] +coef(glm_best_NDT5)[2]*x + coef(glm_best_NDT5)[3]*mean(NDT5_t2$live_stand_volume_125)), add=TRUE)

# create model table (only do this once) and add the relevant data
top_mod_table <- data.frame (matrix (ncol = 16, nrow = 0))
colnames (top_mod_table) <- c ("ZONE", "TREED", "Model_terms", "intercept", "coef_climate_1", "coef_climate_2", "coef_climate_interaction", "coef_stand_height", "coef_live_stand_volume_125", "coef_proj_age", "coef_vegtypeD", "coef_vegtypeOP", "coef_vegtypeS", "coef_vegtypeTB", "coef_vegtypeTC", "coef_vegtypeTM")


##STILL NEED TO ADD DATA FOR TABLE

##Add data for NDT5
top_mod_table[1,1]<-"NDT5"
top_mod_table[1,2]<-"Y"
top_mod_table[1,3]<-"fire_pres ~ ppt09 + proj_height_1" ######### UPDATE
top_mod_table[1,4]<- coef(glm_best_NDT5)[1] #Intercept
top_mod_table[1,5]<- coef(glm_best_NDT5)[2] #Climate variable 1
#top_mod_table[1,6]<- coef(glm_best_NDT5)[2] #Climate variable 2
#top_mod_table[1,7]<- coef(glm_best_NDT5)[3] #Interaction climate variables
#top_mod_table[1,8]<- coef(glm_best_NDT5)[3] #coef_stand_height
#top_mod_table[1,9]<- coef(glm_best_NDT5)[3] #live_stand_volume_125
#top_mod_table[1,10]<- coef(glm_best_NDT5)[4] #proj_age_1
#top_mod_table[1,11]<- coef(glm_best_NDT5)[4] #coefficient vegtypeD
#top_mod_table[1,12]<- coef(glm_best_NDT5)[4] #coefficient vegtypeOP
#top_mod_table[1,13]<- coef(glm_best_NDT5)[4] #coefficient vegtypeS
#top_mod_table[1,14]<- coef(glm_best_NDT5)[4] #coefficient vegtypeTB
#top_mod_table[1,15]<- coef(glm_best_NDT5)[4] #coefficient vegtypeTC
#top_mod_table[1,16]<- coef(glm_best_NDT5)[5] #coefficient vegtypeTM
top_mod_table ##Determine if better way to represent categories for vegtype, and if each climate variable should have its own column

########################## NDT5 Model Selection Complete ###################

```




############# Now repeat for person-caused fires ###########

Now repeat for the entire model selection process for each NDT for person-caused fires. For person caused fires, the variables of interest include:

1. Climate variable(s)
2. vegtype
3. Projected Height (proj_height_1)
4. projected age (proj_age_1)  
5. live_stand_volume_125
6. slope
7. aspect
8. elevation
9. road density (roads_km)

We will include road density in our final model selection and compare AIC for top model with and without road density (while including the top climate and topography model).

First we will create the variable lists that contain all of our variables of interest. This variable list will differ from that for the lightning-caused model, but relevant interactions should remain the same.


```{r}
##Create variable lists to be used in the model loop.
variables_all_p<-c(climate1 = "climate1", climate2 = "climate2", proj_height_1 = "proj_height_1", proj_age_1 = "proj_age_1", live_stand_volume_125 = "live_stand_volume_125", slope = "slope", aspect = "aspect", elevation ="elevation", vegtype = "vegtype", roads_km = "roads_km") #this will apply to NDT1, NDT4 and NDT5

variables_all_p_c1<-c(climate1 = "climate1", proj_height_1 = "proj_height_1", proj_age_1 = "proj_age_1", live_stand_volume_125 = "live_stand_volume_125", slope = "slope", aspect = "aspect", elevation ="elevation", vegtype = "vegtype", roads_km = "roads_km") #This will apply to NDT2 and NDT3


vars.clim<-c("climate1")
vars.clim.vegtype<-c("climate1", "vegtype")
vars.oth<-c("proj_height_1", "proj_age_1", "live_stand_volume_125") 
vars.topo<-c("slope", "aspect", "elevation")


#Also for later with 2 climate variables
vars.clim.vegtype2<-c("climate1", "climate2","vegtype")

##Create interaction for climate and vegtype
inputs.me <- c(vars.clim.vegtype)
inputs.me2 <- c(vars.clim.vegtype2)
```

Now, we will generate two-way interactions for each of these lists. These interactions will be the same as they were for the lightning-caused fire models, so no need to repeat this chunk of code if you already have that loaded.

```{r}

#####1a. For those with one climate variable
#get the names of all possible two-way interactions for climate variable(s) and vegtype.
twoway.ints <- NULL
for (i in 1:(length(inputs.me)-1)) {
  for (j in (i+1):length(inputs.me)) {
     twoway.ints <- cbind(twoway.ints, paste(inputs.me[i], inputs.me[j], sep=":"))
  }
}
twoway.ints
length(twoway.ints)

#
#Create function to determine Powerset for any vector of variable names
## or use rje package
#powerSet <- function(x) {
#   z.list <- NULL
#   for(i in 1:length(x)) {
#      z.list <- append(z.list, combn(x, m=i, simplify=F))
#   }    
#   return(z.list)
#}


#Get variables on own
#complete list of models using non-climate vars
mods.me.tmp <- powerSet(vars.clim.vegtype) 
#add climate vars to all of the above
mods.me.climate <- list()
for (i in 1: length(mods.me.tmp)) {
   mods.me.climate[[i]] <- c(mods.me.tmp[[i]])
}

mods.me.climate


#####1b. For those with two climate variables
#get the names of all possible two-way interactions for climate variable(s) and vegtype.
twoway.ints2 <- NULL
for (i in 1:(length(inputs.me2)-1)) {
  for (j in (i+1):length(inputs.me2)) {
     twoway.ints2 <- cbind(twoway.ints2, paste(inputs.me2[i], inputs.me2[j], sep=":"))
  }
}
twoway.ints2
length(twoway.ints2)

#Get variables on own
#complete list of models using non-climate vars
mods.me.tmp <- powerSet(vars.clim.vegtype2) 
#add climate vars to all of the above
mods.me.climate2 <- list()
for (i in 1: length(mods.me.tmp)) {
   mods.me.climate2[[i]] <- c(mods.me.tmp[[i]])
}

mods.me.climate2

#complete list of two-way interactions
mods.twoway2 <- powerSet(twoway.ints2)
length(mods.twoway2) #7
mods.twoway2

#Finding models in mods.me that accommodate/allow interaction terms in each mods.twoway to be added
mods.inter2 <- list()
counter <- 0
for (i in 1: length(mods.twoway2)) {
   s1 <- unique(unlist( strsplit(mods.twoway2[[i]], split=':', fixed=TRUE) ) )
   for (j in 1: length(mods.me.climate2)) {
      if (all(s1 %in% mods.me.climate2[[j]])==TRUE) {
        counter <- counter + 1
        both <-  c(mods.me.climate2[[j]], mods.twoway2[[i]])
        mods.inter2[[counter]] <- both
      }
   }
}

length(mods.inter2)
mods.inter2



#########2. Now for topography data, get all possible two-way interactions

#get the names of all possible two-way interactions
twoway.intsT <- NULL
for (i in 1:(length(vars.topo)-1)) {
  for (j in (i+1):length(vars.topo)) {
     twoway.intsT <- cbind(twoway.intsT, paste(vars.topo[i], vars.topo[j], sep=":"))
  }
}
twoway.intsT
length(twoway.intsT)

#complete list of models using non-climate vars (topo)
mods.me.tmp <- powerSet(vars.topo) 
#add climate vars to all of the above
mods.meT <- list()
for (i in 1: length(mods.me.tmp)) {
   mods.meT[[i]] <- c(mods.me.tmp[[i]])
}

mods.meT

#complete list of two-way interactions
mods.twowayT <- powerSet(twoway.intsT)
length(mods.twowayT) #7
mods.twowayT

#Finding models in mods.me that accommodate/allow interaction terms in each mods.twoway to be added

mods.interT <- list()
counter <- 0
for (i in 1: length(mods.twowayT)) {
   s1 <- unique(unlist( strsplit(mods.twowayT[[i]], split=':', fixed=TRUE) ) )
   for (j in 1: length(mods.meT)) {
      if (all(s1 %in% mods.meT[[j]])==TRUE) {
        counter <- counter + 1
        both <-  c(mods.meT[[j]], mods.twowayT[[i]])
        mods.interT[[counter]] <- both
      }
   }
}

length(mods.interT)
mods.interT


####3.For other VRI data, get without interactions

#complete list of models using VRI - no interactions
mods.me.tmp <- powerSet(vars.oth) 
#add climate vars to all of the above
mods.me.oth <- list()
for (i in 1: length(mods.me.tmp)) {
   mods.me.oth[[i]] <- c(mods.me.tmp[[i]])
}

mods.me.oth

#Combine
all.poss.mods.clim.vegtype<-c(1, mods.me.climate, twoway.ints)
all.poss.mods.clim.vegtype 
#all.poss.mods.clim.vegtype<-all.poss.mods.clim.vegtype [-2] #Use this line only if there is an odd character(0) added to list
all.poss.mods.clim.vegtype2<-c(1, mods.me.climate2, mods.inter2)
all.poss.mods.clim.vegtype2
#all.poss.mods.clim.vegtype2<-all.poss.mods.clim.vegtype2[-2]
#all.poss.mods.clim.vegtype2<-all.poss.mods.clim.vegtype2[-9]
all.poss.mods.VRI<-c(1, mods.me.oth)
all.poss.mods.VRI
#all.poss.mods.VRI<-all.poss.mods.VRI[-2]
all.poss.mods.topo<-c(1, mods.meT, mods.interT)
all.poss.mods.topo
#all.poss.mods.topo<-all.poss.mods.topo[-10]
#all.poss.mods.topo<-all.poss.mods.topo[-2]

```

Let's work with one NDT at a time. 

Because of the large number of models with all variables included, we will test the climate and vegtype first, then the topography variables. Then we will combine the top models and road density.

```{r}
#View vegtype by NDT
table(dat_person_t$fire_veg, dat_person_t$ntrl_ds)
#We see that there are not enough OP type to be able to do anything with it, so we will remove.

dat_person_t<-subset(dat_person_t, dat_person_t$vegtype!="OP")

```



############### Part 3 of 4 Model Series: Person Caused Fires, Trees ##########

Select first NDT: NDT4 

```{r}
zones1<-c("NDT4") #Do one zone at a time

filenames<-list()
prop<-0.75

########### 1. Climate and vegtype ############
#for (g in 1:100){

for (h in 1:length(zones1)) {
  dat2<- dat_person_t %>% dplyr::filter(ntrl_ds ==zones1[h])

for (i in 1: length(all.poss.mods.clim.vegtype2)){
  print(paste((all.poss.mods.clim.vegtype2[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, variables_all_p[i])
  model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, !!variables_all_p)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="fire_pres") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.aic, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.clim.vegtype2, big.mod, df.train=dat1, df.test=Valid)

}
}
}


```


Now extract elements from the output .

```{r}
#terms in each model
x1 <- unlist(sapply(mods.fit, '[', 1))
x1
#Aic for models
x3 <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3
#auc from validation data
x4 <- unlist(sapply(mods.fit, '[', 4))
x4
#combining all as df
tab.sum.climate <- cbind.data.frame(model=x1, edf=x3[,1], aic=x3[,2], auc.valid=x4)
tab.sum.climate$NDT<-c("NDT4")
tab.sum.climate$delta.aic<- tab.sum.climate$aic - (min(tab.sum.climate$aic))
tab.sum.climate 

```


#Now repeat for VRI data


```{r}

########### 2. VRI ############
#for (g in 1:100){

for (h in 1:length(zones1)) {
  dat2<- dat_person_t %>% dplyr::filter(ntrl_ds ==zones1[h])

for (i in 1: length(all.poss.mods.VRI)){
  print(paste((all.poss.mods.VRI[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, variables_all_p[i])
  model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, !!variables_all_p)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="fire_pres") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.aic, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.VRI, big.mod, df.train=dat1, df.test=Valid)

}
}
}


```

Now extract elements from the output .

```{r}
#terms in each model
x1b <- unlist(sapply(mods.fit, '[', 1))
x1b
#Aic for models
x3b <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3b
#auc from validation data
x4b <- unlist(sapply(mods.fit, '[', 4))
x4b
#combining all as df
tab.sum.VRI <- cbind.data.frame(model=x1b, edf=x3b[,1], aic=x3b[,2], auc.valid=x4b)
tab.sum.VRI$NDT<-c("NDT4")
tab.sum.VRI$delta.aic<- tab.sum.VRI$aic - (min(tab.sum.VRI$aic))
tab.sum.VRI 

```


#Now repeat for topography

```{r}

########### 3. Topography ############
#for (g in 1:100){

for (h in 1:length(zones1)) {
 dat2<- dat_person_t %>% dplyr::filter(ntrl_ds ==zones1[h])

for (i in 1: length(all.poss.mods.topo)){
  print(paste((all.poss.mods.topo[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, variables_all_p[i])
  model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, !!variables_all_p)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="fire_pres") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.aic, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.topo, big.mod, df.train=dat1, df.test=Valid)

}
}
}


```

Now extract elements from the output .

```{r}
#terms in each model
x1c <- unlist(sapply(mods.fit, '[', 1))
x1c
#Aic for models
x3c <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3c
#auc from validation data
x4c <- unlist(sapply(mods.fit, '[', 4))
x4c
#combining all as df
tab.sum.topo <- cbind.data.frame(model=x1c, edf=x3c[,1], aic=x3c[,2], auc.valid=x4c)
tab.sum.topo$NDT<-c("NDT4")
tab.sum.topo$delta.aic<- tab.sum.topo$aic - (min(tab.sum.topo$aic))
tab.sum.topo

```

#Now combine the datatables and save to computer

```{r}
NDT4_p_models<-rbind(tab.sum.climate, tab.sum.VRI, tab.sum.topo)
NDT4_p_models

write.csv(NDT4_p_models, file="D:\\Fire\\fire_data\\raw_data\\NDT4_person_models.csv")
```

Now choose the top variables and create final model. The below code will need to be updated manually, depending on what the results of the above analyses are.

######## UPDATE BELOW #########

```{r}
##### TOP MODEL####
NDT4_t<-dat_person_t %>%
  filter(ntrl_ds=="NDT4")

NDT4_t2<-NDT4_t %>% drop_na(live_stand_volume_125, vegtype, climate1, climate2, proj_height_1)

glm_best_NDT4<- glm(fire_pres ~ scale(climate1)*scale(climate2) +
             scale(live_stand_volume_125) +
               scale(proj_height_1) +
               vegtype, 
           data= NDT4_t2,
           family = binomial,
           na.action=na.omit)

summary(glm_best_NDT4)

# model diagnostic plots
binnedplot (fitted(glm_best_NDT4), 
            residuals(glm_best_NDT4), 
            nclass = NULL, 
            xlab = "Expected Values", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))


NDT4_t2$resids<-resid(glm_best_NDT4)

binnedplot (NDT4_t2$live_stand_volume_125, 
            NDT4_t2$resids, 
            nclass = NULL, 
            xlab = "live stand volume", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))

binnedplot (NDT4_t2$climate1, 
            NDT4_t2$resids, 
            nclass = NULL, 
            xlab = "", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))

# Diagnostic plots look good

# Looking at effect of forest height at the average amount of rainfall in September
plot(NDT4_t2$live_stand_volume_125,NDT4_t2$fire_pres)
curve(invlogit(coef(glm_best_NDT4)[1] +coef(glm_best_NDT4)[2]*mean(NDT4_t2$climate1) + coef(glm_best_NDT4)[3]*x), add=TRUE)

# looking at effect of climate1 at the average forest height.
plot(NDT4_t2$climate1,NDT4_t2$fire_pres)
curve(invlogit(coef(glm_best_NDT4)[1] +coef(glm_best_NDT4)[2]*x + coef(glm_best_NDT4)[3]*mean(NDT4_t2$live_stand_volume_125)), add=TRUE)


# create model table (only do this once) and add the relevant data
top_mod_table <- data.frame (matrix (ncol = 16, nrow = 0))
colnames (top_mod_table) <- c ("ZONE", "TREED", "Model_terms", "intercept", "coef_climate_1", "coef_climate_2", "coef_climate_interaction", "coef_stand_height", "coef_live_stand_volume_125", "coef_proj_age", "coef_vegtypeD", "coef_vegtypeOP", "coef_vegtypeS", "coef_vegtypeTB", "coef_vegtypeTC", "coef_vegtypeTM")



##STILL NEED TO ADD DATA FOR TABLE

##Add data for NDT4
top_mod_table[1,1]<-"NDT4"
top_mod_table[1,2]<-"Y"
top_mod_table[1,3]<-"fire_pres ~ ppt09 + proj_height_1" ######### UPDATE
top_mod_table[1,4]<- coef(glm_best_NDT4)[1] #Intercept
top_mod_table[1,5]<- coef(glm_best_NDT4)[2] #Climate variable 1
#top_mod_table[1,6]<- coef(glm_best_NDT4)[2] #Climate variable 2
#top_mod_table[1,7]<- coef(glm_best_NDT4)[3] #Interaction climate variables
#top_mod_table[1,8]<- coef(glm_best_NDT4)[3] #coef_stand_height
#top_mod_table[1,9]<- coef(glm_best_NDT4)[3] #live_stand_volume_125
#top_mod_table[1,10]<- coef(glm_best_NDT4)[4] #proj_age_1
#top_mod_table[1,11]<- coef(glm_best_NDT4)[4] #coefficient vegtypeD
#top_mod_table[1,12]<- coef(glm_best_NDT4)[4] #coefficient vegtypeOP
#top_mod_table[1,13]<- coef(glm_best_NDT4)[4] #coefficient vegtypeS
#top_mod_table[1,14]<- coef(glm_best_NDT4)[4] #coefficient vegtypeTB
#top_mod_table[1,15]<- coef(glm_best_NDT4)[4] #coefficient vegtypeTC
#top_mod_table[1,16]<- coef(glm_best_NDT4)[5] #coefficient vegtypeTM
top_mod_table ##Determine if better way to represent categories for vegtype, and if each climate variable should have its own column

########################## NDT4 Model Selection Complete ###################

```
 


############### Now choose the next NDT zone and repeat ########
Note: currently doing  those with one climate variable)
Models complete above: NDT4
Models to still do henceforth:NDT1, NDT2, NDT3, NDT5

Select next zone: NDT1

```{r}
zones1<-c("NDT1") #Do one zone at a time

filenames<-list()
prop<-0.75

########### 1. Climate and vegtype ############
#for (g in 1:100){

for (h in 1:length(zones1)) {
  dat2<- dat_person_t %>% dplyr::filter(ntrl_ds ==zones1[h])

for (i in 1: length(all.poss.mods.clim.vegtype2)){
  print(paste((all.poss.mods.clim.vegtype2[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, variables_all_p[i])
  model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, !!variables_all_p)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="fire_pres") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.aic, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.clim.vegtype2, big.mod, df.train=dat1, df.test=Valid)

}
}
}


```

Now extract elements from the output .

```{r}
#terms in each model
x1.1 <- unlist(sapply(mods.fit, '[', 1))
x1.1
#Aic for models
x3.1 <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3.1
#auc from validation data
x4.1 <- unlist(sapply(mods.fit, '[', 4))
x4.1
#combining all as df
tab.sum.climate <- cbind.data.frame(model=x1.1, edf=x3.1[,1], aic=x3.1[,2], auc.valid=x4.1)
tab.sum.climate$NDT<-c("NDT1")
tab.sum.climate$delta.aic<- tab.sum.climate$aic - (min(tab.sum.climate$aic))
tab.sum.climate 

```

#Now repeat for VRI data

```{r}

########### 2. VRI ############
#for (g in 1:100){

for (h in 1:length(zones1)) {
  dat2<- dat_person_t %>% dplyr::filter(ntrl_ds ==zones1[h])

for (i in 1: length(all.poss.mods.VRI)){
  print(paste((all.poss.mods.VRI[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, variables_all_p[i])
  model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, !!variables_all_p)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="fire_pres") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.aic, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.VRI, big.mod, df.train=dat1, df.test=Valid)

}
}
}


```

Now extract elements from the output .

```{r}
#terms in each model
x1.1b <- unlist(sapply(mods.fit, '[', 1))
x1.1b
#Aic for models
x3.1b <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3.1b
#auc from validation data
x4.1b <- unlist(sapply(mods.fit, '[', 4))
x4.1b
#combining all as df
tab.sum.VRI <- cbind.data.frame(model=x1.1b, edf=x3.1b[,1], aic=x3.1b[,2], auc.valid=x4.1b)
tab.sum.VRI$NDT<-c("NDT1")
tab.sum.VRI$delta.aic<- tab.sum.VRI$aic - (min(tab.sum.VRI$aic))
tab.sum.VRI 

```


#Now repeat for topography

```{r}

########### 3. Topography ############
#for (g in 1:100){

for (h in 1:length(zones1)) {
 dat2<- dat_person_t %>% dplyr::filter(ntrl_ds ==zones1[h])

for (i in 1: length(all.poss.mods.topo)){
  print(paste((all.poss.mods.topo[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, variables_all_p[i])
  model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, !!variables_all_p)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="fire_pres") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.aic, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.topo, big.mod, df.train=dat1, df.test=Valid)

}
}
}


```

Now extract elements from the output.

```{r}
#terms in each model
x1.1c <- unlist(sapply(mods.fit, '[', 1))
x1.1c
#Aic for models
x3.1c <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3.1c
#auc from validation data
x4.1c <- unlist(sapply(mods.fit, '[', 4))
x4.1c
#combining all as df
tab.sum.topo <- cbind.data.frame(model=x1.1c, edf=x3.1c[,1], aic=x3.1c[,2], auc.valid=x4.1c)
tab.sum.topo$NDT<-c("NDT1")
tab.sum.topo$delta.aic<- tab.sum.topo$aic - (min(tab.sum.topo$aic))
tab.sum.topo

```

#Now combine the datatables and save to computer

```{r}
NDT1_p_models<-rbind(tab.sum.climate, tab.sum.VRI, tab.sum.topo)
NDT1_p_models

write.csv(NDT1_p_models, file="D:\\Fire\\fire_data\\raw_data\\NDT1_person_models.csv")
```

Now choose the top variables and create final model. The below code will need to be updated manually, depending on what the results of the above analyses are.

######## UPDATE BELOW #########

```{r}
##### TOP MODEL####
NDT1_t<-dat_person_t %>%
  filter(ntrl_ds=="NDT1")

NDT1_t2<-NDT1_t %>% drop_na(live_stand_volume_125, vegtype, climate1, climate2, proj_height_1)

glm_best_NDT1<- glm(fire_pres ~ scale(climate1)*scale(climate2) +
             scale(live_stand_volume_125) +
               scale(proj_height_1) +
               vegtype, 
           data= NDT1_t2,
           family = binomial,
           na.action=na.omit)

summary(glm_best_NDT1)

# model diagnostic plots
binnedplot (fitted(glm_best_NDT1), 
            residuals(glm_best_NDT1), 
            nclass = NULL, 
            xlab = "Expected Values", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))


NDT1_t2$resids<-resid(glm_best_NDT1)

binnedplot (NDT1_t2$live_stand_volume_125, 
            NDT1_t2$resids, 
            nclass = NULL, 
            xlab = "live stand volume", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))

binnedplot (NDT1_t2$climate1, 
            NDT1_t2$resids, 
            nclass = NULL, 
            xlab = "", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))

# Diagnostic plots look good

# Looking at effect of forest height at the average amount of rainfall in September
plot(NDT1_t2$live_stand_volume_125,NDT1_t2$fire_pres)
curve(invlogit(coef(glm_best_NDT1)[1] +coef(glm_best_NDT1)[2]*mean(NDT1_t2$climate1) + coef(glm_best_NDT1)[3]*x), add=TRUE)

# looking at effect of climate1 at the average forest height.
plot(NDT1_t2$climate1,NDT1_t2$fire_pres)
curve(invlogit(coef(glm_best_NDT1)[1] +coef(glm_best_NDT1)[2]*x + coef(glm_best_NDT1)[3]*mean(NDT1_t2$live_stand_volume_125)), add=TRUE)


# create model table (only do this once) and add the relevant data
top_mod_table <- data.frame (matrix (ncol = 16, nrow = 0))
colnames (top_mod_table) <- c ("ZONE", "TREED", "Model_terms", "intercept", "coef_climate_1", "coef_climate_2", "coef_climate_interaction", "coef_stand_height", "coef_live_stand_volume_125", "coef_proj_age", "coef_vegtypeD", "coef_vegtypeOP", "coef_vegtypeS", "coef_vegtypeTB", "coef_vegtypeTC", "coef_vegtypeTM")



##STILL NEED TO ADD DATA FOR TABLE

##Add data for NDT1
top_mod_table[1,1]<-"NDT1"
top_mod_table[1,2]<-"Y"
top_mod_table[1,3]<-"fire_pres ~ ppt09 + proj_height_1" ######### UPDATE
top_mod_table[1,4]<- coef(glm_best_NDT1)[1] #Intercept
top_mod_table[1,5]<- coef(glm_best_NDT1)[2] #Climate variable 1
#top_mod_table[1,6]<- coef(glm_best_NDT1)[2] #Climate variable 2
#top_mod_table[1,7]<- coef(glm_best_NDT1)[3] #Interaction climate variables
#top_mod_table[1,8]<- coef(glm_best_NDT1)[3] #coef_stand_height
#top_mod_table[1,9]<- coef(glm_best_NDT1)[3] #live_stand_volume_125
#top_mod_table[1,10]<- coef(glm_best_NDT1)[4] #proj_age_1
#top_mod_table[1,11]<- coef(glm_best_NDT1)[4] #coefficient vegtypeD
#top_mod_table[1,12]<- coef(glm_best_NDT1)[4] #coefficient vegtypeOP
#top_mod_table[1,13]<- coef(glm_best_NDT1)[4] #coefficient vegtypeS
#top_mod_table[1,14]<- coef(glm_best_NDT1)[4] #coefficient vegtypeTB
#top_mod_table[1,15]<- coef(glm_best_NDT1)[4] #coefficient vegtypeTC
#top_mod_table[1,16]<- coef(glm_best_NDT1)[5] #coefficient vegtypeTM
top_mod_table ##Determine if better way to represent categories for vegtype, and if each climate variable should have its own column

########################## NDT1 Model Selection Complete ###################



```



############### Now choose the next NDT zone and repeat ########
Note: currently doing  those with one climate variable)
Models complete above: NDT4, NDT1
Models to still do henceforth:NDT2, NDT3, NDT5


Select next zone: NDT2 (ONLY ONE CLIMATE VARIABLE)


```{r}
zones1<-c("NDT2") #Do one zone at a time

filenames<-list()
prop<-0.75

########### 1. Climate and vegtype ############
#for (g in 1:100){

for (h in 1:length(zones1)) {
  dat2<- dat_person_t %>% dplyr::filter(ntrl_ds ==zones1[h])

for (i in 1: length(all.poss.mods.clim.vegtype)){
  print(paste((all.poss.mods.clim.vegtype[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, variables_all_p[i])
  model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, !!variables_all_p_c1)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="fire_pres") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.aic, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.clim.vegtype, big.mod, df.train=dat1, df.test=Valid)

}
}
}


```

Now extract elements from the output .

```{r}
#terms in each model
x1.2 <- unlist(sapply(mods.fit, '[', 1))
x1.2
#Aic for models
x3.2 <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3.2
#auc from validation data
x4.2 <- unlist(sapply(mods.fit, '[', 4))
x4.2
#combining all as df
tab.sum.climate <- cbind.data.frame(model=x1.2, edf=x3.2[,1], aic=x3.2[,2], auc.valid=x4.2)
tab.sum.climate$NDT<-c("NDT2")
tab.sum.climate$delta.aic<- tab.sum.climate$aic - (min(tab.sum.climate$aic))
tab.sum.climate 

```


#Now repeat for VRI data


```{r}

########### 2. VRI ############
#for (g in 1:100){

for (h in 1:length(zones1)) {
  dat2<- dat_person_t %>% dplyr::filter(ntrl_ds ==zones1[h])

for (i in 1: length(all.poss.mods.VRI)){
  print(paste((all.poss.mods.VRI[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, variables_all_p[i])
  model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, !!variables_all_p_c1)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="fire_pres") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.aic, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.VRI, big.mod, df.train=dat1, df.test=Valid)

}
}
}


```

Now extract elements from the output .

```{r}
#terms in each model
x1.2b <- unlist(sapply(mods.fit, '[', 1))
x1.2b
#Aic for models
x3.2b <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3.2b
#auc from validation data
x4.2b <- unlist(sapply(mods.fit, '[', 4))
x4.2b
#combining all as df
tab.sum.VRI <- cbind.data.frame(model=x1.2b, edf=x3.2b[,1], aic=x3.2b[,2], auc.valid=x4.2b)
tab.sum.VRI$NDT<-c("NDT2")
tab.sum.VRI$delta.aic<- tab.sum.VRI$aic - (min(tab.sum.VRI$aic))
tab.sum.VRI 

```


#Now repeat for topography

```{r}

########### 3. Topography ############
#for (g in 1:100){

for (h in 1:length(zones1)) {
 dat2<- dat_person_t %>% dplyr::filter(ntrl_ds ==zones1[h])

for (i in 1: length(all.poss.mods.topo)){
  print(paste((all.poss.mods.topo[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, variables_all_p[i])
  model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, !!variables_all_p_c1)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="fire_pres") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.aic, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.topo, big.mod, df.train=dat1, df.test=Valid)

}
}
}


```

Now extract elements from the output .

```{r}
#terms in each model
x1.2c <- unlist(sapply(mods.fit, '[', 1))
x1.2c
#Aic for models
x3.2c <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3.2c
#auc from validation data
x4.2c <- unlist(sapply(mods.fit, '[', 4))
x4.2c
#combining all as df
tab.sum.topo <- cbind.data.frame(model=x1.2c, edf=x3.2c[,1], aic=x3.2c[,2], auc.valid=x4.2c)
tab.sum.topo$NDT<-c("NDT2")
tab.sum.topo$delta.aic<- tab.sum.topo$aic - (min(tab.sum.topo$aic))
tab.sum.topo

```

#Now combine the datatables and save to computer

```{r}
NDT2_p_models<-rbind(tab.sum.climate, tab.sum.VRI, tab.sum.topo)
NDT2_p_models

write.csv(NDT2_p_models, file="D:\\Fire\\fire_data\\raw_data\\NDT2_person_models.csv")
```

Now choose the top variables and create final model. The below code will need to be updated manually, depending on what the results of the above analyses are.

######## UPDATE BELOW #########

```{r}
##### TOP MODEL####
NDT2_t<-dat_person_t %>%
  filter(ntrl_ds=="NDT2")

NDT2_t2<-NDT2_t %>% drop_na(live_stand_volume_125, vegtype, climate1, climate2, proj_height_1)

glm_best_NDT2<- glm(fire_pres ~ scale(climate1)*scale(climate2) +
             scale(live_stand_volume_125) +
               scale(proj_height_1) +
               vegtype, 
           data= NDT2_t2,
           family = binomial,
           na.action=na.omit)

summary(glm_best_NDT2)

# model diagnostic plots
binnedplot (fitted(glm_best_NDT2), 
            residuals(glm_best_NDT2), 
            nclass = NULL, 
            xlab = "Expected Values", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))


NDT2_t2$resids<-resid(glm_best_NDT2)

binnedplot (NDT2_t2$live_stand_volume_125, 
            NDT2_t2$resids, 
            nclass = NULL, 
            xlab = "live stand volume", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))

binnedplot (NDT2_t2$climate1, 
            NDT2_t2$resids, 
            nclass = NULL, 
            xlab = "", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))

# Diagnostic plots look good

# Looking at effect of forest height at the average amount of rainfall in September
plot(NDT2_t2$live_stand_volume_125,NDT2_t2$fire_pres)
curve(invlogit(coef(glm_best_NDT2)[1] +coef(glm_best_NDT2)[2]*mean(NDT2_t2$climate1) + coef(glm_best_NDT2)[3]*x), add=TRUE)

# looking at effect of climate1 at the average forest height.
plot(NDT2_t2$climate1,NDT2_t2$fire_pres)
curve(invlogit(coef(glm_best_NDT2)[1] +coef(glm_best_NDT2)[2]*x + coef(glm_best_NDT2)[3]*mean(NDT2_t2$live_stand_volume_125)), add=TRUE)


# create model table (only do this once) and add the relevant data
top_mod_table <- data.frame (matrix (ncol = 16, nrow = 0))
colnames (top_mod_table) <- c ("ZONE", "TREED", "Model_terms", "intercept", "coef_climate_1", "coef_climate_2", "coef_climate_interaction", "coef_stand_height", "coef_live_stand_volume_125", "coef_proj_age", "coef_vegtypeD", "coef_vegtypeOP", "coef_vegtypeS", "coef_vegtypeTB", "coef_vegtypeTC", "coef_vegtypeTM")



##STILL NEED TO ADD DATA FOR TABLE

##Add data for NDT2
top_mod_table[1,1]<-"NDT2"
top_mod_table[1,2]<-"Y"
top_mod_table[1,3]<-"fire_pres ~ ppt09 + proj_height_1" ######### UPDATE
top_mod_table[1,4]<- coef(glm_best_NDT2)[1] #Intercept
top_mod_table[1,5]<- coef(glm_best_NDT2)[2] #Climate variable 1
#top_mod_table[1,6]<- coef(glm_best_NDT2)[2] #Climate variable 2
#top_mod_table[1,7]<- coef(glm_best_NDT2)[3] #Interaction climate variables
#top_mod_table[1,8]<- coef(glm_best_NDT2)[3] #coef_stand_height
#top_mod_table[1,9]<- coef(glm_best_NDT2)[3] #live_stand_volume_125
#top_mod_table[1,10]<- coef(glm_best_NDT2)[4] #proj_age_1
#top_mod_table[1,11]<- coef(glm_best_NDT2)[4] #coefficient vegtypeD
#top_mod_table[1,12]<- coef(glm_best_NDT2)[4] #coefficient vegtypeOP
#top_mod_table[1,13]<- coef(glm_best_NDT2)[4] #coefficient vegtypeS
#top_mod_table[1,14]<- coef(glm_best_NDT2)[4] #coefficient vegtypeTB
#top_mod_table[1,15]<- coef(glm_best_NDT2)[4] #coefficient vegtypeTC
#top_mod_table[1,16]<- coef(glm_best_NDT2)[5] #coefficient vegtypeTM
top_mod_table ##Determine if better way to represent categories for vegtype, and if each climate variable should have its own column

########################## NDT2 Model Selection Complete ###################



```


############### Now choose the next NDT zone and repeat ########
Note: currently doing  those with one climate variable)
Models complete above: NDT4, NDT1, NDT2
Models to still do henceforth: NDT3, NDT5


Select next zone: NDT3 (only 1 climate variable!)


```{r}
zones1<-c("NDT3") #Do one zone at a time

filenames<-list()
prop<-0.75

########### 1. Climate and vegtype ############
#for (g in 1:100){

for (h in 1:length(zones1)) {
  dat2<- dat_person_t %>% dplyr::filter(ntrl_ds ==zones1[h])

for (i in 1: length(all.poss.mods.clim.vegtype)){
  print(paste((all.poss.mods.clim.vegtype[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, variables_all_p[i])
  model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, !!variables_all_p_c1)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="fire_pres") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.aic, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.clim.vegtype, big.mod, df.train=dat1, df.test=Valid)

}
}
}


```

Now extract elements from the output .

```{r}
#terms in each model
x1.3 <- unlist(sapply(mods.fit, '[', 1))
x1.3
#Aic for models
x3.3 <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3.3
#auc from validation data
x4.3 <- unlist(sapply(mods.fit, '[', 4))
x4.3
#combining all as df
tab.sum.climate <- cbind.data.frame(model=x1.3, edf=x3.3[,1], aic=x3.3[,2], auc.valid=x4.3)
tab.sum.climate$NDT<-c("NDT3")
tab.sum.climate$delta.aic<- tab.sum.climate$aic - (min(tab.sum.climate$aic))
tab.sum.climate 

```


#Now repeat for VRI data


```{r}

########### 2. VRI ############
#for (g in 1:100){

for (h in 1:length(zones1)) {
  dat2<- dat_person_t %>% dplyr::filter(ntrl_ds ==zones1[h])

for (i in 1: length(all.poss.mods.VRI)){
  print(paste((all.poss.mods.VRI[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, variables_all_p[i])
  model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, !!variables_all_p_c1)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="fire_pres") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.aic, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.VRI, big.mod, df.train=dat1, df.test=Valid)

}
}
}


```

Now extract elements from the output .

```{r}
#terms in each model
x1.3b <- unlist(sapply(mods.fit, '[', 1))
x1.3b
#Aic for models
x3.3b <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3.3b
#auc from validation data
x4.3b <- unlist(sapply(mods.fit, '[', 4))
x4.3b
#combining all as df
tab.sum.VRI <- cbind.data.frame(model=x1.3b, edf=x3.3b[,1], aic=x3.3b[,2], auc.valid=x4.3b)
tab.sum.VRI$NDT<-c("NDT3")
tab.sum.VRI$delta.aic<- tab.sum.VRI$aic - (min(tab.sum.VRI$aic))
tab.sum.VRI 

```


#Now repeat for topography

```{r}

########### 3. Topography ############
#for (g in 1:100){

for (h in 1:length(zones1)) {
 dat2<- dat_person_t %>% dplyr::filter(ntrl_ds ==zones1[h])

for (i in 1: length(all.poss.mods.topo)){
  print(paste((all.poss.mods.topo[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, variables_all_p[i])
  model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, !!variables_all_p_c1)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="fire_pres") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.aic, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.topo, big.mod, df.train=dat1, df.test=Valid)

}
}
}


```

Now extract elements from the output .

```{r}
#terms in each model
x1.3c <- unlist(sapply(mods.fit, '[', 1))
x1.3c
#Aic for models
x3.3c <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3.3c
#auc from validation data
x4.3c <- unlist(sapply(mods.fit, '[', 4))
x4.3c
#combining all as df
tab.sum.topo <- cbind.data.frame(model=x1.3c, edf=x3.3c[,1], aic=x3.3c[,2], auc.valid=x4.3c)
tab.sum.topo$NDT<-c("NDT3")
tab.sum.topo$delta.aic<- tab.sum.topo$aic - (min(tab.sum.topo$aic))
tab.sum.topo

```

#Now combine the datatables and save to computer

```{r}
NDT3_p_models<-rbind(tab.sum.climate, tab.sum.VRI, tab.sum.topo)
NDT3_p_models

write.csv(NDT3_p_models, file="D:\\Fire\\fire_data\\raw_data\\NDT3_person_models.csv")
```

Now choose the top variables and create final model. The below code will need to be updated manually, depending on what the results of the above analyses are.

######## UPDATE BELOW #########

```{r}
##### TOP MODEL####
NDT3_t<-dat_person_t %>%
  filter(ntrl_ds=="NDT3")

NDT3_t2<-NDT3_t %>% drop_na(live_stand_volume_125, vegtype, climate1, climate2, proj_height_1)

glm_best_NDT3<- glm(fire_pres ~ scale(climate1)*scale(climate2) +
             scale(live_stand_volume_125) +
               scale(proj_height_1) +
               vegtype, 
           data= NDT3_t2,
           family = binomial,
           na.action=na.omit)

summary(glm_best_NDT3)

# model diagnostic plots
binnedplot (fitted(glm_best_NDT3), 
            residuals(glm_best_NDT3), 
            nclass = NULL, 
            xlab = "Expected Values", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))


NDT3_t2$resids<-resid(glm_best_NDT3)

binnedplot (NDT3_t2$live_stand_volume_125, 
            NDT3_t2$resids, 
            nclass = NULL, 
            xlab = "live stand volume", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))

binnedplot (NDT3_t2$climate1, 
            NDT3_t2$resids, 
            nclass = NULL, 
            xlab = "", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))

# Diagnostic plots look good

# Looking at effect of forest height at the average amount of rainfall in September
plot(NDT3_t2$live_stand_volume_125,NDT3_t2$fire_pres)
curve(invlogit(coef(glm_best_NDT3)[1] +coef(glm_best_NDT3)[2]*mean(NDT3_t2$climate1) + coef(glm_best_NDT3)[3]*x), add=TRUE)

# looking at effect of climate1 at the average forest height.
plot(NDT3_t2$climate1,NDT3_t2$fire_pres)
curve(invlogit(coef(glm_best_NDT3)[1] +coef(glm_best_NDT3)[2]*x + coef(glm_best_NDT3)[3]*mean(NDT3_t2$live_stand_volume_125)), add=TRUE)


# create model table (only do this once) and add the relevant data
top_mod_table <- data.frame (matrix (ncol = 16, nrow = 0))
colnames (top_mod_table) <- c ("ZONE", "TREED", "Model_terms", "intercept", "coef_climate_1", "coef_climate_2", "coef_climate_interaction", "coef_stand_height", "coef_live_stand_volume_125", "coef_proj_age", "coef_vegtypeD", "coef_vegtypeOP", "coef_vegtypeS", "coef_vegtypeTB", "coef_vegtypeTC", "coef_vegtypeTM")



##STILL NEED TO ADD DATA FOR TABLE

##Add data for NDT3
top_mod_table[1,1]<-"NDT3"
top_mod_table[1,2]<-"Y"
top_mod_table[1,3]<-"fire_pres ~ ppt09 + proj_height_1" ######### UPDATE
top_mod_table[1,4]<- coef(glm_best_NDT3)[1] #Intercept
top_mod_table[1,5]<- coef(glm_best_NDT3)[2] #Climate variable 1
#top_mod_table[1,6]<- coef(glm_best_NDT3)[2] #Climate variable 2
#top_mod_table[1,7]<- coef(glm_best_NDT3)[3] #Interaction climate variables
#top_mod_table[1,8]<- coef(glm_best_NDT3)[3] #coef_stand_height
#top_mod_table[1,9]<- coef(glm_best_NDT3)[3] #live_stand_volume_125
#top_mod_table[1,10]<- coef(glm_best_NDT3)[4] #proj_age_1
#top_mod_table[1,11]<- coef(glm_best_NDT3)[4] #coefficient vegtypeD
#top_mod_table[1,12]<- coef(glm_best_NDT3)[4] #coefficient vegtypeOP
#top_mod_table[1,13]<- coef(glm_best_NDT3)[4] #coefficient vegtypeS
#top_mod_table[1,14]<- coef(glm_best_NDT3)[4] #coefficient vegtypeTB
#top_mod_table[1,15]<- coef(glm_best_NDT3)[4] #coefficient vegtypeTC
#top_mod_table[1,16]<- coef(glm_best_NDT3)[5] #coefficient vegtypeTM
top_mod_table ##Determine if better way to represent categories for vegtype, and if each climate variable should have its own column

########################## NDT3 Model Selection Complete ###################



```



############### Now choose the next NDT zone and repeat ########
Note: currently doing  those with one climate variable)
Models complete above: NDT4, NDT1, NDT2, NDT3
Models to still do henceforth: NDT5


Select next zone: NDT5


```{r}
zones1<-c("NDT5") #Do one zone at a time

filenames<-list()
prop<-0.75

########### 1. Climate and vegtype ############
#for (g in 1:100){

for (h in 1:length(zones1)) {
  dat2<- dat_person_t %>% dplyr::filter(ntrl_ds ==zones1[h])

for (i in 1: length(all.poss.mods.clim.vegtype2)){
  print(paste((all.poss.mods.clim.vegtype2[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, variables_all_p[i])
  model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, !!variables_all_p)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="fire_pres") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.aic, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.clim.vegtype2, big.mod, df.train=dat1, df.test=Valid)

}
}
}


```

Now extract elements from the output .

```{r}
#terms in each model
x1.5 <- unlist(sapply(mods.fit, '[', 1))
x1.5
#Aic for models
x3.5 <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3.5
#auc from validation data
x4.5 <- unlist(sapply(mods.fit, '[', 4))
x4.5
#combining all as df
tab.sum.climate <- cbind.data.frame(model=x1.5, edf=x3.5[,1], aic=x3.5[,2], auc.valid=x4.5)
tab.sum.climate$NDT<-c("NDT5")
tab.sum.climate$delta.aic<- tab.sum.climate$aic - (min(tab.sum.climate$aic))
tab.sum.climate 

```


#Now repeat for VRI data


```{r}

########### 2. VRI ############
#for (g in 1:100){

for (h in 1:length(zones1)) {
  dat2<- dat_person_t %>% dplyr::filter(ntrl_ds ==zones1[h])

for (i in 1: length(all.poss.mods.VRI)){
  print(paste((all.poss.mods.VRI[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, variables_all_p[i])
  model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, !!variables_all_p)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="fire_pres") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.aic, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.VRI, big.mod, df.train=dat1, df.test=Valid)

}
}
}


```

Now extract elements from the output .

```{r}
#terms in each model
x1.5b <- unlist(sapply(mods.fit, '[', 1))
x1.5b
#Aic for models
x3.5b <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3.5b
#auc from validation data
x4.5b <- unlist(sapply(mods.fit, '[', 4))
x4.5b
#combining all as df
tab.sum.VRI <- cbind.data.frame(model=x1.5b, edf=x3.5b[,1], aic=x3.5b[,2], auc.valid=x4.5b)
tab.sum.VRI$NDT<-c("NDT5")
tab.sum.VRI$delta.aic<- tab.sum.VRI$aic - (min(tab.sum.VRI$aic))
tab.sum.VRI 

```


#Now repeat for topography

```{r}

########### 3. Topography ############
#for (g in 1:100){

for (h in 1:length(zones1)) {
 dat2<- dat_person_t %>% dplyr::filter(ntrl_ds ==zones1[h])

for (i in 1: length(all.poss.mods.topo)){
  print(paste((all.poss.mods.topo[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, variables_all_p[i])
  model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, !!variables_all_p)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="fire_pres") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.aic, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.topo, big.mod, df.train=dat1, df.test=Valid)

}
}
}


```

Now extract elements from the output .

```{r}
#terms in each model
x1.5c <- unlist(sapply(mods.fit, '[', 1))
x1.5c
#Aic for models
x3.5c <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3.5c
#auc from validation data
x4.5c <- unlist(sapply(mods.fit, '[', 4))
x4.5c
#combining all as df
tab.sum.topo <- cbind.data.frame(model=x1.5c, edf=x3.5c[,1], aic=x3.5c[,2], auc.valid=x4.5c)
tab.sum.topo$NDT<-c("NDT5")
tab.sum.topo$delta.aic<- tab.sum.topo$aic - (min(tab.sum.topo$aic))
tab.sum.topo

```

#Now combine the datatables and save to computer

```{r}
NDT5_p_models<-rbind(tab.sum.climate, tab.sum.VRI, tab.sum.topo)
NDT5_p_models

write.csv(NDT5_p_models, file="D:\\Fire\\fire_data\\raw_data\\NDT5_person_models.csv")
```

Now choose the top variables and create final model. The below code will need to be updated manually, depending on what the results of the above analyses are.

######## UPDATE BELOW #########

```{r}
##### TOP MODEL####
NDT5_t<-dat_person_t %>%
  filter(ntrl_ds=="NDT5")

NDT5_t2<-NDT5_t %>% drop_na(live_stand_volume_125, vegtype, climate1, climate2, proj_height_1)

glm_best_NDT5<- glm(fire_pres ~ scale(climate1)*scale(climate2) +
             scale(live_stand_volume_125) +
               scale(proj_height_1) +
               vegtype, 
           data= NDT5_t2,
           family = binomial,
           na.action=na.omit)

summary(glm_best_NDT5)

# model diagnostic plots
binnedplot (fitted(glm_best_NDT5), 
            residuals(glm_best_NDT5), 
            nclass = NULL, 
            xlab = "Expected Values", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))


NDT5_t2$resids<-resid(glm_best_NDT5)

binnedplot (NDT5_t2$live_stand_volume_125, 
            NDT5_t2$resids, 
            nclass = NULL, 
            xlab = "live stand volume", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))

binnedplot (NDT5_t2$climate1, 
            NDT5_t2$resids, 
            nclass = NULL, 
            xlab = "", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))

# Diagnostic plots look good

# Looking at effect of forest height at the average amount of rainfall in September
plot(NDT5_t2$live_stand_volume_125,NDT5_t2$fire_pres)
curve(invlogit(coef(glm_best_NDT5)[1] +coef(glm_best_NDT5)[2]*mean(NDT5_t2$climate1) + coef(glm_best_NDT5)[3]*x), add=TRUE)

# looking at effect of climate1 at the average forest height.
plot(NDT5_t2$climate1,NDT5_t2$fire_pres)
curve(invlogit(coef(glm_best_NDT5)[1] +coef(glm_best_NDT5)[2]*x + coef(glm_best_NDT5)[3]*mean(NDT5_t2$live_stand_volume_125)), add=TRUE)


# create model table (only do this once) and add the relevant data
top_mod_table <- data.frame (matrix (ncol = 16, nrow = 0))
colnames (top_mod_table) <- c ("ZONE", "TREED", "Model_terms", "intercept", "coef_climate_1", "coef_climate_2", "coef_climate_interaction", "coef_stand_height", "coef_live_stand_volume_125", "coef_proj_age", "coef_vegtypeD", "coef_vegtypeOP", "coef_vegtypeS", "coef_vegtypeTB", "coef_vegtypeTC", "coef_vegtypeTM")



##STILL NEED TO ADD DATA FOR TABLE

##Add data for NDT5
top_mod_table[1,1]<-"NDT5"
top_mod_table[1,2]<-"Y"
top_mod_table[1,3]<-"fire_pres ~ ppt09 + proj_height_1" ######### UPDATE
top_mod_table[1,4]<- coef(glm_best_NDT5)[1] #Intercept
top_mod_table[1,5]<- coef(glm_best_NDT5)[2] #Climate variable 1
#top_mod_table[1,6]<- coef(glm_best_NDT5)[2] #Climate variable 2
#top_mod_table[1,7]<- coef(glm_best_NDT5)[3] #Interaction climate variables
#top_mod_table[1,8]<- coef(glm_best_NDT5)[3] #coef_stand_height
#top_mod_table[1,9]<- coef(glm_best_NDT5)[3] #live_stand_volume_125
#top_mod_table[1,10]<- coef(glm_best_NDT5)[4] #proj_age_1
#top_mod_table[1,11]<- coef(glm_best_NDT5)[4] #coefficient vegtypeD
#top_mod_table[1,12]<- coef(glm_best_NDT5)[4] #coefficient vegtypeOP
#top_mod_table[1,13]<- coef(glm_best_NDT5)[4] #coefficient vegtypeS
#top_mod_table[1,14]<- coef(glm_best_NDT5)[4] #coefficient vegtypeTB
#top_mod_table[1,15]<- coef(glm_best_NDT5)[4] #coefficient vegtypeTC
#top_mod_table[1,16]<- coef(glm_best_NDT5)[5] #coefficient vegtypeTM
top_mod_table ##Determine if better way to represent categories for vegtype, and if each climate variable should have its own column

########################## NDT5 Model Selection Complete ###################



```




############### Part 4 of 4 Model Series: Person Caused Fires, No Trees ##########

Because these areas are predominately not full of trees, we will ignore the VRI. Some locations will still have some VRI attributes because trees may exist on <50% of the plot, but many plots will have no VRI attributes. So we will ignore the VRI results for this section.

For person caused fires with no trees, the variables of interest include:

1. Climate variable(s)
2. vegtype
3. slope
4. aspect (cos)
5. elevation
6. road density (roads_km2)

Interactions of interest: two-way interactions between climate (1) and vegtype (2); two-way interactions between topography measures (3-5).

```{r}
table(dat_person_nt$vegtype, dat_person_nt$ntrl_ds)
table(dat_person_nt$ntrl_ds, dat_person_nt$fire_veg)

#Note, running below, we encounter problems because the Disturbed type gets unequally allocated between training and validation datasets, despite asking it to partition by fire_veg. Unsure how to fix.
```


===

Select first NDT: NDT4 

The loop for NDT4 kept coming up with an error in which "new level vegtype D not present", or something along those lines, so we are performing the below code to attempt to get this it work despite this error message. This does not happen for any other grouping since "fire_veg" was created to resolve this problem that had arisen prior to the creation of "fire-veg".

```{r}
dat_person_nt_NDT4<-subset(dat_person_nt, dat_person_nt$ntrl_ds=="NDT4")
head(dat_person_nt_NDT4)
table(dat_person_nt_NDT4$fire_veg, dat_person_nt_NDT4$ntrl_ds)

trainIndex <- createDataPartition(dat_person_nt_NDT4$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)

   dat1 <- dat_person_nt_NDT4[ trainIndex,]
   Valid <- dat_person_nt_NDT4[-trainIndex,]
   
   table(dat1$fire_veg, dat1$ntrl_ds)
   table(Valid$fire_veg, Valid$ntrl_ds)

```


```{r}
zones1<-c("NDT4") #Do one zone at a time

#filenames<-list()
#prop<-0.75

########### 1. Climate and vegtype ############
#for (g in 1:100){


#  for (h in 1:length(zones1)) {
#  dat2<- dat_person_nt %>% dplyr::filter(ntrl_ds ==zones1[h])
  
for (h in 1:length(zones1)) {
  dat2<- dat_person_nt_NDT4 %>% dplyr::filter(ntrl_ds ==zones1[h])

for (i in 1: length(all.poss.mods.clim.vegtype2)){
  print(paste((all.poss.mods.clim.vegtype2[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, variables_all_p[i])
 # model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, !!variables_all_p)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
#  trainIndex <- createDataPartition(model_dat$fire_veg, p = prop,
 #                                   list = FALSE,
  #                                  times = 1)
  
   #dat1 <- model_dat[ trainIndex,]
   #Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="fire_pres") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.aic, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.clim.vegtype2, big.mod, df.train=dat1, df.test=Valid)

}
}
}


```

Now extract elements from the output .

```{r}
#terms in each model
x1 <- unlist(sapply(mods.fit, '[', 1))
x1
#Aic for models
x3 <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3
#auc from validation data
x4 <- unlist(sapply(mods.fit, '[', 4))
x4
#combining all as df
tab.sum.climate.nt <- cbind.data.frame(model=x1, edf=x3[,1], aic=x3[,2], auc.valid=x4)
tab.sum.climate.nt$NDT<-c("NDT4 No trees")
tab.sum.climate.nt$delta.aic<- tab.sum.climate.nt$aic - (min(tab.sum.climate.nt$aic))
tab.sum.climate.nt 

```


#Now repeat for topography

```{r}

########### 2. Topography ############
#for (g in 1:100){

for (h in 1:length(zones1)) {
 dat2<- dat_person_nt %>% dplyr::filter(ntrl_ds ==zones1[h])

for (i in 1: length(all.poss.mods.topo)){
  print(paste((all.poss.mods.topo[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, variables_all_p[i])
  model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, !!variables_all_p)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="fire_pres") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.aic, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.topo, big.mod, df.train=dat1, df.test=Valid)

}
}
}


```

Now extract elements from the output .

```{r}
#terms in each model
x1c <- unlist(sapply(mods.fit, '[', 1))
x1c
#Aic for models
x3c <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3c
#auc from validation data
x4c <- unlist(sapply(mods.fit, '[', 4))
x4c
#combining all as df
tab.sum.topo.nt <- cbind.data.frame(model=x1c, edf=x3c[,1], aic=x3c[,2], auc.valid=x4c)
tab.sum.topo.nt$NDT<-c("NDT4 No trees")
tab.sum.topo.nt$delta.aic<- tab.sum.topo.nt$aic - (min(tab.sum.topo.nt$aic))
tab.sum.topo.nt

```

#Now combine the datatables and save to computer

```{r}
NDT4_p_models_nt<-rbind(tab.sum.climate.nt, tab.sum.topo.nt)
NDT4_p_models_nt

write.csv(NDT4_p_models_nt, file="D:\\Fire\\fire_data\\raw_data\\NDT4_person_models_nt.csv")
```

Now choose the top variables and create final model. The below code will need to be updated manually, depending on what the results of the above analyses are.

######## UPDATE BELOW #########

```{r}
##### TOP MODEL####
NDT4_t<-dat_person_nt %>%
  filter(ntrl_ds=="NDT4")

NDT4_t2<-NDT4_t %>% drop_na(live_stand_volume_125, vegtype, climate1, climate2, proj_height_1)

glm_best_NDT4<- glm(fire_pres ~ scale(climate1)*scale(climate2) +
             scale(live_stand_volume_125) +
               scale(proj_height_1) +
               vegtype, 
           data= NDT4_t2,
           family = binomial,
           na.action=na.omit)

summary(glm_best_NDT4)

# model diagnostic plots
binnedplot (fitted(glm_best_NDT4), 
            residuals(glm_best_NDT4), 
            nclass = NULL, 
            xlab = "Expected Values", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))


NDT4_t2$resids<-resid(glm_best_NDT4)

binnedplot (NDT4_t2$live_stand_volume_125, 
            NDT4_t2$resids, 
            nclass = NULL, 
            xlab = "live stand volume", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))

binnedplot (NDT4_t2$climate1, 
            NDT4_t2$resids, 
            nclass = NULL, 
            xlab = "", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))

# Diagnostic plots look good

# Looking at effect of forest height at the average amount of rainfall in September
plot(NDT4_t2$live_stand_volume_125,NDT4_t2$fire_pres)
curve(invlogit(coef(glm_best_NDT4)[1] +coef(glm_best_NDT4)[2]*mean(NDT4_t2$climate1) + coef(glm_best_NDT4)[3]*x), add=TRUE)

# looking at effect of climate1 at the average forest height.
plot(NDT4_t2$climate1,NDT4_t2$fire_pres)
curve(invlogit(coef(glm_best_NDT4)[1] +coef(glm_best_NDT4)[2]*x + coef(glm_best_NDT4)[3]*mean(NDT4_t2$live_stand_volume_125)), add=TRUE)


# create model table (only do this once) and add the relevant data
top_mod_table <- data.frame (matrix (ncol = 16, nrow = 0))
colnames (top_mod_table) <- c ("ZONE", "TREED", "Model_terms", "intercept", "coef_climate_1", "coef_climate_2", "coef_climate_interaction", "coef_stand_height", "coef_live_stand_volume_125", "coef_proj_age", "coef_vegtypeD", "coef_vegtypeOP", "coef_vegtypeS", "coef_vegtypeTB", "coef_vegtypeTC", "coef_vegtypeTM")



##STILL NEED TO ADD DATA FOR TABLE

##Add data for NDT4
top_mod_table[1,1]<-"NDT4"
top_mod_table[1,2]<-"Y"
top_mod_table[1,3]<-"fire_pres ~ ppt09 + proj_height_1" ######### UPDATE
top_mod_table[1,4]<- coef(glm_best_NDT4)[1] #Intercept
top_mod_table[1,5]<- coef(glm_best_NDT4)[2] #Climate variable 1
#top_mod_table[1,6]<- coef(glm_best_NDT4)[2] #Climate variable 2
#top_mod_table[1,7]<- coef(glm_best_NDT4)[3] #Interaction climate variables
#top_mod_table[1,8]<- coef(glm_best_NDT4)[3] #coef_stand_height
#top_mod_table[1,9]<- coef(glm_best_NDT4)[3] #live_stand_volume_125
#top_mod_table[1,10]<- coef(glm_best_NDT4)[4] #proj_age_1
#top_mod_table[1,11]<- coef(glm_best_NDT4)[4] #coefficient vegtypeD
#top_mod_table[1,12]<- coef(glm_best_NDT4)[4] #coefficient vegtypeOP
#top_mod_table[1,13]<- coef(glm_best_NDT4)[4] #coefficient vegtypeS
#top_mod_table[1,14]<- coef(glm_best_NDT4)[4] #coefficient vegtypeTB
#top_mod_table[1,15]<- coef(glm_best_NDT4)[4] #coefficient vegtypeTC
#top_mod_table[1,16]<- coef(glm_best_NDT4)[5] #coefficient vegtypeTM
top_mod_table ##Determine if better way to represent categories for vegtype, and if each climate variable should have its own column

########################## NDT4 Model Selection Complete ###################

```
 
############### Now choose the next NDT zone and repeat ########
Note: currently doing  those with one climate variable)
Models complete above: NDT4
Models to still do henceforth:NDT1, NDT2, NDT3, NDT5


Select next zone: NDT1


```{r}
zones1<-c("NDT1") #Do one zone at a time

filenames<-list()
prop<-0.75

########### 1. Climate and vegtype ############
#for (g in 1:100){

for (h in 1:length(zones1)) {
  dat2<- dat_person_nt %>% dplyr::filter(ntrl_ds ==zones1[h])

for (i in 1: length(all.poss.mods.clim.vegtype2)){
  print(paste((all.poss.mods.clim.vegtype2[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, variables_all_p[i])
  model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, !!variables_all_p)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="fire_pres") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.aic, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.clim.vegtype2, big.mod, df.train=dat1, df.test=Valid)

}
}
}


```

Now extract elements from the output .

```{r}
#terms in each model
x1.1 <- unlist(sapply(mods.fit, '[', 1))
x1.1
#Aic for models
x3.1 <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3.1
#auc from validation data
x4.1 <- unlist(sapply(mods.fit, '[', 4))
x4.1
#combining all as df
tab.sum.climate.nt <- cbind.data.frame(model=x1.1, edf=x3.1[,1], aic=x3.1[,2], auc.valid=x4.1)
tab.sum.climate.nt$NDT<-c("NDT1 No trees")
tab.sum.climate.nt$delta.aic<- tab.sum.climate.nt$aic - (min(tab.sum.climate.nt$aic))
tab.sum.climate.nt 

```


#Now repeat for topography

```{r}

########### 2. Topography ############
#for (g in 1:100){

for (h in 1:length(zones1)) {
 dat2<- dat_person_nt %>% dplyr::filter(ntrl_ds ==zones1[h])

for (i in 1: length(all.poss.mods.topo)){
  print(paste((all.poss.mods.topo[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, variables_all_p[i])
  model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, !!variables_all_p)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="fire_pres") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.aic, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.topo, big.mod, df.train=dat1, df.test=Valid)

}
}
}


```

Now extract elements from the output.

```{r}
#terms in each model
x1.1c <- unlist(sapply(mods.fit, '[', 1))
x1.1c
#Aic for models
x3.1c <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3.1c
#auc from validation data
x4.1c <- unlist(sapply(mods.fit, '[', 4))
x4.1c
#combining all as df
tab.sum.topo.nt <- cbind.data.frame(model=x1.1c, edf=x3.1c[,1], aic=x3.1c[,2], auc.valid=x4.1c)
tab.sum.topo.nt$NDT<-c("NDT1 No trees")
tab.sum.topo.nt$delta.aic<- tab.sum.topo.nt$aic - (min(tab.sum.topo.nt$aic))
tab.sum.topo.nt

```

#Now combine the datatables and save to computer

```{r}
NDT1_p_models_nt<-rbind(tab.sum.climate.nt, tab.sum.topo.nt)
NDT1_p_models_nt

write.csv(NDT1_p_models_nt, file="D:\\Fire\\fire_data\\raw_data\\NDT1_person_models_nt.csv")
```

Now choose the top variables and create final model. The below code will need to be updated manually, depending on what the results of the above analyses are.

######## UPDATE BELOW #########

```{r}
##### TOP MODEL####
NDT1_t<-dat_person_nt %>%
  filter(ntrl_ds=="NDT1")

NDT1_t2<-NDT1_t %>% drop_na(live_stand_volume_125, vegtype, climate1, climate2, proj_height_1)

glm_best_NDT1<- glm(fire_pres ~ scale(climate1)*scale(climate2) +
             scale(live_stand_volume_125) +
               scale(proj_height_1) +
               vegtype, 
           data= NDT1_t2,
           family = binomial,
           na.action=na.omit)

summary(glm_best_NDT1)

# model diagnostic plots
binnedplot (fitted(glm_best_NDT1), 
            residuals(glm_best_NDT1), 
            nclass = NULL, 
            xlab = "Expected Values", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))


NDT1_t2$resids<-resid(glm_best_NDT1)

binnedplot (NDT1_t2$live_stand_volume_125, 
            NDT1_t2$resids, 
            nclass = NULL, 
            xlab = "live stand volume", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))

binnedplot (NDT1_t2$climate1, 
            NDT1_t2$resids, 
            nclass = NULL, 
            xlab = "", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))

# Diagnostic plots look good

# Looking at effect of forest height at the average amount of rainfall in September
plot(NDT1_t2$live_stand_volume_125,NDT1_t2$fire_pres)
curve(invlogit(coef(glm_best_NDT1)[1] +coef(glm_best_NDT1)[2]*mean(NDT1_t2$climate1) + coef(glm_best_NDT1)[3]*x), add=TRUE)

# looking at effect of climate1 at the average forest height.
plot(NDT1_t2$climate1,NDT1_t2$fire_pres)
curve(invlogit(coef(glm_best_NDT1)[1] +coef(glm_best_NDT1)[2]*x + coef(glm_best_NDT1)[3]*mean(NDT1_t2$live_stand_volume_125)), add=TRUE)


# create model table (only do this once) and add the relevant data
top_mod_table <- data.frame (matrix (ncol = 16, nrow = 0))
colnames (top_mod_table) <- c ("ZONE", "TREED", "Model_terms", "intercept", "coef_climate_1", "coef_climate_2", "coef_climate_interaction", "coef_stand_height", "coef_live_stand_volume_125", "coef_proj_age", "coef_vegtypeD", "coef_vegtypeOP", "coef_vegtypeS", "coef_vegtypeTB", "coef_vegtypeTC", "coef_vegtypeTM")



##STILL NEED TO ADD DATA FOR TABLE

##Add data for NDT1
top_mod_table[1,1]<-"NDT1"
top_mod_table[1,2]<-"Y"
top_mod_table[1,3]<-"fire_pres ~ ppt09 + proj_height_1" ######### UPDATE
top_mod_table[1,4]<- coef(glm_best_NDT1)[1] #Intercept
top_mod_table[1,5]<- coef(glm_best_NDT1)[2] #Climate variable 1
#top_mod_table[1,6]<- coef(glm_best_NDT1)[2] #Climate variable 2
#top_mod_table[1,7]<- coef(glm_best_NDT1)[3] #Interaction climate variables
#top_mod_table[1,8]<- coef(glm_best_NDT1)[3] #coef_stand_height
#top_mod_table[1,9]<- coef(glm_best_NDT1)[3] #live_stand_volume_125
#top_mod_table[1,10]<- coef(glm_best_NDT1)[4] #proj_age_1
#top_mod_table[1,11]<- coef(glm_best_NDT1)[4] #coefficient vegtypeD
#top_mod_table[1,12]<- coef(glm_best_NDT1)[4] #coefficient vegtypeOP
#top_mod_table[1,13]<- coef(glm_best_NDT1)[4] #coefficient vegtypeS
#top_mod_table[1,14]<- coef(glm_best_NDT1)[4] #coefficient vegtypeTB
#top_mod_table[1,15]<- coef(glm_best_NDT1)[4] #coefficient vegtypeTC
#top_mod_table[1,16]<- coef(glm_best_NDT1)[5] #coefficient vegtypeTM
top_mod_table ##Determine if better way to represent categories for vegtype, and if each climate variable should have its own column

########################## NDT1 Model Selection Complete ###################



```



############### Now choose the next NDT zone and repeat ########
Note: currently doing  those with one climate variable)
Models complete above: NDT4, NDT1
Models to still do henceforth:NDT2, NDT3, NDT5


Select next zone: NDT2

```{r}
zones1<-c("NDT2") #Do one zone at a time

filenames<-list()
prop<-0.75

########### 1. Climate and vegtype ############
#for (g in 1:100){

for (h in 1:length(zones1)) {
  dat2<- dat_person_nt %>% dplyr::filter(ntrl_ds ==zones1[h])

for (i in 1: length(all.poss.mods.clim.vegtype)){
  print(paste((all.poss.mods.clim.vegtype[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, variables_all_p[i])
  model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, !!variables_all_p_c1)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="fire_pres") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.aic, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.clim.vegtype, big.mod, df.train=dat1, df.test=Valid)

}
}
}


```

Now extract elements from the output .

```{r}
#terms in each model
x1.2 <- unlist(sapply(mods.fit, '[', 1))
x1.2
#Aic for models
x3.2 <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3.2
#auc from validation data
x4.2 <- unlist(sapply(mods.fit, '[', 4))
x4.2
#combining all as df
tab.sum.climate.nt <- cbind.data.frame(model=x1.2, edf=x3.2[,1], aic=x3.2[,2], auc.valid=x4.2)
tab.sum.climate.nt$NDT<-c("NDT2 No trees")
tab.sum.climate.nt$delta.aic<- tab.sum.climate.nt$aic - (min(tab.sum.climate.nt$aic))
tab.sum.climate.nt 

```


#Now repeat for topography

```{r}

########### 2. Topography ############
#for (g in 1:100){

for (h in 1:length(zones1)) {
 dat2<- dat_person_nt %>% dplyr::filter(ntrl_ds ==zones1[h])

for (i in 1: length(all.poss.mods.topo)){
  print(paste((all.poss.mods.topo[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, variables_all_p[i])
  model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, !!variables_all_p)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="fire_pres") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.aic, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.topo, big.mod, df.train=dat1, df.test=Valid)

}
}
}


```

Now extract elements from the output .

```{r}
#terms in each model
x1.2c <- unlist(sapply(mods.fit, '[', 1))
x1.2c
#Aic for models
x3.2c <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3.2c
#auc from validation data
x4.2c <- unlist(sapply(mods.fit, '[', 4))
x4.2c
#combining all as df
tab.sum.topo.nt <- cbind.data.frame(model=x1.2c, edf=x3.2c[,1], aic=x3.2c[,2], auc.valid=x4.2c)
tab.sum.topo.nt$NDT<-c("NDT2 No trees")
tab.sum.topo.nt$delta.aic<- tab.sum.topo.nt$aic - (min(tab.sum.topo.nt$aic))
tab.sum.topo.nt

```

#Now combine the datatables and save to computer

```{r}
NDT2_p_models_nt<-rbind(tab.sum.climate.nt, tab.sum.topo.nt)
NDT2_p_models_nt

write.csv(NDT2_p_models_nt, file="D:\\Fire\\fire_data\\raw_data\\NDT2_person_models_nt.csv")
```

Now choose the top variables and create final model. The below code will need to be updated manually, depending on what the results of the above analyses are.

######## UPDATE BELOW #########

```{r}
##### TOP MODEL####
NDT2_t<-dat_person_nt %>%
  filter(ntrl_ds=="NDT2")

NDT2_t2<-NDT2_t %>% drop_na(live_stand_volume_125, vegtype, climate1, climate2, proj_height_1)

glm_best_NDT2<- glm(fire_pres ~ scale(climate1)*scale(climate2) +
             scale(live_stand_volume_125) +
               scale(proj_height_1) +
               vegtype, 
           data= NDT2_t2,
           family = binomial,
           na.action=na.omit)

summary(glm_best_NDT2)

# model diagnostic plots
binnedplot (fitted(glm_best_NDT2), 
            residuals(glm_best_NDT2), 
            nclass = NULL, 
            xlab = "Expected Values", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))


NDT2_t2$resids<-resid(glm_best_NDT2)

binnedplot (NDT2_t2$live_stand_volume_125, 
            NDT2_t2$resids, 
            nclass = NULL, 
            xlab = "live stand volume", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))

binnedplot (NDT2_t2$climate1, 
            NDT2_t2$resids, 
            nclass = NULL, 
            xlab = "", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))

# Diagnostic plots look good

# Looking at effect of forest height at the average amount of rainfall in September
plot(NDT2_t2$live_stand_volume_125,NDT2_t2$fire_pres)
curve(invlogit(coef(glm_best_NDT2)[1] +coef(glm_best_NDT2)[2]*mean(NDT2_t2$climate1) + coef(glm_best_NDT2)[3]*x), add=TRUE)

# looking at effect of climate1 at the average forest height.
plot(NDT2_t2$climate1,NDT2_t2$fire_pres)
curve(invlogit(coef(glm_best_NDT2)[1] +coef(glm_best_NDT2)[2]*x + coef(glm_best_NDT2)[3]*mean(NDT2_t2$live_stand_volume_125)), add=TRUE)


# create model table (only do this once) and add the relevant data
top_mod_table <- data.frame (matrix (ncol = 16, nrow = 0))
colnames (top_mod_table) <- c ("ZONE", "TREED", "Model_terms", "intercept", "coef_climate_1", "coef_climate_2", "coef_climate_interaction", "coef_stand_height", "coef_live_stand_volume_125", "coef_proj_age", "coef_vegtypeD", "coef_vegtypeOP", "coef_vegtypeS", "coef_vegtypeTB", "coef_vegtypeTC", "coef_vegtypeTM")



##STILL NEED TO ADD DATA FOR TABLE

##Add data for NDT2
top_mod_table[1,1]<-"NDT2"
top_mod_table[1,2]<-"Y"
top_mod_table[1,3]<-"fire_pres ~ ppt09 + proj_height_1" ######### UPDATE
top_mod_table[1,4]<- coef(glm_best_NDT2)[1] #Intercept
top_mod_table[1,5]<- coef(glm_best_NDT2)[2] #Climate variable 1
#top_mod_table[1,6]<- coef(glm_best_NDT2)[2] #Climate variable 2
#top_mod_table[1,7]<- coef(glm_best_NDT2)[3] #Interaction climate variables
#top_mod_table[1,8]<- coef(glm_best_NDT2)[3] #coef_stand_height
#top_mod_table[1,9]<- coef(glm_best_NDT2)[3] #live_stand_volume_125
#top_mod_table[1,10]<- coef(glm_best_NDT2)[4] #proj_age_1
#top_mod_table[1,11]<- coef(glm_best_NDT2)[4] #coefficient vegtypeD
#top_mod_table[1,12]<- coef(glm_best_NDT2)[4] #coefficient vegtypeOP
#top_mod_table[1,13]<- coef(glm_best_NDT2)[4] #coefficient vegtypeS
#top_mod_table[1,14]<- coef(glm_best_NDT2)[4] #coefficient vegtypeTB
#top_mod_table[1,15]<- coef(glm_best_NDT2)[4] #coefficient vegtypeTC
#top_mod_table[1,16]<- coef(glm_best_NDT2)[5] #coefficient vegtypeTM
top_mod_table ##Determine if better way to represent categories for vegtype, and if each climate variable should have its own column

########################## NDT2 Model Selection Complete ###################



```


############### Now choose the next NDT zone and repeat ########
Note: currently doing  those with one climate variable)
Models complete above: NDT4, NDT1, NDT2
Models to still do henceforth: NDT3, NDT5


Select next zone: NDT3


```{r}
zones1<-c("NDT3") #Do one zone at a time

filenames<-list()
prop<-0.75

########### 1. Climate and vegtype ############
#for (g in 1:100){

for (h in 1:length(zones1)) {
  dat2<- dat_person_nt %>% dplyr::filter(ntrl_ds ==zones1[h])

for (i in 1: length(all.poss.mods.clim.vegtype)){
  print(paste((all.poss.mods.clim.vegtype[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, variables_all_p[i])
  model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, !!variables_all_p_c1)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="fire_pres") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.aic, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.clim.vegtype, big.mod, df.train=dat1, df.test=Valid)

}
}
}


```

Now extract elements from the output .

```{r}
#terms in each model
x1.3 <- unlist(sapply(mods.fit, '[', 1))
x1.3
#Aic for models
x3.3 <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3.3
#auc from validation data
x4.3 <- unlist(sapply(mods.fit, '[', 4))
x4.3
#combining all as df
tab.sum.climate.nt <- cbind.data.frame(model=x1.3, edf=x3.3[,1], aic=x3.3[,2], auc.valid=x4.3)
tab.sum.climate.nt$NDT<-c("NDT3 No trees")
tab.sum.climate.nt$delta.aic<- tab.sum.climate.nt$aic - (min(tab.sum.climate.nt$aic))
tab.sum.climate.nt 

```

#Now repeat for topography

```{r}

########### 2. Topography ############
#for (g in 1:100){

for (h in 1:length(zones1)) {
 dat2<- dat_person_nt %>% dplyr::filter(ntrl_ds ==zones1[h])

for (i in 1: length(all.poss.mods.topo)){
  print(paste((all.poss.mods.topo[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, variables_all_p[i])
  model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, !!variables_all_p)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="fire_pres") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.aic, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.topo, big.mod, df.train=dat1, df.test=Valid)

}
}
}


```

Now extract elements from the output .

```{r}
#terms in each model
x1.3c <- unlist(sapply(mods.fit, '[', 1))
x1.3c
#Aic for models
x3.3c <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3.3c
#auc from validation data
x4.3c <- unlist(sapply(mods.fit, '[', 4))
x4.3c
#combining all as df
tab.sum.topo.nt <- cbind.data.frame(model=x1.3c, edf=x3.3c[,1], aic=x3.3c[,2], auc.valid=x4.3c)
tab.sum.topo.nt$NDT<-c("NDT3 No trees")
tab.sum.topo.nt$delta.aic<- tab.sum.topo.nt$aic - (min(tab.sum.topo.nt$aic))
tab.sum.topo.nt

```

#Now combine the datatables and save to computer

```{r}
NDT3_p_models_nt<-rbind(tab.sum.climate.nt, tab.sum.topo.nt)
NDT3_p_models_nt

write.csv(NDT3_p_models_nt, file="D:\\Fire\\fire_data\\raw_data\\NDT3_person_models_nt.csv")
```

Now choose the top variables and create final model. The below code will need to be updated manually, depending on what the results of the above analyses are.

######## UPDATE BELOW #########

```{r}
##### TOP MODEL####
NDT3_t<-dat_person_nt %>%
  filter(ntrl_ds=="NDT3")

NDT3_t2<-NDT3_t %>% drop_na(live_stand_volume_125, vegtype, climate1, climate2, proj_height_1)

glm_best_NDT3<- glm(fire_pres ~ scale(climate1)*scale(climate2) +
             scale(live_stand_volume_125) +
               scale(proj_height_1) +
               vegtype, 
           data= NDT3_t2,
           family = binomial,
           na.action=na.omit)

summary(glm_best_NDT3)

# model diagnostic plots
binnedplot (fitted(glm_best_NDT3), 
            residuals(glm_best_NDT3), 
            nclass = NULL, 
            xlab = "Expected Values", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))


NDT3_t2$resids<-resid(glm_best_NDT3)

binnedplot (NDT3_t2$live_stand_volume_125, 
            NDT3_t2$resids, 
            nclass = NULL, 
            xlab = "live stand volume", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))

binnedplot (NDT3_t2$climate1, 
            NDT3_t2$resids, 
            nclass = NULL, 
            xlab = "", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))

# Diagnostic plots look good

# Looking at effect of forest height at the average amount of rainfall in September
plot(NDT3_t2$live_stand_volume_125,NDT3_t2$fire_pres)
curve(invlogit(coef(glm_best_NDT3)[1] +coef(glm_best_NDT3)[2]*mean(NDT3_t2$climate1) + coef(glm_best_NDT3)[3]*x), add=TRUE)

# looking at effect of climate1 at the average forest height.
plot(NDT3_t2$climate1,NDT3_t2$fire_pres)
curve(invlogit(coef(glm_best_NDT3)[1] +coef(glm_best_NDT3)[2]*x + coef(glm_best_NDT3)[3]*mean(NDT3_t2$live_stand_volume_125)), add=TRUE)


# create model table (only do this once) and add the relevant data
top_mod_table <- data.frame (matrix (ncol = 16, nrow = 0))
colnames (top_mod_table) <- c ("ZONE", "TREED", "Model_terms", "intercept", "coef_climate_1", "coef_climate_2", "coef_climate_interaction", "coef_stand_height", "coef_live_stand_volume_125", "coef_proj_age", "coef_vegtypeD", "coef_vegtypeOP", "coef_vegtypeS", "coef_vegtypeTB", "coef_vegtypeTC", "coef_vegtypeTM")



##STILL NEED TO ADD DATA FOR TABLE

##Add data for NDT3
top_mod_table[1,1]<-"NDT3"
top_mod_table[1,2]<-"Y"
top_mod_table[1,3]<-"fire_pres ~ ppt09 + proj_height_1" ######### UPDATE
top_mod_table[1,4]<- coef(glm_best_NDT3)[1] #Intercept
top_mod_table[1,5]<- coef(glm_best_NDT3)[2] #Climate variable 1
#top_mod_table[1,6]<- coef(glm_best_NDT3)[2] #Climate variable 2
#top_mod_table[1,7]<- coef(glm_best_NDT3)[3] #Interaction climate variables
#top_mod_table[1,8]<- coef(glm_best_NDT3)[3] #coef_stand_height
#top_mod_table[1,9]<- coef(glm_best_NDT3)[3] #live_stand_volume_125
#top_mod_table[1,10]<- coef(glm_best_NDT3)[4] #proj_age_1
#top_mod_table[1,11]<- coef(glm_best_NDT3)[4] #coefficient vegtypeD
#top_mod_table[1,12]<- coef(glm_best_NDT3)[4] #coefficient vegtypeOP
#top_mod_table[1,13]<- coef(glm_best_NDT3)[4] #coefficient vegtypeS
#top_mod_table[1,14]<- coef(glm_best_NDT3)[4] #coefficient vegtypeTB
#top_mod_table[1,15]<- coef(glm_best_NDT3)[4] #coefficient vegtypeTC
#top_mod_table[1,16]<- coef(glm_best_NDT3)[5] #coefficient vegtypeTM
top_mod_table ##Determine if better way to represent categories for vegtype, and if each climate variable should have its own column

########################## NDT3 Model Selection Complete ###################

```

############### Now choose the next NDT zone and repeat ########
Note: currently doing  those with one climate variable)
Models complete above: NDT4, NDT1, NDT2, NDT3
Models to still do henceforth: NDT5

Select next zone: NDT5

```{r}
zones1<-c("NDT5") #Do one zone at a time

filenames<-list()
prop<-0.75

########### 1. Climate and vegtype ############
#for (g in 1:100){

for (h in 1:length(zones1)) {
  dat2<- dat_person_nt %>% dplyr::filter(ntrl_ds ==zones1[h])

for (i in 1: length(all.poss.mods.clim.vegtype2)){
  print(paste((all.poss.mods.clim.vegtype2[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, variables_all_p[i])
  model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, !!variables_all_p)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="fire_pres") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.aic, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.clim.vegtype2, big.mod, df.train=dat1, df.test=Valid)

}
}
}


```

Now extract elements from the output .

```{r}
#terms in each model
x1.5 <- unlist(sapply(mods.fit, '[', 1))
x1.5
#Aic for models
x3.5 <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3.5
#auc from validation data
x4.5 <- unlist(sapply(mods.fit, '[', 4))
x4.5
#combining all as df
tab.sum.climate.nt <- cbind.data.frame(model=x1.5, edf=x3.5[,1], aic=x3.5[,2], auc.valid=x4.5)
tab.sum.climate.nt$NDT<-c("NDT5 No trees")
tab.sum.climate.nt$delta.aic<- tab.sum.climate.nt$aic - (min(tab.sum.climate.nt$aic))
tab.sum.climate.nt 

```


#Now repeat for topography

```{r}

########### 2. Topography ############
#for (g in 1:100){

for (h in 1:length(zones1)) {
 dat2<- dat_person_nt %>% dplyr::filter(ntrl_ds ==zones1[h])

for (i in 1: length(all.poss.mods.topo)){
  print(paste((all.poss.mods.topo[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, variables_all_p[i])
  model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, !!variables_all_p)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="fire_pres") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.aic, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.topo, big.mod, df.train=dat1, df.test=Valid)

}
}
}


```

Now extract elements from the output .

```{r}
#terms in each model
x1.5c <- unlist(sapply(mods.fit, '[', 1))
x1.5c
#Aic for models
x3.5c <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3.5c
#auc from validation data
x4.5c <- unlist(sapply(mods.fit, '[', 4))
x4.5c
#combining all as df
tab.sum.topo.nt <- cbind.data.frame(model=x1.5c, edf=x3.5c[,1], aic=x3.5c[,2], auc.valid=x4.5c)
tab.sum.topo.nt$NDT<-c("NDT5 No trees")
tab.sum.topo.nt$delta.aic<- tab.sum.topo.nt$aic - (min(tab.sum.topo.nt$aic))
tab.sum.topo.nt

```

#Now combine the datatables and save to computer

```{r}
NDT5_p_models_nt<-rbind(tab.sum.climate.nt, tab.sum.topo.nt)
NDT5_p_models_nt

write.csv(NDT5_p_models_nt, file="D:\\Fire\\fire_data\\raw_data\\NDT5_person_models_nt.csv")
```

Now choose the top variables and create final model. The below code will need to be updated manually, depending on what the results of the above analyses are.

######## UPDATE BELOW #########

```{r}
##### TOP MODEL####
NDT5_t<-dat_person_nt %>%
  filter(ntrl_ds=="NDT5")

NDT5_t2<-NDT5_t %>% drop_na(live_stand_volume_125, vegtype, climate1, climate2, proj_height_1)

glm_best_NDT5<- glm(fire_pres ~ scale(climate1)*scale(climate2) +
             scale(live_stand_volume_125) +
               scale(proj_height_1) +
               vegtype, 
           data= NDT5_t2,
           family = binomial,
           na.action=na.omit)

summary(glm_best_NDT5)

# model diagnostic plots
binnedplot (fitted(glm_best_NDT5), 
            residuals(glm_best_NDT5), 
            nclass = NULL, 
            xlab = "Expected Values", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))


NDT5_t2$resids<-resid(glm_best_NDT5)

binnedplot (NDT5_t2$live_stand_volume_125, 
            NDT5_t2$resids, 
            nclass = NULL, 
            xlab = "live stand volume", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))

binnedplot (NDT5_t2$climate1, 
            NDT5_t2$resids, 
            nclass = NULL, 
            xlab = "", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))

# Diagnostic plots look good

# Looking at effect of forest height at the average amount of rainfall in September
plot(NDT5_t2$live_stand_volume_125,NDT5_t2$fire_pres)
curve(invlogit(coef(glm_best_NDT5)[1] +coef(glm_best_NDT5)[2]*mean(NDT5_t2$climate1) + coef(glm_best_NDT5)[3]*x), add=TRUE)

# looking at effect of climate1 at the average forest height.
plot(NDT5_t2$climate1,NDT5_t2$fire_pres)
curve(invlogit(coef(glm_best_NDT5)[1] +coef(glm_best_NDT5)[2]*x + coef(glm_best_NDT5)[3]*mean(NDT5_t2$live_stand_volume_125)), add=TRUE)

# create model table (only do this once) and add the relevant data
top_mod_table <- data.frame (matrix (ncol = 16, nrow = 0))
colnames (top_mod_table) <- c ("ZONE", "TREED", "Model_terms", "intercept", "coef_climate_1", "coef_climate_2", "coef_climate_interaction", "coef_stand_height", "coef_live_stand_volume_125", "coef_proj_age", "coef_vegtypeD", "coef_vegtypeOP", "coef_vegtypeS", "coef_vegtypeTB", "coef_vegtypeTC", "coef_vegtypeTM")


##STILL NEED TO ADD DATA FOR TABLE

##Add data for NDT5
top_mod_table[1,1]<-"NDT5"
top_mod_table[1,2]<-"Y"
top_mod_table[1,3]<-"fire_pres ~ ppt09 + proj_height_1" ######### UPDATE
top_mod_table[1,4]<- coef(glm_best_NDT5)[1] #Intercept
top_mod_table[1,5]<- coef(glm_best_NDT5)[2] #Climate variable 1
#top_mod_table[1,6]<- coef(glm_best_NDT5)[2] #Climate variable 2
#top_mod_table[1,7]<- coef(glm_best_NDT5)[3] #Interaction climate variables
#top_mod_table[1,8]<- coef(glm_best_NDT5)[3] #coef_stand_height
#top_mod_table[1,9]<- coef(glm_best_NDT5)[3] #live_stand_volume_125
#top_mod_table[1,10]<- coef(glm_best_NDT5)[4] #proj_age_1
#top_mod_table[1,11]<- coef(glm_best_NDT5)[4] #coefficient vegtypeD
#top_mod_table[1,12]<- coef(glm_best_NDT5)[4] #coefficient vegtypeOP
#top_mod_table[1,13]<- coef(glm_best_NDT5)[4] #coefficient vegtypeS
#top_mod_table[1,14]<- coef(glm_best_NDT5)[4] #coefficient vegtypeTB
#top_mod_table[1,15]<- coef(glm_best_NDT5)[4] #coefficient vegtypeTC
#top_mod_table[1,16]<- coef(glm_best_NDT5)[5] #coefficient vegtypeTM
top_mod_table ##Determine if better way to represent categories for vegtype, and if each climate variable should have its own column

########################## NDT5 Model Selection Complete ###################

```
















Write as a table to save data for top models for all BEC zones, for those with trees. Will need to repeat for areas without trees.

```{r}
write.csv(top_mod_table, file="D:\\Fire\\fire_data\\raw_data\\Top_Models_Treed.csv")

```
