---
title: "VRI_data_prep"
author: "Elizabeth Kleynhans"
date: "07/07/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


# Copyright 2021 Province of British Columbia
# 
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
# 
# http://www.apache.org/licenses/LICENSE-2.0
# 
# Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and limitations under the License.


#=================================
#  Script Name: 03_vri_data_prep.R
#  Script Version: 1.0
#  Script Purpose: This script creates a table of 1ha x 1ha pixels with vegetation data taken from the VRI for each year for each location.  These locations line up with the locations that I collected climate data from. 
#  Script Author: Elizabeth Kleynhans, Ecological Modeling Specialist, Forest Analysis and Inventory Branch, B.C. Ministry of Forests, Lands, and Natural Resource Operations.
#  Script Contributor: Cora Skaien, Ecological Modeling Specialist, Forest Analysis and Inventory Branch, B.C. Ministry of Forests, Lands, and Natural Resource Operations.
#=================================

#Overview:
In this file, we acquire the VRI (Vegetation Resources Inventory) for each year by location from 2002 to 2020. This is likely already uploaded onto a network and may not need to be redone.
The final product will be a file with veg data along with ignition data and climate data (vegetation, climate and presence/absence of fire data).

The first portion of this code cannot be run on R. Instead, you must use PgAdmin command line.


#### VEGETATION DATA #### 
2002 to 2019 are the only years that VRI data exists, there is no earlier data. I have located a 2020 data file, but it has some too but not all columns for VRI info.

##This first section has been completed on this computer.
from https://catalogue.data.gov.bc.ca/dataset/vri-historical-vegetation-resource-inventory-2002-2019-
I (Liz) then extracted this data and uploaded it into my local postgres database by running the command below in terminal. If running it in the R terminal does not work try run it in here: 
#C:\data\localApps\QGIS10.16\OSGeo4W (the terminal window)

You may get a warning indicating that this will take a long time, or that databases are not supported. You should specify a specific item within the database.
#ogr2ogr -f "PostgreSQL" PG:"host=localhost user=postgres dbname=postgres password=postgres port=5432" C:\\Work\\caribou\\clus_data\\Fire\\VEG_COMP_POLY_AND_LAYER_2020.gdb -overwrite -a_srs EPSG:3005 -progress --config PG_USE_COPY YES -nlt PROMOTE_TO_MULTI

Above is run or each year 2002 to 2020 separately from the data. This is already on the private server, so if you are using the private server, you do not need to run again.

# rename the table in postgres if need be
#ALTER TABLE veg_comp_lyr_r1_poly RENAME TO veg_comp_lyr_r1_poly2017

# When the table name is changed the idx name is not so you might have to change that too so that more files can be uploaded into postgres by running the following command
#ALTER INDEX veg_comp_lyr_r1_poly_shape_geom_idx RENAME TO veg_comp_lyr_r1_poly2019_geometry_geom_idx;
# and if need be change the name of the geometry column from shape to geometry
#ALTER TABLE veg_comp_lyr_r1_poly2019 RENAME COLUMN shape TO geometry;

#### Join ignition data to VRI data ####
Run following query in postgres for all years 2002-2019 except 2007 and 2008. 2020 also has slightly different code. This will need to be done each time new data is generated for random points in file 02. This below code is fast. Note, there are 5 locations in the below code for which to update the year.

CREATE TABLE fire_veg_2002_D AS
(SELECT feature_id, bclcs_level_2, bclcs_level_3, bclcs_level_4, bclcs_level_5,
  harvest_date, proj_age_1, proj_height_1, live_stand_volume_125,
  fire.idno, fire.fire_yr, fire.fire_cs, fire.fir_typ, fire.ign_mnt, fire.size_ha, fire.fire,
  fire.zone, fire.subzone, fire.ntrl_ds, fire.tmax05, fire.tmax06, fire.tmax07,
  fire.tmax08, fire.tmax09, fire.tave05, fire.tave06, fire.tave07, fire.tave08,
  fire.tave09, fire.ppt05, fire.ppt06, fire.ppt07, fire.ppt08, fire.ppt09,
  fire.mdc_05, fire.mdc_06, fire.mdc_07, fire.mdc_08, fire.mdc_09, fire. slp_h_b, 
  fire.aspct__, fire.shp_ln_, 
  veg_comp_lyr_r1_poly2002.geometry FROM veg_comp_lyr_r1_poly2002,
  (SELECT wkb_geometry, idno, fire_yr, fire_cs, fir_typ, ign_mnt, size_ha, fire, zone,
   subzone, ntrl_ds, tmax05, tmax06, tmax07, tmax08, tmax09, tave05, tave06, tave07,
   tave08, tave09, ppt05, ppt06, ppt07, ppt08, ppt09, mdc_05, mdc_06, mdc_07, mdc_08,
   mdc_09, slp_h_b, aspct__, shp_ln_ from Data_climate_DEM_roads where fire_yr = '2002') 
   as fire where st_contains
  (veg_comp_lyr_r1_poly2002.geometry, fire.wkb_geometry))


## See specifics of land cover types here: https://www2.gov.bc.ca/assets/gov/environment/natural-resource-stewardship/nr-laws-policy/risc/landcover-02.pdf
bclcs_level_2: The second level of the BC land cover classification scheme classifies the polygon as to the land cover type:
   # treed or non-treed for vegetated polygons; land or water for non-vegetated polygons.
bclcs_level_3: The location of the polygon relative to elevation and drainage, and is described as either alpine, wetland
   # or upland. In rare cases, the polygon may be alpine wetland.
bclcs_level_4: Classifies the vegetation types and non-vegetated cover types (as described by the presence of distinct features
    # upon the land base within the polygon).
bclcs_level_5: Classifies the vegetation density classes and Non-Vegetated categories.



############## 
#For 2020, run this code because no projected age, height or stand volume 
##############
CREATE TABLE fire_veg_2020_D AS
(SELECT feature_id, bclcs_level_2, bclcs_level_3, bclcs_level_4, bclcs_level_5,
  harvest_date,
  fire.idno, fire.fire_yr, fire.fire_cs, fire.fir_typ, fire.ign_mnt, fire.size_ha, fire.fire,
  fire.zone, fire.subzone, fire.ntrl_ds, fire.tmax05, fire.tmax06, fire.tmax07,
  fire.tmax08, fire.tmax09, fire.tave05, fire.tave06, fire.tave07, fire.tave08,
  fire.tave09, fire.ppt05, fire.ppt06, fire.ppt07, fire.ppt08, fire.ppt09,
  fire.mdc_05, fire.mdc_06, fire.mdc_07, fire.mdc_08, fire.mdc_09, fire. slp_h_b, 
  fire.aspct__, fire.shp_ln_,
  veg_comp_lyr_r1_poly2020.geometry FROM veg_comp_lyr_r1_poly2020,
  (SELECT wkb_geometry, idno, fire_yr, fire_cs, fir_typ, ign_mnt, size_ha, fire, zone,
   subzone, ntrl_ds, tmax05, tmax06, tmax07, tmax08, tmax09, tave05, tave06, tave07,
   tave08, tave09, ppt05, ppt06, ppt07, ppt08, ppt09, mdc_05, mdc_06, mdc_07, mdc_08,
   mdc_09, slp_h_b, aspct__, shp_ln_ from Data_climate_DEM_roads where fire_yr = '2020') as fire where st_contains
  (veg_comp_lyr_r1_poly2020.geometry, fire.wkb_geometry))


###################
#FOR 2007 run this because some of the names for the VRI_2007 file are different to what they are in other years. In particular:
###################

# bclcs_level_2 = bclcs_lv_2 same for the other bclcs layers
#proj_height_1 = proj_ht_1
#harvest_date = upd_htdate
# live_stand_volume_125 does not exist

 CREATE TABLE fire_veg_2007_D AS
 (SELECT feature_id, bclcs_lv_2, bclcs_lv_3, bclcs_lv_4, bclcs_lv_5,
  upd_htdate, proj_age_1, proj_ht_1, COALESCE(volsp1_125,0)+COALESCE(volsp2_125,0)+COALESCE(volsp3_125,0)+COALESCE(volsp4_125,0)+COALESCE(volsp5_125,0) AS live_stand_volume_125,
  fire.idno, fire.fire_yr, fire.fire_cs, fire.fir_typ, fire.ign_mnt, fire.size_ha, fire.fire,
  fire.zone, fire.subzone, fire.ntrl_ds, fire.tmax05, fire.tmax06, fire.tmax07,
  fire.tmax08, fire.tmax09, fire.tave05, fire.tave06, fire.tave07, fire.tave08,
  fire.tave09, fire.ppt05, fire.ppt06, fire.ppt07, fire.ppt08, fire.ppt09,
  fire.mdc_05, fire.mdc_06, fire.mdc_07, fire.mdc_08, fire.mdc_09, fire. slp_h_b, fire.aspct__,
  fire.shp_ln_,
  veg_comp_lyr_r1_poly2007.geometry FROM veg_comp_lyr_r1_poly2007,
  (SELECT wkb_geometry, idno, fire_yr, fire_cs, fir_typ, ign_mnt, size_ha, fire, zone,
   subzone, ntrl_ds, tmax05, tmax06, tmax07, tmax08, tmax09, tave05, tave06, tave07,
   tave08, tave09, ppt05, ppt06, ppt07, ppt08, ppt09, mdc_05, mdc_06, mdc_07, mdc_08,
   mdc_09, slp_h_b, aspct__, shp_ln_ from Data_climate_DEM_roads where fire_yr = '2007') 
   as fire where st_contains (veg_comp_lyr_r1_poly2007.geometry, fire.wkb_geometry))


##############################
# FOR 2008 Run this code:
##############################
 CREATE TABLE fire_veg_2008_D AS
 (SELECT feature_id, bclcs_level_2, bclcs_level_3, bclcs_level_4, bclcs_level_5,
   harvest_date, proj_age_1, proj_height_1, COALESCE(vol_per_ha_spp1_125,0)+
     COALESCE(vol_per_ha_spp2_125,0)+COALESCE(vol_per_ha_spp3_125,0)+COALESCE(vol_per_ha_spp4_125,0)
   +COALESCE(vol_per_ha_spp5_125,0)+COALESCE(vol_per_ha_spp6_125,0) AS live_stand_volume_125,
   fire.idno, fire.fire_yr, fire.fire_cs, fire.fir_typ, fire.ign_mnt, fire.size_ha, fire.fire,
   fire.zone, fire.subzone, fire.ntrl_ds, fire.tmax05, fire.tmax06, fire.tmax07,
   fire.tmax08, fire.tmax09, fire.tave05, fire.tave06, fire.tave07, fire.tave08,
   fire.tave09, fire.ppt05, fire.ppt06, fire.ppt07, fire.ppt08, fire.ppt09,
   fire.mdc_05, fire.mdc_06, fire.mdc_07, fire.mdc_08, fire.mdc_09, fire. slp_h_b, fire.aspct__,
   fire.shp_ln_,
   veg_comp_lyr_r1_poly2008.geometry FROM veg_comp_lyr_r1_poly2008,
   (SELECT wkb_geometry, idno, fire_yr, fire_cs, fir_typ, ign_mnt, size_ha, fire, zone,
    subzone, ntrl_ds, tmax05, tmax06, tmax07, tmax08, tmax09, tave05, tave06, tave07,
    tave08, tave09, ppt05, ppt06, ppt07, ppt08, ppt09, mdc_05, mdc_06, mdc_07, mdc_08,
    mdc_09, slp_h_b, aspct__, shp_ln_ from Data_climate_DEM_roads where fire_yr = '2008') 
    as fire where st_contains (veg_comp_lyr_r1_poly2008.geometry, fire.wkb_geometry))


# note that the VRI for 2008 does not have live_stand_volume so I also tried to extract it from the 2009 VRI and put it in here -  assuming that a year would not make much difference to volume. Below is the code i used to try and do this (but note this does not seem to work.... )
### July 2021, when ran, there already is a column for live_stand_volume_125, so this may not be necessary

#ALTER TABLE fire_veg_2008_C
#ADD COLUMN live_stand_volume_125 double precision;

# INSERT INTO fire_veg_2008_C
# SELECT live_stand_volume_125
# FROM veg_comp_lyr_r1_poly2009,
# (SELECT wkb_geometry from Data_climate_DEM_roads_5x where fire_yr = '2008') as fire where st_contains
# (veg_comp_lyr_r1_poly2009.geometry, fire.wkb_geometry)


# Another problem is that fire_veg_2011 has a geometry column that is type MultiPolygonZ instead of MultiPolygon so this needs to be changed with the following query in postgres
 ALTER TABLE fire_veg_2011_D  
 ALTER COLUMN geometry TYPE geometry(MULTIPOLYGON, 3005) 
 USING ST_Force2D(geometry);

Now, we can use R for the next step.

=====================

```{r}
#Load necessary libraries

library(dplyr)
library(tidyr)
library(keyring)
library(sf)
library(DBI)
library(purrr)
library(tidyverse)
library(ggplot2)
library (ggcorrplot)
library (RPostgreSQL)
library (rpostgis)
library (lme4)
library (arm)
library(ggpubr)
library(mgcv)
library(nlme)
library(caret)
library(pROC)



source(here::here("R/functions/R_Postgres.R"))

```

Now we will bring all of the files we made above into R. You may need to create a new connection to bring each one in instead, or at least run line by line and not as a code chunk.

```{r}

#Import all fire_veg
conn <- dbConnect (dbDriver ("PostgreSQL"), 
                   host = "",
                   user = "postgres",
                   dbname = "postgres",
                   password = "postgres",
                   port = "5432")
fire_veg_2002 <- sf::st_read  (dsn = conn, # connKyle
                               query = "SELECT * FROM public.fire_veg_2002_D")
fire_veg_2003 <- sf::st_read  (dsn = conn, # connKyle
                               query = "SELECT * FROM public.fire_veg_2003_D")
fire_veg_2004 <- sf::st_read  (dsn = conn, # connKyle
                               query = "SELECT * FROM public.fire_veg_2004_D")
fire_veg_2005 <- sf::st_read  (dsn = conn, # connKyle
                               query = "SELECT * FROM public.fire_veg_2005_D")
fire_veg_2006 <- sf::st_read  (dsn = conn, # connKyle
                               query = "SELECT * FROM public.fire_veg_2006_D")
fire_veg_2007 <- sf::st_read  (dsn = conn, # connKyle
                               query = "SELECT * FROM public.fire_veg_2007_D")
fire_veg_2008 <- sf::st_read  (dsn = conn, # connKyle
                               query = "SELECT * FROM public.fire_veg_2008_D")
fire_veg_2009 <- sf::st_read  (dsn = conn, # connKyle
                               query = "SELECT * FROM public.fire_veg_2009_D")
fire_veg_2010 <- sf::st_read  (dsn = conn, # connKyle
                               query = "SELECT * FROM public.fire_veg_2010_D")
fire_veg_2011 <- sf::st_read  (dsn = conn, # connKyle
                               query = "SELECT * FROM public.fire_veg_2011_D")
fire_veg_2012 <- sf::st_read  (dsn = conn, # connKyle
                               query = "SELECT * FROM public.fire_veg_2012_D")
fire_veg_2013 <- sf::st_read  (dsn = conn, # connKyle
                               query = "SELECT * FROM public.fire_veg_2013_D")
fire_veg_2014 <- sf::st_read  (dsn = conn, # connKyle
                               query = "SELECT * FROM public.fire_veg_2014_D")
fire_veg_2015 <- sf::st_read  (dsn = conn, # connKyle
                               query = "SELECT * FROM public.fire_veg_2015_D")
fire_veg_2016 <- sf::st_read  (dsn = conn, # connKyle
                               query = "SELECT * FROM public.fire_veg_2016_D")
fire_veg_2017 <- sf::st_read  (dsn = conn, # connKyle
                               query = "SELECT * FROM public.fire_veg_2017_D")
fire_veg_2018 <- sf::st_read  (dsn = conn, # connKyle
                               query = "SELECT * FROM public.fire_veg_2018_D")
fire_veg_2019 <- sf::st_read  (dsn = conn, # connKyle
                               query = "SELECT * FROM public.fire_veg_2019_D")
fire_veg_2020 <- sf::st_read  (dsn = conn, # connKyle
                               query = "SELECT * FROM public.fire_veg_2020_D")


dbDisconnect (conn) # connKyle

```

We need to update naming conventions from the 2007 and 2008 data given that it is different in those VRI files than for other years.

```{r}

# REMEMBER TO CHANGE THE 0 values in the 2007 and 2008 fire_veg datasets for volume to NULL.

# the VRI for 2007 had harvest_date named upd_htdate and proj_height_1, proj_height_2 as proj_ht_1, proj_ht_2. So I need to be renamed these columns
#fire_veg_2007$harvest_date <- NA
names(fire_veg_2007)
names(fire_veg_2002)
fire_veg_2007<- fire_veg_2007 %>% rename(
  bclcs_level_2=bclcs_lv_2,
  bclcs_level_3=bclcs_lv_3,
  bclcs_level_4=bclcs_lv_4,
  bclcs_level_5=bclcs_lv_5,
  proj_height_1=proj_ht_1, 
  harvest_date=upd_htdate)


# change the 0 values in live_stand_volume_125 to NULL for both 2007 and 2008 data

fire_veg_2007$live_stand_volume_125[fire_veg_2007$live_stand_volume_125 == 0] <- NA
fire_veg_2008$live_stand_volume_125[fire_veg_2008$live_stand_volume_125 == 0] <- NA

fire_veg_2020$proj_height_1<-NA
fire_veg_2020$proj_age_1<-NA
fire_veg_2020$live_stand_volume_125<-NA

```

Now we must combine all of the files together into one.

```{r}

# join all fire_veg datasets together. This function is faster than a list of rbinds
filenames3<- c("fire_veg_2002", "fire_veg_2003", "fire_veg_2004","fire_veg_2005", "fire_veg_2006", "fire_veg_2007","fire_veg_2008", "fire_veg_2009", "fire_veg_2010","fire_veg_2011", "fire_veg_2012", "fire_veg_2013","fire_veg_2014", "fire_veg_2015", "fire_veg_2016","fire_veg_2017", "fire_veg_2018", "fire_veg_2019", "fire_veg_2020")
filenames3

mkFrameList <- function(nfiles) {
  d <- lapply(seq_len(nfiles),function(i) {
    eval(parse(text=filenames3[i])) # for new files lists change the name at filenames2
  })
  do.call(rbind,d)
}

n<-length(filenames3)
fire_veg_data_B<-mkFrameList(n)

table(fire_veg_data_B$fire_yr, fire_veg_data_B$fire_cs)


#Rename columns for ease of use
head(fire_veg_data_B)
fire_veg_data_B<- fire_veg_data_B %>% rename(
  slope=slp_h_b,
  aspect=aspct__,
  ign_month=ign_mnt,
  roads_km=shp_ln_)
names(fire_veg_data_B)

```
Try saving file, but you will note that it is too large.

```{r}
st_write(fire_veg_data_B, dsn = "D:\\Fire\\fire_data\\raw_data\\ClimateBC_Data\\fire_ignitions_veg_climate_ALL_5x.shp", delete_layer=TRUE)
```

Because we have many large objects open in R, we will close some that we no longer need

```{r}
##Now we will remove all of the fire_veg_20XX files since we are finished with processing these

rm(fire_veg_2002, fire_veg_2003, fire_veg_2004,fire_veg_2005, fire_veg_2006, fire_veg_2007,fire_veg_2008, fire_veg_2009, fire_veg_2010,fire_veg_2011, fire_veg_2012, fire_veg_2013,fire_veg_2014, fire_veg_2015, fire_veg_2016,fire_veg_2017, fire_veg_2018, fire_veg_2019, fire_veg_2020)


```


Files are too large to save. So we will subsample here before moving on to next file. Some processing must occur first. We will remove all sites that are predominately water, for example.

```{r}
##1. Remove all sites that are predominately water
str(fire_veg_data_B)
ignition_pres_abs3 <-fire_veg_data_B %>%
  filter(bclcs_level_2!="W") %>%
  filter(bclcs_level_2!=" ")
table(ignition_pres_abs3$bclcs_level_2, ignition_pres_abs3$fire_cs) # T=treed, N =  non-treed and L = land.
table(ignition_pres_abs3$fire_yr, ignition_pres_abs3$fire_cs) 
str(ignition_pres_abs3)

#Creating new variable of vegetation type and a description of how open the vegetation is
# TB =  Treed broadleaf, TC = Treed Conifer, TM = Treed mixed, SL = short shrub, ST = tall shrubs, D = disturbed, O = open. I will combine tall and short shrub. We dont estimate shrub cover in our CLUS model so Im not sure how this will influence our results since I dont think I can track it over time. Maybe I should include it in Open or disturbed?

ignition_pres_abs3$bclcs_level_4<- as.factor(ignition_pres_abs3$bclcs_level_4)
ignition_pres_abs4<- ignition_pres_abs3 %>% drop_na(bclcs_level_4) # this drops from 389464 to 389394 locations so I think its ok to remove the NA's
unique(ignition_pres_abs4$bclcs_level_4)

ignition_pres_abs4$vegtype<-"OP" #setting anything that is not one of the categories below to Open.
ignition_pres_abs4 <- ignition_pres_abs4 %>%
  mutate(vegtype = if_else(bclcs_level_4=="TC","TC", # Treed coniferous
                           if_else(bclcs_level_4=="TM", "TM", # Treed mixed
                                   if_else(bclcs_level_4== "TB","TB", #Treed broadleaf
                                           if_else(bclcs_level_4=="SL", "S", # shrub
                                                   if_else(bclcs_level_4=="ST", "S", vegtype))))))
ignition_pres_abs4$vegtype[which(ignition_pres_abs4$proj_age_1 <16)]<-"D" # disturbed -  following Marchal et al 2017 I make anything that is younger than 15 years old to disturbed. This might be something I should check whether this assumption is ok.

#ignition_pres_abs4<- ignition_pres_abs4 %>% filter(fir_typ!="Nuisance Fire") 
table(ignition_pres_abs4$vegtype, ignition_pres_abs4$fire_cs)

# look at vegetation height, volume and age as we track these in CLUS. 
ignition_pres_abs4$proj_age_1<- as.numeric(ignition_pres_abs4$proj_age_1)
hist(ignition_pres_abs4$proj_age_1)
hist(ignition_pres_abs4$proj_height_1) # not sure we have height in CLUS, we do have volume though. So maybe I should include age and volume in my model. This might be a surrogate for height
hist(ignition_pres_abs4$live_stand_volume_125)
hist(log(ignition_pres_abs4$live_stand_volume_125))
```
Try saving file again

```{r}
st_write(ignition_pres_abs4, dsn = "D:\\Fire\\fire_data\\raw_data\\ClimateBC_Data\\fire_ignitions_veg_climate_ALL_5x_NoW_.shp", delete_layer=TRUE) #File very large > 2 GB, so having saving issues. Perhaps now is a good time to separate the file into lightning, person caused, etc.
```

We will separate into component parts and try to save smaller files as the file is still too big.

```{r}
#fire_veg_data_B_df<-as.data.frame(fire_veg_data_B)
#write.csv(fire_veg_data_B_df, #file="D:\\Fire\\fire_data\\raw_data\\ClimateBC_Data\\fire_ignitions_veg_climate_ALL_df.csv")

table(ignition_pres_abs4$fire_cs)
##Subset data for fire cause of lightning and NA, Person and NA, and Unknown and NA
fire_veg_data_lightning_5x<-ignition_pres_abs4 %>% filter(fire_cs=="Lightning")
table(fire_veg_data_lightning_5x$fire_cs) #15228
fire_veg_data_person_5x<-ignition_pres_abs4 %>% filter(fire_cs=="Person")
table(fire_veg_data_person_5x$fire_cs) #21373
fire_veg_data_NA_5x<-ignition_pres_abs4 %>% filter(fire_cs=="NA")
table(fire_veg_data_NA_5x$fire_cs) #351829
fire_veg_data_unknown_5x<-ignition_pres_abs4 %>% filter(fire_cs=="Unknown")
table(fire_veg_data_unknown_5x$fire_cs) #964

fire_veg_data_lightning_NA_5x<-rbind(fire_veg_data_lightning_5x, fire_veg_data_NA_5x)
table(fire_veg_data_lightning_NA_5x$fire_cs)
table(fire_veg_data_lightning_NA_5x$vegtype)

fire_veg_data_person_NA_5x<-rbind(fire_veg_data_person_5x, fire_veg_data_NA_5x)
table(fire_veg_data_person_NA_5x$fire_cs)

##Write individual files
st_write(fire_veg_data_lightning_5x, dsn = "D:\\Fire\\fire_data\\raw_data\\Fire_climate_DEM_VRI_shape_files\\fire_veg_dem_lightning_5x_NoW.shp", delete_layer=TRUE)

st_write(fire_veg_data_person_5x, dsn = "D:\\Fire\\fire_data\\raw_data\\Fire_climate_DEM_VRI_shape_files\\fire_veg_dem_person_5x_NoW.shp", delete_layer=TRUE)

st_write(fire_veg_data_NA_5x, dsn = "D:\\Fire\\fire_data\\raw_data\\Fire_climate_DEM_VRI_shape_files\\fire_veg_dem_NA_5x_NoW.shp", delete_layer=TRUE) #Get error

##Write aggregated files for lightning and person caused
st_write(fire_veg_data_lightning_NA_5x, dsn = "D:\\Fire\\fire_data\\raw_data\\Fire_climate_DEM_VRI_shape_files\\fire_veg_dem_lightning_NA_5x_NoW.shp", delete_layer=TRUE) #Get error

st_write(fire_veg_data_person_NA_5x, dsn = "D:\\Fire\\fire_data\\raw_data\\Fire_climate_DEM_VRI_shape_files\\fire_veg_dem_person_NA_5x_NoW.shp", delete_layer=TRUE) #Get error

# write final fire ignitions, weather and vegetation types to postgres

##To save to clus, need OsGeo4W
#Modify below with correct credentials and upload on clus as desired
#ogr2ogr -f PostgreSQL PG:"dbname=clus port=5432 user= password= host=DC052586" D:\\Fire\\fire_data\\raw_data\\Fire_climate_DEM_VRI_shape_files\\fire_veg_dem_person_NA_5x_NoW.shp -overwrite -a_srs EPSG:3005 -progress --config PG_USE_COPY YES -nlt PROMOTE_TO_MULTI 
#ogr2ogr -f PostgreSQL PG:"dbname=clus port=5432 user= password= host=DC052586" D:\\Fire\\fire_data\\raw_data\\Fire_climate_DEM_VRI_shape_files\\fire_veg_dem_lightning_NA_5x_NoW.shp -overwrite -a_srs EPSG:3005 -progress --config PG_USE_COPY YES -nlt PROMOTE_TO_MULTI 



```

If you still have many objects open in your Environment, then let's clean the R environment of other elements if we have continued from previous files. This will help R run and not crash. Many methods can be found here: https://stackoverflow.com/questions/6190051/how-can-i-remove-all-objects-but-one-from-the-workspace-in-r

```{r}
ls()

library(gdata)

keep(fire_veg_data_B, ignition_pres_abs4, fire_veg_data_lightning_5x, fire_veg_data_person_5x, fire_veg_data_NA_5x, fire_veg_data_lightning_NA_5x, fire_veg_data_person_NA_5x) #shows you which variables will be removed

keep(fire_veg_data_B, ignition_pres_abs4, fire_veg_data_lightning_5x, fire_veg_data_person_5x, fire_veg_data_NA_5x, fire_veg_data_lightning_NA_5x, fire_veg_data_person_NA_5x, sure = TRUE) # setting sure to TRUE removes variables not in the list
 
ls()
gc(TRUE)

```
Now, we must subsample the data since the sample sizes for the zeros are too large. At least two different papers used 1.5 times the number of presence points as absences. See:
   - Chang et al (2013) Predicting fire occurrence patterns with logistic regression in Heilongjiang Province, China. Landscape Ecology 28, 1989-2004 and
   - Catry et al. (2009) Modeling and mapping wildfire ignition risk in Portugal. International Journal of Wildland Fire 18, 921-931.

# Steps for subsampling:
First, get sample sizes per habitat type and year for the 1's. 
Then sample 2x or some amount more than that value in each of those vegetation, year categories. 
See https://jennybc.github.io/purrr-tutorial/ls12_different-sized-samples.html for an idea on how to do this.

This will be done separately for lightning and person caused fires. 


```{r}
#Lightning caused fires

#Remove geometry
fire_veg_data_lightning_NA_5x_df<- st_set_geometry(fire_veg_data_lightning_NA_5x, NULL)

##Lightning caused
pre<- fire_veg_data_lightning_NA_5x_df %>%
  filter(fire==1) %>%
  dplyr::select(fire_yr, fire, zone, bclcs_level_2) %>%
  group_by(fire_yr, zone, bclcs_level_2) %>%
  summarize(fire_n=n())

##Change to dataframe otherwise code will take a few hours to run
pre_checkpre<- fire_veg_data_lightning_NA_5x_df %>%
  filter(fire==0) %>%
  dplyr::select(fire_yr, fire, zone, bclcs_level_2) %>%
  group_by(fire_yr, zone, bclcs_level_2) %>%
  summarize(abs_n=n())

#check<-left_join(pre, pre_checkpre)
#check<-st_join(pre, pre_checkpre)
check<-left_join(pre, pre_checkpre)
check %>% print(n=100) # hmm there are some NA's in the 0 column. I should probably correct that.

abs_match <- fire_veg_data_lightning_NA_5x_df %>%
  filter(fire == 0) %>%
  group_by(fire_yr, zone, bclcs_level_2) %>%   # prep for work by yr and veg type
  nest() %>%              # --> one row per yr and vegtype
  ungroup()

df<-left_join(check, abs_match) # make sure there are not veg year combinations that are not also in the fire_pres==1 file


# there are several year, zone, subzone combinations with no data in the tibble.  This code below removes the Null values. I should increase my sample of fire absences so that I don't have any combinations with zero data or sample it in a different way. TO DO!
df2 <- df %>% 
  filter(lengths(data)>0)

# here I sample from the tibble the number of data points I want for the absences
# I should probably have replace = false but there are a few rows where there are more fire ignitions in that subzone than randomly sampled locations which is causing issues with this code. For now I'll leave it like this.
  sampled_df<- df2 %>% 
    mutate(samp = map2(data, ceiling(fire_n*2), sample_n, replace=TRUE)) %>%
    dplyr::select(-data) %>%
    unnest(samp) %>%
    dplyr::select(fire_yr, zone, subzone, bclcs_level_2, feature_id:vegtype)
 
# joining my subsampled absence data back to the fire ignition presence data
pre1<- fire_veg_data_lightning_NA_5x_df %>%
  filter(fire==1)
dim(sampled_df) # 22715 rows
dim(pre1) #  15228 rows

dat_lightning<- rbind(pre1, as.data.frame(sampled_df))
dim(dat_lightning) # 37673 rows good this worked I think; Cora July 5 has 45656 rows. This is fewer than the >180,000 rows of the data at the end of file 01

head(dat_lightning)
str(dat_lightning)

#Write file
st_write(dat_lightning, dsn = "D:\\Fire\\fire_data\\raw_data\\Fire_climate_DEM_VRI_shape_files\\dat_lightning_for_analysis_.shp", delete_layer=TRUE)
```
Repeat for person-caused fires

```{r}
############ Repeat abovw for person-caused fires
##Person caused

#Make as dataframe to increase processing speed
fire_veg_data_person_NA_5x_df<- st_set_geometry(fire_veg_data_person_NA_5x, NULL)

#Prepare tables
pre<- fire_veg_data_person_NA_5x_df %>%
  filter(fire==1) %>%
  dplyr::select(fire_yr, fire, zone, bclcs_level_2) %>%
  group_by(fire_yr, zone, bclcs_level_2) %>%
  summarize(fire_n=n())

pre_checkpre<- fire_veg_data_person_NA_5x_df %>%
  filter(fire==0) %>%
  dplyr::select(fire_yr, fire, zone, bclcs_level_2) %>%
  group_by(fire_yr, zone, bclcs_level_2) %>%
  summarize(abs_n=n())

check<-left_join(pre, pre_checkpre)
check %>% print(n=100) # hmm there are some NA's in the 0 column. I should probably correct that.

abs_match <- fire_veg_data_person_NA_5x_df %>%
  filter(fire == 0) %>%
  group_by(fire_yr, zone, bclcs_level_2) %>%   # prep for work by yr and veg type
  nest() %>%              # --> one row per yr and vegtype
  ungroup()

df<-left_join(check, abs_match) # make sure there are not veg year combinations that are not also in the fire_pres==1 file


# there are several year, zone, subzone combinations with no data in the tibble.  This code below removes the Null values. I should increase my sample of fire absences so that I don't have any combinations with zero data or sample it in a different way. TO DO!
df2 <- df %>% 
  filter(lengths(data)>0)

# here I sample from the tibble the number of data points I want for the absences
# I should probably have replace = false but there are a few rows where there are more fire ignitions in that subzone than randomly sampled locations which is causing issues with this code. For now I'll leave it like this.
  sampled_df<- df2 %>% 
    mutate(samp = map2(data, ceiling(fire_n*2), sample_n, replace=TRUE)) %>%
    dplyr::select(-data) %>%
    unnest(samp) %>%
    dplyr::select(fire_yr, zone, subzone, bclcs_level_2, feature_id:vegtype)
 
# joining my subsampled absence data back to the fire ignition presence data
pre1<- fire_veg_data_person_NA_5x_df %>%
  filter(fire==1)
dim(sampled_df) # 22715 rows
dim(pre1) #  15228 rows

dat_person<- rbind(pre1, as.data.frame(sampled_df))
dim(dat_person) # 37673 rows good this worked I think; Cora July 5 has 45656 rows. This is fewer than the >180,000 rows of the data at the end of file 01

head(dat_person)
str(dat_person)

#Write file
st_write(dat_person, dsn = "D:\\Fire\\fire_data\\raw_data\\Fire_climate_DEM_VRI_shape_files\\dat_person_for_analysis_.shp", delete_layer=TRUE) 

 
```

Upload these files to the clus database

```{r}
##Lightning Caused
connKyle <- dbConnect(drv = RPostgreSQL::PostgreSQL(), 
                      host = key_get('dbhost', keyring = 'postgreSQL'),
                      user = key_get('dbuser', keyring = 'postgreSQL'),
                      dbname = key_get('dbname', keyring = 'postgreSQL'),
                      password = key_get('dbpass', keyring = 'postgreSQL'),
                      port = "5432")

st_write (obj = dat_lightning, 
          dsn = connKyle, 
          layer = c ("public", "dat_lightning_for_analysis"))


dbDisconnect (connKyle)


#Person caused
connKyle <- dbConnect(drv = RPostgreSQL::PostgreSQL(), 
                      host = key_get('dbhost', keyring = 'postgreSQL'),
                      user = key_get('dbuser', keyring = 'postgreSQL'),
                      dbname = key_get('dbname', keyring = 'postgreSQL'),
                      password = key_get('dbpass', keyring = 'postgreSQL'),
                      port = "5432")

st_write (obj = dat_person, 
          dsn = connKyle, 
          layer = c ("public", "dat_person_for_analysis"))


dbDisconnect (connKyle)
```


```{r}

##You may wish to clear your environment after this portion
rm(list = ls(all.names = TRUE)) #will clear all objects includes hidden objects.
gc() #free up memory and report the memory usage.
```

############## Now move on to file 06_ignition_climate_variable_selection#############
