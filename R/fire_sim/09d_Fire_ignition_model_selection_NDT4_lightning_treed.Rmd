---
title: "09d_fire_ignition_model_selection_NDT4_lightning_treed"
author: "Cora Skaien"
date: "16/09/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library (data.table)
library (DBI)
library (RPostgreSQL)
library (dplyr)
library (ggplot2)
library (here)
library(ggpubr)
library(arm)
library(tidyr)
library(AICcmodavg)
library(keyring)
library(caret)
library(pROC)
library(rje)
library(car)
library(visreg)

source(here::here("R/functions/R_Postgres.R"))
```


<!--
Copyright 2021 Province of British Columbia

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and limitations under the License.
-->

#=================================
#  Script Name: 09d_fire_ignition_model_selection_NDT4_lightning_treed.R
#  Script Version: 1.0
#  Script Purpose: Model selection, using various initial models to inform the final model selection.
#  Script Author: Cora Skaien, Ecological Modeling Specialist, Forest Analysis and Inventory Branch, B.C. Ministry of Forests, Lands, and Natural Resource Operations.
#=================================

#Load data back in if starting from here
Note: depending where your geometry column was located when saved as a csv (and turned into a dataframe), you may need to manually correct column headings on the csv file before loading back in. This has been performed for the below files.

```{r}
dat_lightning_t<-read.csv(file="D:\\Fire\\fire_data\\raw_data\\ClimateBC_Data\\data_lightning_trees_NDT_Oct.csv")
head(dat_lightning_t)

dat_lightning_nt<-read.csv(file="D:\\Fire\\fire_data\\raw_data\\ClimateBC_Data\\data_lightning_notrees_NDT_Oct.csv")
head(dat_lightning_nt)

dat_person_t<-read.csv(file="D:\\Fire\\fire_data\\raw_data\\ClimateBC_Data\\data_person_trees_NDT_Oct.csv")
head(dat_person_t)

dat_person_nt<-read.csv(file="D:\\Fire\\fire_data\\raw_data\\ClimateBC_Data\\data_person_notrees_NDT_Oct.csv")
head(dat_person_nt)
```

######################### ANALYSES: TREED, LIGHTNING #########################

Now, we will make a loop that does something very similar to our last loop, but with the selected climate variable plus other variables of interest. For lightning caused fires with trees, the variables of interest include:

1. Climate variable(s)
2. Projected Height (proj_height_1)
3. projected age (proj_age_1)  
4. live_stand_volume_125
5. vegtype2 (with additional categories)
6. slope
7. aspect_cos (cos)
8. elevation
9. Various distance to infrastructure variables (dist_mun, dist_dam, dist_nat, dist_pow, dist_mine, dist_any) - no interactions
10. Some measure of death or mountain pine beetle damage -- TBD

Variables to be added after initial model selection for next round model selection:
1. bclcs_level_5_2 (land use) (to be added to final investigated model)

Interactions of interest: two-way interactions between climate (1) and vegtype (6); two-way interactions between topography measures (7-9); interactions between VRI variables.

This will be done separately for trees and non-treed areas. 

Consider modelling by landuse type spread_data_lightning$bclcs_level_5.

First, let's do this for treed areas (with the lightning-caused fires dataset).

##We will do each loop separately for each NDT zone given the large number of possible models for each zone.

First we will create the variable lists that contain all of our variables of interest.

```{r}
##Create variable lists to be used in the model loop.
variables_all<-c(climate1 = "climate1", climate2 = "climate2", proj_height_1 = "proj_height_1", proj_age_1 = "proj_age_1", live_stand_volume_125 = "live_stand_volume_125", slope = "slope", aspect_cos = "aspect_cos", elevation ="elevation", vegtype2 = "vegtype2", dist_mun = "dist_mun", dist_dam = "dist_dam", dist_nat = "dist_nat", dist_pow = "dist_pow", dist_mine = "dist_mine", dist_any = "dist_any") #heatload="heatload",

variables_all_c1<-c(climate1 = "climate1", proj_height_1 = "proj_height_1", proj_age_1 = "proj_age_1", live_stand_volume_125 = "live_stand_volume_125", slope = "slope", aspect_cos = "aspect_cos", elevation ="elevation", vegtype2 = "vegtype2", dist_mun = "dist_mun", dist_dam = "dist_dam", dist_nat = "dist_nat", dist_pow = "dist_pow", dist_mine = "dist_mine", dist_any = "dist_any") #heatload="heatload",

vars.clim<-c("climate1")
vars.clim.vegtype<-c("climate1", "vegtype2")
vars.clim.vegtype2<-c("climate1", "climate2","vegtype2")
vars.clim.vegtype2b<-c("climate1", "climate2")

vars.oth<-c("proj_height_1", "proj_age_1", "live_stand_volume_125") 
vars.topo<-c("slope", "aspect_cos", "elevation")
vars.heatload<-c("heatload")
vars.infra<-c("dist_mun", "dist_dam", "dist_nat", "dist_pow", "dist_mine", "dist_any")


##Create interaction for climate and vegtype
inputs.me <- c(vars.clim.vegtype)
inputs.me2 <- c(vars.clim.vegtype2)
inputs.me2b <- c(vars.clim.vegtype2b)
```

Now, we will generate two-way interactions for each of these lists. 

```{r}

#####1a. For those with one climate variable
#get the names of all possible two-way interactions for climate variable(s) and vegtype.
twoway.ints <- NULL
for (i in 1:(length(inputs.me)-1)) {
  for (j in (i+1):length(inputs.me)) {
     twoway.ints <- cbind(twoway.ints, paste(inputs.me[i], inputs.me[j], sep=":"))
  }
}
twoway.ints
length(twoway.ints)

#
#Create function to determine Powerset for any vector of variable names
## or use rje package
#powerSet <- function(x) {
#   z.list <- NULL
#   for(i in 1:length(x)) {
#      z.list <- append(z.list, combn(x, m=i, simplify=F))
#   }    
#   return(z.list)
#}


#Get variables on own
#complete list of models using non-climate vars
mods.me.tmp <- powerSet(vars.clim.vegtype) 
#add climate vars to all of the above
mods.me.climate <- list()
for (i in 1: length(mods.me.tmp)) {
   mods.me.climate[[i]] <- c(mods.me.tmp[[i]])
}

mods.me.climate


#####1b. For those with two climate variables
#get the names of all possible two-way interactions for climate variable(s) and vegtype.
twoway.ints2 <- NULL
for (i in 1:(length(inputs.me2)-1)) {
  for (j in (i+1):length(inputs.me2)) {
     twoway.ints2 <- cbind(twoway.ints2, paste(inputs.me2[i], inputs.me2[j], sep=":"))
  }
}
twoway.ints2
length(twoway.ints2)

#Get variables on own
#complete list of models using non-climate vars
mods.me.tmp <- powerSet(vars.clim.vegtype2) 
#add climate vars to all of the above
mods.me.climate2 <- list()
for (i in 1: length(mods.me.tmp)) {
   mods.me.climate2[[i]] <- c(mods.me.tmp[[i]])
}

mods.me.climate2

#complete list of two-way interactions
mods.twoway2 <- powerSet(twoway.ints2)
length(mods.twoway2) #7
mods.twoway2

#Finding models in mods.me that accommodate/allow interaction terms in each mods.twoway to be added
mods.inter2 <- list()
counter <- 0
for (i in 1: length(mods.twoway2)) {
   s1 <- unique(unlist( strsplit(mods.twoway2[[i]], split=':', fixed=TRUE) ) )
   for (j in 1: length(mods.me.climate2)) {
      if (all(s1 %in% mods.me.climate2[[j]])==TRUE) {
        counter <- counter + 1
        both <-  c(mods.me.climate2[[j]], mods.twoway2[[i]])
        mods.inter2[[counter]] <- both
      }
   }
}

length(mods.inter2)
mods.inter2


####1c. Two variables, no variation in vegtype
#get the names of all possible two-way interactions for climate variable(s) and vegtype.
twoway.ints2b <- NULL
for (i in 1:(length(inputs.me2b)-1)) {
  for (j in (i+1):length(inputs.me2b)) {
     twoway.ints2b <- cbind(twoway.ints2b, paste(inputs.me2b[i], inputs.me2b[j], sep=":"))
  }
}
twoway.ints2b
length(twoway.ints2b)

#Get variables on own
#complete list of models using non-climate vars
mods.me.tmp <- powerSet(vars.clim.vegtype2b) 
#add climate vars to all of the above
mods.me.climate2b <- list()
for (i in 1: length(mods.me.tmp)) {
   mods.me.climate2b[[i]] <- c(mods.me.tmp[[i]])
}

mods.me.climate2b

#complete list of two-way interactions
mods.twoway2b <- powerSet(twoway.ints2b)
length(mods.twoway2b) #7
mods.twoway2b

#Finding models in mods.me that accommodate/allow interaction terms in each mods.twoway to be added
mods.inter2b <- list()
counter <- 0
for (i in 1: length(mods.twoway2b)) {
   s1 <- unique(unlist( strsplit(mods.twoway2b[[i]], split=':', fixed=TRUE) ) )
   for (j in 1: length(mods.me.climate2b)) {
      if (all(s1 %in% mods.me.climate2b[[j]])==TRUE) {
        counter <- counter + 1
        both <-  c(mods.me.climate2b[[j]], mods.twoway2b[[i]])
        mods.inter2b[[counter]] <- both
      }
   }
}

length(mods.inter2b)
mods.inter2b


#########2. Now for topography data, get all possible two-way interactions

#get the names of all possible two-way interactions
twoway.intsT <- NULL
for (i in 1:(length(vars.topo)-1)) {
  for (j in (i+1):length(vars.topo)) {
     twoway.intsT <- cbind(twoway.intsT, paste(vars.topo[i], vars.topo[j], sep=":"))
  }
}
twoway.intsT
length(twoway.intsT)

#complete list of models using non-climate vars (topo)
mods.me.tmp <- powerSet(vars.topo) 
#add climate vars to all of the above
mods.meT <- list()
for (i in 1: length(mods.me.tmp)) {
   mods.meT[[i]] <- c(mods.me.tmp[[i]])
}

mods.meT

#complete list of two-way interactions
mods.twowayT <- powerSet(twoway.intsT)
length(mods.twowayT) #7
mods.twowayT

#Finding models in mods.me that accommodate/allow interaction terms in each mods.twoway to be added

mods.interT <- list()
counter <- 0
for (i in 1: length(mods.twowayT)) {
   s1 <- unique(unlist( strsplit(mods.twowayT[[i]], split=':', fixed=TRUE) ) )
   for (j in 1: length(mods.meT)) {
      if (all(s1 %in% mods.meT[[j]])==TRUE) {
        counter <- counter + 1
        both <-  c(mods.meT[[j]], mods.twowayT[[i]])
        mods.interT[[counter]] <- both
      }
   }
}

length(mods.interT)
mods.interT
mods.interTb<-c(mods.interT,vars.heatload)
mods.interTb

####3.For other VRI data, get without interactions

#complete list of models using VRI - no interactions
mods.me.tmp <- powerSet(vars.oth) 
#add climate vars to all of the above
mods.me.oth <- list()
for (i in 1: length(mods.me.tmp)) {
   mods.me.oth[[i]] <- c(mods.me.tmp[[i]])
}

mods.me.oth


#########4. Now for distance to infrastructure data, get all possible two-way interactions

#get the names of all possible two-way interactions
twoway.intsI <- NULL
for (i in 1:(length(vars.infra)-1)) {
  for (j in (i+1):length(vars.infra)) {
     twoway.intsI <- cbind(twoway.intsI, paste(vars.infra[i], vars.infra[j], sep=":"))
  }
}
twoway.intsI
length(twoway.intsI)

#complete list of models using non-climate vars (infra)
mods.me.tmp <- powerSet(vars.infra) 
#add climate vars to all of the above
mods.meI <- list()
for (i in 1: length(mods.me.tmp)) {
   mods.meI[[i]] <- c(mods.me.tmp[[i]])
}

mods.meI

#complete list of two-way interactions
mods.twowayI <- powerSet(twoway.intsI)
length(mods.twowayI) #32768
mods.twowayI

#Finding models in mods.me that accommodate/allow interaction terms in each mods.twoway to be added

mods.interI <- list()
counter <- 0
for (i in 1: length(mods.twowayI)) {
   s1 <- unique(unlist( strsplit(mods.twowayI[[i]], split=':', fixed=TRUE) ) )
   for (j in 1: length(mods.meI)) {
      if (all(s1 %in% mods.meI[[j]])==TRUE) {
        counter <- counter + 1
        both <-  c(mods.meI[[j]], mods.twowayI[[i]])
        mods.interI[[counter]] <- both
      }
   }
}

length(mods.interI)
mods.interI


#the list of all possible model RHSs. 
#all.poss.mods <- c(1, vars.clim, twoway.ints, mods.me.oth, mods.me2, mods.inter2)
#all.poss.mods

all.poss.mods.clim.vegtype<-c(1, mods.me.climate, twoway.ints)
all.poss.mods.clim.vegtype 
all.poss.mods.clim.vegtype<-all.poss.mods.clim.vegtype [-2] #Use this line only if there is an odd character(0) added to list
all.poss.mods.clim.vegtype2<-c(1, mods.inter2)
all.poss.mods.clim.vegtype2
all.poss.mods.clim.vegtype2<-all.poss.mods.clim.vegtype2[-2]
#all.poss.mods.clim.vegtype2<-all.poss.mods.clim.vegtype2[-9]
all.poss.mods.clim.vegtype2b<-c(1, mods.inter2b)
#all.poss.mods.clim.vegtype2b<-c(1, mods.me.climate2b, mods.inter2b)
all.poss.mods.clim.vegtype2b
all.poss.mods.clim.vegtype2b<-all.poss.mods.clim.vegtype2b[-2]
#all.poss.mods.clim.vegtype2b<-all.poss.mods.clim.vegtype2b[-5]

all.poss.mods.VRI<-c(1, mods.me.oth)
all.poss.mods.VRI
all.poss.mods.VRI<-all.poss.mods.VRI[-2]
#all.poss.mods.topo<-c(1, mods.meT, mods.interT)
all.poss.mods.topo<-c(1, mods.interT)
all.poss.mods.topo
#all.poss.mods.topo<-all.poss.mods.topo[-10]
all.poss.mods.topo<-all.poss.mods.topo[-2]
all.poss.mods.infra<-c(1, mods.meI) #I don't think we want interactions here actually...
#all.poss.mods.infra<-c(1, mods.meI, mods.interI)
all.poss.mods.infra<-all.poss.mods.infra[-2] #See if have future errors to see if need to remove

#If need to determine which ones are character(0), try this:
biglist <- list(list("A","B","C"), "foo", "", character(0), integer(0))
lapply(biglist, function(x) {length(x) == 0L} ) 


##Check and rid of any duplicated models
duplicated(all.poss.mods.clim.vegtype) #None duplicated
duplicated(all.poss.mods.clim.vegtype2)
duplicated(all.poss.mods.clim.vegtype2b)
duplicated(all.poss.mods.VRI)
duplicated(all.poss.mods.topo)
duplicated(all.poss.mods.infra)

```

THE ABOVE CODE CHUNKS WILL ALSO APPLY TO TREED, LIGHTNING NDT4-3 and 5.



############### Part 1 of 4 Model Series: Lightning Caused Fires, Trees ##########

Because of the large number of models with all variables included, we will test the climate and vegtype first, then the VRI variables, then the topography variables. Then we will test the top models together, with determining best AIC model from there. Or perhaps we will just combine the top models for each together, and eliminate models if the intercept was the best predictor.

Select NDT: NDT4 

```{r}
zones1<-c("NDT4") #Do one zone at a time

prop<-0.75

#Create empty table
table.glm.climate.simple <- data.frame (matrix (ncol = 5, nrow = 0))
colnames (table.glm.climate.simple) <- c ("model", "edf", "aic", "auc.valid", "NDT")

########### 1. Climate and vegtype ############
for (g in 1:100){

for (h in 1:length(zones1)) {
  dat2<- dat_lightning_t %>% dplyr::filter(ntrl_ds ==zones1[h])

#for (i in 1: length(all.poss.mods.clim.vegtype2)){
#  print(paste((all.poss.mods.clim.vegtype2[i]), (zones1[h]), sep=" "))
  
for (i in 1: length(zones1)){
  print(paste((all.poss.mods.clim.vegtype2[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, variables_all[i])
  model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, !!variables_all)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="fire_pres") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.aic, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.clim.vegtype2, big.mod, df.train=dat1, df.test=Valid)

#terms in each model
x1.1 <- unlist(sapply(mods.fit, '[', 1))
x1.1
#Aic for models
x3.1 <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3.1
#auc from validation data
x4.1 <- unlist(sapply(mods.fit, '[', 4))
x4.1
#combining all as df
tab.sum.climate <- cbind.data.frame(model=x1.1, edf=x3.1[,1], aic=x3.1[,2], auc.valid=x4.1)
tab.sum.climate$NDT<-c("NDT4")
tab.sum.climate 

table.glm.climate.simple<-rbind(table.glm.climate.simple, tab.sum.climate)

}
}
}


```

Now that we have run the model 100 times, we want the average AIC and AUC for each variable combination.

```{r}
head(table.glm.climate.simple)
table(table.glm.climate.simple$model) # 100 per model

AIC_lightning_NDT4_treed_climate<-table.glm.climate.simple

AIC_lightning_NDT4_treed_summary_climate<- AIC_lightning_NDT4_treed_climate %>%
  group_by(model) %>%
  summarise(meanAIC=mean(aic),
            meanAUC=mean(auc.valid),
            sdAUC=sd(auc.valid),
            )

AIC_lightning_NDT4_treed_summary_climate2<- AIC_lightning_NDT4_treed_summary_climate %>%
  mutate(deltaAIC=meanAIC-min(meanAIC))

head(AIC_lightning_NDT4_treed_summary_climate2)
```

#Now repeat for VRI data

```{r}
########### 2. VRI ############
#Create empty table
table.glm.VRI.simple <- data.frame (matrix (ncol = 5, nrow = 0))
colnames (table.glm.VRI.simple) <- c ("model", "edf", "aic", "auc.valid", "NDT")

####
for (g in 1:100){

for (h in 1:length(zones1)) {
  dat2<- dat_lightning_t %>% dplyr::filter(ntrl_ds ==zones1[h])

#for (i in 1: length(all.poss.mods.VRI)){
#  print(paste((all.poss.mods.VRI[i]), (zones1[h]), sep=" "))
  
for (i in 1: length(zones1)){
  print(paste((all.poss.mods.VRI[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, variables_all[i])
  model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, !!variables_all)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="fire_pres") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.aic, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.VRI, big.mod, df.train=dat1, df.test=Valid)

#terms in each model
x1.1 <- unlist(sapply(mods.fit, '[', 1))
x1.1
#Aic for models
x3.1 <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3.1
#auc from validation data
x4.1 <- unlist(sapply(mods.fit, '[', 4))
x4.1
#combining all as df
tab.sum.VRI <- cbind.data.frame(model=x1.1, edf=x3.1[,1], aic=x3.1[,2], auc.valid=x4.1)
tab.sum.VRI$NDT<-c("NDT4")
tab.sum.VRI 

table.glm.VRI.simple<-rbind(table.glm.VRI.simple, tab.sum.VRI)

}
}
}
```

Now that we have run the model 100 times, we want the average AIC and AUC for each variable combination.

```{r}
head(table.glm.VRI.simple)
table(table.glm.VRI.simple$model) # 100 per model

AIC_lightning_NDT4_treed_VRI<-table.glm.VRI.simple

AIC_lightning_NDT4_treed_summary_VRI<- AIC_lightning_NDT4_treed_VRI %>%
  group_by(model) %>%
  summarise(meanAIC=mean(aic),
            meanAUC=mean(auc.valid),
            sdAUC=sd(auc.valid),
            )

AIC_lightning_NDT4_treed_summary_VRI2<- AIC_lightning_NDT4_treed_summary_VRI %>%
  mutate(deltaAIC=meanAIC-min(meanAIC))

head(AIC_lightning_NDT4_treed_summary_VRI2)
```


#Now repeat for topography

```{r}
########### 3. topo ############
#Create empty table
table.glm.topo.simple <- data.frame (matrix (ncol = 5, nrow = 0))
colnames (table.glm.topo.simple) <- c ("model", "edf", "aic", "auc.valid", "NDT")

#
for (g in 1:100){

for (h in 1:length(zones1)) {
  dat2<- dat_lightning_t %>% dplyr::filter(ntrl_ds ==zones1[h])

#for (i in 1: length(all.poss.mods.topo)){
#  print(paste((all.poss.mods.topo[i]), (zones1[h]), sep=" "))
  
for (i in 1: length(zones1)){
  print(paste((all.poss.mods.topo[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, variables_all[i])
  model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, !!variables_all)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="fire_pres") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.aic, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.topo, big.mod, df.train=dat1, df.test=Valid)

#terms in each model
x1.1 <- unlist(sapply(mods.fit, '[', 1))
x1.1
#Aic for models
x3.1 <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3.1
#auc from validation data
x4.1 <- unlist(sapply(mods.fit, '[', 4))
x4.1
#combining all as df
tab.sum.topo <- cbind.data.frame(model=x1.1, edf=x3.1[,1], aic=x3.1[,2], auc.valid=x4.1)
tab.sum.topo$NDT<-c("NDT4")
tab.sum.topo 

table.glm.topo.simple<-rbind(table.glm.topo.simple, tab.sum.topo)

}
}
}
```

Now that we have run the model 100 times, we want the average AIC and AUC for each variable combination.

```{r}
head(table.glm.topo.simple)
table(table.glm.topo.simple$model) # 100 per model

AIC_lightning_NDT4_treed_topo<-table.glm.topo.simple

AIC_lightning_NDT4_treed_summary_topo<- AIC_lightning_NDT4_treed_topo %>%
  group_by(model) %>%
  summarise(meanAIC=mean(aic),
            meanAUC=mean(auc.valid),
            sdAUC=sd(auc.valid),
            )

AIC_lightning_NDT4_treed_summary_topo2<- AIC_lightning_NDT4_treed_summary_topo %>%
  mutate(deltaAIC=meanAIC-min(meanAIC))

head(AIC_lightning_NDT4_treed_summary_topo2)
```


#Now repeat for infrastructure

```{r}
########### 4. Distance to Infrastructure ############
#Create empty table
table.glm.infra.simple <- data.frame (matrix (ncol = 5, nrow = 0))
colnames (table.glm.infra.simple) <- c ("model", "edf", "aic", "auc.valid", "NDT")

#
for (g in 1:100){

for (h in 1:length(zones1)) {
  dat2<- dat_lightning_t %>% dplyr::filter(ntrl_ds ==zones1[h])

#for (i in 1: length(all.poss.mods.infra)){
#  print(paste((all.poss.mods.infra[i]), (zones1[h]), sep=" "))
  
for (i in 1: length(zones1)){
  print(paste((all.poss.mods.infra[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, variables_all[i])
  model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, !!variables_all)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="fire_pres") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.aic, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.infra, big.mod, df.train=dat1, df.test=Valid)

#terms in each model
x1.1 <- unlist(sapply(mods.fit, '[', 1))
x1.1
#Aic for models
x3.1 <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3.1
#auc from validation data
x4.1 <- unlist(sapply(mods.fit, '[', 4))
x4.1
#combining all as df
tab.sum.infra <- cbind.data.frame(model=x1.1, edf=x3.1[,1], aic=x3.1[,2], auc.valid=x4.1)
tab.sum.infra$NDT<-c("NDT4")
tab.sum.infra 

table.glm.infra.simple<-rbind(table.glm.infra.simple, tab.sum.infra)

}
}
}
```

Now that we have run the model 100 times, we want the average AIC and AUC for each variable combination.

```{r}
head(table.glm.infra.simple)
table(table.glm.infra.simple$model) # 100 per model

AIC_lightning_NDT4_treed_infra<-table.glm.infra.simple

AIC_lightning_NDT4_treed_summary_infra<- AIC_lightning_NDT4_treed_infra %>%
  group_by(model) %>%
  summarise(meanAIC=mean(aic),
            meanAUC=mean(auc.valid),
            sdAUC=sd(auc.valid),
            )

AIC_lightning_NDT4_treed_summary_infra2<- AIC_lightning_NDT4_treed_summary_infra %>%
  mutate(deltaAIC=meanAIC-min(meanAIC))

head(AIC_lightning_NDT4_treed_summary_infra2)

```

#Now combine the datatables and save to computer

```{r}
NDT4_l_models_treed<-rbind(AIC_lightning_NDT4_treed_summary_climate2, AIC_lightning_NDT4_treed_summary_VRI2, AIC_lightning_NDT4_treed_summary_topo2, AIC_lightning_NDT4_treed_summary_infra2)
NDT4_l_models_treed
NDT4_l_models_treed$NDT<-"NDT4"

write.csv(NDT4_l_models_treed, file="D:\\Fire\\fire_data\\raw_data\\NDT4_lightning_models_treed.csv")
```

################################ STAGE TWO ########################

#STAGE TWO: PUT TOGETHER MORE VARIABLES
Now choose the top variables and create final model. The below code will need to be updated manually, depending on what the results of the above analyses are. From the top models, we will re-create two-way interactions for the variables selected from each model, plus the other variables listed as needed to be included. We will assess each set to ensure only interactions that make sense are investigated ultimately, given that sample sizes will be an issues.

Top Models:
1. climate1 + climate2 + vegtype2 + climate1:climate2
2. proj_height_1 + live_stand_volume_125
3. slope + aspect_cos + elevation + slope:aspect_cos
4. dist_mun + dist_dam + dist_nat + dist_pow + dist_any. 

Additional Variabes:
1. bclcs_level_5_2 (land use) (to be added to final investigated model)

We want to include interactions between variables from within each list. This will make for many models.

```{r}
##Create variable lists to be used in the model loop.
variables_all_NDT4<-c(climate1 = "climate1", climate2 = "climate2", vegtype2 = "vegtype2", proj_height_1 = "proj_height_1", live_stand_volume_125 = "live_stand_volume_125", slope = "slope", aspect_cos = "aspect_cos", elevation ="elevation", dist_mun = "dist_mun", dist_dam = "dist_dam", dist_nat = "dist_nat", dist_pow = "dist_pow", dist_any = "dist_any", bclcs_level_5_2 = "bclcs_level_5_2")

variables_all_NDT4<-c(climate1 = "climate1", climate2 = "climate2", vegtype2 = "vegtype2", proj_height_1 = "proj_height_1", live_stand_volume_125 = "live_stand_volume_125", slope = "slope", aspect_cos = "aspect_cos", elevation ="elevation", dist_any = "dist_any", bclcs_level_5_2 = "bclcs_level_5_2")

variables_all_NDT4<-c("climate1", "climate2", "vegtype2", "proj_height_1", "live_stand_volume_125","slope", "aspect_cos", "elevation", "dist_any", "bclcs_level_5_2")

#Too many permutations to be able to include two-way interactions and all possible models, so need to divide into what we think may have interactions and which not.
variables_clim_VRI_NDT4<-c(climate1 = "climate1", climate2 = "climate2", vegtype2 = "vegtype2", proj_height_1 = "proj_height_1", live_stand_volume_125 = "live_stand_volume_125")

#treat slope, aspect_cos and elevation as their own thing.And we have already done this analysis with them.
#slope = "slope", aspect_cos = "aspect_cos", elevation ="elevation")

variables_all_infra_landuse_NDT4<-c(dist_mun = "dist_mun", dist_dam = "dist_dam", dist_nat = "dist_nat", dist_pow = "dist_pow", dist_any = "dist_any", bclcs_level_5_2 = "bclcs_level_5_2") #I don't think it makes sense to have interactions between the distance elements, but maybe with land use and each distance element?

##
inputs.me.NDT4 <- c(variables_all_NDT4)
#inputs.me.clim_VRI_DEM_NDT4 <- c(variables_clim_VRI_DEM_NDT4)
inputs.me.clim_VRI_NDT4 <- c(variables_clim_VRI_NDT4)
inputs.me.infra_landuse_NDT4 <- c(variables_all_infra_landuse_NDT4)

```

Before the next step, you may need to clear much of the workspace. Many elements below are from previous files, or from code that follows that I ran before. So you will likely need to modify to suit your needs.

```{r}
#First remove the AIC tables from this section. Note, you may not have created them all yet, and may need to remove some sections.
rm(AIC_lightning_NDT4_treed, AIC_lightning_NDT4_treed_climate, AIC_lightning_NDT4_treed_infra, AIC_lightning_NDT4_treed_summary, AIC_lightning_NDT4_treed_summary_climate, AIC_lightning_NDT4_treed_summary_climate2, AIC_lightning_NDT4_treed_summary_infra, AIC_lightning_NDT4_treed_summary_infra2, AIC_lightning_NDT4_treed_summary_topo, AIC_lightning_NDT4_treed_summary_topo2, AIC_lightning_NDT4_treed_summary_VRI, AIC_lightning_NDT4_treed_summary_VRI2, AIC_lightning_NDT4_treed_topo, AIC_lightning_NDT4_treed_VRI, AIC_lightning_NDT4_treed_infra, AIC_lightning_NDT2_treed_climate, 
   
   AIC_lightning_NDT2_treed, AIC_lightning_NDT2_treed_climate, AIC_lightning_NDT2_treed_infra, AIC_lightning_NDT2_treed_summary, AIC_lightning_NDT2_treed_summary_climate, AIC_lightning_NDT2_treed_summary_climate2, AIC_lightning_NDT2_treed_summary_infra, AIC_lightning_NDT2_treed_summary_infra2, AIC_lightning_NDT2_treed_summary_topo, AIC_lightning_NDT2_treed_summary_topo2, AIC_lightning_NDT2_treed_summary_VRI, AIC_lightning_NDT2_treed_summary_VRI2, AIC_lightning_NDT2_treed_topo, AIC_lightning_NDT2_treed_VRI, AIC_lightning_NDT2_treed_infra, AIC_lightning_NDT2_treed_climate,
   
   AIC_lightning_NDT3_treed, AIC_lightning_NDT3_treed_climate, AIC_lightning_NDT3_treed_infra, AIC_lightning_NDT3_treed_summary, AIC_lightning_NDT3_treed_summary_climate, AIC_lightning_NDT3_treed_summary_climate2, AIC_lightning_NDT3_treed_summary_infra, AIC_lightning_NDT3_treed_summary_infra2, AIC_lightning_NDT3_treed_summary_topo, AIC_lightning_NDT3_treed_summary_topo2, AIC_lightning_NDT3_treed_summary_VRI, AIC_lightning_NDT3_treed_summary_VRI2, AIC_lightning_NDT3_treed_topo, AIC_lightning_NDT3_treed_VRI, AIC_lightning_NDT3_treed_infra, AIC_lightning_NDT2_treed_climate,
   
   AIC_lightning_NDT4_treed, AIC_lightning_NDT4_treed_climate, AIC_lightning_NDT4_treed_infra, AIC_lightning_NDT4_treed_summary, AIC_lightning_NDT4_treed_summary_climate, AIC_lightning_NDT4_treed_summary_climate2, AIC_lightning_NDT4_treed_summary_infra, AIC_lightning_NDT4_treed_summary_infra2, AIC_lightning_NDT4_treed_summary_topo, AIC_lightning_NDT4_treed_summary_topo2, AIC_lightning_NDT4_treed_summary_VRI, AIC_lightning_NDT4_treed_summary_VRI2, AIC_lightning_NDT4_treed_topo, AIC_lightning_NDT4_treed_VRI, AIC_lightning_NDT4_treed_infra, AIC_lightning_NDT4_treed_climate,
   
   AIC_lightning_NDT5_treed, AIC_lightning_NDT5_treed_climate, AIC_lightning_NDT5_treed_infra, AIC_lightning_NDT5_treed_summary, AIC_lightning_NDT5_treed_summary_climate, AIC_lightning_NDT5_treed_summary_climate2, AIC_lightning_NDT5_treed_summary_infra, AIC_lightning_NDT5_treed_summary_infra2, AIC_lightning_NDT5_treed_summary_topo, AIC_lightning_NDT5_treed_summary_topo2, AIC_lightning_NDT5_treed_summary_VRI, AIC_lightning_NDT5_treed_summary_VRI2, AIC_lightning_NDT5_treed_topo, AIC_lightning_NDT5_treed_VRI, AIC_lightning_NDT5_treed_infra, AIC_lightning_NDT2_treed_climate)

#Now, remove any elements created prior that are also not needed
rm(dat_lightning___, dat_Disturbed, dist.cut.corr, filenames, fire_veg_data_B, fire_veg_data_lighnight_5x, fire_veg_data_lighnight_NA_5x, fire_veg_data_lighnight_NA_5x_, fire_veg_data_NA_5x, fire_veg_data_person_5x, fire_veg_data_person_NA_5x, fire_veg_data_person_NA_5x_, fire_veg_data_unknown_5x, ignition_pres_abs3, ignition_pres_abs4, table.glm.climate.simple180, table.glm.climate.simple1800)
```

Now, we will generate two-way interactions for each of these lists. We cannot make two-way interactions between them all because apparently it will be >2 GB in size.  

DO NOT RUN THIS NEXT CHUNK! The mods.twoway.NDT4 is >2 GB and will not run successfully. You will likely need to skip to the subsequent chunk.
```{r}
twoway.ints <- NULL
for (i in 1:(length(inputs.me.NDT4)-1)) {
  for (j in (i+1):length(inputs.me.NDT4)) {
     twoway.ints <- cbind(twoway.ints, paste(inputs.me.NDT4[i], inputs.me.NDT4[j], sep=":"))
  }
}
twoway.ints
length(twoway.ints) #45

#Create function to determine Powerset for any vector of variable names
## or use rje package
#powerSet <- function(x) {
#   z.list <- NULL
#   for(i in 1:length(x)) {
#      z.list <- append(z.list, combn(x, m=i, simplify=F))
#   }    
#   return(z.list)
#}

#Get variables on own
#complete list of models using non-climate vars
mods.me.tmp <- powerSet(variables_all_NDT4) 
#add climate vars to all of the above
mods.me.NDT4 <- list()
for (i in 1: length(mods.me.tmp)) {
   mods.me.NDT4[[i]] <- c(mods.me.tmp[[i]])
}

mods.me.NDT4
length(mods.me.NDT4) #1024 with only dist_any

## DO NOT RUN BELOW ####
#complete list of two-way interactions
mods.twoway.NDT4 <- powerSet(twoway.ints) #Too large > 2 GB, so cannot perform, with all distances to infrastructure; also too large for smaller subset of data.
length(mods.twoway.NDT4) #
mods.twoway.NDT4
```

ALSO DO NOT RUN THIS CHUNK!
Actually skip to chunk after this one, unless you go back and add DEM back in... but it will also be > 2 GB and unable to write.

```{r}

###########Try with subset: ############## 
twoway.ints <- NULL
for (i in 1:(length(inputs.me.clim_VRI_DEM_NDT4)-1)) {
  for (j in (i+1):length(inputs.me.clim_VRI_DEM_NDT4)) {
     twoway.ints <- cbind(twoway.ints, paste(inputs.me.clim_VRI_DEM_NDT4[i], inputs.me.clim_VRI_DEM_NDT4[j], sep=":"))
  }
}
twoway.ints
length(twoway.ints) #28

#Create function to determine Powerset for any vector of variable names
## or use rje package
#powerSet <- function(x) {
#   z.list <- NULL
#   for(i in 1:length(x)) {
#      z.list <- append(z.list, combn(x, m=i, simplify=F))
#   }    
#   return(z.list)
#}

#Get variables on own
#complete list of models using non-climate vars
mods.me.tmp <- powerSet(variables_clim_VRI_DEM_NDT4) 
#add climate vars to all of the above
mods.me.clim_VRI_DEM_NDT4 <- list()
for (i in 1: length(mods.me.tmp)) {
   mods.me.clim_VRI_DEM_NDT4[[i]] <- c(mods.me.tmp[[i]])
}

mods.me.clim_VRI_DEM_NDT4
length(mods.me.clim_VRI_DEM_NDT4) #256


##Continue from here

#complete list of two-way interactions
mods.twoway.NDT4 <- powerSet(twoway.ints) # File still too large > 2 GB
length(mods.twoway.NDT4) #
mods.twoway.NDT4

#Finding models in mods.me that accommodate/allow interaction terms in each mods.twoway to be added
mods.inter.NDT4 <- list()
counter <- 0
for (i in 1: length(mods.twoway.NDT4)) {
   s1 <- unique(unlist( strsplit(mods.twoway.NDT4[[i]], split=':', fixed=TRUE) ) )
   for (j in 1: length(mods.me.NDT4)) {
      if (all(s1 %in% mods.me.NDT4[[j]])==TRUE) {
        counter <- counter + 1
        both <-  c(mods.me.clim_VRI_DEM_NDT4[[j]], mods.twoway.NDT4[[i]])
        mods.inter.NDT4[[counter]] <- both
      }
   }
}

length(mods.inter.NDT4)
mods.inter.NDT4
```

RUN FROM HERE
```{r}
####Reduce further; remove DEM
twoway.ints <- NULL
for (i in 1:(length(inputs.me.clim_VRI_NDT4)-1)) {
  for (j in (i+1):length(inputs.me.clim_VRI_NDT4)) {
     twoway.ints <- cbind(twoway.ints, paste(inputs.me.clim_VRI_NDT4[i], inputs.me.clim_VRI_NDT4[j], sep=":"))
  }
}
twoway.ints
length(twoway.ints) #10

#Create function to determine Powerset for any vector of variable names
## or use rje package
#powerSet <- function(x) {
#   z.list <- NULL
#   for(i in 1:length(x)) {
#      z.list <- append(z.list, combn(x, m=i, simplify=F))
#   }    
#   return(z.list)
#}

#Get variables on own
#complete list of models using non-climate vars
mods.me.tmp <- powerSet(variables_clim_VRI_NDT4) 
#add climate vars to all of the above
mods.me.clim_VRI_NDT4 <- list()
for (i in 1: length(mods.me.tmp)) {
   mods.me.clim_VRI_NDT4[[i]] <- c(mods.me.tmp[[i]])
}

mods.me.clim_VRI_NDT4
length(mods.me.clim_VRI_NDT4) #32


##Continue from here

#complete list of two-way interactions
mods.twoway.NDT4 <- powerSet(twoway.ints) # Works now!
length(mods.twoway.NDT4) #1024
mods.twoway.NDT4

#Finding models in mods.me that accommodate/allow interaction terms in each mods.twoway to be added
mods.inter.NDT4 <- list()
counter <- 0
for (i in 1: length(mods.twoway.NDT4)) {
   s1 <- unique(unlist( strsplit(mods.twoway.NDT4[[i]], split=':', fixed=TRUE) ) )
   for (j in 1: length(mods.me.clim_VRI_NDT4)) {
      if (all(s1 %in% mods.me.clim_VRI_NDT4[[j]])==TRUE) {
        counter <- counter + 1
        both <-  c(mods.me.clim_VRI_NDT4[[j]], mods.twoway.NDT4[[i]])
        mods.inter.NDT4[[counter]] <- both
      }
   }
}

length(mods.inter.NDT4) #1450: this number is manageable for analyses
mods.inter.NDT4

##Subset 2: Infrastructure and land use ########
#inputs.me.infra_landuse_NDT4
twoway.ints <- NULL
for (i in 1:(length(inputs.me.infra_landuse_NDT4)-1)) {
  for (j in (i+1):length(inputs.me.infra_landuse_NDT4)) {
     twoway.ints <- cbind(twoway.ints, paste(inputs.me.infra_landuse_NDT4[i], inputs.me.infra_landuse_NDT4[j], sep=":"))
  }
}
twoway.ints
length(twoway.ints) #15
#Review. If we do not want interactions between the different distance measurements, but only those between land use and distance, subset those.
twoway.ints
twoway.ints_dist<-twoway.ints[c(5,9,12,14,15)]
twoway.ints_dist


#Create function to determine Powerset for any vector of variable names
## or use rje package
#powerSet <- function(x) {
#   z.list <- NULL
#   for(i in 1:length(x)) {
#      z.list <- append(z.list, combn(x, m=i, simplify=F))
#   }    
#   return(z.list)
#}

#Get variables on own
#complete list of models using non-climate vars
mods.me.tmp <- powerSet(variables_all_infra_landuse_NDT4) 
#add climate vars to all of the above
mods.me.infra_landuse_NDT4 <- list()
for (i in 1: length(mods.me.tmp)) {
   mods.me.infra_landuse_NDT4[[i]] <- c(mods.me.tmp[[i]])
}

mods.me.infra_landuse_NDT4
length(mods.me.infra_landuse_NDT4) #64


#complete list of two-way interactions
mods.twoway.NDT4b <- powerSet(twoway.ints) #
#Or use subset of interactions
mods.twoway.NDT4b <- powerSet(twoway.ints_dist) 
length(mods.twoway.NDT4b) #32768 if use all interactions; 32 if use subset
mods.twoway.NDT4b

#Finding models in mods.me that accommodate/allow interaction terms in each mods.twoway to be added
mods.inter.NDT4b <- list()
counter <- 0
for (i in 1: length(mods.twoway.NDT4b)) {
   s1 <- unique(unlist( strsplit(mods.twoway.NDT4b[[i]], split=':', fixed=TRUE) ) )
   for (j in 1: length(mods.me.infra_landuse_NDT4)) {
      if (all(s1 %in% mods.me.infra_landuse_NDT4[[j]])==TRUE) {
        counter <- counter + 1
        both <-  c(mods.me.infra_landuse_NDT4[[j]], mods.twoway.NDT4b[[i]])
        mods.inter.NDT4b[[counter]] <- both
      }
   }
}

length(mods.inter.NDT4b) #40069 if use all interactions - this is too many to handle; 275 with subset of interactions
mods.inter.NDT4b
```

Make final list of variables to assess.

```{r}
## 1. climate and VRI
#the list of all possible model RHSs. 
all.poss.mods.clim_VRI_NDT4<-c(1, mods.me.clim_VRI_NDT4, mods.inter.NDT4)
all.poss.mods.clim_VRI_NDT4
length(mods.me.clim_VRI_NDT4) #32
all.poss.mods.clim_VRI_NDT4[2]
all.poss.mods.clim_VRI_NDT4[34] #character 0
all.poss.mods.clim_VRI_NDT4<-all.poss.mods.clim_VRI_NDT4[-34]
all.poss.mods.clim_VRI_NDT4<-all.poss.mods.clim_VRI_NDT4[-2] #Use this line only if there is an odd character(0) added to list

##Check and rid of any duplicated models
duplicated(all.poss.mods.clim_VRI_NDT4) #Need to remove #33-63
all.poss.mods.clim_VRI_NDT4b<-all.poss.mods.clim_VRI_NDT4[-(33:63)]
duplicated(all.poss.mods.clim_VRI_NDT4b) 


##2. Infrastructure and land use
all.poss.mods.infra_landuse_NDT4<-c(1,mods.me.infra_landuse_NDT4, mods.inter.NDT4b)

##Check and rid of any duplicated models
duplicated(all.poss.mods.infra_landuse_NDT4) #Need to remove #66-129
all.poss.mods.infra_landuse_NDT4b<-all.poss.mods.infra_landuse_NDT4[-(66:129)]
duplicated(all.poss.mods.infra_landuse_NDT4b) 
all.poss.mods.infra_landuse_NDT4b[2]
all.poss.mods.infra_landuse_NDT4b<-all.poss.mods.infra_landuse_NDT4b[-2] #There is probably another one that needs removing...
all.poss.mods.infra_landuse_NDT4[66] #It was removed! Yay!
duplicated(all.poss.mods.infra_landuse_NDT4b)

###########Using a subset of interactions interactions
all.poss.mods.infra_landuse_NDT4<-c(1,mods.me.infra_landuse_NDT4, mods.inter.NDT4b)

##Check and rid of any duplicated models
duplicated(all.poss.mods.infra_landuse_NDT4) #Need to remove #66-119
all.poss.mods.infra_landuse_NDT4b<-all.poss.mods.infra_landuse_NDT4[-(66:128)]
duplicated(all.poss.mods.infra_landuse_NDT4b) 
all.poss.mods.infra_landuse_NDT4b[2]
all.poss.mods.infra_landuse_NDT4b<-all.poss.mods.infra_landuse_NDT4b[-2] #There is probably another one that needs removing...
duplicated(all.poss.mods.infra_landuse_NDT4b)
length(all.poss.mods.infra_landuse_NDT4b)#276


#If need to determine which ones are character(0), try this:
biglist <- list(list("A","B","C"), "foo", "", character(0), integer(0))
lapply(biglist, function(x) {length(x) == 0L} ) 

#Below does not work
lapply(biglist, all.poss.mods.infra_landuse_NDT4b {length(all.poss.mods.infra_landuse_NDT4b) == 0L} ) 


#Proceed with 
  ## all.poss.mods.clim_VRI_NDT4b
  ## all.poss.mods.infra_landuse_NDT4b

```


#all.poss.mods.clim_VRI_NDT4b
We cannot run the model 100 times without R crashing. Instead, we will run it 25 times, then save the output, then run that another 3 times (for a total of 100 runs). Then we will combine all 100 runs, and calculate the deltaAIC from that.

```{r}
zones1<-"NDT4"

#Create empty table
table.glm.clim_VRI.simple <- data.frame (matrix (ncol = 5, nrow = 0))
colnames (table.glm.clim_VRI.simple) <- c ("model", "edf", "aic", "auc.valid", "NDT")

#
for (g in 1:25){

for (h in 1:length(zones1)) {
  dat2<- dat_lightning_t %>% dplyr::filter(ntrl_ds ==zones1[h])

#for (i in 1: length(all.poss.mods.topo)){
#  print(paste((all.poss.mods.topo[i]), (zones1[h]), sep=" "))
  
for (i in 1: length(zones1)){
  print(paste((all.poss.mods.clim_VRI_NDT4b[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, variables_all[i])
  model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, !!variables_clim_VRI_NDT4)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="fire_pres") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.aic, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.clim_VRI_NDT4b, big.mod, df.train=dat1, df.test=Valid)

#terms in each model
x1.1 <- unlist(sapply(mods.fit, '[', 1))
x1.1
#Aic for models
x3.1 <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3.1
#auc from validation data
x4.1 <- unlist(sapply(mods.fit, '[', 4))
x4.1
#combining all as df
tab.sum.clim_VRI <- cbind.data.frame(model=x1.1, edf=x3.1[,1], aic=x3.1[,2], auc.valid=x4.1)
tab.sum.clim_VRI$NDT<-c("NDT4")
tab.sum.clim_VRI 

table.glm.clim_VRI.simple<-rbind(table.glm.clim_VRI.simple, tab.sum.clim_VRI)

}
}
}
```

For the below chunks, they will need to be run in specific order, with repeating the previous chunk in between. DO NOT RUN THIS CHUNK MORE THAN ONCE! RUN EACH ONE ONCE, AFTER EACH SUBSEQUENT RUN OF THE ABOVE.

```{r}
table.glm.clim_VRI.simple_run1<-table.glm.clim_VRI.simple
head(table.glm.clim_VRI.simple_run1)
```

STOP! RUN the model x25 again.
```{r}
table.glm.clim_VRI.simple_run2<-table.glm.clim_VRI.simple
head(table.glm.clim_VRI.simple_run2)
```

STOP! RUN the model x25 again.
```{r}
table.glm.clim_VRI.simple_run3<-table.glm.clim_VRI.simple
```

STOP! RUN the model x25 again.
```{r}
table.glm.clim_VRI.simple_run4<-table.glm.clim_VRI.simple
```

Now that we have run the model 100 times, we want the average AIC and AUC for each variable combination. First, combine the 4 runs back together.

```{r}
table.glm.clim_VRI.simple<-rbind(table.glm.clim_VRI.simple_run1, table.glm.clim_VRI.simple_run2, table.glm.clim_VRI.simple_run3, table.glm.clim_VRI.simple_run4)
```

Now determine deltaAIC.

```{r}
head(table.glm.clim_VRI.simple)
table(table.glm.clim_VRI.simple$model) # 100 per model

AIC_lightning_NDT4_treed_clim_VRI<-table.glm.clim_VRI.simple

AIC_lightning_NDT4_treed_summary_clim_VRI<- AIC_lightning_NDT4_treed_clim_VRI %>%
  group_by(model) %>%
  summarise(meanAIC=mean(aic),
            meanAUC=mean(auc.valid),
            sdAUC=sd(auc.valid),
            )

AIC_lightning_NDT4_treed_summary_clim_VRI2<- AIC_lightning_NDT4_treed_summary_clim_VRI %>%
  mutate(deltaAIC=meanAIC-min(meanAIC))

head(AIC_lightning_NDT4_treed_summary_clim_VRI2)
```

Save file.
```{r}
write.csv(AIC_lightning_NDT4_treed_summary_clim_VRI2, file="D:\\Fire\\fire_data\\raw_data\\AIC_lightning_NDT4_treed_summary_clim_VRI2.csv")
```

#Assessing models, all had low AUC (~0.55), so these models are barely performing better than 50-50.

#Now repeat for all.poss.mods.infra_landuse_NDT4b

```{r}
########### 2. Distance to Infrastructure ############
#Create empty table
table.glm.infra.lu.simple <- data.frame (matrix (ncol = 5, nrow = 0))
colnames (table.glm.infra.lu.simple) <- c ("model", "edf", "aic", "auc.valid", "NDT")

#
for (g in 1:25){

for (h in 1:length(zones1)) {
  dat2<- dat_lightning_t %>% dplyr::filter(ntrl_ds ==zones1[h])

#for (i in 1: length(all.poss.mods.infra)){
#  print(paste((all.poss.mods.infra[i]), (zones1[h]), sep=" "))
  
for (i in 1: length(zones1)){
  print(paste((all.poss.mods.infra_landuse_NDT4b[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, variables_all[i])
  model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, !!variables_all_infra_landuse_NDT4)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="fire_pres") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.aic, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.infra_landuse_NDT4b, big.mod, df.train=dat1, df.test=Valid)

#terms in each model
x1.1 <- unlist(sapply(mods.fit, '[', 1))
x1.1
#Aic for models
x3.1 <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3.1
#auc from validation data
x4.1 <- unlist(sapply(mods.fit, '[', 4))
x4.1
#combining all as df
tab.sum.infra.lu <- cbind.data.frame(model=x1.1, edf=x3.1[,1], aic=x3.1[,2], auc.valid=x4.1)
tab.sum.infra.lu$NDT<-c("NDT4")
tab.sum.infra.lu 

table.glm.infra.lu.simple<-rbind(table.glm.infra.lu.simple, tab.sum.infra.lu)

}
}
}
```

For the below chunks, they will need to be run in specific order, with repeating the previous chunk in between. DO NOT RUN THIS CHUNK MORE THAN ONCE! RUN EACH ONE ONCE, AFTER EACH SUBSEQUENT RUN OF THE ABOVE.

```{r}
#Check that it ran correctly
table.glm.infra.lu.simple

table.glm.infra.lu.simple_run1<-table.glm.infra.lu.simple
head(table.glm.infra.lu.simple_run1)

```

STOP! RUN the model x25 again.
```{r}
table.glm.infra.lu.simple_run2<-table.glm.infra.lu.simple
head(table.glm.infra.lu.simple_run2)
```

STOP! RUN the model x25 again.
```{r}
table.glm.infra.lu.simple_run3<-table.glm.infra.lu.simple
head(table.glm.infra.lu.simple_run3)
```

STOP! RUN the model x25 again.
```{r}
table.glm.infra.lu.simple_run4<-table.glm.infra.lu.simple
```

Now that we have run the model 100 times, we want the average AIC and AUC for each variable combination. First, combine the 4 runs back together.

```{r}
table.glm.infra.lu.simple<-rbind(table.glm.infra.lu.simple_run1, table.glm.infra.lu.simple_run2, table.glm.infra.lu.simple_run3, table.glm.infra.lu.simple_run4)
```

Now determine deltaAIC.

```{r}
head(table.glm.infra.lu.simple)
table(table.glm.infra.lu.simple$model) # 100 per model

AIC_lightning_NDT4_treed_infra<-table.glm.infra.lu.simple

AIC_lightning_NDT4_treed_summary_infra<- AIC_lightning_NDT4_treed_infra %>%
  group_by(model) %>%
  summarise(meanAIC=mean(aic),
            meanAUC=mean(auc.valid),
            sdAUC=sd(auc.valid),
            )

AIC_lightning_NDT4_treed_summary_infra2<- AIC_lightning_NDT4_treed_summary_infra %>%
  mutate(deltaAIC=meanAIC-min(meanAIC))

head(AIC_lightning_NDT4_treed_summary_infra2)
```

Save to computer.

```{r}
write.csv(AIC_lightning_NDT4_treed_summary_infra2, file="D:\\Fire\\fire_data\\raw_data\\AIC_lightning_NDT4_treed_summary_infra.csv")
```


########################### STAGE THREE ###########################

#STAGE THREE: ALL VARIABLES
Now that we have even more information about how some variables perform with others, we need test them all together... unfortunately, we cannot accomplish this the same as above given that there are so many possible combinations and R cannot write vectors so long. Below, I include code for (1) manual investigation and (2) the full investigation for those who may be able to get R not to crash while attempting it.

##Top variables
1. Top models have live_stand_volume and proj_height with various combinations of interactions with climate 1 and climate 2. Vegtype 2 is not included, but this is important. So we should explore interactions between climate 1, climate 2, live stand volume and projected age, and add vegtype 2 with no interactions separately.

2. Infrastructure and landuse: distance to any and distance to municipality best model. Land use not found important, but I think it is useful to have in model. Try full model with these 3 variables first. AUC low for all (<0.57). No interactions found to be important.

3. DEM: slope + aspect_cos + elevation + slope:aspect_cos was the top model. Include elements of these in but not interactions with other variables unless we have a reason to expect an interaction (perhaps try landuse*elevation, for example; or with slope or aspect_cos)

#Top Models
1. climate1 + climate2 + vegtype2 + climate1:climate2
2. proj_height_1 + live_stand_volume_125
3. slope + aspect_cos + elevation + slope:aspect_cos
4. dist_mun + dist_dam + dist_nat + dist_pow + dist_any1. 

Additional Variabes:
1. bclcs_level_5_2 (land use) (to be added to final investigated model)
##Remember to add elevation*climate1 and eevation*climate2

#Could consider trying backwards stepwise regression since the code chunk below this one creates an object that is too large and cannot run.
There are a few options from this point. Either, we repeat a similar routine as prior to this step but with running half of one set of variables (since one full set is too much for R to handle), or we try stepwise regression using the step() function or manually. The former approach requires some manual adjustment as well since we need to create training and validation data sets first that remain the same to feed into each of the ha;ves of the possible models. Then we would need to repeat that process several times to be able to get meanAIC and meanAUC. The latter approach also takes time since it is all manual, but it is easier to reason with what inputs are included and why.

```{r}
dat_lightning_t_NDT4<-subset(dat_lightning_t, dat_lightning_t$ntrl_ds=="NDT4")

#Divide data into training and valid
prop<-0.75
# Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(dat_lightning_t_NDT4$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- dat_lightning_t_NDT4[ trainIndex,]
   Valid <- dat_lightning_t_NDT4[-trainIndex,]

#Run model using dat1
model.NDT4<-glm(fire_pres ~ climate1 + climate2 + climate1*climate2 + proj_height_1 + live_stand_volume_125 + proj_height_1*live_stand_volume_125 + climate1*proj_height_1 + climate2*proj_height_1 + climate1*live_stand_volume_125 + climate2*live_stand_volume_125 + slope + aspect_cos + elevation + slope*aspect_cos + dist_any + vegtype2 + elevation*climate1 + elevation*climate2 + dist_mun +  dist_dam + dist_nat + dist_pow + vegtype2 + bclcs_level_5_2, family = binomial, data = dat1) 
   
AIC(model.NDT4) #6178.97
Anova(model.NDT4)

#Determine AUC
mod.valid <- predict.glm(model.NDT4, newdata=Valid, type="response")
   roc_obj <- roc(Valid[,"fire_pres"], mod.valid)
   mod.auc <- auc(roc_obj)
   mod.auc # 0.61 --> poor fit

#Remove least significant interaction
model.NDT4<-glm(fire_pres ~ climate1 + climate2 + climate1*climate2 + proj_height_1 + live_stand_volume_125 + proj_height_1*live_stand_volume_125 + climate2*proj_height_1 + climate1*live_stand_volume_125 + climate2*live_stand_volume_125 + slope + aspect_cos + elevation + slope*aspect_cos + dist_any + vegtype2 + elevation*climate1 + elevation*climate2 + dist_mun +  dist_dam + dist_nat + dist_pow + vegtype2 + bclcs_level_5_2, family = binomial, data = dat1) 
   
AIC(model.NDT4) #6176.97
Anova(model.NDT4)

#Determine AUC
mod.valid <- predict.glm(model.NDT4, newdata=Valid, type="response")
   roc_obj <- roc(Valid[,"fire_pres"], mod.valid)
   mod.auc <- auc(roc_obj)
   mod.auc # 0.60 --> poor fit
   
#Remove least significant interaction
model.NDT4<-glm(fire_pres ~ climate1 + climate2 + climate1*climate2 + proj_height_1 + live_stand_volume_125  + climate2*proj_height_1 + climate1*live_stand_volume_125 + climate2*live_stand_volume_125 + slope + aspect_cos + elevation + slope*aspect_cos + dist_any + vegtype2 + elevation*climate1 + elevation*climate2 + dist_mun +  dist_dam + dist_nat + dist_pow + vegtype2 + bclcs_level_5_2, family = binomial, data = dat1) 
   
AIC(model.NDT4) #6175.2
Anova(model.NDT4)

#Determine AUC
mod.valid <- predict.glm(model.NDT4, newdata=Valid, type="response")
   roc_obj <- roc(Valid[,"fire_pres"], mod.valid)
   mod.auc <- auc(roc_obj)
   mod.auc # 0.60 --> poor fit
   
#Remove least significant interaction
model.NDT4<-glm(fire_pres ~ climate1 + climate2 + climate1*climate2 + proj_height_1 + live_stand_volume_125  + climate2*proj_height_1 + climate1*live_stand_volume_125 + climate2*live_stand_volume_125 + slope + aspect_cos + elevation + slope*aspect_cos + dist_any + vegtype2 + elevation*climate1 + dist_mun +  dist_dam + dist_nat + dist_pow + vegtype2 + bclcs_level_5_2, family = binomial, data = dat1) 
   
AIC(model.NDT4) #6173.4
Anova(model.NDT4)

#Determine AUC
mod.valid <- predict.glm(model.NDT4, newdata=Valid, type="response")
   roc_obj <- roc(Valid[,"fire_pres"], mod.valid)
   mod.auc <- auc(roc_obj)
   mod.auc # 0.60 --> poor fit
   
#Remove least significant interaction
model.NDT4<-glm(fire_pres ~ climate1 + climate2 + climate1*climate2 + proj_height_1 + live_stand_volume_125  + climate2*proj_height_1 + climate1*live_stand_volume_125 + climate2*live_stand_volume_125 + slope + aspect_cos + elevation + dist_any + vegtype2 + elevation*climate1 + dist_mun +  dist_dam + dist_nat + dist_pow + vegtype2 + bclcs_level_5_2, family = binomial, data = dat1) 
   
AIC(model.NDT4) #6172.0
Anova(model.NDT4)

#Determine AUC
mod.valid <- predict.glm(model.NDT4, newdata=Valid, type="response")
   roc_obj <- roc(Valid[,"fire_pres"], mod.valid)
   mod.auc <- auc(roc_obj)
   mod.auc # 0.60 --> poor fit
   
   
#Remove dist_any because decided not using it
model.NDT4<-glm(fire_pres ~ climate1 + climate2 + climate1*climate2 + proj_height_1 + live_stand_volume_125  + climate2*proj_height_1 + climate1*live_stand_volume_125 + climate2*live_stand_volume_125 + slope + aspect_cos + elevation + vegtype2 + elevation*climate1 + dist_mun +  dist_dam + dist_nat + dist_pow + vegtype2 + bclcs_level_5_2, family = binomial, data = dat1) 
   
AIC(model.NDT4) #6172.1
Anova(model.NDT4)

#Determine AUC
mod.valid <- predict.glm(model.NDT4, newdata=Valid, type="response")
   roc_obj <- roc(Valid[,"fire_pres"], mod.valid)
   mod.auc <- auc(roc_obj)
   mod.auc # 0.59 --> poor fit
   

### This is the best model with this specific division of training and validation data. Repeat with new subset and compare AUC.

```
Repeat subsetting data into training and validation datasets. We will do this more fully later again too.

```{r}
prop<-0.75
# Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(dat_lightning_t_NDT4$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- dat_lightning_t_NDT4[ trainIndex,]
   Valid <- dat_lightning_t_NDT4[-trainIndex,]
```

Get AUC for model again.

```{r}
model.NDT4<-glm(fire_pres ~ climate1 + climate2 + climate1*climate2 + proj_height_1 + live_stand_volume_125  + climate2*proj_height_1 + climate1*live_stand_volume_125 + climate2*live_stand_volume_125 + slope + aspect_cos + elevation + vegtype2 + elevation*climate1 + dist_mun +  dist_dam + dist_nat + dist_pow + vegtype2 + bclcs_level_5_2, family = binomial, data = dat1) #AUC - Round 2: 0.62. Round 3: 0.59; Round 4: 0.59; Round 5: 0.59; Round 6: 0.6002. 

mod.valid <- predict.glm(model.NDT4, newdata=Valid, type="response")
   roc_obj <- roc(Valid[,"fire_pres"], mod.valid)
   mod.auc <- auc(roc_obj)
   mod.auc # --> poor fit
  
Anova(model.NDT4, type=3,singular.ok = TRUE)


```

NDT4 is the natural disturbance type with frequent stand-maintaining fires. Perhaps it is just an ecosystem where it is hard to predict and there is a lot of stochasticity in ignitions by lightning.

In the original models, they all performed poorly as well (0.52-0.575, with distance to mun, dam, nat, pow and any being best). 

Re-run with na.omit and check diagnostics.

```{r}
#Remove NAs to ensure all same data used so we can compare AICs
NDT4_t<-dat_lightning_t_NDT4 %>% drop_na(climate1, climate2, proj_height_1, live_stand_volume_125, dist_mun,  dist_dam, dist_nat, dist_pow, vegtype2, bclcs_level_5_2)

model.NDT4<-glm(fire_pres ~ climate1 + climate2 + climate1*climate2 + proj_height_1 + live_stand_volume_125  + climate2*proj_height_1 + climate1*live_stand_volume_125 + climate2*live_stand_volume_125 + slope + aspect_cos + elevation + vegtype2 + elevation*climate1 + dist_mun +  dist_dam + dist_nat + dist_pow + vegtype2 + bclcs_level_5_2, family = binomial, data = NDT4_t) 
  
Anova(model.NDT4, type=3,singular.ok = TRUE)
AIC(model.NDT4) #8631.8

# model diagnostic plots
binnedplot (fitted(model.NDT4), 
            residuals(model.NDT4), 
            nclass = NULL, 
            xlab = "Expected Values", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))


NDT4_t$resids<-resid(model.NDT4)

binnedplot (NDT4_t$live_stand_volume_125, 
            NDT4_t$resids, 
            nclass = NULL, 
            xlab = "live stand volume", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))

binnedplot (NDT4_t$climate1, 
            NDT4_t$resids, 
            nclass = NULL, 
            xlab = "", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))

# Diagnostic plots look good
#Residual Plots
#climate1 + climate2 + climate1*climate2 + proj_height_1 + live_stand_volume_125  + climate2*proj_height_1 + climate1*live_stand_volume_125 + climate2*live_stand_volume_125 + slope + aspect_cos + elevation + vegtype2 + elevation*climate1 + dist_mun +  dist_dam + dist_nat + dist_pow + bclcs_level_5_2

visreg(model.NDT4, "climate1", by="climate2")
visreg(model.NDT4, "climate1", by="elevation")
visreg(model.NDT4, "climate1", by="live_stand_volume_125")

visreg(model.NDT4, "climate2", by="climate1")
visreg(model.NDT4, "climate2", by="proj_height_1")
visreg(model.NDT4, "climate2", by="live_stand_volume_125")

visreg(model.NDT4, "proj_height_1", by="climate2")
visreg(model.NDT4, "live_stand_volume_125", by="climate2")
visreg(model.NDT4, "live_stand_volume_125", by="climate1")

visreg(model.NDT4, "slope")
visreg(model.NDT4, "aspect_cos")
visreg(model.NDT4, "elevation", by="climate1")

visreg(model.NDT4, "vegtype2")
visreg(model.NDT4, "vegtype2", ylim=c(-10,10))
visreg(model.NDT4, "bclcs_level_5_2")

visreg(model.NDT4, "dist_dam")
visreg(model.NDT4, "dist_mun")
visreg(model.NDT4, "dist_nat")
visreg(model.NDT4, "dist_pow")


```

######## Save selected Model as Final Model ############
We will save the coefficients to a table and export it as a csv file. There will be future models that will have other variables, so we will ignore that for now and modify as needed later when combining tables.

```{r}
model.NDT4<-glm(fire_pres ~ climate1 + climate2 + climate1*climate2 + proj_height_1 + live_stand_volume_125 + dist_mun +  dist_dam + dist_nat + dist_pow + + vegtype2 + bclcs_level_5_2 + climate2*proj_height_1 + climate1*live_stand_volume_125 + climate2*live_stand_volume_125 + slope + aspect_cos + elevation + vegtype2 + elevation*climate1, family = binomial, data = NDT4_t) 

summary(model.NDT4)

# create model table (only do this once) and add the relevant data
top_mod_table_NDT4_light_t <- data.frame (matrix (ncol = 29, nrow = 0))
colnames (top_mod_table_NDT4_light_t ) <- c ("CAUSE", "NDT", "TREED", "Model_terms", "intercept", "coef_climate_1", "coef_climate_2", "coef_climate_interaction", "coef_stand_height", "coef_live_stand_volume_125", "coef_dist_mun", "coef_dist_dam", "coef_dist_nat", "coef_dist_pow", "coef_vegtypeOP", "coef_vegtypeTB", "coef_vegtypeTC", "coef_vegtypeTM", "coef_bclcs_level_5_2DE", "coef_bclcs_level_5_2DIST", "coef_bclcs_level_5_2OP", "coef_bclcs_level_5_2SP", "coef_slope", "coef_aspect_cos", "coef_elevation", "coef_climate2:proj_height", "coef_climate1:live_stand_volume_125", "coef_climate2:live_stand_volume_125", "coef_climate1:elevation")


##Add data for NDT4
top_mod_table_NDT4_light_t[1,1]<-"lightning"
top_mod_table_NDT4_light_t[1,2]<-"NDT4"
top_mod_table_NDT4_light_t[1,3]<-"Y"
top_mod_table_NDT4_light_t[1,4]<-"climate1 + climate2 + climate1*climate2 + proj_height_1 + live_stand_volume_125 + dist_mun +  dist_dam + dist_nat + dist_pow + + vegtype2 + bclcs_level_5_2 + climate2*proj_height_1 + climate1*live_stand_volume_125 + climate2*live_stand_volume_125 + slope + aspect_cos + elevation + vegtype2 + elevation*climate1" 
top_mod_table_NDT4_light_t[1,5]<- coef(model.NDT4)[1] #Intercept
top_mod_table_NDT4_light_t[1,6]<- coef(model.NDT4)[2] #Climate variable 1
top_mod_table_NDT4_light_t[1,7]<- coef(model.NDT4)[3] #Climate variable 2
top_mod_table_NDT4_light_t[1,8]<- coef(model.NDT4)[21] #Interaction climate variables
top_mod_table_NDT4_light_t[1,9]<- coef(model.NDT4)[4] #coef_stand_height
top_mod_table_NDT4_light_t[1,10]<- coef(model.NDT4)[5] #live_stand_volume_125
top_mod_table_NDT4_light_t[1,11]<- coef(model.NDT4)[6] #dist_mun
top_mod_table_NDT4_light_t[1,12]<- coef(model.NDT4)[7] #dist_dam
top_mod_table_NDT4_light_t[1,13]<- coef(model.NDT4)[8] #dist_nat
top_mod_table_NDT4_light_t[1,14]<- coef(model.NDT4)[9] #dist_pow
top_mod_table_NDT4_light_t[1,15]<- coef(model.NDT4)[10] #coefficient vegtypeOP
top_mod_table_NDT4_light_t[1,16]<- coef(model.NDT4)[11] #coefficient vegtypeTB
top_mod_table_NDT4_light_t[1,17]<- coef(model.NDT4)[12] #coefficient vegtypeTC
top_mod_table_NDT4_light_t[1,18]<- coef(model.NDT4)[13] #coefficient vegtypeTM
top_mod_table_NDT4_light_t[1,19]<- coef(model.NDT4)[14] #coefficient bclcs_level_5_2DE
top_mod_table_NDT4_light_t[1,20]<- coef(model.NDT4)[15] #coefficient bclcs_level_5_2DIST
top_mod_table_NDT4_light_t[1,21]<- coef(model.NDT4)[16] #coefficient bclcs_level_5_2OP 
top_mod_table_NDT4_light_t[1,22]<- coef(model.NDT4)[17] #coefficient bclcs_level_5_2SP
top_mod_table_NDT4_light_t[1,23]<- coef(model.NDT4)[18] #coefficient slope
top_mod_table_NDT4_light_t[1,24]<- coef(model.NDT4)[19] #coefficient aspect_cos
top_mod_table_NDT4_light_t[1,25]<- coef(model.NDT4)[20] #coefficient elevation
top_mod_table_NDT4_light_t[1,26]<- coef(model.NDT4)[22] #coefficient climate2:proj_height_1
top_mod_table_NDT4_light_t[1,27]<- coef(model.NDT4)[23] #coefficient climate1:live_stand_volume_125
top_mod_table_NDT4_light_t[1,28]<- coef(model.NDT4)[24] #coefficient climate2:live_stand_volume_125
top_mod_table_NDT4_light_t[1,29]<- coef(model.NDT4)[25] #coefficient climate1:elevation 
top_mod_table_NDT4_light_t ##Check

########################## NDT4 Model Selection Complete ###################
```
Save coefficient table.
```{r}
write.csv(top_mod_table_NDT4_light_t, file="D:\\Fire\\fire_data\\raw_data\\top_mod_table_NDT4_light_t.csv")
```

We should repeat the above several times and take the mean of the coefficients.

```{r}
top_mod_table_NDT4_light_t_ALL<-top_mod_table_NDT4_light_t 
summary(model.NDT4)

#Or create a new blank table and get AUC too
top_mod_table_NDT4_light_t_ALL <- data.frame (matrix (ncol = 29, nrow = 0))
colnames (top_mod_table_NDT4_light_t_ALL ) <- c ("CAUSE", "NDT", "TREED", "Model_terms", "intercept", "coef_climate_1", "coef_climate_2", "coef_stand_height", "coef_live_stand_volume_125", "coef_dist_mun", "coef_dist_dam", "coef_dist_nat", "coef_dist_pow", "coef_vegtypeOP", "coef_vegtypeTB", "coef_vegtypeTC", "coef_vegtypeTM", "coef_bclcs_level_5_2DE", "coef_bclcs_level_5_2OP", "coef_bclcs_level_5_2SP", "coef_slope", "coef_aspect_cos", "coef_elevation", "coef_climate1:climate2", "coef_climate2:proj_height", "coef_climate1:live_stand_volume_125", "coef_climate2:live_stand_volume_125", "coef_climate1:elevation", "AUC")
```

Let's run it 500 times to get good mean values.

```{r}

for (g in 1:500){

prop<-0.75
# Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data
  trainIndex <- createDataPartition(NDT4_t$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- NDT4_t[ trainIndex,]
   Valid <- NDT4_t[-trainIndex,]
   
#Model   
model.NDT4<-glm(fire_pres ~ climate1 + climate2 + climate1*climate2 + proj_height_1 + live_stand_volume_125 + dist_mun +  dist_dam + dist_nat + dist_pow + + vegtype2 + bclcs_level_5_2 + climate2*proj_height_1 + climate1*live_stand_volume_125 + climate2*live_stand_volume_125 + slope + aspect_cos + elevation + vegtype2 + elevation*climate1, family = binomial, data = dat1) 

mod.valid <- predict.glm(model.NDT4, newdata=Valid, type="response")
   roc_obj <- roc(Valid[,"fire_pres"], mod.valid)
   mod.auc <- auc(roc_obj)

# create model table (only do this once) and add the relevant data
top_mod_table_NDT4_light_t <- data.frame (matrix (ncol = 29, nrow = 0))
colnames (top_mod_table_NDT4_light_t ) <- c ("CAUSE", "NDT", "TREED", "Model_terms", "intercept", "coef_climate_1", "coef_climate_2", "coef_stand_height", "coef_live_stand_volume_125", "coef_dist_mun", "coef_dist_dam", "coef_dist_nat", "coef_dist_pow", "coef_vegtypeOP", "coef_vegtypeTB", "coef_vegtypeTC", "coef_vegtypeTM", "coef_bclcs_level_5_2DE", "coef_bclcs_level_5_2OP", "coef_bclcs_level_5_2SP", "coef_slope", "coef_aspect_cos", "coef_elevation", "coef_climate1:climate2", "coef_climate2:proj_height", "coef_climate1:live_stand_volume_125", "coef_climate2:live_stand_volume_125", "coef_climate1:elevation", "AUC")

##Add data for NDT4
top_mod_table_NDT4_light_t[1,1]<-"lightning"
top_mod_table_NDT4_light_t[1,2]<-"NDT4"
top_mod_table_NDT4_light_t[1,3]<-"Y"
top_mod_table_NDT4_light_t[1,4]<-"fire_pres ~ climate1 + climate2 + climate1*climate2 + proj_height_1 + live_stand_volume_125 + dist_mun +  dist_dam + dist_nat + dist_pow + + vegtype2 + bclcs_level_5_2 + climate2*proj_height_1 + climate1*live_stand_volume_125 + climate2*live_stand_volume_125 + slope + aspect_cos + elevation + vegtype2 + elevation*climate1" 
top_mod_table_NDT4_light_t[1,5]<- coef(model.NDT4)[1] #
top_mod_table_NDT4_light_t[1,6]<- coef(model.NDT4)[2] #
top_mod_table_NDT4_light_t[1,7]<- coef(model.NDT4)[3] #
top_mod_table_NDT4_light_t[1,8]<- coef(model.NDT4)[4] #Int
top_mod_table_NDT4_light_t[1,9]<- coef(model.NDT4)[5] #coef_
top_mod_table_NDT4_light_t[1,10]<- coef(model.NDT4)[6] #
top_mod_table_NDT4_light_t[1,11]<- coef(model.NDT4)[7] #d
top_mod_table_NDT4_light_t[1,12]<- coef(model.NDT4)[8] #
top_mod_table_NDT4_light_t[1,13]<- coef(model.NDT4)[9] #d
top_mod_table_NDT4_light_t[1,14]<- coef(model.NDT4)[10] #dis
top_mod_table_NDT4_light_t[1,15]<- coef(model.NDT4)[11] #coeffi
top_mod_table_NDT4_light_t[1,16]<- coef(model.NDT4)[12] #coeffic
top_mod_table_NDT4_light_t[1,17]<- coef(model.NDT4)[13] #coeffic
top_mod_table_NDT4_light_t[1,18]<- coef(model.NDT4)[14] #coefficient
top_mod_table_NDT4_light_t[1,19]<- coef(model.NDT4)[15] #coef
top_mod_table_NDT4_light_t[1,20]<- coef(model.NDT4)[16] #co
top_mod_table_NDT4_light_t[1,21]<- coef(model.NDT4)[17] #coeff
top_mod_table_NDT4_light_t[1,22]<- coef(model.NDT4)[18] #coe
top_mod_table_NDT4_light_t[1,23]<- coef(model.NDT4)[19] #coeffic
top_mod_table_NDT4_light_t[1,24]<- coef(model.NDT4)[20] #coeffis
top_mod_table_NDT4_light_t[1,25]<- coef(model.NDT4)[21] #coeffici
top_mod_table_NDT4_light_t[1,26]<- coef(model.NDT4)[22] #co
top_mod_table_NDT4_light_t[1,27]<- coef(model.NDT4)[23] #c
top_mod_table_NDT4_light_t[1,28]<- coef(model.NDT4)[24] #
top_mod_table_NDT4_light_t[1,29]<- mod.auc

top_mod_table_NDT4_light_t_ALL<-rbind(top_mod_table_NDT4_light_t_ALL, top_mod_table_NDT4_light_t)

}

```

Check.
```{r}
head(top_mod_table_NDT4_light_t_ALL)
```

#Save coefficient table

```{r}
write.csv(top_mod_table_NDT4_light_t_ALL, file="D:\\Fire\\fire_data\\raw_data\\top_mod_table_NDT4_light_t_ALL.csv")
```

Get mean values.

```{r}
names(top_mod_table_NDT4_light_t_ALL)

top_mod_table_NDT4_light_t_Means<-top_mod_table_NDT4_light_t_ALL %>% summarise_each(funs( mean( .,na.rm = TRUE)))
top_mod_table_NDT4_light_t_Means

top_mod_table_NDT4_light_t_Means[1,1]<-"lightning"
top_mod_table_NDT4_light_t_Means[1,2]<-"NDT4"
top_mod_table_NDT4_light_t_Means[1,3]<-"Treed"
top_mod_table_NDT4_light_t_Means[1,4]<- "fire_pres ~ climate1 + climate2 + climate1*climate2 + proj_height_1 + live_stand_volume_125 + dist_mun +  dist_dam + dist_nat + dist_pow + + vegtype2 + bclcs_level_5_2 + climate2*proj_height_1 + climate1*live_stand_volume_125 + climate2*live_stand_volume_125 + slope + aspect_cos + elevation + vegtype2 + elevation*climate1" 
top_mod_table_NDT4_light_t_Means
```
Save table.

```{r}
write.csv(top_mod_table_NDT4_light_t_Means, file="D:\\Fire\\fire_data\\raw_data\\top_mod_table_NDT4_light_t_Means.csv")
```

Standard deviation.

```{r}
top_mod_table_NDT4_light_t_SD<-top_mod_table_NDT4_light_t_ALL %>% summarise_each(funs( sd( .,na.rm = TRUE)))
top_mod_table_NDT4_light_t_SD

top_mod_table_NDT4_light_t_SD[1,1]<-"lightning"
top_mod_table_NDT4_light_t_SD[1,2]<-"NDT4"
top_mod_table_NDT4_light_t_SD[1,3]<-"Treed"
top_mod_table_NDT4_light_t_SD[1,4]<-"fire_pres ~ climate1 + climate2 + climate1*climate2 + proj_height_1 + live_stand_volume_125 + dist_mun +  dist_dam + dist_nat + dist_pow + + vegtype2 + bclcs_level_5_2 + climate2*proj_height_1 + climate1*live_stand_volume_125 + climate2*live_stand_volume_125 + slope + aspect_cos + elevation + vegtype2 + elevation*climate1" 
top_mod_table_NDT4_light_t_SD
```

Save sd coefficient table.

```{r}
write.csv(top_mod_table_NDT4_light_t_SD, file="D:\\Fire\\fire_data\\raw_data\\top_mod_table_NDT4_light_t_SD.csv")
```

