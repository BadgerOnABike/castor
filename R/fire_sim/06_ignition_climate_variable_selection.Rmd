---
title: "06_ignition_climate_variable_selection"
author: "Elizabeth Kleynhans"
date: "08/07/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Copyright 2020 Province of British Columbia
# 
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
# 
# http://www.apache.org/licenses/LICENSE-2.0
# 
# Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and limitations under the License.

#=================================
#  Script Name: 05_ignition_climate_variable_selection.R
#  Script Version: 1.0
#  Script Purpose: Run logistic regression models to determine the top candidate climate variable to use in the final analysis of fire ignitions.
#  Script Author: Elizabeth Kleynhans, Ecological Modeling Specialist, Forest Analysis and Inventory Branch, B.C. Ministry of Forests, Lands, and Natural Resource Operations.
#  Script Contributor: Cora Skaien, Ecological Modeling Specialist, Forest Analysis and Inventory Branch, B.C. Ministry of Forests, Lands, and Natural Resource Operations.
#=================================

#Overview
The purpose of this script is to prepare additional climate data, sub-sample points where no fires occurred (for a better ratio of fire to no fire), and perform model selection to determine the climate variable that best predicts fire occurence for each BEC zone.

```{r}

library(sf)
library(tidyverse)
library(ggplot2)
library (ggcorrplot)
library (RPostgreSQL)
library (rpostgis)
library (dplyr)
library (lme4)
library (arm)
library(ggpubr)
library(mgcv)
library(nlme)
library(purrr)
library(tidyr)
library(caret)
library(pROC)
library(keyring)
library(ggcorrplot) 

source(here::here("R/functions/R_Postgres.R"))
```

Now we must bring in the data that we created at the end of 05_VRI_data_prep. We need only the lightning + NA and the person + NA data sets here. We also need the fire ignition data from the end of our first file (01_fire_ignition_data_prep)

```{r}
#bring in lightning caused fire data
connKyle <- dbConnect(drv = RPostgreSQL::PostgreSQL(), 
                      host = key_get('dbhost', keyring = 'postgreSQL'),
                      user = key_get('dbuser', keyring = 'postgreSQL'),
                      dbname = key_get('dbname', keyring = 'postgreSQL'),
                      password = key_get('dbpass', keyring = 'postgreSQL'),
                      port = "5432")
dat_lightning <- sf::st_read  (dsn = connKyle, # connKyle
                               query = "SELECT * FROM public.dat_lightning_for_analysis")
dbDisconnect (connKyle)

#Bring in person-caused fire data
connKyle <- dbConnect(drv = RPostgreSQL::PostgreSQL(), 
                      host = key_get('dbhost', keyring = 'postgreSQL'),
                      user = key_get('dbuser', keyring = 'postgreSQL'),
                      dbname = key_get('dbname', keyring = 'postgreSQL'),
                      password = key_get('dbpass', keyring = 'postgreSQL'),
                      port = "5432")
dat_person <- sf::st_read  (dsn = connKyle, # connKyle
                               query = "SELECT * FROM public.dat_person_for_analysis")
dbDisconnect (connKyle)

#Bring in fire ignition data from end of 01 file  
conn <- dbConnect(drv = RPostgreSQL::PostgreSQL(), 
                      host = key_get('dbhost', keyring = 'postgreSQL'),
                      user = key_get('dbuser', keyring = 'postgreSQL'),
                      dbname = key_get('dbname', keyring = 'postgreSQL'),
                      password = key_get('dbpass', keyring = 'postgreSQL'),
                      port = "5432")

fire_ignitions <- sf::st_read  (dsn = conn, # connKyle
                               query = "SELECT * FROM public.bc_fire_ignition")
dbDisconnect (conn) # connKyle

```

Inspect the fire ignition data.

```{r}

fire_ignitions1<-st_set_geometry(fire_ignitions,NULL) # remove geometry column for dataset

# look at histogram of when fires were ignited per year
fire_ignitions1$month<- substring(fire_ignitions1$ign_date, 5, 6)

# Histogram of lightning caused fires
fire_ignitions1_new<- fire_ignitions1 %>%
  filter(fire_year >=2002) %>%
  filter(fire_cause=="Lightning")
fire_ignitions1_new$month<- as.numeric(fire_ignitions1_new$month)
hist(fire_ignitions1_new$month, xlab="Month", main="Histogram of lightning caused fires") # most lightning fires appear to occur between May - Sept, with a peak in July and August!

#Histogram of human caused fires
fire_ignitions1_person<- fire_ignitions1 %>%
  filter(fire_year >=2002) %>%
  filter(fire_cause=="Person")
fire_ignitions1_person$month<- as.numeric(fire_ignitions1_person$month)
hist(fire_ignitions1_person$month, xlab="Month", main="Histogram of person caused fires") # Person caused fires occur throughout the year but also peak in July and August!

table(fire_ignitions1_new$fire_year, fire_ignitions1_new$fire_cause)
table(fire_ignitions1_person$fire_year, fire_ignitions1_person$fire_cause)
```

Now that the data is prepped from 05_VRI_data_prep, we can move on to the analysis for selecting the best climatic variable(s) for each BEC zone. The loop below will be run first for lightning caused fires, and then for person-caused fires.

To select the best single fire weather covariate we first conducted exploratory graphical analyses of the correlations between fire frequency and various fire weather variables. Then we fit generalized linear models for each fire weather variable (Eq. 1) using a binomial error structure with logarithmic link. Candidate variables were monthly average temperature, monthly maximum temperature, monthly precipitations and the six mean drought codes (MDCâ€™s). We also added various two, three or fourth-month means of these values (e.g. for May, June, July and August) to test for seasonal effects (e.g. spring vs. summer).

Before we begin the analyses, we will look at some correlations.


```{r}
#### looking at correlations between variables####

####1. Lightning ########

# correlation between max T and MDC. Across all the data MDC and Tmax are correlated with values ranging between 0.78 and 0.15
dist.cut.corr <- dat_lightning [c (20:24, 35:39)]
corr <- round (cor (dist.cut.corr), 3)
ggcorrplot (corr, type = "lower", lab = TRUE, tl.cex = 10,  lab_size = 3,
            title = "Correlation between maximum temperature and MDC")

# Correlation between total precipitation and MDC. This is also pretty correlated with values between -0.75 and -0.18
dist.cut.corr <- dat_lightning [c (30:34, 35:39)]
corr <- round (cor (dist.cut.corr), 3)
ggcorrplot (corr, type = "lower", lab = TRUE, tl.cex = 10,  lab_size = 3,
            title = "Correlation between total precipitation and MDC")

# Correlation between Tmax and total precipitation. The correlation is very low, as would be expected (-0.02 to -0.57) 
dist.cut.corr <- dat_lightning [c (20:24, 30:34)]
corr <- round (cor (dist.cut.corr), 3)
ggcorrplot (corr, type = "lower", lab = TRUE, tl.cex = 10,  lab_size = 3,
            title = "Correlation between total precipitation and Tmax")


# Correlation between Tave and total precipitation. The correlation is very low, as would be expected (-0.03 to -0.43) 
dist.cut.corr <- dat_lightning [c (24:28, 29:33)]
corr <- round (cor (dist.cut.corr), 3)
ggcorrplot (corr, type = "lower", lab = TRUE, tl.cex = 10,  lab_size = 3,
            title = "Correlation between total precipitation and Tave")
```


```{r}
######## Person Caused Fires #############

# correlation between max T and MDC. Across all the data MDC and Tmax are correlated with values ranging between 0.78 and 0.15
dist.cut.corr <- dat_person [c (20:24, 35:39)]
corr <- round (cor (dist.cut.corr), 3)
ggcorrplot (corr, type = "lower", lab = TRUE, tl.cex = 10,  lab_size = 3,
            title = "Correlation between maximum temperature and MDC")

# Correlation between total precipitation and MDC. This is also pretty correlated with values between -0.75 and -0.18
dist.cut.corr <- dat_person [c (30:34, 35:39)]
corr <- round (cor (dist.cut.corr), 3)
ggcorrplot (corr, type = "lower", lab = TRUE, tl.cex = 10,  lab_size = 3,
            title = "Correlation between total precipitation and MDC")

# Correlation between Tmax and total precipitation. The correlation is very low, as would be expected (-0.02 to -0.57) 
dist.cut.corr <- dat_person [c (19:23, 29:33)]
corr <- round (cor (dist.cut.corr), 3)
ggcorrplot (corr, type = "lower", lab = TRUE, tl.cex = 10,  lab_size = 3,
            title = "Correlation between total precipitation and Tmax")


# Correlation between Tave and total precipitation. The correlation is very low, as would be expected (-0.03 to -0.43) 
dist.cut.corr <- dat_person [c (25:29, 30:34)]
corr <- round (cor (dist.cut.corr), 3)
ggcorrplot (corr, type = "lower", lab = TRUE, tl.cex = 10,  lab_size = 3,
            title = "Correlation between total precipitation and Tave")

```


#################################
# ANALYSIS OF CLIMATE VARIABLES
#################################

Loosely following the methods of Marchal et al. (2017) Ecography (https://onlinelibrary.wiley.com/doi/full/10.1111/ecog.01849) Supporting Information Appendix 1 I try to figure out which is the best climate variable or climate variables to include in my model. I run simple models of the form:

     logb(p/1-p) = B0 + B1x1 or logb(p/1-p) = B0 + B1x1 + B2x2

and extract the AIC as a means for comparison. I also calculate the AUC by splitting the data into a training and validation data set. Finally I repeat the analysis calculating the AIC and AUC using training and validation data sets 10 times taking the average of both the AIC and AUC values. These are the values that I spit out into a csv file so that I can examine which climate variable is best for each BEC zone. 

Before we begin, we will create additional climate variables.

```{r}
#Climate variable creation for lightning data

### creating amalgamations of variables to test different combinations of variables.##
dat_lightning$mean_tmax05_tmax06<- (dat_lightning$tmax05+ dat_lightning$tmax06)/2
dat_lightning$mean_tmax06_tmax07<- (dat_lightning$tmax06+ dat_lightning$tmax07)/2
dat_lightning$mean_tmax07_tmax08<- (dat_lightning$tmax07+ dat_lightning$tmax08)/2
dat_lightning$mean_tmax08_tmax09<- (dat_lightning$tmax08+ dat_lightning$tmax09)/2
dat_lightning$mean_tmax05_tmax06_tmax07<- (dat_lightning$tmax05+ dat_lightning$tmax06 + dat_lightning$tmax07)/3
dat_lightning$mean_tmax06_tmax07_tmax08<- (dat_lightning$tmax06+ dat_lightning$tmax07 + dat_lightning$tmax08)/3
dat_lightning$mean_tmax07_tmax08_tmax09<- (dat_lightning$tmax07+ dat_lightning$tmax08 + dat_lightning$tmax09)/3
dat_lightning$mean_tmax05_tmax06_tmax07_tmax08<- (dat_lightning$tmax05 + dat_lightning$tmax06+ dat_lightning$tmax07 + dat_lightning$tmax08)/4
dat_lightning$mean_tmax06_tmax07_tmax08_tmax09<- (dat_lightning$tmax06 + dat_lightning$tmax07+ dat_lightning$tmax08 + dat_lightning$tmax09)/4
dat_lightning$mean_tmax05_tmax06_tmax07_tmax08_tmax09<- (dat_lightning$tmax05 + dat_lightning$tmax06 + dat_lightning$tmax07+ dat_lightning$tmax08 + dat_lightning$tmax09)/5

dat_lightning$mean_tave05_tave06<- (dat_lightning$tave05+ dat_lightning$tave06)/2
dat_lightning$mean_tave06_tave07<- (dat_lightning$tave06+ dat_lightning$tave07)/2
dat_lightning$mean_tave07_tave08<- (dat_lightning$tave07+ dat_lightning$tave08)/2
dat_lightning$mean_tave08_tave09<- (dat_lightning$tave08+ dat_lightning$tave09)/2
dat_lightning$mean_tave05_tave06_tave07<- (dat_lightning$tave05+ dat_lightning$tave06 + dat_lightning$tave07)/3
dat_lightning$mean_tave06_tave07_tave08<- (dat_lightning$tave06+ dat_lightning$tave07 + dat_lightning$tave08)/3
dat_lightning$mean_tave07_tave08_tave09<- (dat_lightning$tave07+ dat_lightning$tave08 + dat_lightning$tave09)/3
dat_lightning$mean_tave05_tave06_tave07_tave08<- (dat_lightning$tave05 + dat_lightning$tave06+ dat_lightning$tave07 + dat_lightning$tave08)/4
dat_lightning$mean_tave06_tave07_tave08_tave09<- (dat_lightning$tave06 + dat_lightning$tave07+ dat_lightning$tave08 + dat_lightning$tave09)/4
dat_lightning$mean_tave05_tave06_tave07_tave08_tave09<- (dat_lightning$tave05 + dat_lightning$tave06 + dat_lightning$tave07+ dat_lightning$tave08 + dat_lightning$tave09)/5


dat_lightning$mean_ppt05_ppt06<- (dat_lightning$ppt05+ dat_lightning$ppt06)/2
dat_lightning$mean_ppt06_ppt07<- (dat_lightning$ppt06+ dat_lightning$ppt07)/2
dat_lightning$mean_ppt07_ppt08<- (dat_lightning$ppt07+ dat_lightning$ppt08)/2
dat_lightning$mean_ppt08_ppt09<- (dat_lightning$ppt08+ dat_lightning$ppt09)/2
dat_lightning$mean_ppt05_ppt06_ppt07<- (dat_lightning$ppt05+ dat_lightning$ppt06 + dat_lightning$ppt07)/3
dat_lightning$mean_ppt06_ppt07_ppt08<- (dat_lightning$ppt06+ dat_lightning$ppt07 + dat_lightning$ppt08)/3
dat_lightning$mean_ppt07_ppt08_ppt09<- (dat_lightning$ppt07+ dat_lightning$ppt08 + dat_lightning$ppt09)/3
dat_lightning$mean_ppt05_ppt06_ppt07_ppt08<- (dat_lightning$ppt05+ dat_lightning$ppt06 + dat_lightning$ppt07 + dat_lightning$ppt08)/4
dat_lightning$mean_ppt06_ppt07_ppt08_ppt09<- (dat_lightning$ppt06+ dat_lightning$ppt07 + dat_lightning$ppt08 + dat_lightning$ppt09)/4
dat_lightning$mean_ppt05_ppt06_ppt07_ppt08_ppt09<- (dat_lightning$ppt05 + dat_lightning$ppt06 + dat_lightning$ppt07 + dat_lightning$ppt08 + dat_lightning$ppt09)/5

dat_lightning$mean_mdc05_mdc06<- (dat_lightning$mdc_05+ dat_lightning$mdc_06)/2
dat_lightning$mean_mdc06_mdc07<- (dat_lightning$mdc_06+ dat_lightning$mdc_07)/2
dat_lightning$mean_mdc07_mdc08<- (dat_lightning$mdc_07+ dat_lightning$mdc_08)/2
dat_lightning$mean_mdc08_mdc09<- (dat_lightning$mdc_08+ dat_lightning$mdc_09)/2
dat_lightning$mean_mdc05_mdc06_mdc07<- (dat_lightning$mdc_05+ dat_lightning$mdc_06 + dat_lightning$mdc_07)/3
dat_lightning$mean_mdc06_mdc07_mdc08<- (dat_lightning$mdc_06+ dat_lightning$mdc_07 + dat_lightning$mdc_08)/3
dat_lightning$mean_mdc07_mdc08_mdc09<- (dat_lightning$mdc_07+ dat_lightning$mdc_08 + dat_lightning$mdc_09)/3
dat_lightning$mean_mdc05_mdc06_mdc07_mdc08<- (dat_lightning$mdc_05+ dat_lightning$mdc_06 + dat_lightning$mdc_07 + dat_lightning$mdc_08)/4
dat_lightning$mean_mdc06_mdc07_mdc08_mdc09<- (dat_lightning$mdc_06+ dat_lightning$mdc_07 + dat_lightning$mdc_08 + dat_lightning$mdc_09)/4
dat_lightning$mean_mdc05_mdc06_mdc07_mdc08_mdc09<- (dat_lightning$mdc_05 + dat_lightning$mdc_06+ dat_lightning$mdc_07 + dat_lightning$mdc_08 + dat_lightning$mdc_09)/5


```

For each fire, let's extract the MDC in the specific month that fire began. Note that some fires actually began in months other than 05-09. For these, for now, we will select the nearest time (05 for January to April, and 09 for October and November). We may wish to get the actual values.

```{r}

names(dat_lightning)
table(dat_lightning$ign_month) #Some of these fires were started in October, November, January, February and March. Very unexpected.

dat_lightning$mdc_atfire<-0
dat_lightning$ign_month<-as.numeric(dat_lightning$ign_month)
head(dat_lightning)
dat_lightning_<-dat_lightning %>%
    mutate(mdc_atfire = case_when(ign_month == 5 ~ mdc_05,
                                  ign_month == 6 ~ mdc_06,
                                  ign_month == 7 ~ mdc_07,
                                  ign_month == 8 ~ mdc_08,
                                  ign_month == 9 ~ mdc_09,
                                  ign_month == 10 ~ mdc_09,
                                  ign_month == 11 ~ mdc_09,
                                  ign_month == 4 ~ mdc_05,
                                  ign_month == 3 ~ mdc_05,
                                  ign_month == 2 ~ mdc_05,
                                  ign_month == 1 ~ mdc_05,
                                  TRUE ~ mean_mdc05_mdc06_mdc07_mdc08_mdc09)) #Those areas without fire will receive the mean value for the season. These MDC values may be most accurately used for the escape and spread data, wherein we only assess those areas where fires began.

head(dat_lightning_)

```


```{r}
#Climate variable creation for person-caused fire data

### creating amalgamations of variables to test different combinations of variables.##
dat_person$mean_tmax05_tmax06<- (dat_person$tmax05+ dat_person$tmax06)/2
dat_person$mean_tmax06_tmax07<- (dat_person$tmax06+ dat_person$tmax07)/2
dat_person$mean_tmax07_tmax08<- (dat_person$tmax07+ dat_person$tmax08)/2
dat_person$mean_tmax08_tmax09<- (dat_person$tmax08+ dat_person$tmax09)/2
dat_person$mean_tmax05_tmax06_tmax07<- (dat_person$tmax05+ dat_person$tmax06 + dat_person$tmax07)/3
dat_person$mean_tmax06_tmax07_tmax08<- (dat_person$tmax06+ dat_person$tmax07 + dat_person$tmax08)/3
dat_person$mean_tmax07_tmax08_tmax09<- (dat_person$tmax07+ dat_person$tmax08 + dat_person$tmax09)/3
dat_person$mean_tmax05_tmax06_tmax07_tmax08<- (dat_person$tmax05 + dat_person$tmax06+ dat_person$tmax07 + dat_person$tmax08)/4
dat_person$mean_tmax06_tmax07_tmax08_tmax09<- (dat_person$tmax06 + dat_person$tmax07+ dat_person$tmax08 + dat_person$tmax09)/4
dat_person$mean_tmax05_tmax06_tmax07_tmax08_tmax09<- (dat_person$tmax05 + dat_person$tmax06 + dat_person$tmax07+ dat_person$tmax08 + dat_person$tmax09)/5

dat_person$mean_tave05_tave06<- (dat_person$tave05+ dat_person$tave06)/2
dat_person$mean_tave06_tave07<- (dat_person$tave06+ dat_person$tave07)/2
dat_person$mean_tave07_tave08<- (dat_person$tave07+ dat_person$tave08)/2
dat_person$mean_tave08_tave09<- (dat_person$tave08+ dat_person$tave09)/2
dat_person$mean_tave05_tave06_tave07<- (dat_person$tave05+ dat_person$tave06 + dat_person$tave07)/3
dat_person$mean_tave06_tave07_tave08<- (dat_person$tave06+ dat_person$tave07 + dat_person$tave08)/3
dat_person$mean_tave07_tave08_tave09<- (dat_person$tave07+ dat_person$tave08 + dat_person$tave09)/3
dat_person$mean_tave05_tave06_tave07_tave08<- (dat_person$tave05 + dat_person$tave06+ dat_person$tave07 + dat_person$tave08)/4
dat_person$mean_tave06_tave07_tave08_tave09<- (dat_person$tave06 + dat_person$tave07+ dat_person$tave08 + dat_person$tave09)/4
dat_person$mean_tave05_tave06_tave07_tave08_tave09<- (dat_person$tave05 + dat_person$tave06 + dat_person$tave07+ dat_person$tave08 + dat_person$tave09)/5


dat_person$mean_ppt05_ppt06<- (dat_person$ppt05+ dat_person$ppt06)/2
dat_person$mean_ppt06_ppt07<- (dat_person$ppt06+ dat_person$ppt07)/2
dat_person$mean_ppt07_ppt08<- (dat_person$ppt07+ dat_person$ppt08)/2
dat_person$mean_ppt08_ppt09<- (dat_person$ppt08+ dat_person$ppt09)/2
dat_person$mean_ppt05_ppt06_ppt07<- (dat_person$ppt05+ dat_person$ppt06 + dat_person$ppt07)/3
dat_person$mean_ppt06_ppt07_ppt08<- (dat_person$ppt06+ dat_person$ppt07 + dat_person$ppt08)/3
dat_person$mean_ppt07_ppt08_ppt09<- (dat_person$ppt07+ dat_person$ppt08 + dat_person$ppt09)/3
dat_person$mean_ppt05_ppt06_ppt07_ppt08<- (dat_person$ppt05+ dat_person$ppt06 + dat_person$ppt07 + dat_person$ppt08)/4
dat_person$mean_ppt06_ppt07_ppt08_ppt09<- (dat_person$ppt06+ dat_person$ppt07 + dat_person$ppt08 + dat_person$ppt09)/4
dat_person$mean_ppt05_ppt06_ppt07_ppt08_ppt09<- (dat_person$ppt05 + dat_person$ppt06 + dat_person$ppt07 + dat_person$ppt08 + dat_person$ppt09)/5

dat_person$mean_mdc05_mdc06<- (dat_person$mdc_05+ dat_person$mdc_06)/2
dat_person$mean_mdc06_mdc07<- (dat_person$mdc_06+ dat_person$mdc_07)/2
dat_person$mean_mdc07_mdc08<- (dat_person$mdc_07+ dat_person$mdc_08)/2
dat_person$mean_mdc08_mdc09<- (dat_person$mdc_08+ dat_person$mdc_09)/2
dat_person$mean_mdc05_mdc06_mdc07<- (dat_person$mdc_05+ dat_person$mdc_06 + dat_person$mdc_07)/3
dat_person$mean_mdc06_mdc07_mdc08<- (dat_person$mdc_06+ dat_person$mdc_07 + dat_person$mdc_08)/3
dat_person$mean_mdc07_mdc08_mdc09<- (dat_person$mdc_07+ dat_person$mdc_08 + dat_person$mdc_09)/3
dat_person$mean_mdc05_mdc06_mdc07_mdc08<- (dat_person$mdc_05+ dat_person$mdc_06 + dat_person$mdc_07 + dat_person$mdc_08)/4
dat_person$mean_mdc06_mdc07_mdc08_mdc09<- (dat_person$mdc_06+ dat_person$mdc_07 + dat_person$mdc_08 + dat_person$mdc_09)/4
dat_person$mean_mdc05_mdc06_mdc07_mdc08_mdc09<- (dat_person$mdc_05 + dat_person$mdc_06+ dat_person$mdc_07 + dat_person$mdc_08 + dat_person$mdc_09)/5
```


For each fire, let's extract the MDC in the specific month that fire began. Note that some fires actually began in months other than 05-09. For these, for now, we will select the nearest time (05 for January to April, and 09 for October and November). We may wish to get the actual values.

```{r}

names(dat_person)
table(dat_person$ign_month) #Some of these fires were started in October, November, January, February and March. Very unexpected.

dat_person$mdc_atfire<-0
dat_person$ign_month<-as.numeric(dat_person$ign_month)
head(dat_person)
dat_person_<-dat_person %>%
    mutate(mdc_atfire = case_when(ign_month == 5 ~ mdc_05,
                                  ign_month == 6 ~ mdc_06,
                                  ign_month == 7 ~ mdc_07,
                                  ign_month == 8 ~ mdc_08,
                                  ign_month == 9 ~ mdc_09,
                                  ign_month == 10 ~ mdc_09,
                                  ign_month == 11 ~ mdc_09,
                                  ign_month == 4 ~ mdc_05,
                                  ign_month == 3 ~ mdc_05,
                                  ign_month == 2 ~ mdc_05,
                                  ign_month == 1 ~ mdc_05,
                                  TRUE ~ mean_mdc05_mdc06_mdc07_mdc08_mdc09)) #Those areas without fire will receive the mean value for the season. These MDC values may be most accurately used for the escape and spread data, wherein we only assess those areas where fires began.

head(dat_person_)
```

Create groupings of variables to put into model selection loop.

```{r}

variables<- c("tmax05","tmax06", "tmax07", "tmax08", "tmax09", 
              "mean_tmax05_tmax06","mean_tmax06_tmax07", "mean_tmax07_tmax08", "mean_tmax08_tmax09", 
              "mean_tmax05_tmax06_tmax07", "mean_tmax06_tmax07_tmax08","mean_tmax07_tmax08_tmax09", 
              "mean_tmax05_tmax06_tmax07_tmax08", "mean_tmax06_tmax07_tmax08_tmax09", "mean_tmax05_tmax06_tmax07_tmax08_tmax09",
              
              "tave05","tave06", "tave07", "tave08", "tave09", 
              "mean_tave05_tave06","mean_tave06_tave07", "mean_tave07_tave08", "mean_tave08_tave09", 
              "mean_tave05_tave06_tave07", "mean_tave06_tave07_tave08","mean_tave07_tave08_tave09", 
              "mean_tave05_tave06_tave07_tave08", "mean_tave06_tave07_tave08_tave09", "mean_tave05_tave06_tave07_tave08_tave09",
              
              "ppt05","ppt06", "ppt07", "ppt08", "ppt09",
              "mean_ppt05_ppt06", "mean_ppt06_ppt07", "mean_ppt07_ppt08", "mean_ppt08_ppt09", 
              "mean_ppt05_ppt06_ppt07","mean_ppt06_ppt07_ppt08", "mean_ppt07_ppt08_ppt09",
              "mean_ppt05_ppt06_ppt07_ppt08", "mean_ppt06_ppt07_ppt08_ppt09",
              "mean_ppt05_ppt06_ppt07_ppt08_ppt09",
              
              "mdc_05","mdc_06", "mdc_07", "mdc_08", "mdc_09",
              "mean_mdc05_mdc06", "mean_mdc06_mdc07", "mean_mdc07_mdc08", "mean_mdc08_mdc09", 
              "mean_mdc05_mdc06_mdc07", "mean_mdc06_mdc07_mdc08", "mean_mdc07_mdc08_mdc09", 
              "mean_mdc05_mdc06_mdc07_mdc08", "mean_mdc06_mdc07_mdc08_mdc09",
              "mean_mdc05_mdc06_mdc07_mdc08_mdc09")

 variables1<-c("tmax05", "tmax06", "tmax07", "tmax08", "tmax09",
               "tave05", "tave06", "tave07", "tave08", "tave09"
#               "tmax05","tmax06", "tmax07", "tmax08", "tmax09",
#               "mdc_05", "mdc_06", "mdc_07", "mdc_08", "mdc_09"
)
variables2<-c("ppt05", "ppt06", "ppt07", "ppt08", "ppt09",
              "ppt05", "ppt06", "ppt07", "ppt08", "ppt09"
              # "mdc_05", "mdc_06", "mdc_07", "mdc_08", "mdc_09",
              # "ppt05", "ppt06", "ppt07", "ppt08", "ppt09"
) 
# precipitation and MDC and temperature and MDC are quite correlated so I'm leaving this combination of variables out. 

```

Modify variable names for ease in analysis.

```{r}
#Lightning
dat_lightning$fire_pres<-as.numeric(dat_lightning$fire) 
table(dat_lightning$fire_yr, dat_lightning$fire_pres)
table(dat_lightning$fire_yr, dat_lightning$fire_cs, dat_lightning$zone)

#Person-caused
dat_person$fire_pres<-as.numeric(dat_person$fire) 
table(dat_person$fire_yr, dat_person$fire_pres)
table(dat_person$fire_yr, dat_person$fire_cs, dat_person$zone)

```

#################################
#### Running simple logistic regression model
#################################

Now that the data is prepped, we are ready to run the logistic regression model for the lightning and person caused fires separately to determine the best climate variables.

```{r}
# create loop to do variable selection of climate data
unique(dat_lightning$zone)
zones<- c("ICH", "ESSF", "CWH", "MH", "CMA", "MS", "PP", "IDF", "SBPS", "IMA", "BWBS", "BG", "SBS", "SWB") #"CDF", "BAFA"

# CDF and BAFA have few fire ignitions (CHECK!), I'm going to leave them out for the moment because there are not many fire ignition locations in these two. Other BEC zones that may need to be excluded due to small sample sizes include: SWB, CMA, and maybe BG. IMA seems to have small sample sizes, but consistent results.

filenames<-list()
prop<-0.75

```

Model selection for lightning caused fires:

```{r}

for (g in 1:100){

for (h in 1:length(zones)) {
  dat2<- dat_lightning %>% dplyr::filter(zone ==zones[h])
  
#Create frame of AIC table
# summary table
table.glm.climate.simple <- data.frame (matrix (ncol = 4, nrow = 0))
colnames (table.glm.climate.simple) <- c ("Zone", "Variable", "AIC", "AUC")

model_dat<- dat2 %>% dplyr::select(fire_pres)
trainIndex <- createDataPartition(model_dat$fire_pres, p = prop,
                                  list = FALSE,
                                  times = 1)
dat1 <- as.data.frame(model_dat[ trainIndex,])
names(dat1)[1] <- "fire_pres"
Valid <- as.data.frame(model_dat[-trainIndex,])
names(Valid)[1] <- "fire_pres"


model1 <- glm (fire_pres ~ 1 ,
               data=dat1,
               family = binomial (link = "logit"))

table.glm.climate.simple[1,1]<-zones[h]
table.glm.climate.simple[1,2]<-"intercept"
table.glm.climate.simple[1,3]<-extractAIC(model1)[2]

# lets look at fit of the Valid (validation) dataset
Valid$model1_predict <- predict.glm(model1,newdata = Valid,type="response")
roc_obj <- roc(Valid$fire_pres, Valid$model1_predict)
auc(roc_obj)
table.glm.climate.simple[1,4]<-auc(roc_obj)

rm(model_dat,dat1,Valid)

for (i in 1: length(variables)){
  print(paste((variables[i]), (zones[h]), sep=" "))
  
  model_dat<- dat2 %>% dplyr::select(fire_pres, variables[i])
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_pres, p = prop,
                                    list = FALSE,
                                    times = 1)
  dat1 <- model_dat[ trainIndex,]
  Valid <- model_dat[-trainIndex,]
  
  model1 <- glm (fire_pres ~ . ,
                 data=dat1,
                 family = binomial (link = "logit"))
  
  table.glm.climate.simple[i+1,1]<-zones[h]
  table.glm.climate.simple[i+1,2]<-variables[i]
  table.glm.climate.simple[i+1,3]<-extractAIC(model1)[2]
  
  # lets look at fit of the Valid (validation) dataset
  Valid$model1_predict <- predict.glm(model1,newdata = Valid,type="response")
  roc_obj <- roc(Valid$fire_pres, Valid$model1_predict)
  auc(roc_obj)
  table.glm.climate.simple[i+1,4]<-auc(roc_obj)
  
}

# This is an addition to the table above allowing combinations of temperature and precipitation

for (i in 1: length(variables1)){
  print(paste((variables1[i]), variables2[i], (zones[h]), sep=" "))
  model_dat<- dat2 %>% dplyr::select(fire_pres, variables1[i], variables2[i])
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_pres, p = prop,
                                    list = FALSE,
                                    times = 1)
  dat1 <- model_dat[ trainIndex,]
  Valid <- model_dat[-trainIndex,]
  
  model2 <- glm (fire_pres ~ . ,
                 data=dat1,
                 family = binomial (link = "logit"))
  
  table.glm.climate.simple[(i+length(variables))+1,1]<-zones[h]
  table.glm.climate.simple[(i+length(variables))+1,2]<-paste0(variables1[i],"+", variables2[i])
  table.glm.climate.simple[(i+length(variables))+1,3]<-extractAIC(model2)[2]
  
  Valid$model2_predict <- predict.glm(model2,newdata = Valid,type="response")
  roc_obj <- roc(Valid$fire_pres, Valid$model2_predict)
  auc(roc_obj)
  table.glm.climate.simple[(i+length(variables))+1,4]<-auc(roc_obj)
  
}

for (i in 1: length(variables1)){
  print(paste((variables1[i]), "x",variables2[i], (zones[h]), sep=" "))

  model_dat<- dat2 %>% dplyr::select(fire_pres, variables1[i], variables2[i])
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_pres, p = prop,
                                    list = FALSE,
                                    times = 1)
  dat1 <- model_dat[ trainIndex,]
  Valid <- model_dat[-trainIndex,]

  model2 <- glm (fire_pres ~ (.)^2,
                 data=dat1,
                 family = binomial (link = "logit"))

  table.glm.climate.simple[(i+length(variables) +length(variables1) + 1),1]<-zones[h]
  table.glm.climate.simple[(i+length(variables) +length(variables1) + 1),2]<-paste0(variables1[i],"x", variables2[i])
  table.glm.climate.simple[(i+length(variables) +length(variables1) + 1),3]<-extractAIC(model2)[2]

  Valid$model2_predict <- predict.glm(model2,newdata = Valid,type="response")
  roc_obj <- roc(Valid$fire_pres, Valid$model2_predict)
  auc(roc_obj)
  table.glm.climate.simple[(i+length(variables) +length(variables1) + 1),4]<-auc(roc_obj)

}
table.glm.climate1<-table.glm.climate.simple %>% drop_na(AIC)


#assign file names to the work
nam1<-paste("AIC",zones[h],"run",g,sep="_") #defining the name
assign(nam1,table.glm.climate.simple)
filenames<-append(filenames,nam1)
}
}
# Common warning message: glm.fit: fitted probabilities numerically 0 or 1 occurred


```

Save output:

```{r}

mkFrameList <- function(nfiles) {
  d <- lapply(seq_len(nfiles),function(i) {
    eval(parse(text=filenames[i]))
  })
  do.call(rbind,d)
}

n<-length(filenames)
aic_bec_lightning<-mkFrameList(n) 

aic_bec_lightning_summary<- aic_bec_lightning %>%
  group_by(Zone, Variable) %>%
  summarise(meanAIC=mean(AIC),
            meanAUC=mean(AUC),
            sdAUC=sd(AUC),
            )

aic_bec_lightning_summary2<- aic_bec_lightning_summary %>%
  group_by(Zone) %>%
  mutate(deltaAIC=meanAIC-min(meanAIC))

aic_bec_lightning_summary2

```

Save file to local computer:

```{r}
write.csv(aic_bec_lightning_summary2, file="D:\\Fire\\fire_data\\raw_data\\ClimateBC_Data\\climate_AIC_results_lightning_July8.csv")
```


Repeat for person-caused fires:

```{r}
##Different zones need to be excluded
unique(dat_person$zone)

zones<- c("SBS", "ICH", "ESSF", "MH",  "CWH", "CMA", "SBPS", "MS", "PP", "IDF", "BWBS","BG", "CDF") #"BAFA", "IMA", "SWB"


filenames<-list()
prop<-0.75

##Run loop
for (g in 1:100){

for (h in 1:length(zones)) {
  dat2<- dat_person %>% dplyr::filter(zone ==zones[h])
  
#Create frame of AIC table
# summary table
table.glm.climate.simple <- data.frame (matrix (ncol = 4, nrow = 0))
colnames (table.glm.climate.simple) <- c ("Zone", "Variable", "AIC", "AUC")

model_dat<- dat2 %>% dplyr::select(fire_pres)
trainIndex <- createDataPartition(model_dat$fire_pres, p = prop,
                                  list = FALSE,
                                  times = 1)
dat1 <- as.data.frame(model_dat[ trainIndex,])
names(dat1)[1] <- "fire_pres"
Valid <- as.data.frame(model_dat[-trainIndex,])
names(Valid)[1] <- "fire_pres"


model1 <- glm (fire_pres ~ 1 ,
               data=dat1,
               family = binomial (link = "logit"))

table.glm.climate.simple[1,1]<-zones[h]
table.glm.climate.simple[1,2]<-"intercept"
table.glm.climate.simple[1,3]<-extractAIC(model1)[2]

# lets look at fit of the Valid (validation) dataset
Valid$model1_predict <- predict.glm(model1,newdata = Valid,type="response")
roc_obj <- roc(Valid$fire_pres, Valid$model1_predict)
auc(roc_obj)
table.glm.climate.simple[1,4]<-auc(roc_obj)

rm(model_dat,dat1,Valid)

for (i in 1: length(variables)){
  print(paste((variables[i]), (zones[h]), sep=" "))
  
  model_dat<- dat2 %>% dplyr::select(fire_pres, variables[i])
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_pres, p = prop,
                                    list = FALSE,
                                    times = 1)
  dat1 <- model_dat[ trainIndex,]
  Valid <- model_dat[-trainIndex,]
  
  model1 <- glm (fire_pres ~ . ,
                 data=dat1,
                 family = binomial (link = "logit"))
  
  table.glm.climate.simple[i+1,1]<-zones[h]
  table.glm.climate.simple[i+1,2]<-variables[i]
  table.glm.climate.simple[i+1,3]<-extractAIC(model1)[2]
  
  # lets look at fit of the Valid (validation) dataset
  Valid$model1_predict <- predict.glm(model1,newdata = Valid,type="response")
  roc_obj <- roc(Valid$fire_pres, Valid$model1_predict)
  auc(roc_obj)
  table.glm.climate.simple[i+1,4]<-auc(roc_obj)
  
}

# This is an addition to the table above allowing combinations of temperature and precipitation

for (i in 1: length(variables1)){
  print(paste((variables1[i]), variables2[i], (zones[h]), sep=" "))
  model_dat<- dat2 %>% dplyr::select(fire_pres, variables1[i], variables2[i])
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_pres, p = prop,
                                    list = FALSE,
                                    times = 1)
  dat1 <- model_dat[ trainIndex,]
  Valid <- model_dat[-trainIndex,]
  
  model2 <- glm (fire_pres ~ . ,
                 data=dat1,
                 family = binomial (link = "logit"))
  
  table.glm.climate.simple[(i+length(variables))+1,1]<-zones[h]
  table.glm.climate.simple[(i+length(variables))+1,2]<-paste0(variables1[i],"+", variables2[i])
  table.glm.climate.simple[(i+length(variables))+1,3]<-extractAIC(model2)[2]
  
  Valid$model2_predict <- predict.glm(model2,newdata = Valid,type="response")
  roc_obj <- roc(Valid$fire_pres, Valid$model2_predict)
  auc(roc_obj)
  table.glm.climate.simple[(i+length(variables))+1,4]<-auc(roc_obj)
  
}

for (i in 1: length(variables1)){
  print(paste((variables1[i]), "x",variables2[i], (zones[h]), sep=" "))

  model_dat<- dat2 %>% dplyr::select(fire_pres, variables1[i], variables2[i])
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_pres, p = prop,
                                    list = FALSE,
                                    times = 1)
  dat1 <- model_dat[ trainIndex,]
  Valid <- model_dat[-trainIndex,]

  model2 <- glm (fire_pres ~ (.)^2,
                 data=dat1,
                 family = binomial (link = "logit"))

  table.glm.climate.simple[(i+length(variables) +length(variables1) + 1),1]<-zones[h]
  table.glm.climate.simple[(i+length(variables) +length(variables1) + 1),2]<-paste0(variables1[i],"x", variables2[i])
  table.glm.climate.simple[(i+length(variables) +length(variables1) + 1),3]<-extractAIC(model2)[2]

  Valid$model2_predict <- predict.glm(model2,newdata = Valid,type="response")
  roc_obj <- roc(Valid$fire_pres, Valid$model2_predict)
  auc(roc_obj)
  table.glm.climate.simple[(i+length(variables) +length(variables1) + 1),4]<-auc(roc_obj)

}
table.glm.climate1<-table.glm.climate.simple %>% drop_na(AIC)


#assign file names to the work
nam1<-paste("AIC",zones[h],"run",g,sep="_") #defining the name
assign(nam1,table.glm.climate.simple)
filenames<-append(filenames,nam1)
}
}


```

Save output:

```{r}

mkFrameList <- function(nfiles) {
  d <- lapply(seq_len(nfiles),function(i) {
    eval(parse(text=filenames[i]))
  })
  do.call(rbind,d)
}

n<-length(filenames)
aic_bec_person<-mkFrameList(n) 

aic_bec_person_summary<- aic_bec_person %>%
  group_by(Zone, Variable) %>%
  summarise(meanAIC=mean(AIC),
            meanAUC=mean(AUC),
            sdAUC=sd(AUC),
            )

aic_bec_person_summary2<- aic_bec_person_summary %>%
  group_by(Zone) %>%
  mutate(deltaAIC=meanAIC-min(meanAIC))

head(aic_bec_person_summary2)
```

Save file to local computer:

```{r}
write.csv(aic_bec_person_summary2, file="D:\\Fire\\fire_data\\raw_data\\ClimateBC_Data\\climate_AIC_results_person_July9b.csv")

```

Save lightning and person caused fire datasets to clus.
#Below is not working

```{r}

###
connKyle <- dbConnect(drv = RPostgreSQL::PostgreSQL(), 
                      host = key_get('dbhost', keyring = 'postgreSQL'),
                      user = key_get('dbuser', keyring = 'postgreSQL'),
                      dbname = key_get('dbname', keyring = 'postgreSQL'),
                      password = key_get('dbpass', keyring = 'postgreSQL'),
                      port = "5432")
st_write (obj = dat_lightning, 
          dsn = connKyle, 
          layer = c ("public", "Data_Lightning"))
dbDisconnect (connKyle)
```

```{r}
connKyle <- dbConnect(drv = RPostgreSQL::PostgreSQL(), 
                      host = key_get('dbhost', keyring = 'postgreSQL'),
                      user = key_get('dbuser', keyring = 'postgreSQL'),
                      dbname = key_get('dbname', keyring = 'postgreSQL'),
                      password = key_get('dbpass', keyring = 'postgreSQL'),
                      port = "5432")
st_write (obj = dat_person, 
          dsn = connKyle, 
          layer = c ("public", "Data_Person"))
dbDisconnect (connKyle)
```


Clear work space to help R run faster again


```{r}
library(gdata)

keep(fire_veg_data_B, ignition_pres_abs4, fire_veg_data_lightning_5x, fire_veg_data_person_5x, fire_veg_data_NA_5x, fire_veg_data_lightning_NA_5x, fire_veg_data_person_NA_5x, dat_lightning, dat_person, aic_bec_person_summary2, aic_bec_lightning_summary2, sure = TRUE) # setting sure to TRUE removes variables not in the list
 
ls()
gc(TRUE)
```


############### Complete. Now move on to 07_Fire_ignition_model_fits_by_BEC wherein the results of these AIC tests will be utilized###########

Note: for person-caused fires, we still need to load the roads map and decide whether to use the roads clus to predict road occurence back in time to 2002, or keep as is.
