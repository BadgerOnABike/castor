---
title: "09a_fire_ignition_model_selection_NDT1_lightning_treed"
author: "Cora Skaien"
date: "16/09/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library (data.table)
library (DBI)
library (RPostgreSQL)
library (dplyr)
library (ggplot2)
library (here)
library(ggpubr)
library(arm)
library(tidyr)
library(AICcmodavg)
library(keyring)
library(caret)
library(pROC)
library(rje)
library(car)
library(visreg)

source(here::here("R/functions/R_Postgres.R"))
```

<!--
Copyright 2021 Province of British Columbia

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and limitations under the License.
-->

#=================================
#  Script Name: 09a_fire_ignition_model_selection_NDT1_lightning_treed.R
#  Script Version: 1.0
#  Script Purpose: Model selection, using various initial models to inform the final model selection.
#  Script Author: Cora Skaien, Ecological Modeling Specialist, Forest Analysis and Inventory Branch, B.C. Ministry of Forests, Lands, and Natural Resource Operations.
#=================================

#Load data back in if starting from here
Note: depending where your geometry column was located when saved as a csv (and turned into a dataframe), you may need to manually correct column headings on the csv file before loading back in. This has been performed for the below files.

```{r}
dat_lightning_t<-read.csv(file="D:\\Fire\\fire_data\\raw_data\\ClimateBC_Data\\data_lightning_trees_NDT_Oct.csv")
head(dat_lightning_t)

table(dat_lightning_t$ntrl_ds)

```

######################### ANALYSES: TREED, LIGHTNING #########################

Now, we will make a loop that does something very similar to our last loop, but with the selected climate variable plus other variables of interest. For lightning caused fires with trees, the variables of interest include:

1. Climate variable(s)
2. Projected Height (proj_height_1)
3. projected age (proj_age_1)  
4. live_stand_volume_125
5. vegtype2 (with additional categories)
6. slope
7. aspect_cos (cos)
8. elevation
9. Various distance to infrastructure variables (dist_mun, dist_dam, dist_nat, dist_pow, dist_mine, dist_any) - no interactions
10. Some measure of death or mountain pine beetle damage -- TBD

Variables to be added after initial model selection for next round model selection:
1. bclcs_level_5_2 (land use) (to be added to final investigated model)

Interactions of interest: two-way interactions between climate (1) and vegtype (6); two-way interactions between topography measures (7-9); interactions between VRI variables.

This will be done separately for trees and non-treed areas. 

##We will do each loop separately for each NDT zone given the large number of possible models for each zone.

First we will create the variable lists that contain all of our variables of interest.

```{r}
##Create variable lists to be used in the model loop.
variables_all<-c(climate1 = "climate1", climate2 = "climate2", proj_height_1 = "proj_height_1", proj_age_1 = "proj_age_1", live_stand_volume_125 = "live_stand_volume_125", slope = "slope", aspect_cos = "aspect_cos", elevation ="elevation", vegtype2 = "vegtype2", dist_mun = "dist_mun", dist_dam = "dist_dam", dist_nat = "dist_nat", dist_pow = "dist_pow", dist_mine = "dist_mine", dist_any = "dist_any") #heatload="heatload",

variables_all_c1<-c(climate1 = "climate1", proj_height_1 = "proj_height_1", proj_age_1 = "proj_age_1", live_stand_volume_125 = "live_stand_volume_125", slope = "slope", aspect_cos = "aspect_cos", elevation ="elevation", vegtype2 = "vegtype2", dist_mun = "dist_mun", dist_dam = "dist_dam", dist_nat = "dist_nat", dist_pow = "dist_pow", dist_mine = "dist_mine", dist_any = "dist_any") #heatload="heatload",

vars.clim<-c("climate1")
vars.clim.vegtype<-c("climate1", "vegtype2")
vars.clim.vegtype2<-c("climate1", "climate2","vegtype2")
vars.clim.vegtype2b<-c("climate1", "climate2")

vars.oth<-c("proj_height_1", "proj_age_1", "live_stand_volume_125") 
vars.topo<-c("slope", "aspect_cos", "elevation")
vars.infra<-c("dist_mun", "dist_dam", "dist_nat", "dist_pow", "dist_mine", "dist_any")


##Create interaction for climate and vegtype
inputs.me <- c(vars.clim.vegtype)
inputs.me2 <- c(vars.clim.vegtype2)
inputs.me2b <- c(vars.clim.vegtype2b)
```

Now, we will generate two-way interactions for each of these lists. 

```{r}

#####1a. For those with one climate variable
#get the names of all possible two-way interactions for climate variable(s) and vegtype.
twoway.ints <- NULL
for (i in 1:(length(inputs.me)-1)) {
  for (j in (i+1):length(inputs.me)) {
     twoway.ints <- cbind(twoway.ints, paste(inputs.me[i], inputs.me[j], sep=":"))
  }
}
twoway.ints
length(twoway.ints)

#
#Create function to determine Powerset for any vector of variable names
## or use rje package
#powerSet <- function(x) {
#   z.list <- NULL
#   for(i in 1:length(x)) {
#      z.list <- append(z.list, combn(x, m=i, simplify=F))
#   }    
#   return(z.list)
#}


#Get variables on own
#complete list of models using non-climate vars
mods.me.tmp <- powerSet(vars.clim.vegtype) 
#add climate vars to all of the above
mods.me.climate <- list()
for (i in 1: length(mods.me.tmp)) {
   mods.me.climate[[i]] <- c(mods.me.tmp[[i]])
}

mods.me.climate


#####1b. For those with two climate variables
#get the names of all possible two-way interactions for climate variable(s) and vegtype.
twoway.ints2 <- NULL
for (i in 1:(length(inputs.me2)-1)) {
  for (j in (i+1):length(inputs.me2)) {
     twoway.ints2 <- cbind(twoway.ints2, paste(inputs.me2[i], inputs.me2[j], sep=":"))
  }
}
twoway.ints2
length(twoway.ints2)

#Get variables on own
#complete list of models using non-climate vars
mods.me.tmp <- powerSet(vars.clim.vegtype2) 
#add climate vars to all of the above
mods.me.climate2 <- list()
for (i in 1: length(mods.me.tmp)) {
   mods.me.climate2[[i]] <- c(mods.me.tmp[[i]])
}

mods.me.climate2

#complete list of two-way interactions
mods.twoway2 <- powerSet(twoway.ints2)
length(mods.twoway2) #7
mods.twoway2

#Finding models in mods.me that accommodate/allow interaction terms in each mods.twoway to be added
mods.inter2 <- list()
counter <- 0
for (i in 1: length(mods.twoway2)) {
   s1 <- unique(unlist( strsplit(mods.twoway2[[i]], split=':', fixed=TRUE) ) )
   for (j in 1: length(mods.me.climate2)) {
      if (all(s1 %in% mods.me.climate2[[j]])==TRUE) {
        counter <- counter + 1
        both <-  c(mods.me.climate2[[j]], mods.twoway2[[i]])
        mods.inter2[[counter]] <- both
      }
   }
}

length(mods.inter2)
#mods.inter2


####1c. Two variables, no variation in vegtype
#get the names of all possible two-way interactions for climate variable(s) and vegtype.
twoway.ints2b <- NULL
for (i in 1:(length(inputs.me2b)-1)) {
  for (j in (i+1):length(inputs.me2b)) {
     twoway.ints2b <- cbind(twoway.ints2b, paste(inputs.me2b[i], inputs.me2b[j], sep=":"))
  }
}
twoway.ints2b
length(twoway.ints2b)

#Get variables on own
#complete list of models using non-climate vars
mods.me.tmp <- powerSet(vars.clim.vegtype2b) 
#add climate vars to all of the above
mods.me.climate2b <- list()
for (i in 1: length(mods.me.tmp)) {
   mods.me.climate2b[[i]] <- c(mods.me.tmp[[i]])
}

mods.me.climate2b

#complete list of two-way interactions
mods.twoway2b <- powerSet(twoway.ints2b)
length(mods.twoway2b) #7
mods.twoway2b

#Finding models in mods.me that accommodate/allow interaction terms in each mods.twoway to be added
mods.inter2b <- list()
counter <- 0
for (i in 1: length(mods.twoway2b)) {
   s1 <- unique(unlist( strsplit(mods.twoway2b[[i]], split=':', fixed=TRUE) ) )
   for (j in 1: length(mods.me.climate2b)) {
      if (all(s1 %in% mods.me.climate2b[[j]])==TRUE) {
        counter <- counter + 1
        both <-  c(mods.me.climate2b[[j]], mods.twoway2b[[i]])
        mods.inter2b[[counter]] <- both
      }
   }
}

length(mods.inter2b)
#mods.inter2b


#########2. Now for topography data, get all possible two-way interactions

#get the names of all possible two-way interactions
twoway.intsT <- NULL
for (i in 1:(length(vars.topo)-1)) {
  for (j in (i+1):length(vars.topo)) {
     twoway.intsT <- cbind(twoway.intsT, paste(vars.topo[i], vars.topo[j], sep=":"))
  }
}
twoway.intsT
length(twoway.intsT)

#complete list of models using non-climate vars (topo)
mods.me.tmp <- powerSet(vars.topo) 
#add climate vars to all of the above
mods.meT <- list()
for (i in 1: length(mods.me.tmp)) {
   mods.meT[[i]] <- c(mods.me.tmp[[i]])
}

mods.meT

#complete list of two-way interactions
mods.twowayT <- powerSet(twoway.intsT)
length(mods.twowayT) #7
mods.twowayT

#Finding models in mods.me that accommodate/allow interaction terms in each mods.twoway to be added

mods.interT <- list()
counter <- 0
for (i in 1: length(mods.twowayT)) {
   s1 <- unique(unlist( strsplit(mods.twowayT[[i]], split=':', fixed=TRUE) ) )
   for (j in 1: length(mods.meT)) {
      if (all(s1 %in% mods.meT[[j]])==TRUE) {
        counter <- counter + 1
        both <-  c(mods.meT[[j]], mods.twowayT[[i]])
        mods.interT[[counter]] <- both
      }
   }
}

length(mods.interT)
#mods.interT
mods.interTb<-c(mods.interT,vars.heatload)
#mods.interTb

####3.For other VRI data, get without interactions

#complete list of models using VRI - no interactions
mods.me.tmp <- powerSet(vars.oth) 
#add climate vars to all of the above
mods.me.oth <- list()
for (i in 1: length(mods.me.tmp)) {
   mods.me.oth[[i]] <- c(mods.me.tmp[[i]])
}

#mods.me.oth


#########4. Now for distance to infrastructure data, get all possible two-way interactions

#get the names of all possible two-way interactions
twoway.intsI <- NULL
for (i in 1:(length(vars.infra)-1)) {
  for (j in (i+1):length(vars.infra)) {
     twoway.intsI <- cbind(twoway.intsI, paste(vars.infra[i], vars.infra[j], sep=":"))
  }
}
twoway.intsI
length(twoway.intsI)

#complete list of models using non-climate vars (infra)
mods.me.tmp <- powerSet(vars.infra) 
#add climate vars to all of the above
mods.meI <- list()
for (i in 1: length(mods.me.tmp)) {
   mods.meI[[i]] <- c(mods.me.tmp[[i]])
}

mods.meI

#complete list of two-way interactions
mods.twowayI <- powerSet(twoway.intsI)
length(mods.twowayI) #32768
#mods.twowayI

#Finding models in mods.me that accommodate/allow interaction terms in each mods.twoway to be added

mods.interI <- list()
counter <- 0
for (i in 1: length(mods.twowayI)) {
   s1 <- unique(unlist( strsplit(mods.twowayI[[i]], split=':', fixed=TRUE) ) )
   for (j in 1: length(mods.meI)) {
      if (all(s1 %in% mods.meI[[j]])==TRUE) {
        counter <- counter + 1
        both <-  c(mods.meI[[j]], mods.twowayI[[i]])
        mods.interI[[counter]] <- both
      }
   }
}

length(mods.interI)
#mods.interI


#the list of all possible model RHSs. 
#all.poss.mods <- c(1, vars.clim, twoway.ints, mods.me.oth, mods.me2, mods.inter2)
#all.poss.mods

all.poss.mods.clim.vegtype<-c(1, mods.me.climate, twoway.ints)
all.poss.mods.clim.vegtype 
all.poss.mods.clim.vegtype<-all.poss.mods.clim.vegtype [-2] #Use this line only if there is an odd character(0) added to list
all.poss.mods.clim.vegtype2<-c(1, mods.inter2)
all.poss.mods.clim.vegtype2
all.poss.mods.clim.vegtype2<-all.poss.mods.clim.vegtype2[-2]
#all.poss.mods.clim.vegtype2<-all.poss.mods.clim.vegtype2[-9]
all.poss.mods.clim.vegtype2b<-c(1, mods.inter2b)
#all.poss.mods.clim.vegtype2b<-c(1, mods.me.climate2b, mods.inter2b)
all.poss.mods.clim.vegtype2b
all.poss.mods.clim.vegtype2b<-all.poss.mods.clim.vegtype2b[-2]
#all.poss.mods.clim.vegtype2b<-all.poss.mods.clim.vegtype2b[-5]

all.poss.mods.VRI<-c(1, mods.me.oth)
all.poss.mods.VRI
all.poss.mods.VRI<-all.poss.mods.VRI[-2]
#all.poss.mods.topo<-c(1, mods.meT, mods.interT)
all.poss.mods.topo<-c(1, mods.interT)
all.poss.mods.topo
#all.poss.mods.topo<-all.poss.mods.topo[-10]
all.poss.mods.topo<-all.poss.mods.topo[-2]
all.poss.mods.infra<-c(1, mods.meI) #I don't think we want interactions here actually...
#all.poss.mods.infra<-c(1, mods.meI, mods.interI)
all.poss.mods.infra<-all.poss.mods.infra[-2] #See if have future errors to see if need to remove

#If need to determine which ones are character(0), try this:
biglist <- list(list("A","B","C"), "foo", "", character(0), integer(0))
lapply(biglist, function(x) {length(x) == 0L} ) 


##Check and rid of any duplicated models
duplicated(all.poss.mods.clim.vegtype) #None duplicated
duplicated(all.poss.mods.clim.vegtype2)
duplicated(all.poss.mods.clim.vegtype2b)
duplicated(all.poss.mods.VRI)
duplicated(all.poss.mods.topo)
duplicated(all.poss.mods.infra)

```




############### Part 1 of 4 Model Series: Lightning Caused Fires, Trees ##########

Because of the large number of models with all variables included, we will test the climate and vegtype first, then the VRI variables, then the topography variables. Then we will test the top models together, with determining best AIC model from there. Or perhaps we will just combine the top models for each together, and eliminate models if the intercept was the best predictor.

Select NDT: NDT1

```{r}
zones1<-c("NDT1") #Do one zone at a time

prop<-0.75

#Create empty table
table.glm.climate.simple <- data.frame (matrix (ncol = 5, nrow = 0))
colnames (table.glm.climate.simple) <- c ("model", "edf", "aic", "auc.valid", "NDT")

########### 1. Climate and vegtype ############
for (g in 1:100){

for (h in 1:length(zones1)) {
  dat2<- dat_lightning_t %>% dplyr::filter(ntrl_ds ==zones1[h])

#for (i in 1: length(all.poss.mods.clim.vegtype2)){
#  print(paste((all.poss.mods.clim.vegtype2[i]), (zones1[h]), sep=" "))
  
for (i in 1: length(zones1)){
  print(paste((all.poss.mods.clim.vegtype2[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, variables_all[i])
  model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, !!variables_all)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="fire_pres") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.aic, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.clim.vegtype2, big.mod, df.train=dat1, df.test=Valid)

#terms in each model
x1.1 <- unlist(sapply(mods.fit, '[', 1))
x1.1
#Aic for models
x3.1 <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3.1
#auc from validation data
x4.1 <- unlist(sapply(mods.fit, '[', 4))
x4.1
#combining all as df
tab.sum.climate <- cbind.data.frame(model=x1.1, edf=x3.1[,1], aic=x3.1[,2], auc.valid=x4.1)
tab.sum.climate$NDT<-c("NDT1")
tab.sum.climate 

table.glm.climate.simple<-rbind(table.glm.climate.simple, tab.sum.climate)

}
}
}


```

Now that we have run the model 100 times, we want the average AIC and AUC for each variable combination.

```{r}
head(table.glm.climate.simple)
table(table.glm.climate.simple$model) # 100 per model

AIC_lightning_NDT1_t_ignitereed_climate<-table.glm.climate.simple

AIC_lightning_NDT1_t_ignitereed_summary_climate<- AIC_lightning_NDT1_t_ignitereed_climate %>%
  group_by(model) %>%
  summarise(meanAIC=mean(aic),
            meanAUC=mean(auc.valid),
            sdAUC=sd(auc.valid),
            )

AIC_lightning_NDT1_t_ignitereed_summary_climate2<- AIC_lightning_NDT1_t_ignitereed_summary_climate %>%
  mutate(deltaAIC=meanAIC-min(meanAIC))

head(AIC_lightning_NDT1_t_ignitereed_summary_climate2)
```

#Now repeat for VRI data

```{r}
########### 2. VRI ############
#Create empty table
table.glm.VRI.simple <- data.frame (matrix (ncol = 5, nrow = 0))
colnames (table.glm.VRI.simple) <- c ("model", "edf", "aic", "auc.valid", "NDT")

####
for (g in 1:100){

for (h in 1:length(zones1)) {
  dat2<- dat_lightning_t %>% dplyr::filter(ntrl_ds ==zones1[h])

#for (i in 1: length(all.poss.mods.VRI)){
#  print(paste((all.poss.mods.VRI[i]), (zones1[h]), sep=" "))
  
for (i in 1: length(zones1)){
  print(paste((all.poss.mods.VRI[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, variables_all[i])
  model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, !!variables_all)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="fire_pres") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.aic, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.VRI, big.mod, df.train=dat1, df.test=Valid)

#terms in each model
x1.1 <- unlist(sapply(mods.fit, '[', 1))
x1.1
#Aic for models
x3.1 <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3.1
#auc from validation data
x4.1 <- unlist(sapply(mods.fit, '[', 4))
x4.1
#combining all as df
tab.sum.VRI <- cbind.data.frame(model=x1.1, edf=x3.1[,1], aic=x3.1[,2], auc.valid=x4.1)
tab.sum.VRI$NDT<-c("NDT1")
tab.sum.VRI 

table.glm.VRI.simple<-rbind(table.glm.VRI.simple, tab.sum.VRI)

}
}
}
```

Now that we have run the model 100 times, we want the average AIC and AUC for each variable combination.

```{r}
head(table.glm.VRI.simple)
table(table.glm.VRI.simple$model) # 100 per model

AIC_lightning_NDT1_t_ignitereed_VRI<-table.glm.VRI.simple

AIC_lightning_NDT1_t_ignitereed_summary_VRI<- AIC_lightning_NDT1_t_ignitereed_VRI %>%
  group_by(model) %>%
  summarise(meanAIC=mean(aic),
            meanAUC=mean(auc.valid),
            sdAUC=sd(auc.valid),
            )

AIC_lightning_NDT1_t_ignitereed_summary_VRI2<- AIC_lightning_NDT1_t_ignitereed_summary_VRI %>%
  mutate(deltaAIC=meanAIC-min(meanAIC))

head(AIC_lightning_NDT1_t_ignitereed_summary_VRI2)
```

#Now repeat for topography

```{r}
########### 3. topo ############
#Create empty table
table.glm.topo.simple <- data.frame (matrix (ncol = 5, nrow = 0))
colnames (table.glm.topo.simple) <- c ("model", "edf", "aic", "auc.valid", "NDT")

#
for (g in 1:100){

for (h in 1:length(zones1)) {
  dat2<- dat_lightning_t %>% dplyr::filter(ntrl_ds ==zones1[h])

#for (i in 1: length(all.poss.mods.topo)){
#  print(paste((all.poss.mods.topo[i]), (zones1[h]), sep=" "))
  
for (i in 1: length(zones1)){
  print(paste((all.poss.mods.topo[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, variables_all[i])
  model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, !!variables_all)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="fire_pres") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.aic, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.topo, big.mod, df.train=dat1, df.test=Valid)

#terms in each model
x1.1 <- unlist(sapply(mods.fit, '[', 1))
x1.1
#Aic for models
x3.1 <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3.1
#auc from validation data
x4.1 <- unlist(sapply(mods.fit, '[', 4))
x4.1
#combining all as df
tab.sum.topo <- cbind.data.frame(model=x1.1, edf=x3.1[,1], aic=x3.1[,2], auc.valid=x4.1)
tab.sum.topo$NDT<-c("NDT1")
tab.sum.topo 

table.glm.topo.simple<-rbind(table.glm.topo.simple, tab.sum.topo)

}
}
}
```

Now that we have run the model 100 times, we want the average AIC and AUC for each variable combination.

```{r}
head(table.glm.topo.simple)
table(table.glm.topo.simple$model) # 100 per model

AIC_lightning_NDT1_t_ignitereed_topo<-table.glm.topo.simple

AIC_lightning_NDT1_t_ignitereed_summary_topo<- AIC_lightning_NDT1_t_ignitereed_topo %>%
  group_by(model) %>%
  summarise(meanAIC=mean(aic),
            meanAUC=mean(auc.valid),
            sdAUC=sd(auc.valid),
            )

AIC_lightning_NDT1_t_ignitereed_summary_topo2<- AIC_lightning_NDT1_t_ignitereed_summary_topo %>%
  mutate(deltaAIC=meanAIC-min(meanAIC))

head(AIC_lightning_NDT1_t_ignitereed_summary_topo2)
```

#Now repeat for infrastructure

```{r}
########### 4. Distance to Infrastructure ############
#Create empty table
table.glm.infra.simple <- data.frame (matrix (ncol = 5, nrow = 0))
colnames (table.glm.infra.simple) <- c ("model", "edf", "aic", "auc.valid", "NDT")

#
for (g in 1:100){

for (h in 1:length(zones1)) {
  dat2<- dat_lightning_t %>% dplyr::filter(ntrl_ds ==zones1[h])

#for (i in 1: length(all.poss.mods.infra)){
#  print(paste((all.poss.mods.infra[i]), (zones1[h]), sep=" "))
  
for (i in 1: length(zones1)){
  print(paste((all.poss.mods.infra[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, variables_all[i])
  model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, !!variables_all)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="fire_pres") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.aic, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.infra, big.mod, df.train=dat1, df.test=Valid)

#terms in each model
x1.1 <- unlist(sapply(mods.fit, '[', 1))
x1.1
#Aic for models
x3.1 <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3.1
#auc from validation data
x4.1 <- unlist(sapply(mods.fit, '[', 4))
x4.1
#combining all as df
tab.sum.infra <- cbind.data.frame(model=x1.1, edf=x3.1[,1], aic=x3.1[,2], auc.valid=x4.1)
tab.sum.infra$NDT<-c("NDT1")
tab.sum.infra 

table.glm.infra.simple<-rbind(table.glm.infra.simple, tab.sum.infra)

}
}
}
```

Now that we have run the model 100 times, we want the average AIC and AUC for each variable combination.

```{r}
head(table.glm.infra.simple)
table(table.glm.infra.simple$model) # 100 per model

AIC_lightning_NDT1_t_ignitereed_infra<-table.glm.infra.simple

AIC_lightning_NDT1_t_ignitereed_summary_infra<- AIC_lightning_NDT1_t_ignitereed_infra %>%
  group_by(model) %>%
  summarise(meanAIC=mean(aic),
            meanAUC=mean(auc.valid),
            sdAUC=sd(auc.valid),
            )

AIC_lightning_NDT1_t_ignitereed_summary_infra2<- AIC_lightning_NDT1_t_ignitereed_summary_infra %>%
  mutate(deltaAIC=meanAIC-min(meanAIC))

head(AIC_lightning_NDT1_t_ignitereed_summary_infra2)

```

#Now combine the datatables and save to computer

```{r}
NDT1_l_models_treed<-rbind(AIC_lightning_NDT1_t_ignitereed_summary_climate2, AIC_lightning_NDT1_t_ignitereed_summary_VRI2, AIC_lightning_NDT1_t_ignitereed_summary_topo2, AIC_lightning_NDT1_t_ignitereed_summary_infra2)
NDT1_l_models_treed
NDT1_l_models_treed$NDT<-"NDT1"

write.csv(NDT1_l_models_treed, file="D:\\Fire\\fire_data\\raw_data\\NDT1_lightning_models_treed.csv")
```




################################ STAGE TWO ########################

#STAGE TWO: PUT TOGETHER MORE VARIABLES
Now choose the top variables and create final model. The below code will need to be updated manually, depending on what the results of the above analyses are. From the top models, we will re-create two-way interactions for the variables selected from each model, plus the other variables listed as needed to be included. We will assess each set to ensure only interactions that make sense are investigated ultimately, given that sample sizes will be an issues.

Top Models:
1. climate1 + climate2 + vegtype2 + climate1:climate2 + climate1:vegtype2 + climate2:vegtype2
2. proj_height_1 + proj_age_1 + live_stand_volume_125
3. slope + aspect_cos + elevation + aspect_cos:elevation
4. dist_mun + dist_dam + dist_nat + dist_mine 

Additional Variables:
1. bclcs_level_5_2 (land use) (to be added to final investigated model)

We want to include interactions between variables from within each list. This will make for many models, which may be hard to process in R.

```{r}
##Create variable lists to be used in the model loop.
variables_all_NDT1<-c(climate1 = "climate1", climate2 = "climate2", vegtype2 = "vegtype2", proj_height_1 = "proj_height_1", live_stand_volume_125 = "live_stand_volume_125", proj_age_1 = "proj_age_1", slope = "slope", aspect_cos = "aspect_cos", elevation ="elevation", dist_mun = "dist_mun", dist_dam = "dist_dam", dist_nat = "dist_nat", dist_mine = "dist_mine", bclcs_level_5_2 = "bclcs_level_5_2")


#Too many permutations to be able to include two-way interactions and all possible models, so need to divide into what we think may have interactions and which not.
variables_clim_VRI_NDT1<-c(climate1 = "climate1", climate2 = "climate2", vegtype2 = "vegtype2", proj_height_1 = "proj_height_1", live_stand_volume_125 = "live_stand_volume_125", proj_age_1 = "proj_age_1")

#treat slope, aspect_cos and elevation as their own thing. And we have already done this analysis with them.
#slope = "slope", aspect_cos = "aspect_cos", elevation ="elevation")

variables_all_infra_landuse_NDT1<-c(dist_mun = "dist_mun", dist_dam = "dist_dam", dist_nat = "dist_nat", dist_mine = "dist_mine", bclcs_level_5_2 = "bclcs_level_5_2") #I don't think it makes sense to have interactions between the distance elements, but maybe with land use and each distance element?

##
inputs.me.NDT1 <- c(variables_all_NDT1)
#inputs.me.clim_VRI_DEM_NDT1 <- c(variables_clim_VRI_DEM_NDT1)
inputs.me.clim_VRI_NDT1 <- c(variables_clim_VRI_NDT1)
inputs.me.infra_landuse_NDT1 <- c(variables_all_infra_landuse_NDT1)

```

Now, we will generate two-way interactions for each of these lists. We cannot make two-way interactions between them all because apparently it will be >2 GB in size.

```{r}
####Reduce further
twoway.ints <- NULL
for (i in 1:(length(inputs.me.clim_VRI_NDT1)-1)) {
  for (j in (i+1):length(inputs.me.clim_VRI_NDT1)) {
     twoway.ints <- cbind(twoway.ints, paste(inputs.me.clim_VRI_NDT1[i], inputs.me.clim_VRI_NDT1[j], sep=":"))
  }
}
twoway.ints
length(twoway.ints) #15

#Create function to determine Powerset for any vector of variable names
## or use rje package
#powerSet <- function(x) {
#   z.list <- NULL
#   for(i in 1:length(x)) {
#      z.list <- append(z.list, combn(x, m=i, simplify=F))
#   }    
#   return(z.list)
#}

#Get variables on own
#complete list of models using non-climate vars
mods.me.tmp <- powerSet(variables_clim_VRI_NDT1) 
#add climate vars to all of the above
mods.me.clim_VRI_NDT1 <- list()
for (i in 1: length(mods.me.tmp)) {
   mods.me.clim_VRI_NDT1[[i]] <- c(mods.me.tmp[[i]])
}

mods.me.clim_VRI_NDT1
length(mods.me.clim_VRI_NDT1) #64


#complete list of two-way interactions
mods.twoway.NDT1 <- powerSet(twoway.ints) # 
length(mods.twoway.NDT1) #32768
#mods.twoway.NDT1

#Finding models in mods.me that accommodate/allow interaction terms in each mods.twoway to be added
mods.inter.NDT1 <- list()
counter <- 0
for (i in 1: length(mods.twoway.NDT1)) {
   s1 <- unique(unlist( strsplit(mods.twoway.NDT1[[i]], split=':', fixed=TRUE) ) )
   for (j in 1: length(mods.me.clim_VRI_NDT1)) {
      if (all(s1 %in% mods.me.clim_VRI_NDT1[[j]])==TRUE) {
        counter <- counter + 1
        both <-  c(mods.me.clim_VRI_NDT1[[j]], mods.twoway.NDT1[[i]])
        mods.inter.NDT1[[counter]] <- both
      }
   }
}

length(mods.inter.NDT1) #40069: this number is very large
#mods.inter.NDT1

##Subset 2: Infrastructure and land use ########
#inputs.me.infra_landuse_NDT1
twoway.ints <- NULL
for (i in 1:(length(inputs.me.infra_landuse_NDT1)-1)) {
  for (j in (i+1):length(inputs.me.infra_landuse_NDT1)) {
     twoway.ints <- cbind(twoway.ints, paste(inputs.me.infra_landuse_NDT1[i], inputs.me.infra_landuse_NDT1[j], sep=":"))
  }
}
twoway.ints
length(twoway.ints) #10
#Review. If we do not want interactions between the different distance measurements, but only those between land use and distance, subset those.
twoway.ints
twoway.ints_dist<-twoway.ints[c(4,7,9,10)]
twoway.ints_dist


#Create function to determine Powerset for any vector of variable names
## or use rje package
#powerSet <- function(x) {
#   z.list <- NULL
#   for(i in 1:length(x)) {
#      z.list <- append(z.list, combn(x, m=i, simplify=F))
#   }    
#   return(z.list)
#}

#Get variables on own
#complete list of models using non-climate vars
mods.me.tmp <- powerSet(variables_all_infra_landuse_NDT1) 
#add climate vars to all of the above
mods.me.infra_landuse_NDT1 <- list()
for (i in 1: length(mods.me.tmp)) {
   mods.me.infra_landuse_NDT1[[i]] <- c(mods.me.tmp[[i]])
}

mods.me.infra_landuse_NDT1
length(mods.me.infra_landuse_NDT1) #32


#complete list of two-way interactions
#mods.twoway.NDT1b <- powerSet(twoway.ints) #
#Or use subset of interactions
mods.twoway.NDT1b <- powerSet(twoway.ints_dist) 
length(mods.twoway.NDT1b) #16
mods.twoway.NDT1b

#Finding models in mods.me that accommodate/allow interaction terms in each mods.twoway to be added
mods.inter.NDT1b <- list()
counter <- 0
for (i in 1: length(mods.twoway.NDT1b)) {
   s1 <- unique(unlist( strsplit(mods.twoway.NDT1b[[i]], split=':', fixed=TRUE) ) )
   for (j in 1: length(mods.me.infra_landuse_NDT1)) {
      if (all(s1 %in% mods.me.infra_landuse_NDT1[[j]])==TRUE) {
        counter <- counter + 1
        both <-  c(mods.me.infra_landuse_NDT1[[j]], mods.twoway.NDT1b[[i]])
        mods.inter.NDT1b[[counter]] <- both
      }
   }
}

length(mods.inter.NDT1b) #97 
#mods.inter.NDT1b
```

Make final list of variables to assess.

```{r}
## 1. climate and VRI
#the list of all possible model RHSs. 
all.poss.mods.clim_VRI_NDT1<-c(1, mods.me.clim_VRI_NDT1, mods.inter.NDT1)
#all.poss.mods.clim_VRI_NDT1
length(mods.me.clim_VRI_NDT1) #64
all.poss.mods.clim_VRI_NDT1[2]
all.poss.mods.clim_VRI_NDT1[66] #character 0
all.poss.mods.clim_VRI_NDT1<-all.poss.mods.clim_VRI_NDT1[-66]
all.poss.mods.clim_VRI_NDT1<-all.poss.mods.clim_VRI_NDT1[-2] #Use this line only if there is an odd character(0) added to list
length(all.poss.mods.clim_VRI_NDT1) #40132

##Check and rid of any duplicated models
duplicated(all.poss.mods.clim_VRI_NDT1) #Need to remove 
all.poss.mods.clim_VRI_NDT1b<-all.poss.mods.clim_VRI_NDT1[-(65:127)]
duplicated(all.poss.mods.clim_VRI_NDT1b) 
length(all.poss.mods.clim_VRI_NDT1b) #40069

#Divide into smaller chunks to be able to run
all.poss.mods.clim_VRI_NDT1b_1<-all.poss.mods.clim_VRI_NDT1b[1:20000]
all.poss.mods.clim_VRI_NDT1b_2<-all.poss.mods.clim_VRI_NDT1b[20001:30000]
all.poss.mods.clim_VRI_NDT1b_3<-all.poss.mods.clim_VRI_NDT1b[30001:40069]
length(all.poss.mods.clim_VRI_NDT1b_1)
length(all.poss.mods.clim_VRI_NDT1b_2)
head(all.poss.mods.clim_VRI_NDT1b_2)


#####2. Infrastructure and land use
all.poss.mods.infra_landuse_NDT1<-c(1,mods.me.infra_landuse_NDT1, mods.inter.NDT1b)

##Check and rid of any duplicated models
duplicated(all.poss.mods.infra_landuse_NDT1) #Need to remove 
all.poss.mods.infra_landuse_NDT1b<-all.poss.mods.infra_landuse_NDT1[-(34:65)]
duplicated(all.poss.mods.infra_landuse_NDT1b) 
all.poss.mods.infra_landuse_NDT1b[2]
all.poss.mods.infra_landuse_NDT1b<-all.poss.mods.infra_landuse_NDT1b[-2]
```


```{r}
#If need to determine which ones are character(0), try this:
biglist <- list(list("A","B","C"), "foo", "", character(0), integer(0))
lapply(biglist, function(x) {length(x) == 0L} ) 

#Below does not work
lapply(biglist, all.poss.mods.infra_landuse_NDT1b {length(all.poss.mods.infra_landuse_NDT1b) == 0L} ) 

```

#Proceed with 
  ## all.poss.mods.clim_VRI_NDT1b
  ## all.poss.mods.infra_landuse_NDT1b
  
#all.poss.mods.clim_VRI_NDT1b_1, all.poss.mods.clim_VRI_NDT1b_2, all.poss.mods.clim_VRI_NDT1b_3
We cannot run the model 100 times without R crashing. The number of models being assessed is very large. Instead, we had to subset the data and run it piece by piece, and repeat the process to ensure the same training and validation data.


```{r}
zones1<-"NDT1"

#Create empty table
table.glm.clim_VRI.NDT1_set1 <- data.frame (matrix (ncol = 5, nrow = 0))
colnames (table.glm.clim_VRI.NDT1_set1) <- c ("model", "edf", "aic", "auc.valid", "NDT")

#Subset data
dat2<- dat_lightning_t %>% dplyr::filter(ntrl_ds ==zones1[h])

 # model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, variables_all[i])
model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, !!variables_clim_VRI_NDT1)
# Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]
```

Model needs to be run for each set of variables on the same subset of training and validation data to compare AICs.

```{r}
big.mod <- function(mods.in, df.train, df.test, dep.var="fire_pres") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.aic, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.clim_VRI_NDT1b_1, big.mod, df.train=dat1, df.test=Valid)
```

Extract the model terms.

```{r}
#terms in each model
x1.1 <- unlist(sapply(mods.fit, '[', 1))
x1.1
#Aic for models
x3.1 <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3.1
#auc from validation data
x4.1 <- unlist(sapply(mods.fit, '[', 4))
x4.1
#combining all as df
tab.sum.clim_VRI <- cbind.data.frame(model=x1.1, edf=x3.1[,1], aic=x3.1[,2], auc.valid=x4.1)
tab.sum.clim_VRI$NDT<-c("NDT1")
tab.sum.clim_VRI 

table.glm.clim_VRI.NDT1_set1<-rbind(table.glm.clim_VRI.NDT1_set1, tab.sum.clim_VRI)

table.glm.clim_VRI.NDT1_set1

```

#Repeat for set2
Make an empty table.

```{r}
#Create empty table
table.glm.clim_VRI.NDT1_set2 <- data.frame (matrix (ncol = 5, nrow = 0))
colnames (table.glm.clim_VRI.NDT1_set2) <- c ("model", "edf", "aic", "auc.valid", "NDT")
```

Run function for set 2.

```{r}
mods.fit <- lapply(all.poss.mods.clim_VRI_NDT1b_2, big.mod, df.train=dat1, df.test=Valid)
```

Save output.

```{r}
#terms in each model
x1.1 <- unlist(sapply(mods.fit, '[', 1))
x1.1
#Aic for models
x3.1 <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3.1
#auc from validation data
x4.1 <- unlist(sapply(mods.fit, '[', 4))
x4.1
#combining all as df
tab.sum.clim_VRI <- cbind.data.frame(model=x1.1, edf=x3.1[,1], aic=x3.1[,2], auc.valid=x4.1)
tab.sum.clim_VRI$NDT<-c("NDT1")
tab.sum.clim_VRI 

table.glm.clim_VRI.NDT1_set2<-rbind(table.glm.clim_VRI.NDT1_set2, tab.sum.clim_VRI)

table.glm.clim_VRI.NDT1_set2
```

Combine set 1 and set 2

```{r}
table.glm.clim_VRI.NDT1_set1_2<-rbind(table.glm.clim_VRI.NDT1_set1, table.glm.clim_VRI.NDT1_set2)
```

Run function for set 3.

```{r}
mods.fit <- lapply(all.poss.mods.clim_VRI_NDT1b_3, big.mod, df.train=dat1, df.test=Valid)
```

Extract output.

```{r}
#terms in each model
x1.1 <- unlist(sapply(mods.fit, '[', 1))
#x1.1
#Aic for models
x3.1 <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
#x3.1
#auc from validation data
x4.1 <- unlist(sapply(mods.fit, '[', 4))
#x4.1
#combining all as df
tab.sum.clim_VRI <- cbind.data.frame(model=x1.1, edf=x3.1[,1], aic=x3.1[,2], auc.valid=x4.1)
tab.sum.clim_VRI$NDT<-c("NDT1")
tab.sum.clim_VRI 

table.glm.clim_VRI.NDT1_set_ALL<-rbind(table.glm.clim_VRI.NDT1_set1_2, tab.sum.clim_VRI) #Should have 40,069 rows

```

Save.
```{r}
write.csv(table.glm.clim_VRI.NDT1_set_ALL, file="D:\\Fire\\fire_data\\raw_data\\table.glm.clim_VRI.NDT1_ALL.csv")
```

Now repeat the process again many times to get variation.

```{r}
zones1<-"NDT1"

#Create empty table
table.glm.clim_VRI.NDT1_set1 <- data.frame (matrix (ncol = 5, nrow = 0))
colnames (table.glm.clim_VRI.NDT1_set1) <- c ("model", "edf", "aic", "auc.valid", "NDT")

#Subset data
dat2<- dat_lightning_t %>% dplyr::filter(ntrl_ds ==zones1[h])

 # model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, variables_all[i])
model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, !!variables_clim_VRI_NDT1)
# Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]
```

Model needs to be run for each set of variables on the same subset of training and validation data to compare AICs.

```{r}
mods.fit <- lapply(all.poss.mods.clim_VRI_NDT1b_1, big.mod, df.train=dat1, df.test=Valid)
```

Extract the model terms.

```{r}
#terms in each model
x1.1 <- unlist(sapply(mods.fit, '[', 1))
x1.1
#Aic for models
x3.1 <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3.1
#auc from validation data
x4.1 <- unlist(sapply(mods.fit, '[', 4))
x4.1
#combining all as df
tab.sum.clim_VRI <- cbind.data.frame(model=x1.1, edf=x3.1[,1], aic=x3.1[,2], auc.valid=x4.1)
tab.sum.clim_VRI$NDT<-c("NDT1")
tab.sum.clim_VRI 

table.glm.clim_VRI.NDT1_set1<-rbind(table.glm.clim_VRI.NDT1_set1, tab.sum.clim_VRI)

table.glm.clim_VRI.NDT1_set1

```

#Repeat for set2
Make an empty table.

```{r}
#Create empty table
table.glm.clim_VRI.NDT1_set2 <- data.frame (matrix (ncol = 5, nrow = 0))
colnames (table.glm.clim_VRI.NDT1_set2) <- c ("model", "edf", "aic", "auc.valid", "NDT")
```

Run function for set 2.

```{r}
mods.fit <- lapply(all.poss.mods.clim_VRI_NDT1b_2, big.mod, df.train=dat1, df.test=Valid)
```

Save output.

```{r}
#terms in each model
x1.1 <- unlist(sapply(mods.fit, '[', 1))
x1.1
#Aic for models
x3.1 <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3.1
#auc from validation data
x4.1 <- unlist(sapply(mods.fit, '[', 4))
x4.1
#combining all as df
tab.sum.clim_VRI <- cbind.data.frame(model=x1.1, edf=x3.1[,1], aic=x3.1[,2], auc.valid=x4.1)
tab.sum.clim_VRI$NDT<-c("NDT1")
tab.sum.clim_VRI 

table.glm.clim_VRI.NDT1_set2<-rbind(table.glm.clim_VRI.NDT1_set2, tab.sum.clim_VRI)

table.glm.clim_VRI.NDT1_set2
```

Combine set 1 and set 2

```{r}
table.glm.clim_VRI.NDT1_set1_2<-rbind(table.glm.clim_VRI.NDT1_set1, table.glm.clim_VRI.NDT1_set2)
```

Run function for set 3.

```{r}
mods.fit <- lapply(all.poss.mods.clim_VRI_NDT1b_3, big.mod, df.train=dat1, df.test=Valid)
```

Extract output.

```{r}
#terms in each model
x1.1 <- unlist(sapply(mods.fit, '[', 1))
#x1.1
#Aic for models
x3.1 <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
#x3.1
#auc from validation data
x4.1 <- unlist(sapply(mods.fit, '[', 4))
#x4.1
#combining all as df
tab.sum.clim_VRI <- cbind.data.frame(model=x1.1, edf=x3.1[,1], aic=x3.1[,2], auc.valid=x4.1)
tab.sum.clim_VRI$NDT<-c("NDT1")
tab.sum.clim_VRI 

table.glm.clim_VRI.NDT1_set_ALL2<-rbind(table.glm.clim_VRI.NDT1_set1_2, tab.sum.clim_VRI) #Should have 40,069 rows

```

Save.
```{r}
write.csv(table.glm.clim_VRI.NDT1_set_ALL2, file="D:\\Fire\\fire_data\\raw_data\\table.glm.clim_VRI.NDT1_ALL2.csv")
```

Combine the first 2 runs.

```{r}
table.glm.clim_VRI.NDT1_set_ALL1_2<-rbind(table.glm.clim_VRI.NDT1_set_ALL, table.glm.clim_VRI.NDT1_set_ALL2)
```

Save.
```{r}
write.csv(table.glm.clim_VRI.NDT1_set_ALL1_2, file="D:\\Fire\\fire_data\\raw_data\\table.glm.clim_VRI.NDT1_ALL1_2.csv")
```

Now repeat the process again many times to get variation. Likely, much of the environment will need to be cleared to be able to run. Remember to use gc() as well. Keep table.glm.clim_VRI.NDT1_set_ALL1_2 and all relevant model lists.

```{r}
zones1<-"NDT1"

#Create empty table
table.glm.clim_VRI.NDT1_set1 <- data.frame (matrix (ncol = 5, nrow = 0))
colnames (table.glm.clim_VRI.NDT1_set1) <- c ("model", "edf", "aic", "auc.valid", "NDT")

#Subset data
dat2<- dat_lightning_t %>% dplyr::filter(ntrl_ds ==zones1[h])

 # model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, variables_all[i])
model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, !!variables_clim_VRI_NDT1)
# Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]
```

Model needs to be run for each set of variables on the same subset of training and validation data to compare AICs.

Below is not working well, so split in next round.
```{r}
all.poss.mods.clim_VRI_NDT1b_1_a<-all.poss.mods.clim_VRI_NDT1b_1[1:10000]
all.poss.mods.clim_VRI_NDT1b_1_b<-all.poss.mods.clim_VRI_NDT1b_1[10001:20000]
```


```{r}
mods.fit <- lapply(all.poss.mods.clim_VRI_NDT1b_1_a, big.mod, df.train=dat1, df.test=Valid)
```

Extract the model terms.

```{r}
#terms in each model
x1.1 <- unlist(sapply(mods.fit, '[', 1))
x1.1
#Aic for models
x3.1 <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3.1
#auc from validation data
x4.1 <- unlist(sapply(mods.fit, '[', 4))
x4.1
#combining all as df
tab.sum.clim_VRI <- cbind.data.frame(model=x1.1, edf=x3.1[,1], aic=x3.1[,2], auc.valid=x4.1)
tab.sum.clim_VRI$NDT<-c("NDT1")
tab.sum.clim_VRI 

table.glm.clim_VRI.NDT1_set1<-rbind(table.glm.clim_VRI.NDT1_set1, tab.sum.clim_VRI)

table.glm.clim_VRI.NDT1_set1

```

Repeat for second half.
```{r}
mods.fit <- lapply(all.poss.mods.clim_VRI_NDT1b_1_b, big.mod, df.train=dat1, df.test=Valid)
```

Extract the model terms.

```{r}
#terms in each model
x1.1 <- unlist(sapply(mods.fit, '[', 1))
x1.1
#Aic for models
x3.1 <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3.1
#auc from validation data
x4.1 <- unlist(sapply(mods.fit, '[', 4))
x4.1
#combining all as df
tab.sum.clim_VRI <- cbind.data.frame(model=x1.1, edf=x3.1[,1], aic=x3.1[,2], auc.valid=x4.1)
tab.sum.clim_VRI$NDT<-c("NDT1")
tab.sum.clim_VRI 

table.glm.clim_VRI.NDT1_set1<-rbind(table.glm.clim_VRI.NDT1_set1, tab.sum.clim_VRI) #combine with set1 already produced from first half

table.glm.clim_VRI.NDT1_set1

```


#Repeat for set2
Make an empty table.

```{r}
#Create empty table
table.glm.clim_VRI.NDT1_set2 <- data.frame (matrix (ncol = 5, nrow = 0))
colnames (table.glm.clim_VRI.NDT1_set2) <- c ("model", "edf", "aic", "auc.valid", "NDT")
```

Run function for set 2.

```{r}
mods.fit <- lapply(all.poss.mods.clim_VRI_NDT1b_2, big.mod, df.train=dat1, df.test=Valid)
```

Save output.

```{r}
#terms in each model
x1.1 <- unlist(sapply(mods.fit, '[', 1))
x1.1
#Aic for models
x3.1 <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3.1
#auc from validation data
x4.1 <- unlist(sapply(mods.fit, '[', 4))
x4.1
#combining all as df
tab.sum.clim_VRI <- cbind.data.frame(model=x1.1, edf=x3.1[,1], aic=x3.1[,2], auc.valid=x4.1)
tab.sum.clim_VRI$NDT<-c("NDT1")
tab.sum.clim_VRI 

table.glm.clim_VRI.NDT1_set2<-rbind(table.glm.clim_VRI.NDT1_set2, tab.sum.clim_VRI)

table.glm.clim_VRI.NDT1_set2
```

Combine set 1 and set 2

```{r}
table.glm.clim_VRI.NDT1_set1_2<-rbind(table.glm.clim_VRI.NDT1_set1, table.glm.clim_VRI.NDT1_set2)
```

Run function for set 3.

```{r}
mods.fit <- lapply(all.poss.mods.clim_VRI_NDT1b_3, big.mod, df.train=dat1, df.test=Valid)
```

Extract output.

```{r}
#terms in each model
x1.1 <- unlist(sapply(mods.fit, '[', 1))
#x1.1
#Aic for models
x3.1 <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
#x3.1
#auc from validation data
x4.1 <- unlist(sapply(mods.fit, '[', 4))
#x4.1
#combining all as df
tab.sum.clim_VRI <- cbind.data.frame(model=x1.1, edf=x3.1[,1], aic=x3.1[,2], auc.valid=x4.1)
tab.sum.clim_VRI$NDT<-c("NDT1")
tab.sum.clim_VRI 

table.glm.clim_VRI.NDT1_set_ALL3<-rbind(table.glm.clim_VRI.NDT1_set1_2, tab.sum.clim_VRI) #Should have 40,069 rows

```

Save.
```{r}
write.csv(table.glm.clim_VRI.NDT1_set_ALL3, file="D:\\Fire\\fire_data\\raw_data\\table.glm.clim_VRI.NDT1_ALL3.csv")
```

Bring the prior data back in.

Save.
```{r}
table.glm.clim_VRI.NDT1_set_ALL1_2<-read.csv(file="D:\\Fire\\fire_data\\raw_data\\table.glm.clim_VRI.NDT1_ALL1_2.csv")
head(table.glm.clim_VRI.NDT1_set_ALL1_2)
table.glm.clim_VRI.NDT1_set_ALL1_2<-table.glm.clim_VRI.NDT1_set_ALL1_2[-1]
```

Combine.

```{r}
table.glm.clim_VRI.NDT1_set_ALL1_2_3<-rbind(table.glm.clim_VRI.NDT1_set_ALL1_2, table.glm.clim_VRI.NDT1_set_ALL3)
```

Now calculate meanAIC and delatAIC, and mean AUC.

```{r}
table.glm.clim_VRI.NDT1_set_ALL_summary<- table.glm.clim_VRI.NDT1_set_ALL1_2_3%>%
  group_by(model) %>%
  summarise(meanAIC=mean(aic),
            meanAUC=mean(auc.valid),
            sdAUC=sd(auc.valid),
            )

table.glm.clim_VRI.NDT1_set_ALL_summary_2<- table.glm.clim_VRI.NDT1_set_ALL_summary %>%
  mutate(deltaAIC=meanAIC-min(meanAIC))
```

Save summary.

```{r}
write.csv(table.glm.clim_VRI.NDT1_set_ALL_summary_2, file = "D:\\Fire\\fire_data\\raw_data\\AIC_clim_VRI.NDT1_set_ALL_summary_2.csv")
```


#AUC values for prior models with subset of variables were between 0.59-0.68.

#Now repeat for all.poss.mods.infra_landuse_NDT1b
There are not nearly as many models to compare, so we should not need to divide the number of runs ups. Try running it all in one go of 100.

```{r}
########### 2. Distance to Infrastructure ############
#Create empty table
table.glm.infra.lu.simple <- data.frame (matrix (ncol = 5, nrow = 0))
colnames (table.glm.infra.lu.simple) <- c ("model", "edf", "aic", "auc.valid", "NDT")


#
for (g in 1:100){

for (h in 1:length(zones1)) {
  dat2<- dat_lightning_t %>% dplyr::filter(ntrl_ds ==zones1[h])

#for (i in 1: length(all.poss.mods.infra)){
#  print(paste((all.poss.mods.infra[i]), (zones1[h]), sep=" "))
  
for (i in 1: length(zones1)){
  print(paste((all.poss.mods.infra_landuse_NDT1b[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, variables_all[i])
  model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, !!variables_all_infra_landuse_NDT1)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="fire_pres") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.aic, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.infra_landuse_NDT1b, big.mod, df.train=dat1, df.test=Valid)

#terms in each model
x1.1 <- unlist(sapply(mods.fit, '[', 1))
x1.1
#Aic for models
x3.1 <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3.1
#auc from validation data
x4.1 <- unlist(sapply(mods.fit, '[', 4))
x4.1
#combining all as df
tab.sum.infra.lu <- cbind.data.frame(model=x1.1, edf=x3.1[,1], aic=x3.1[,2], auc.valid=x4.1)
tab.sum.infra.lu$NDT<-c("NDT1")
tab.sum.infra.lu 

table.glm.infra.lu.simple<-rbind(table.glm.infra.lu.simple, tab.sum.infra.lu)

}
}
}
```

Now that we have run the model 100 times, we want the average AIC and AUC for each variable combination. Also determine deltaAIC.

```{r}
head(table.glm.infra.lu.simple)
table(table.glm.infra.lu.simple$model) # 100 per model

AIC_lightning_NDT1_t_ignitereed_infra<-table.glm.infra.lu.simple

AIC_lightning_NDT1_t_ignitereed_summary_infra<- AIC_lightning_NDT1_t_ignitereed_infra %>%
  group_by(model) %>%
  summarise(meanAIC=mean(aic),
            meanAUC=mean(auc.valid),
            sdAUC=sd(auc.valid),
            )

AIC_lightning_NDT1_t_ignitereed_summary_infra2<- AIC_lightning_NDT1_t_ignitereed_summary_infra %>%
  mutate(deltaAIC=meanAIC-min(meanAIC))

head(AIC_lightning_NDT1_t_ignitereed_summary_infra2)
```

Save to computer.

```{r}
write.csv(AIC_lightning_NDT1_t_ignitereed_summary_infra2, file="D:\\Fire\\fire_data\\raw_data\\AIC_lightning_NDT1_t_ignitereed_summary_infra.csv")
```

Determine the top models.

#1. Climate and VRI
climate1 + climate2 + vegtype2 + proj_height_1 + live_stand_volume_125 + proj_age_1 + climate1:climate2 + climate1:vegtype2 + climate1:proj_height_1 + climate1:live_stand_volume_125 + climate1:proj_age_1 + climate2:live_stand_volume_125 + climate2:proj_age_1 + vegtype2:live_stand_volume_125 + vegtype2:proj_age_1 + proj_height_1:live_stand_volume_125 + proj_height_1:proj_age_1 + live_stand_volume_125:proj_age_1

Lots of similar top models, with all of the same first 15 terms. We will use the top AIC and work with this one.

#2. Infrastructure 
dist_mun + dist_dam + dist_nat + dist_mine + bclcs_level_5_2 + dist_mun:bclcs_level_5_2 + dist_nat:bclcs_level_5_2 + dist_mine:bclcs_level_5_2

This is the top model, with the next deltaAIC of 3.7, so this is the one.

#3. DEM
slope + aspect_cos + elevation + aspect_cos:elevation

This was the top DEM model prior. We will work with this.

#Next investigation
Because there would be far too many models to investigate including all variables and their interactions, we will start with the above and make educated guesses for what may need to be enhanced.

```{r}
dat_lightning_t_NDT1<-subset(dat_lightning_t, dat_lightning_t$ntrl_ds=="NDT1")

#Divide data into training and valid
prop<-0.75
# Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(dat_lightning_t_NDT1$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- dat_lightning_t_NDT1[ trainIndex,]
   Valid <- dat_lightning_t_NDT1[-trainIndex,]

#Run model using dat1
model.NDT1<-glm(fire_pres ~ climate1 + climate2 + vegtype2 + proj_height_1 + live_stand_volume_125 + proj_age_1 + climate1:climate2 + climate1:vegtype2 + climate1:proj_height_1 + climate1:live_stand_volume_125 + climate1:proj_age_1 + climate2:live_stand_volume_125 + climate2:proj_age_1 + vegtype2:live_stand_volume_125 + vegtype2:proj_age_1 + proj_height_1:live_stand_volume_125 + proj_height_1:proj_age_1 + live_stand_volume_125:proj_age_1 + dist_mun + dist_dam + dist_nat + dist_mine + bclcs_level_5_2 + dist_mun:bclcs_level_5_2 + dist_nat:bclcs_level_5_2 + dist_mine:bclcs_level_5_2 + slope + aspect_cos + elevation + aspect_cos:elevation, family = binomial, data = dat1)

AIC(model.NDT1) #6160.6

#Determine AUC of full model
mod.valid <- predict.glm(model.NDT1, newdata=Valid, type="response")
   roc_obj <- roc(Valid[,"fire_pres"], mod.valid)
   mod.auc <- auc(roc_obj)
   mod.auc #0.75 --> good fit!
   
Anova(model.NDT1, type=3)
Anova(model.NDT1, type=3, singular.ok = TRUE)

#Begin removing least significant interaction
model.NDT1<-glm(fire_pres ~ climate1 + climate2 + vegtype2 + proj_height_1 + live_stand_volume_125 + proj_age_1 + climate1:climate2 + climate1:vegtype2 + climate1:proj_height_1 + climate1:live_stand_volume_125 + climate1:proj_age_1 + climate2:live_stand_volume_125 + climate2:proj_age_1 + vegtype2:live_stand_volume_125 + vegtype2:proj_age_1 + proj_height_1:live_stand_volume_125 + proj_height_1:proj_age_1 + dist_mun + dist_dam + dist_nat + dist_mine + bclcs_level_5_2 + dist_mun:bclcs_level_5_2 + dist_nat:bclcs_level_5_2 + dist_mine:bclcs_level_5_2 + slope + aspect_cos + elevation + aspect_cos:elevation, family = binomial, data = dat1)

AIC(model.NDT1) #6158.6

#Determine AUC of full model
mod.valid <- predict.glm(model.NDT1, newdata=Valid, type="response")
   roc_obj <- roc(Valid[,"fire_pres"], mod.valid)
   mod.auc <- auc(roc_obj)
   mod.auc #0.75 --> good fit!
   
Anova(model.NDT1, type=3)
Anova(model.NDT1, type=3, singular.ok = TRUE)

#Remove least significant interaction
model.NDT1<-glm(fire_pres ~ climate1 + climate2 + vegtype2 + proj_height_1 + live_stand_volume_125 + proj_age_1 + climate1:climate2 + climate1:vegtype2 + climate1:proj_height_1 + climate1:live_stand_volume_125 + climate1:proj_age_1  + climate2:proj_age_1 + vegtype2:live_stand_volume_125 + vegtype2:proj_age_1 + proj_height_1:live_stand_volume_125 + proj_height_1:proj_age_1 + dist_mun + dist_dam + dist_nat + dist_mine + bclcs_level_5_2 + dist_mun:bclcs_level_5_2 + dist_nat:bclcs_level_5_2 + dist_mine:bclcs_level_5_2 + slope + aspect_cos + elevation + aspect_cos:elevation, family = binomial, data = dat1)

AIC(model.NDT1) #6156.6

#Determine AUC of full model
mod.valid <- predict.glm(model.NDT1, newdata=Valid, type="response")
   roc_obj <- roc(Valid[,"fire_pres"], mod.valid)
   mod.auc <- auc(roc_obj)
   mod.auc #0.783 --> good fit!
   
Anova(model.NDT1, type=3)
Anova(model.NDT1, type=3, singular.ok = TRUE)

#Remove least significant interaction
model.NDT1<-glm(fire_pres ~ climate1 + climate2 + vegtype2 + proj_height_1 + live_stand_volume_125 + proj_age_1 + climate1:climate2 + climate1:proj_height_1 + climate1:live_stand_volume_125 + climate1:proj_age_1  + climate2:proj_age_1 + vegtype2:live_stand_volume_125 + proj_height_1:proj_age_1 + dist_mun + dist_dam + dist_nat + dist_mine + bclcs_level_5_2 + dist_mun:bclcs_level_5_2 + dist_nat:bclcs_level_5_2 + dist_mine:bclcs_level_5_2 + slope + aspect_cos + elevation, family = binomial, data = dat1)

AIC(model.NDT1) #6143.8

#Determine AUC of full model
mod.valid <- predict.glm(model.NDT1, newdata=Valid, type="response")
   roc_obj <- roc(Valid[,"fire_pres"], mod.valid)
   mod.auc <- auc(roc_obj)
   mod.auc #0.75 --> good fit!
   
Anova(model.NDT1, type=3)
Anova(model.NDT1, type=3, singular.ok = TRUE)

#Remove least significant interaction
model.NDT1<-glm(fire_pres ~ climate1 + climate2 + vegtype2 + proj_height_1 + live_stand_volume_125 + proj_age_1 + climate1:climate2 + climate1:proj_height_1 + climate1:proj_age_1  + climate2:proj_age_1 + vegtype2:live_stand_volume_125 + proj_height_1:proj_age_1 + dist_mun + dist_dam + dist_nat + dist_mine + bclcs_level_5_2 + dist_mun:bclcs_level_5_2 + dist_nat:bclcs_level_5_2 + dist_mine:bclcs_level_5_2 + slope + aspect_cos + elevation, family = binomial, data = dat1)

AIC(model.NDT1) #6142.4

#Determine AUC of full model
mod.valid <- predict.glm(model.NDT1, newdata=Valid, type="response")
   roc_obj <- roc(Valid[,"fire_pres"], mod.valid)
   mod.auc <- auc(roc_obj)
   mod.auc #0.75 --> good fit!
   
Anova(model.NDT1, type=3)
Anova(model.NDT1, type=3, singular.ok = TRUE)

#Remove least significant interaction
model.NDT1<-glm(fire_pres ~ climate1 + climate2 + vegtype2 + proj_height_1 + live_stand_volume_125 + proj_age_1 + climate1:climate2 + climate1:proj_height_1 + climate1:proj_age_1  + climate2:proj_age_1  + proj_height_1:proj_age_1 + dist_mun + dist_dam + dist_nat + dist_mine + bclcs_level_5_2 + dist_mun:bclcs_level_5_2 + dist_nat:bclcs_level_5_2 + dist_mine:bclcs_level_5_2 + slope + aspect_cos + elevation, family = binomial, data = dat1)

AIC(model.NDT1) #6140.8

#Determine AUC of full model
mod.valid <- predict.glm(model.NDT1, newdata=Valid, type="response")
   roc_obj <- roc(Valid[,"fire_pres"], mod.valid)
   mod.auc <- auc(roc_obj)
   mod.auc #0.75 --> good fit!
   
Anova(model.NDT1, type=3)
Anova(model.NDT1, type=3, singular.ok = TRUE)

#Remove least significant interaction
model.NDT1<-glm(fire_pres ~ climate1 + climate2 + vegtype2 + proj_height_1 + proj_age_1 + climate1:climate2 + climate1:proj_height_1 + climate1:proj_age_1  + climate2:proj_age_1  + proj_height_1:proj_age_1 + dist_mun + dist_dam + dist_nat + dist_mine + bclcs_level_5_2 + dist_mun:bclcs_level_5_2 + dist_nat:bclcs_level_5_2 + dist_mine:bclcs_level_5_2 + slope + aspect_cos + elevation, family = binomial, data = dat1)

AIC(model.NDT1) #6869--> BAD!

#Determine AUC of full model
mod.valid <- predict.glm(model.NDT1, newdata=Valid, type="response")
   roc_obj <- roc(Valid[,"fire_pres"], mod.valid)
   mod.auc <- auc(roc_obj)
   mod.auc #0.75 --> good fit!
   
Anova(model.NDT1, type=3)
Anova(model.NDT1, type=3, singular.ok = TRUE)

#REVERT
model.NDT1<-glm(fire_pres ~ climate1 + climate2 + vegtype2 + proj_height_1 + live_stand_volume_125 + proj_age_1 + climate1:climate2 + climate1:proj_height_1 + climate1:proj_age_1  + climate2:proj_age_1  + proj_height_1:proj_age_1 + dist_mun + dist_dam + dist_nat + dist_mine + bclcs_level_5_2 + dist_mun:bclcs_level_5_2 + dist_nat:bclcs_level_5_2 + dist_mine:bclcs_level_5_2 + slope + aspect_cos + elevation, family = binomial, data = dat1)

AIC(model.NDT1) #6140.8

#Determine AUC of full model
mod.valid <- predict.glm(model.NDT1, newdata=Valid, type="response")
   roc_obj <- roc(Valid[,"fire_pres"], mod.valid)
   mod.auc <- auc(roc_obj)
   mod.auc #0.75 --> good fit!
   
Anova(model.NDT1, type=3)
Anova(model.NDT1, type=3, singular.ok = TRUE)


#Previous top model
model.NDT1<-glm(fire_pres ~ climate1 + climate2 + vegtype2 + proj_height_1 + live_stand_volume_125 + proj_age_1 + climate1:climate2 + climate1:proj_height_1 + climate1:proj_age_1  + climate2:proj_age_1  + proj_height_1:proj_age_1 + dist_mun + dist_dam + dist_nat + dist_mine + bclcs_level_5_2 + dist_mun:bclcs_level_5_2 + dist_nat:bclcs_level_5_2 + dist_mine:bclcs_level_5_2 + slope + aspect_cos + elevation, family = binomial, data = dat1)

AIC(model.NDT1) #6146.98

#Determine AUC of full model
mod.valid <- predict.glm(model.NDT1, newdata=Valid, type="response")
   roc_obj <- roc(Valid[,"fire_pres"], mod.valid)
   mod.auc <- auc(roc_obj)
   mod.auc #0.7556 --> good fit!
   
Anova(model.NDT1, type=3)
Anova(model.NDT1, type=3, singular.ok = TRUE)

#Best model
model.NDT1<-glm(fire_pres ~ climate1 + climate2 + vegtype2 + proj_height_1 + live_stand_volume_125 + proj_age_1 + climate1:climate2 + climate1:proj_height_1 + climate1:proj_age_1  + climate2:proj_age_1  + proj_height_1:proj_age_1 + dist_mun + dist_dam + dist_nat + dist_mine + bclcs_level_5_2 + dist_mun:bclcs_level_5_2 + dist_nat:bclcs_level_5_2 + dist_mine:bclcs_level_5_2 + slope + aspect_cos + elevation, family = binomial, data = dat1)

AIC(model.NDT1) #6140.8

#Determine AUC of full model
mod.valid <- predict.glm(model.NDT1, newdata=Valid, type="response")
   roc_obj <- roc(Valid[,"fire_pres"], mod.valid)
   mod.auc <- auc(roc_obj)
   mod.auc #0.75 --> good fit!
   
Anova(model.NDT1, type=3)
Anova(model.NDT1, type=3, singular.ok = TRUE)

```

Remove NAs and tun multiple times.

```{r}
#Remove NAs to ensure all same data used so we can compare AICs
NDT1_t_ignite<-dat_lightning_t_NDT1 %>% drop_na(climate1, climate2, proj_height_1, live_stand_volume_125, proj_age_1, dist_mun, dist_dam, dist_nat, dist_mine, vegtype2, bclcs_level_5_2, slope, aspect_cos, elevation)

#Run Model again with this data; but uses all data here
model.NDT1<-glm(fire_pres ~ climate1 + climate2 + vegtype2 + proj_height_1 + live_stand_volume_125 + proj_age_1 + climate1:climate2 + climate1:proj_height_1 + climate1:proj_age_1  + climate2:proj_age_1  + proj_height_1:proj_age_1 + dist_mun + dist_dam + dist_nat + dist_mine + bclcs_level_5_2 + dist_mun:bclcs_level_5_2 + dist_nat:bclcs_level_5_2 + dist_mine:bclcs_level_5_2 + slope + aspect_cos + elevation, family = binomial, data = NDT1_t_ignite)

Anova(model.NDT1, type=3)
#Anova(model.NDT1, type=3, singular.ok = TRUE)

# model diagnostic plots
binnedplot (fitted(model.NDT1), 
            residuals(model.NDT1), 
            nclass = NULL, 
            xlab = "Expected Values", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm"))


NDT1_t_ignite$resids<-resid(model.NDT1)

binnedplot (NDT1_t_ignite$live_stand_volume_125, 
            NDT1_t_ignite$resids, 
            nclass = NULL, 
            xlab = "live stand volume", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))

binnedplot (NDT1_t_ignite$climate1, 
            NDT1_t_ignite$resids, 
            nclass = NULL, 
            xlab = "", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))

# Diagnostic plots look good

#Partial Residuals
#climate1 + climate2 + vegtype2 + proj_height_1 + live_stand_volume_125 + proj_age_1 + climate1:climate2 + climate1:proj_height_1 + climate1:proj_age_1  + climate2:proj_age_1  + proj_height_1:proj_age_1 + dist_mun + dist_dam + dist_nat + dist_mine + bclcs_level_5_2 + dist_mun:bclcs_level_5_2 + dist_nat:bclcs_level_5_2 + dist_mine:bclcs_level_5_2 + slope + aspect_cos + elevation
visreg(model.NDT1, "climate1", by="climate2")
visreg(model.NDT1, "climate1", by="proj_age_1")
visreg(model.NDT1, "climate1", by="proj_height_1")

visreg(model.NDT1, "climate2", by="climate1")
visreg(model.NDT1, "climate2", by="proj_age_1")

visreg(model.NDT1, "slope")
visreg(model.NDT1, "aspect_cos")
visreg(model.NDT1, "elevation")

visreg(model.NDT1, "live_stand_volume_125", by="vegtype2", overlay=TRUE, ylim=c(-10,10))

visreg(model.NDT1, "proj_age_1", by="climate2")
visreg(model.NDT1, "proj_age_1", by="climate1")
visreg(model.NDT1, "proj_age_1", by="proj_height_1")

visreg(model.NDT1, "proj_height_1", by="climate1")
visreg(model.NDT1, "proj_height_1", by="proj_age_1")

#dist_mun + dist_dam + dist_nat + dist_mine + bclcs_level_5_2 + dist_mun:bclcs_level_5_2 + dist_nat:bclcs_level_5_2 + dist_mine:bclcs_level_5_2

visreg(model.NDT1, "dist_mun", by="bclcs_level_5_2", overlay=TRUE) #look into these extreme points
visreg(model.NDT1, "dist_dam")
visreg(model.NDT1, "dist_nat", by="bclcs_level_5_2", overlay=TRUE)
visreg(model.NDT1, "dist_mine")

visreg(model.NDT1, "bclcs_level_5_2", by="dist_nat")
visreg(model.NDT1, "bclcs_level_5_2", by="dist_mun")

```


We should repeat the above several times and take the mean of the coefficients.

```{r}
summary(model.NDT1)

#Create a new blank table and get AUC too
top_mod_table_NDT1_light_t_ALL <- data.frame (matrix (ncol = 34, nrow = 0))
colnames (top_mod_table_NDT1_light_t_ALL ) <- c ("CAUSE", "NDT", "TREED", "Model_terms", "intercept", "coef_climate_1", "coef_climate_2", "coef_vegtypeTB", "coef_vegtypeTC", "coef_vegtypeTM", "coef_proj_height_1", "coef_live_stand_volume_125", "coef_proj_age_1",  "coef_dist_mun", "coef_dist_dam", "coef_dist_nat", "coef_dist_mine", "coef_bclcs_level_5_2OP", "coef_bclcs_level_5_2SP", "coef_slope", "coef_aspect_cos", "coef_elevation", "coef_climate1:climate2 ", "coef_climate1:proj_height_1", "coef_climate1:proj_age_1", "coef_climate2:proj_age_1", "coef_proj_height_1:proj_age_1", "coef_dist_mun:bclcs_level_5_2OP", "coef_dist_mun:bclcs_level_5_2SP", "coef_dist_nat:bclcs_level_5_2OP", "coef_dist_nat:bclcs_level_5_2SP", "coef_dist_mine:bclcs_level_5_2OP", "coef_dist_mine:bclcs_level_5_2SP", "AUC")
```

Let's run it 500 times to get good mean values.

```{r}

for (g in 1:500){

prop<-0.75
# Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(NDT1_t_ignite$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- NDT1_t_ignite[ trainIndex,]
   Valid <- NDT1_t_ignite[-trainIndex,]
   
#Model   
model.NDT1<-glm(fire_pres ~ climate1 + climate2 + vegtype2 + proj_height_1 + live_stand_volume_125 + proj_age_1 + climate1:climate2 + climate1:proj_height_1 + climate1:proj_age_1  + climate2:proj_age_1  + proj_height_1:proj_age_1 + dist_mun + dist_dam + dist_nat + dist_mine + bclcs_level_5_2 + dist_mun:bclcs_level_5_2 + dist_nat:bclcs_level_5_2 + dist_mine:bclcs_level_5_2 + slope + aspect_cos + elevation, family = binomial, data = dat1) 

mod.valid <- predict.glm(model.NDT1, newdata=Valid, type="response")
   roc_obj <- roc(Valid[,"fire_pres"], mod.valid)
   mod.auc <- auc(roc_obj)

# create model table (only do this once) and add the relevant data
top_mod_table_NDT1_light_t <- data.frame (matrix (ncol = 34, nrow = 0))
colnames (top_mod_table_NDT1_light_t ) <- c ("CAUSE", "NDT", "TREED", "Model_terms", "intercept", "coef_climate_1", "coef_climate_2", "coef_vegtypeTB", "coef_vegtypeTC", "coef_vegtypeTM", "coef_proj_height_1", "coef_live_stand_volume_125", "coef_proj_age_1",  "coef_dist_mun", "coef_dist_dam", "coef_dist_nat", "coef_dist_mine", "coef_bclcs_level_5_2OP", "coef_bclcs_level_5_2SP", "coef_slope", "coef_aspect_cos", "coef_elevation", "coef_climate1:climate2 ", "coef_climate1:proj_height_1", "coef_climate1:proj_age_1", "coef_climate2:proj_age_1", "coef_proj_height_1:proj_age_1", "coef_dist_mun:bclcs_level_5_2OP", "coef_dist_mun:bclcs_level_5_2SP", "coef_dist_nat:bclcs_level_5_2OP", "coef_dist_nat:bclcs_level_5_2SP", "coef_dist_mine:bclcs_level_5_2OP", "coef_dist_mine:bclcs_level_5_2SP", "AUC")

##Add data for NDT1
top_mod_table_NDT1_light_t[1,1]<-"lightning"
top_mod_table_NDT1_light_t[1,2]<-"NDT1"
top_mod_table_NDT1_light_t[1,3]<-"Y"
top_mod_table_NDT1_light_t[1,4]<-"fire_pres ~ climate1 + climate2 + vegtype2 + proj_height_1 + live_stand_volume_125 + proj_age_1 + climate1:climate2 + climate1:proj_height_1 + climate1:proj_age_1  + climate2:proj_age_1  + proj_height_1:proj_age_1 + dist_mun + dist_dam + dist_nat + dist_mine + bclcs_level_5_2 + dist_mun:bclcs_level_5_2 + dist_nat:bclcs_level_5_2 + dist_mine:bclcs_level_5_2 + slope + aspect_cos + elevation" 
top_mod_table_NDT1_light_t[1,5]<- coef(model.NDT1)[1] #Intercept
top_mod_table_NDT1_light_t[1,6]<- coef(model.NDT1)[2] #Climate variable 1
top_mod_table_NDT1_light_t[1,7]<- coef(model.NDT1)[3] #Climate variable 2
top_mod_table_NDT1_light_t[1,8]<- coef(model.NDT1)[4] #I
top_mod_table_NDT1_light_t[1,9]<- coef(model.NDT1)[5] #co
top_mod_table_NDT1_light_t[1,10]<- coef(model.NDT1)[6] #coe
top_mod_table_NDT1_light_t[1,11]<- coef(model.NDT1)[7] #c
top_mod_table_NDT1_light_t[1,12]<- coef(model.NDT1)[8] #
top_mod_table_NDT1_light_t[1,13]<- coef(model.NDT1)[9] #
top_mod_table_NDT1_light_t[1,14]<- coef(model.NDT1)[10] #pr
top_mod_table_NDT1_light_t[1,15]<- coef(model.NDT1)[11] #coeffic
top_mod_table_NDT1_light_t[1,16]<- coef(model.NDT1)[12] #coefficien
top_mod_table_NDT1_light_t[1,17]<- coef(model.NDT1)[13] #coefficien
top_mod_table_NDT1_light_t[1,18]<- coef(model.NDT1)[14] #coefficient 
top_mod_table_NDT1_light_t[1,19]<- coef(model.NDT1)[15] #coe
top_mod_table_NDT1_light_t[1,20]<- coef(model.NDT1)[16] #co
top_mod_table_NDT1_light_t[1,21]<- coef(model.NDT1)[17] #coe
top_mod_table_NDT1_light_t[1,22]<- coef(model.NDT1)[18] #c
top_mod_table_NDT1_light_t[1,23]<- coef(model.NDT1)[19] #co
top_mod_table_NDT1_light_t[1,24]<- coef(model.NDT1)[20] #
top_mod_table_NDT1_light_t[1,25]<- coef(model.NDT1)[21] #
top_mod_table_NDT1_light_t[1,26]<- coef(model.NDT1)[22] #co
top_mod_table_NDT1_light_t[1,27]<- coef(model.NDT1)[23] #c
top_mod_table_NDT1_light_t[1,28]<- coef(model.NDT1)[24] #c
top_mod_table_NDT1_light_t[1,29]<- coef(model.NDT1)[25] #co
top_mod_table_NDT1_light_t[1,30]<- coef(model.NDT1)[26] #
top_mod_table_NDT1_light_t[1,31]<- coef(model.NDT1)[27] #co
top_mod_table_NDT1_light_t[1,32]<- coef(model.NDT1)[28] #coe
top_mod_table_NDT1_light_t[1,33]<- coef(model.NDT1)[29] #c
top_mod_table_NDT1_light_t[1,34]<- mod.auc

top_mod_table_NDT1_light_t_ALL<-rbind(top_mod_table_NDT1_light_t_ALL, top_mod_table_NDT1_light_t)

}

```

Check.
```{r}
head(top_mod_table_NDT1_light_t_ALL)

```

#Save coefficient table

```{r}
write.csv(top_mod_table_NDT1_light_t_ALL, file="D:\\Fire\\fire_data\\raw_data\\top_mod_table_NDT1_light_t_ALL.csv")
```

Get mean values.

```{r}
names(top_mod_table_NDT1_light_t_ALL)

top_mod_table_NDT1_light_t_Means<-top_mod_table_NDT1_light_t_ALL %>% summarise_each(funs( mean( .,na.rm = TRUE)))
top_mod_table_NDT1_light_t_Means

top_mod_table_NDT1_light_t_Means[1,1]<-"lightning"
top_mod_table_NDT1_light_t_Means[1,2]<-"NDT1"
top_mod_table_NDT1_light_t_Means[1,3]<-"Treed"
top_mod_table_NDT1_light_t_Means[1,4]<- "fire_pres ~ climate1 + climate2 + vegtype2 + proj_height_1 + live_stand_volume_125 + proj_age_1 + climate1:climate2 + climate1:proj_height_1 + climate1:proj_age_1  + climate2:proj_age_1  + proj_height_1:proj_age_1 + dist_mun + dist_dam + dist_nat + dist_mine + bclcs_level_5_2 + dist_mun:bclcs_level_5_2 + dist_nat:bclcs_level_5_2 + dist_mine:bclcs_level_5_2 + slope + aspect_cos + elevation" 
top_mod_table_NDT1_light_t_Means
```

Save table.

```{r}
write.csv(top_mod_table_NDT1_light_t_Means, file="D:\\Fire\\fire_data\\raw_data\\top_mod_table_NDT1_light_t_Means.csv")
```

Standard deviation.

```{r}
top_mod_table_NDT1_light_t_SD<-top_mod_table_NDT1_light_t_ALL %>% summarise_each(funs( sd( .,na.rm = TRUE)))
top_mod_table_NDT1_light_t_SD

top_mod_table_NDT1_light_t_SD[1,1]<-"lightning"
top_mod_table_NDT1_light_t_SD[1,2]<-"NDT1"
top_mod_table_NDT1_light_t_SD[1,3]<-"Treed"
top_mod_table_NDT1_light_t_SD[1,4]<-"fire_pres ~ climate1 + climate2 + vegtype2 + proj_height_1 + live_stand_volume_125 + proj_age_1 + climate1:climate2 + climate1:proj_height_1 + climate1:proj_age_1  + climate2:proj_age_1  + proj_height_1:proj_age_1 + dist_mun + dist_dam + dist_nat + dist_mine + bclcs_level_5_2 + dist_mun:bclcs_level_5_2 + dist_nat:bclcs_level_5_2 + dist_mine:bclcs_level_5_2 + slope + aspect_cos + elevation" 
top_mod_table_NDT1_light_t_SD
```

Save sd coefficient table.

```{r}
write.csv(top_mod_table_NDT1_light_t_SD, file="D:\\Fire\\fire_data\\raw_data\\top_mod_table_NDT1_light_t_SD.csv")
```

