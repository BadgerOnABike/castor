---
title: "15_Fire_Spread_Polygons_Data_NDT1"
author: "Cora Skaien"
date: "16/10/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

#Load relevant libraries
library(sf)
library(tidyverse)
library(ggplot2)
library (ggcorrplot)
library (RPostgreSQL)
library (rpostgis)
library (dplyr)
library (lme4)
library (arm)
library(ggpubr)
library(mgcv)
library(nlme)
library(purrr)
library(tidyr)
library(caret)
library(pROC)
library(keyring)
library(ggcorrplot) 
library (kableExtra)
library (data.table)
library (DBI)
library (RPostgreSQL)
library (dplyr)
library (ggplot2)
library (here)
library(AICcmodavg)
library(caret)
library(pROC)
library(rje)
library(base)
library(car)

source(here::here("R/functions/R_Postgres.R"))
```

<!--
Copyright 2021 Province of British Columbia

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and limitations under the License.
-->

#=================================
#  Script Name: 15_Fire_Spread_Polygons_Data_NDT1.R
#  Script Version: 1.0
#  Script Purpose: model selection for factors that dictate spread into cells (part of spread) by NDT.
#  Script Author: Cora Skaien, Ecological Modeling Specialist, Forest Analysis and Inventory Branch, B.C. Ministry of Forests, Lands, and Natural Resource Operations.
#=================================

Load in the prepped data.

```{r}
fire_spread_veg_data_df<-read.csv(file="D:\\Fire\\fire_data\\raw_data\\Historical_Fire_Perimiter_polygons\\fire_spread_veg_data_.csv")

head(fire_spread_veg_data_df)

```

Check data categories.

```{r}
table(fire_spread_veg_data_df$bclcs_level_2)
fire_spread_veg_data_df$proj_age_1 #Lots of NAs
fire_spread_veg_data_df$proj_height_1
fire_spread_veg_data_df$live_stand_volume_125

names(fire_spread_veg_data_df)
table

str(fire_spread_veg_data_df$spread)
table(fire_spread_veg_data_df$spread)

fire_spread_veg_data_df$spread<-as.numeric(fire_spread_veg_data_df$spread)

table(fire_spread_veg_data_df$fire_cs) #must decide: do we separate into different categories? For this, I suggest not necessary.
```

################ PART 1: Lightning Caused Fires ################

We will perform multiple loops for different subsets of variables for model selection, and then use these results to inform us on best models moving forward. The variables that will be assessed include:

1. Projected Height (proj_height_1) #Note, there may be some NAs and we may not be able to use this
2. projected age (proj_age_1) #Note, there may be some NAs and we may not be able to use this
3. live_stand_volume_125 #Note, there may be some NAs and we may not be able to use this
4. vegtype2
5. slope
6. aspect_cos (cos)
7. elev
8. Various distance to infrastructure variables (dist_mun, dist_dam, dist_nat, dist_pow, dist_mine) - no interactions
9. Land use (bclcs_level_5_2)
10. roads_km (road density, which may relate to ability to fight fires)
11. bclcs_level_2 (Treed or not treed)

First we will create the variable lists that contain all of our variables of interest.

```{r}
##Create variable lists to be used in the model loop.
variables_all<-c(proj_height_1 = "proj_height_1", proj_age_1 = "proj_age_1", live_stand_volume_125 = "live_stand_volume_125", slope = "slope", aspect_cos = "aspect_cos", elev ="elev", vegtype2 = "vegtype2", bclcs_level_5_2 = "bclcs_level_5_2", dist_mun = "dist_mun", dist_dam ="dist_dam", dist_nat = "dist_nat", dist_pow = "dist_pow", dist_mine = "dist_mine", roads_km="roads_km", bclcs_level_2 = "bclcs_level_2") 

vars.oth<-c("proj_height_1", "proj_age_1", "live_stand_volume_125") #Note, there may be some NAs and we may not be able to use this
vars.topo<-c("slope", "aspect_cos", "elev")
vars.infra<-c("dist_mun", "dist_dam", "dist_nat", "dist_pow", "dist_mine", "roads_km", "bclcs_level_5_2")
vars.veg<-c("vegtype2", "bclcs_level_2") #Too few; will add in final model selection

```

Now, we will generate two-way interactions for each of these lists. 

```{r}

#get the names of all possible two-way interactions
twoway.intsT <- NULL
for (i in 1:(length(vars.topo)-1)) {
  for (j in (i+1):length(vars.topo)) {
     twoway.intsT <- cbind(twoway.intsT, paste(vars.topo[i], vars.topo[j], sep=":"))
  }
}
twoway.intsT
length(twoway.intsT) #3

#complete list of models using non-climate vars (topo)
mods.me.tmp <- powerSet(vars.topo) 
#add climate vars to all of the above
mods.meT <- list()
for (i in 1: length(mods.me.tmp)) {
   mods.meT[[i]] <- c(mods.me.tmp[[i]])
}

mods.meT
mods.meT<-mods.meT[-1]

#complete list of two-way interactions
mods.twowayT <- powerSet(twoway.intsT)
length(mods.twowayT) #8
mods.twowayT
mods.twowayT<-mods.twowayT[-1]

#Finding models in mods.me that accommodate/allow interaction terms in each mods.twoway to be added

mods.interT <- list()
counter <- 0
for (i in 1: length(mods.twowayT)) {
   s1 <- unique(unlist( strsplit(mods.twowayT[[i]], split=':', fixed=TRUE) ) )
   for (j in 1: length(mods.meT)) {
      if (all(s1 %in% mods.meT[[j]])==TRUE) {
        counter <- counter + 1
        both <-  c(mods.meT[[j]], mods.twowayT[[i]])
        mods.interT[[counter]] <- both
      }
   }
}

length(mods.interT) #10
#mods.interT


####3.VRI data

#complete list of models using VRI - no interactions
mods.me.tmp <- powerSet(vars.oth) 
#add climate vars to all of the above
mods.me.oth <- list()
for (i in 1: length(mods.me.tmp)) {
   mods.me.oth[[i]] <- c(mods.me.tmp[[i]])
}

mods.me.oth
mods.me.oth<-mods.me.oth[-1]



#complete list of two-way interactions
mods.twowayO <- powerSet(twoway.intsT)
length(mods.twowayO) #8
mods.twowayO
mods.twowayO<-mods.twowayO[-1]

#Finding models in mods.me that accommodate/allow interaction terms in each mods.twoway to be added

mods.interO <- list()
counter <- 0
for (i in 1: length(mods.twowayO)) {
   s1 <- unique(unlist( strsplit(mods.twowayO[[i]], split=':', fixed=TRUE) ) )
   for (j in 1: length(mods.meT)) {
      if (all(s1 %in% mods.meT[[j]])==TRUE) {
        counter <- counter + 1
        both <-  c(mods.meT[[j]], mods.twowayO[[i]])
        mods.interO[[counter]] <- both
      }
   }
}

length(mods.interO) #10
#mods.interO



#########4. Now for distance to infrastructure data, get all possible two-way interactions

#get the names of all possible two-way interactions
twoway.intsI <- NULL
for (i in 1:(length(vars.infra)-1)) {
  for (j in (i+1):length(vars.infra)) {
     twoway.intsI <- cbind(twoway.intsI, paste(vars.infra[i], vars.infra[j], sep=":"))
  }
}
twoway.intsI
length(twoway.intsI) #21

#Subset to get only the interactions of interest
twoway.intsIb<-twoway.intsI[c(5,6,10,11,14,15,17,18,19,20,21)]

#complete list of models using non-climate vars (infra)
mods.me.tmp <- powerSet(vars.infra) 
#add climate vars to all of the above
mods.meI <- list()
for (i in 1: length(mods.me.tmp)) {
   mods.meI[[i]] <- c(mods.me.tmp[[i]])
}

mods.meI
mods.meI<-mods.meI[-1]

#complete list of two-way interactions
mods.twowayI <- powerSet(twoway.intsIb)
length(mods.twowayI) #2048
#mods.twowayI

#Finding models in mods.me that accommodate/allow interaction terms in each mods.twoway to be added

mods.interI <- list()
counter <- 0
for (i in 1: length(mods.twowayI)) {
   s1 <- unique(unlist( strsplit(mods.twowayI[[i]], split=':', fixed=TRUE) ) )
   for (j in 1: length(mods.meI)) {
      if (all(s1 %in% mods.meI[[j]])==TRUE) {
        counter <- counter + 1
        both <-  c(mods.meI[[j]], mods.twowayI[[i]])
        mods.interI[[counter]] <- both
      }
   }
}

length(mods.interI) #6767
head(mods.interI)
#mods.interI


#the list of all possible model RHSs. 
all.poss.mods.VRI<-c(1, mods.interO)
all.poss.mods.VRI

all.poss.mods.topo<-c(1, mods.interT)
all.poss.mods.topo

all.poss.mods.infra<-c(1, mods.interI) 
all.poss.mods.infra
```

############### Part 1 of 4 Model Series: Lightning Caused Fires, Trees ##########

Because of the large number of models with all variables included, we will test the separate combos first. Then we will test the top models together in additional combinations, with determining best AIC model from there. 

Select NDT: NDT1

```{r}
zones1<-c("NDT1") #Do one zone at a time
prop<-0.75

########### 1. VRI ############
#Create empty table
table.glm.VRI.simple <- data.frame (matrix (ncol = 5, nrow = 0))
colnames (table.glm.VRI.simple) <- c ("model", "edf", "aic", "auc.valid", "NDT")

####
for (g in 1:100){

for (h in 1:length(zones1)) {
  dat2<- fire_spread_veg_data_df %>% dplyr::filter(ntrldstrbn ==zones1[h])
  
for (i in 1: length(zones1)){
  print(paste((all.poss.mods.VRI[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(spread, spread, variables_all[i])
  model_dat<- dat2 %>% dplyr::select(spread, !!variables_all)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$spread, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="spread") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.aic, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.VRI, big.mod, df.train=dat1, df.test=Valid)

#terms in each model
x1.1 <- unlist(sapply(mods.fit, '[', 1))
x1.1
#Aic for models
x3.1 <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3.1
#auc from validation data
x4.1 <- unlist(sapply(mods.fit, '[', 4))
x4.1
#combining all as df
tab.sum.VRI <- cbind.data.frame(model=x1.1, edf=x3.1[,1], aic=x3.1[,2], auc.valid=x4.1)
tab.sum.VRI$NDT<-c("NDT1")
tab.sum.VRI 

table.glm.VRI.simple<-rbind(table.glm.VRI.simple, tab.sum.VRI)

}
}
}
```

Now that we have run the model 100 times, we want the average AIC and AUC for each variable combination.

```{r}
head(table.glm.VRI.simple)
table(table.glm.VRI.simple$model) # 100 per model

AIC_lightning_NDT1_spread_treed_VRI<-table.glm.VRI.simple

AIC_lightning_NDT1_spread_treed_summary_VRI<- AIC_lightning_NDT1_spread_treed_VRI %>%
  group_by(model) %>%
  summarise(meanAIC=mean(aic),
            meanAUC=mean(auc.valid),
            sdAUC=sd(auc.valid),
            )

AIC_lightning_NDT1_spread_treed_summary_VRI2<- AIC_lightning_NDT1_spread_treed_summary_VRI %>%
  mutate(deltaAIC=meanAIC-min(meanAIC))

head(AIC_lightning_NDT1_spread_treed_summary_VRI2)
```

#Now repeat for topography

```{r}
########### 2. topo ############
#Create empty table
table.glm.topo.simple <- data.frame (matrix (ncol = 5, nrow = 0))
colnames (table.glm.topo.simple) <- c ("model", "edf", "aic", "auc.valid", "NDT")

#
for (g in 1:100){

for (h in 1:length(zones1)) {
  dat2<- fire_spread_veg_data_df %>% dplyr::filter(ntrldstrbn ==zones1[h])

#for (i in 1: length(all.poss.mods.topo)){
#  print(paste((all.poss.mods.topo[i]), (zones1[h]), sep=" "))
  
for (i in 1: length(zones1)){
  print(paste((all.poss.mods.topo[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(spread, spread, variables_all[i])
  model_dat<- dat2 %>% dplyr::select(spread, spread, !!variables_all)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$spread, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="spread") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.aic, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.topo, big.mod, df.train=dat1, df.test=Valid)

#terms in each model
x1.1 <- unlist(sapply(mods.fit, '[', 1))
x1.1
#Aic for models
x3.1 <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3.1
#auc from validation data
x4.1 <- unlist(sapply(mods.fit, '[', 4))
x4.1
#combining all as df
tab.sum.topo <- cbind.data.frame(model=x1.1, edf=x3.1[,1], aic=x3.1[,2], auc.valid=x4.1)
tab.sum.topo$NDT<-c("NDT1")
tab.sum.topo 

table.glm.topo.simple<-rbind(table.glm.topo.simple, tab.sum.topo)

}
}
}
```

Now that we have run the model 100 times, we want the average AIC and AUC for each variable combination.

```{r}
head(table.glm.topo.simple)
table(table.glm.topo.simple$model) # 100 per model

AIC_lightning_NDT1_spread_treed_topo<-table.glm.topo.simple

AIC_lightning_NDT1_spread_treed_summary_topo<- AIC_lightning_NDT1_spread_treed_topo %>%
  group_by(model) %>%
  summarise(meanAIC=mean(aic),
            meanAUC=mean(auc.valid),
            sdAUC=sd(auc.valid),
            )

AIC_lightning_NDT1_spread_treed_summary_topo2<- AIC_lightning_NDT1_spread_treed_summary_topo %>%
  mutate(deltaAIC=meanAIC-min(meanAIC))

head(AIC_lightning_NDT1_spread_treed_summary_topo2)
```

#Now repeat for infrastructure
Running 100 times takes up too much space, so need to run fewer times and combine.

Cannot run even one full run because too many models. Need to break up into smaller chunks if want to run all of these models. Otherwise, consider reducing models in this set. If run in chunks, need to subset the data into training and validation separately from the loop so that the entire set of variables are with the same data subset per full run for comparing AIC values.

```{r}
########### 3. Distance to Infrastructure ############
#Create empty table
table.glm.infra.simple <- data.frame (matrix (ncol = 5, nrow = 0))
colnames (table.glm.infra.simple) <- c ("model", "edf", "aic", "auc.valid", "NDT")

#
for (g in 1:1){

for (h in 1:length(zones1)) {
  dat2<- fire_spread_veg_data_df %>% dplyr::filter(ntrldstrbn ==zones1[h])

#for (i in 1: length(all.poss.mods.infra)){
#  print(paste((all.poss.mods.infra[i]), (zones1[h]), sep=" "))
  
for (i in 1: length(zones1)){
  print(paste((all.poss.mods.infra[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(spread, spread, variables_all[i])
  model_dat<- dat2 %>% dplyr::select(spread, spread, !!variables_all)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$spread, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="spread") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.aic, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.infra, big.mod, df.train=dat1, df.test=Valid)

#terms in each model
x1.1 <- unlist(sapply(mods.fit, '[', 1))
x1.1
#Aic for models
x3.1 <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3.1
#auc from validation data
x4.1 <- unlist(sapply(mods.fit, '[', 4))
x4.1
#combining all as df
tab.sum.infra <- cbind.data.frame(model=x1.1, edf=x3.1[,1], aic=x3.1[,2], auc.valid=x4.1)
tab.sum.infra$NDT<-c("NDT1")
tab.sum.infra 

table.glm.infra.simple<-rbind(table.glm.infra.simple, tab.sum.infra)

}
}
}
```

Now that we have run the model 100 times, we want the average AIC and AUC for each variable combination.

```{r}
head(table.glm.infra.simple)
table(table.glm.infra.simple$model) # 100 per model

AIC_lightning_NDT1_spread_treed_infra<-table.glm.infra.simple

AIC_lightning_NDT1_spread_treed_summary_infra<- AIC_lightning_NDT1_spread_treed_infra %>%
  group_by(model) %>%
  summarise(meanAIC=mean(aic),
            meanAUC=mean(auc.valid),
            sdAUC=sd(auc.valid),
            )

AIC_lightning_NDT1_spread_treed_summary_infra2<- AIC_lightning_NDT1_spread_treed_summary_infra %>%
  mutate(deltaAIC=meanAIC-min(meanAIC))

head(AIC_lightning_NDT1_spread_treed_summary_infra2)

```

#Now combine the datatables and save to computer

```{r}
NDT1_l_spread_models_treed<-rbind(AIC_lightning_NDT1_spread_treed_summary_VRI2, AIC_lightning_NDT1_spread_treed_summary_topo2, AIC_lightning_NDT1_spread_treed_summary_infra2)
NDT1_l_spread_models_treed
NDT1_l_spread_models_treed$NDT<-"NDT1"

write.csv(NDT1_l_spread_models_treed, file="D:\\Fire\\fire_data\\raw_data\\NDT1_lightning_spread_models_treed_polygon.csv")
```

################################ STAGE TWO ########################

#STAGE TWO: PUT TOGETHER MORE VARIABLES
Now choose the top variables and create final model. The below code will need to be updated manually, depending on what the results of the above analyses are. From the top models, we will re-create two-way interactions for the variables selected from each model, plus the other variables listed as needed to be included. We will assess each set to ensure only interactions that make sense are investigated ultimately, given that sample sizes will be an issues.

Top Models:
1. proj_height_1 + proj_age_1 + live_stand_volume_125
2. slope + aspect_cos + elev + slope:aspect_cos + slope:elev
3.
4. vegtype2 + bclcs_level_2 + vegtype2:bclcs_level_2
