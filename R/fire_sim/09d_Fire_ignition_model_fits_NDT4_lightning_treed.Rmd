---
title: "09d_fire_ignition_model_selection_NDT4_lightning_treed"
author: "Cora Skaien"
date: "16/09/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library (data.table)
library (DBI)
library (RPostgreSQL)
library (dplyr)
library (ggplot2)
library (here)
library(ggpubr)
library(arm)
library(tidyr)
library(AICcmodavg)
library(keyring)
library(caret)
library(pROC)
library(rje)

source(here::here("R/functions/R_Postgres.R"))
```

#Load data back in if starting from here
Note: depending where your geometry column was located when saved as a csv (and turned into a dataframe), you may need to manually correct column headings on the csv file before loading back in. This has been performed for the below files.

```{r}
dat_lightning_t<-read.csv(file="D:\\Fire\\fire_data\\raw_data\\ClimateBC_Data\\data_lightning_trees_NDT.csv")
head(dat_lightning_t)

dat_lightning_nt<-read.csv(file="D:\\Fire\\fire_data\\raw_data\\ClimateBC_Data\\data_lightning_notrees_NDT.csv")
head(dat_lightning_nt)

dat_person_t<-read.csv(file="D:\\Fire\\fire_data\\raw_data\\ClimateBC_Data\\data_person_trees_NDT.csv")
head(dat_person_t)

dat_person_nt<-read.csv(file="D:\\Fire\\fire_data\\raw_data\\ClimateBC_Data\\data_person_notrees_NDT.csv")
head(dat_person_nt)
```

######################### ANALYSES: TREED, LIGHTNING #########################

Now, we will make a loop that does something very similar to our last loop, but with the selected climate variable plus other variables of interest. For lightning caused fires with trees, the variables of interest include:

1. Climate variable(s)
2. Projected Height (proj_height_1)
3. projected age (proj_age_1)  
4. live_stand_volume_125
5. vegtype2 (with additional categories)
6. slope
7. aspect (cos)
8. elevation
9. Various distance to infrastructure variables (dist_mun, dist_dam, dist_nat, dist_pow, dist_mine, dist_any) - no interactions
10. Some measure of death or mountain pine beetle damage -- TBD

Variables to be added after initial model selection for next round model selection:
1. bclcs_level_5_2 (land use) (to be added to final investigated model)

Interactions of interest: two-way interactions between climate (1) and vegtype (6); two-way interactions between topography measures (7-9); interactions between VRI variables.

This will be done separately for trees and non-treed areas. 

Consider modelling by landuse type spread_data_lightning$bclcs_level_5.

First, let's do this for treed areas (with the lightning-caused fires dataset).

##We will do each loop separately for each NDT zone given the large number of possible models for each zone.

First we will create the variable lists that contain all of our variables of interest.

```{r}
##Create variable lists to be used in the model loop.
variables_all<-c(climate1 = "climate1", climate2 = "climate2", proj_height_1 = "proj_height_1", proj_age_1 = "proj_age_1", live_stand_volume_125 = "live_stand_volume_125", slope = "slope", aspect = "aspect", elevation ="elevation", vegtype2 = "vegtype2", dist_mun = "dist_mun", dist_dam = "dist_dam", dist_nat = "dist_nat", dist_pow = "dist_pow", dist_mine = "dist_mine", dist_any = "dist_any") #heatload="heatload",

variables_all_c1<-c(climate1 = "climate1", proj_height_1 = "proj_height_1", proj_age_1 = "proj_age_1", live_stand_volume_125 = "live_stand_volume_125", slope = "slope", aspect = "aspect", elevation ="elevation", vegtype2 = "vegtype2", dist_mun = "dist_mun", dist_dam = "dist_dam", dist_nat = "dist_nat", dist_pow = "dist_pow", dist_mine = "dist_mine", dist_any = "dist_any") #heatload="heatload",

vars.clim<-c("climate1")
vars.clim.vegtype<-c("climate1", "vegtype2")
vars.clim.vegtype2<-c("climate1", "climate2","vegtype2")
vars.clim.vegtype2b<-c("climate1", "climate2")

vars.oth<-c("proj_height_1", "proj_age_1", "live_stand_volume_125") 
vars.topo<-c("slope", "aspect", "elevation")
vars.heatload<-c("heatload")
vars.infra<-c("dist_mun", "dist_dam", "dist_nat", "dist_pow", "dist_mine", "dist_any")


##Create interaction for climate and vegtype
inputs.me <- c(vars.clim.vegtype)
inputs.me2 <- c(vars.clim.vegtype2)
inputs.me2b <- c(vars.clim.vegtype2b)
```

Now, we will generate two-way interactions for each of these lists. 

```{r}

#####1a. For those with one climate variable
#get the names of all possible two-way interactions for climate variable(s) and vegtype.
twoway.ints <- NULL
for (i in 1:(length(inputs.me)-1)) {
  for (j in (i+1):length(inputs.me)) {
     twoway.ints <- cbind(twoway.ints, paste(inputs.me[i], inputs.me[j], sep=":"))
  }
}
twoway.ints
length(twoway.ints)

#
#Create function to determine Powerset for any vector of variable names
## or use rje package
#powerSet <- function(x) {
#   z.list <- NULL
#   for(i in 1:length(x)) {
#      z.list <- append(z.list, combn(x, m=i, simplify=F))
#   }    
#   return(z.list)
#}


#Get variables on own
#complete list of models using non-climate vars
mods.me.tmp <- powerSet(vars.clim.vegtype) 
#add climate vars to all of the above
mods.me.climate <- list()
for (i in 1: length(mods.me.tmp)) {
   mods.me.climate[[i]] <- c(mods.me.tmp[[i]])
}

mods.me.climate


#####1b. For those with two climate variables
#get the names of all possible two-way interactions for climate variable(s) and vegtype.
twoway.ints2 <- NULL
for (i in 1:(length(inputs.me2)-1)) {
  for (j in (i+1):length(inputs.me2)) {
     twoway.ints2 <- cbind(twoway.ints2, paste(inputs.me2[i], inputs.me2[j], sep=":"))
  }
}
twoway.ints2
length(twoway.ints2)

#Get variables on own
#complete list of models using non-climate vars
mods.me.tmp <- powerSet(vars.clim.vegtype2) 
#add climate vars to all of the above
mods.me.climate2 <- list()
for (i in 1: length(mods.me.tmp)) {
   mods.me.climate2[[i]] <- c(mods.me.tmp[[i]])
}

mods.me.climate2

#complete list of two-way interactions
mods.twoway2 <- powerSet(twoway.ints2)
length(mods.twoway2) #7
mods.twoway2

#Finding models in mods.me that accommodate/allow interaction terms in each mods.twoway to be added
mods.inter2 <- list()
counter <- 0
for (i in 1: length(mods.twoway2)) {
   s1 <- unique(unlist( strsplit(mods.twoway2[[i]], split=':', fixed=TRUE) ) )
   for (j in 1: length(mods.me.climate2)) {
      if (all(s1 %in% mods.me.climate2[[j]])==TRUE) {
        counter <- counter + 1
        both <-  c(mods.me.climate2[[j]], mods.twoway2[[i]])
        mods.inter2[[counter]] <- both
      }
   }
}

length(mods.inter2)
mods.inter2


####1c. Two variables, no variation in vegtype
#get the names of all possible two-way interactions for climate variable(s) and vegtype.
twoway.ints2b <- NULL
for (i in 1:(length(inputs.me2b)-1)) {
  for (j in (i+1):length(inputs.me2b)) {
     twoway.ints2b <- cbind(twoway.ints2b, paste(inputs.me2b[i], inputs.me2b[j], sep=":"))
  }
}
twoway.ints2b
length(twoway.ints2b)

#Get variables on own
#complete list of models using non-climate vars
mods.me.tmp <- powerSet(vars.clim.vegtype2b) 
#add climate vars to all of the above
mods.me.climate2b <- list()
for (i in 1: length(mods.me.tmp)) {
   mods.me.climate2b[[i]] <- c(mods.me.tmp[[i]])
}

mods.me.climate2b

#complete list of two-way interactions
mods.twoway2b <- powerSet(twoway.ints2b)
length(mods.twoway2b) #7
mods.twoway2b

#Finding models in mods.me that accommodate/allow interaction terms in each mods.twoway to be added
mods.inter2b <- list()
counter <- 0
for (i in 1: length(mods.twoway2b)) {
   s1 <- unique(unlist( strsplit(mods.twoway2b[[i]], split=':', fixed=TRUE) ) )
   for (j in 1: length(mods.me.climate2b)) {
      if (all(s1 %in% mods.me.climate2b[[j]])==TRUE) {
        counter <- counter + 1
        both <-  c(mods.me.climate2b[[j]], mods.twoway2b[[i]])
        mods.inter2b[[counter]] <- both
      }
   }
}

length(mods.inter2b)
mods.inter2b


#########2. Now for topography data, get all possible two-way interactions

#get the names of all possible two-way interactions
twoway.intsT <- NULL
for (i in 1:(length(vars.topo)-1)) {
  for (j in (i+1):length(vars.topo)) {
     twoway.intsT <- cbind(twoway.intsT, paste(vars.topo[i], vars.topo[j], sep=":"))
  }
}
twoway.intsT
length(twoway.intsT)

#complete list of models using non-climate vars (topo)
mods.me.tmp <- powerSet(vars.topo) 
#add climate vars to all of the above
mods.meT <- list()
for (i in 1: length(mods.me.tmp)) {
   mods.meT[[i]] <- c(mods.me.tmp[[i]])
}

mods.meT

#complete list of two-way interactions
mods.twowayT <- powerSet(twoway.intsT)
length(mods.twowayT) #7
mods.twowayT

#Finding models in mods.me that accommodate/allow interaction terms in each mods.twoway to be added

mods.interT <- list()
counter <- 0
for (i in 1: length(mods.twowayT)) {
   s1 <- unique(unlist( strsplit(mods.twowayT[[i]], split=':', fixed=TRUE) ) )
   for (j in 1: length(mods.meT)) {
      if (all(s1 %in% mods.meT[[j]])==TRUE) {
        counter <- counter + 1
        both <-  c(mods.meT[[j]], mods.twowayT[[i]])
        mods.interT[[counter]] <- both
      }
   }
}

length(mods.interT)
mods.interT
mods.interTb<-c(mods.interT,vars.heatload)
mods.interTb

####3.For other VRI data, get without interactions

#complete list of models using VRI - no interactions
mods.me.tmp <- powerSet(vars.oth) 
#add climate vars to all of the above
mods.me.oth <- list()
for (i in 1: length(mods.me.tmp)) {
   mods.me.oth[[i]] <- c(mods.me.tmp[[i]])
}

mods.me.oth


#########4. Now for distance to infrastructure data, get all possible two-way interactions

#get the names of all possible two-way interactions
twoway.intsI <- NULL
for (i in 1:(length(vars.infra)-1)) {
  for (j in (i+1):length(vars.infra)) {
     twoway.intsI <- cbind(twoway.intsI, paste(vars.infra[i], vars.infra[j], sep=":"))
  }
}
twoway.intsI
length(twoway.intsI)

#complete list of models using non-climate vars (infra)
mods.me.tmp <- powerSet(vars.infra) 
#add climate vars to all of the above
mods.meI <- list()
for (i in 1: length(mods.me.tmp)) {
   mods.meI[[i]] <- c(mods.me.tmp[[i]])
}

mods.meI

#complete list of two-way interactions
mods.twowayI <- powerSet(twoway.intsI)
length(mods.twowayI) #32768
mods.twowayI

#Finding models in mods.me that accommodate/allow interaction terms in each mods.twoway to be added

mods.interI <- list()
counter <- 0
for (i in 1: length(mods.twowayI)) {
   s1 <- unique(unlist( strsplit(mods.twowayI[[i]], split=':', fixed=TRUE) ) )
   for (j in 1: length(mods.meI)) {
      if (all(s1 %in% mods.meI[[j]])==TRUE) {
        counter <- counter + 1
        both <-  c(mods.meI[[j]], mods.twowayI[[i]])
        mods.interI[[counter]] <- both
      }
   }
}

length(mods.interI)
mods.interI


#the list of all possible model RHSs. 
#all.poss.mods <- c(1, vars.clim, twoway.ints, mods.me.oth, mods.me2, mods.inter2)
#all.poss.mods

all.poss.mods.clim.vegtype<-c(1, mods.me.climate, twoway.ints)
all.poss.mods.clim.vegtype 
all.poss.mods.clim.vegtype<-all.poss.mods.clim.vegtype [-2] #Use this line only if there is an odd character(0) added to list
all.poss.mods.clim.vegtype2<-c(1, mods.inter2)
all.poss.mods.clim.vegtype2
all.poss.mods.clim.vegtype2<-all.poss.mods.clim.vegtype2[-2]
#all.poss.mods.clim.vegtype2<-all.poss.mods.clim.vegtype2[-9]
all.poss.mods.clim.vegtype2b<-c(1, mods.inter2b)
#all.poss.mods.clim.vegtype2b<-c(1, mods.me.climate2b, mods.inter2b)
all.poss.mods.clim.vegtype2b
all.poss.mods.clim.vegtype2b<-all.poss.mods.clim.vegtype2b[-2]
#all.poss.mods.clim.vegtype2b<-all.poss.mods.clim.vegtype2b[-5]

all.poss.mods.VRI<-c(1, mods.me.oth)
all.poss.mods.VRI
all.poss.mods.VRI<-all.poss.mods.VRI[-2]
#all.poss.mods.topo<-c(1, mods.meT, mods.interT)
all.poss.mods.topo<-c(1, mods.interT)
all.poss.mods.topo
#all.poss.mods.topo<-all.poss.mods.topo[-10]
all.poss.mods.topo<-all.poss.mods.topo[-2]
all.poss.mods.infra<-c(1, mods.meI) #I don't think we want interactions here actually...
#all.poss.mods.infra<-c(1, mods.meI, mods.interI)
all.poss.mods.infra<-all.poss.mods.infra[-2] #See if have future errors to see if need to remove

#If need to determine which ones are character(0), try this:
biglist <- list(list("A","B","C"), "foo", "", character(0), integer(0))
lapply(biglist, function(x) {length(x) == 0L} ) 


##Check and rid of any duplicated models
duplicated(all.poss.mods.clim.vegtype) #None duplicated
duplicated(all.poss.mods.clim.vegtype2)
duplicated(all.poss.mods.clim.vegtype2b)
duplicated(all.poss.mods.VRI)
duplicated(all.poss.mods.topo)
duplicated(all.poss.mods.infra)

```

THE ABOVE CODE CHUNKS WILL ALSO APPLY TO TREED, LIGHTNING NDT1-3 and 5.



############### Part 1 of 4 Model Series: Lightning Caused Fires, Trees ##########

Because of the large number of models with all variables included, we will test the climate and vegtype first, then the VRI variables, then the topography variables. Then we will test the top models together, with determining best AIC model from there. Or perhaps we will just combine the top models for each together, and eliminate models if the intercept was the best predictor.

Select NDT: NDT4 

```{r}
zones1<-c("NDT4") #Do one zone at a time

prop<-0.75

#Create empty table
table.glm.climate.simple <- data.frame (matrix (ncol = 5, nrow = 0))
colnames (table.glm.climate.simple) <- c ("model", "edf", "aic", "auc.valid", "NDT")

########### 1. Climate and vegtype ############
for (g in 1:100){

for (h in 1:length(zones1)) {
  dat2<- dat_lightning_t %>% dplyr::filter(ntrl_ds ==zones1[h])

#for (i in 1: length(all.poss.mods.clim.vegtype2)){
#  print(paste((all.poss.mods.clim.vegtype2[i]), (zones1[h]), sep=" "))
  
for (i in 1: length(zones1)){
  print(paste((all.poss.mods.clim.vegtype2[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, variables_all[i])
  model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, !!variables_all)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="fire_pres") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.aic, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.clim.vegtype2, big.mod, df.train=dat1, df.test=Valid)

#terms in each model
x1.1 <- unlist(sapply(mods.fit, '[', 1))
x1.1
#Aic for models
x3.1 <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3.1
#auc from validation data
x4.1 <- unlist(sapply(mods.fit, '[', 4))
x4.1
#combining all as df
tab.sum.climate <- cbind.data.frame(model=x1.1, edf=x3.1[,1], aic=x3.1[,2], auc.valid=x4.1)
tab.sum.climate$NDT<-c("NDT4")
tab.sum.climate 

table.glm.climate.simple<-rbind(table.glm.climate.simple, tab.sum.climate)

}
}
}


```

Now that we have run the model 100 times, we want the average AIC and AUC for each variable combination.

```{r}
head(table.glm.climate.simple)
table(table.glm.climate.simple$model) # 100 per model

AIC_lightning_NDT4_treed_climate<-table.glm.climate.simple

AIC_lightning_NDT4_treed_summary_climate<- AIC_lightning_NDT4_treed_climate %>%
  group_by(model) %>%
  summarise(meanAIC=mean(aic),
            meanAUC=mean(auc.valid),
            sdAUC=sd(auc.valid),
            )

AIC_lightning_NDT4_treed_summary_climate2<- AIC_lightning_NDT4_treed_summary_climate %>%
  mutate(deltaAIC=meanAIC-min(meanAIC))

head(AIC_lightning_NDT4_treed_summary_climate2)
```

#Now repeat for VRI data

```{r}
########### 2. VRI ############
#Create empty table
table.glm.VRI.simple <- data.frame (matrix (ncol = 5, nrow = 0))
colnames (table.glm.VRI.simple) <- c ("model", "edf", "aic", "auc.valid", "NDT")

####
for (g in 1:100){

for (h in 1:length(zones1)) {
  dat2<- dat_lightning_t %>% dplyr::filter(ntrl_ds ==zones1[h])

#for (i in 1: length(all.poss.mods.VRI)){
#  print(paste((all.poss.mods.VRI[i]), (zones1[h]), sep=" "))
  
for (i in 1: length(zones1)){
  print(paste((all.poss.mods.VRI[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, variables_all[i])
  model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, !!variables_all)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="fire_pres") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.aic, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.VRI, big.mod, df.train=dat1, df.test=Valid)

#terms in each model
x1.1 <- unlist(sapply(mods.fit, '[', 1))
x1.1
#Aic for models
x3.1 <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3.1
#auc from validation data
x4.1 <- unlist(sapply(mods.fit, '[', 4))
x4.1
#combining all as df
tab.sum.VRI <- cbind.data.frame(model=x1.1, edf=x3.1[,1], aic=x3.1[,2], auc.valid=x4.1)
tab.sum.VRI$NDT<-c("NDT4")
tab.sum.VRI 

table.glm.VRI.simple<-rbind(table.glm.VRI.simple, tab.sum.VRI)

}
}
}
```

Now that we have run the model 100 times, we want the average AIC and AUC for each variable combination.

```{r}
head(table.glm.VRI.simple)
table(table.glm.VRI.simple$model) # 100 per model

AIC_lightning_NDT4_treed_VRI<-table.glm.VRI.simple

AIC_lightning_NDT4_treed_summary_VRI<- AIC_lightning_NDT4_treed_VRI %>%
  group_by(model) %>%
  summarise(meanAIC=mean(aic),
            meanAUC=mean(auc.valid),
            sdAUC=sd(auc.valid),
            )

AIC_lightning_NDT4_treed_summary_VRI2<- AIC_lightning_NDT4_treed_summary_VRI %>%
  mutate(deltaAIC=meanAIC-min(meanAIC))

head(AIC_lightning_NDT4_treed_summary_VRI2)
```


#Now repeat for topography

```{r}
########### 3. topo ############
#Create empty table
table.glm.topo.simple <- data.frame (matrix (ncol = 5, nrow = 0))
colnames (table.glm.topo.simple) <- c ("model", "edf", "aic", "auc.valid", "NDT")

#
for (g in 1:100){

for (h in 1:length(zones1)) {
  dat2<- dat_lightning_t %>% dplyr::filter(ntrl_ds ==zones1[h])

#for (i in 1: length(all.poss.mods.topo)){
#  print(paste((all.poss.mods.topo[i]), (zones1[h]), sep=" "))
  
for (i in 1: length(zones1)){
  print(paste((all.poss.mods.topo[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, variables_all[i])
  model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, !!variables_all)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="fire_pres") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.aic, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.topo, big.mod, df.train=dat1, df.test=Valid)

#terms in each model
x1.1 <- unlist(sapply(mods.fit, '[', 1))
x1.1
#Aic for models
x3.1 <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3.1
#auc from validation data
x4.1 <- unlist(sapply(mods.fit, '[', 4))
x4.1
#combining all as df
tab.sum.topo <- cbind.data.frame(model=x1.1, edf=x3.1[,1], aic=x3.1[,2], auc.valid=x4.1)
tab.sum.topo$NDT<-c("NDT4")
tab.sum.topo 

table.glm.topo.simple<-rbind(table.glm.topo.simple, tab.sum.topo)

}
}
}
```

Now that we have run the model 100 times, we want the average AIC and AUC for each variable combination.

```{r}
head(table.glm.topo.simple)
table(table.glm.topo.simple$model) # 100 per model

AIC_lightning_NDT4_treed_topo<-table.glm.topo.simple

AIC_lightning_NDT4_treed_summary_topo<- AIC_lightning_NDT4_treed_topo %>%
  group_by(model) %>%
  summarise(meanAIC=mean(aic),
            meanAUC=mean(auc.valid),
            sdAUC=sd(auc.valid),
            )

AIC_lightning_NDT4_treed_summary_topo2<- AIC_lightning_NDT4_treed_summary_topo %>%
  mutate(deltaAIC=meanAIC-min(meanAIC))

head(AIC_lightning_NDT4_treed_summary_topo2)
```


#Now repeat for infrastructure

```{r}
########### 4. Distance to Infrastructure ############
#Create empty table
table.glm.infra.simple <- data.frame (matrix (ncol = 5, nrow = 0))
colnames (table.glm.infra.simple) <- c ("model", "edf", "aic", "auc.valid", "NDT")

#
for (g in 1:100){

for (h in 1:length(zones1)) {
  dat2<- dat_lightning_t %>% dplyr::filter(ntrl_ds ==zones1[h])

#for (i in 1: length(all.poss.mods.infra)){
#  print(paste((all.poss.mods.infra[i]), (zones1[h]), sep=" "))
  
for (i in 1: length(zones1)){
  print(paste((all.poss.mods.infra[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, variables_all[i])
  model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, !!variables_all)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="fire_pres") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.aic, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.infra, big.mod, df.train=dat1, df.test=Valid)

#terms in each model
x1.1 <- unlist(sapply(mods.fit, '[', 1))
x1.1
#Aic for models
x3.1 <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3.1
#auc from validation data
x4.1 <- unlist(sapply(mods.fit, '[', 4))
x4.1
#combining all as df
tab.sum.infra <- cbind.data.frame(model=x1.1, edf=x3.1[,1], aic=x3.1[,2], auc.valid=x4.1)
tab.sum.infra$NDT<-c("NDT4")
tab.sum.infra 

table.glm.infra.simple<-rbind(table.glm.infra.simple, tab.sum.infra)

}
}
}
```

Now that we have run the model 100 times, we want the average AIC and AUC for each variable combination.

```{r}
head(table.glm.infra.simple)
table(table.glm.infra.simple$model) # 100 per model

AIC_lightning_NDT4_treed_infra<-table.glm.infra.simple

AIC_lightning_NDT4_treed_summary_infra<- AIC_lightning_NDT4_treed_infra %>%
  group_by(model) %>%
  summarise(meanAIC=mean(aic),
            meanAUC=mean(auc.valid),
            sdAUC=sd(auc.valid),
            )

AIC_lightning_NDT4_treed_summary_infra2<- AIC_lightning_NDT4_treed_summary_infra %>%
  mutate(deltaAIC=meanAIC-min(meanAIC))

head(AIC_lightning_NDT4_treed_summary_infra2)

```

#Now combine the datatables and save to computer

```{r}
NDT4_l_models_treed<-rbind(AIC_lightning_NDT4_treed_summary_climate2, AIC_lightning_NDT4_treed_summary_VRI2, AIC_lightning_NDT4_treed_summary_topo2, AIC_lightning_NDT4_treed_summary_infra2)
NDT4_l_models_treed
NDT4_l_models_treed$NDT<-"NDT4"

write.csv(NDT4_l_models_treed, file="D:\\Fire\\fire_data\\raw_data\\NDT4_lightning_models_treed.csv")
```

################################ STAGE TWO ########################

#STAGE TWO: PUT TOGETHER MORE VARIABLES
Now choose the top variables and create final model. The below code will need to be updated manually, depending on what the results of the above analyses are. From the top models, we will re-create two-way interactions for the variables selected from each model, plus the other variables listed as needed to be included. We will assess each set to ensure only interactions that make sense are investigated ultimately, given that sample sizes will be an issues.

Top Models:
1. climate1 + climate2 + vegtype2 + climate1:climate2
2. proj_height_1 + live_stand_volume_125
3. slope + aspect + elevation + slope:aspect
4. dist_mun + dist_dam + dist_nat + dist_pow + dist_any. 

Additional Variabes:
1. bclcs_level_5_2 (land use) (to be added to final investigated model)

We want to include interactions between variables from within each list. This will make for many models.

```{r}
##Create variable lists to be used in the model loop.
variables_all_NDT4<-c(climate1 = "climate1", climate2 = "climate2", vegtype2 = "vegtype2", proj_height_1 = "proj_height_1", live_stand_volume_125 = "live_stand_volume_125", slope = "slope", aspect = "aspect", elevation ="elevation", dist_mun = "dist_mun", dist_dam = "dist_dam", dist_nat = "dist_nat", dist_pow = "dist_pow", dist_any = "dist_any", bclcs_level_5_2 = "bclcs_level_5_2")

variables_all_NDT4<-c(climate1 = "climate1", climate2 = "climate2", vegtype2 = "vegtype2", proj_height_1 = "proj_height_1", live_stand_volume_125 = "live_stand_volume_125", slope = "slope", aspect = "aspect", elevation ="elevation", dist_any = "dist_any", bclcs_level_5_2 = "bclcs_level_5_2")

variables_all_NDT4<-c("climate1", "climate2", "vegtype2", "proj_height_1", "live_stand_volume_125","slope", "aspect", "elevation", "dist_any", "bclcs_level_5_2")

#Too many permutations to be able to include two-way interactions and all possible models, so need to divide into what we think may have interactions and which not.
variables_clim_VRI_NDT4<-c(climate1 = "climate1", climate2 = "climate2", vegtype2 = "vegtype2", proj_height_1 = "proj_height_1", live_stand_volume_125 = "live_stand_volume_125")

#treat slope, aspect and elevation as their own thing.And we have already done this analysis with them.
#slope = "slope", aspect = "aspect", elevation ="elevation")

variables_all_infra_landuse_NDT4<-c(dist_mun = "dist_mun", dist_dam = "dist_dam", dist_nat = "dist_nat", dist_pow = "dist_pow", dist_any = "dist_any", bclcs_level_5_2 = "bclcs_level_5_2") #I don't think it makes sense to have interactions between the distance elements, but maybe with land use and each distance element?

##
inputs.me.NDT4 <- c(variables_all_NDT4)
#inputs.me.clim_VRI_DEM_NDT4 <- c(variables_clim_VRI_DEM_NDT4)
inputs.me.clim_VRI_NDT4 <- c(variables_clim_VRI_NDT4)
inputs.me.infra_landuse_NDT4 <- c(variables_all_infra_landuse_NDT4)

```

Before the next step, you may need to clear much of the workspace. Many elements below are from previous files, or from code that follows that I ran before. So you will likely need to modify to suit your needs.

```{r}
#First remove the AIC tables from this section. Note, you may not have created them all yet, and may need to remove some sections.
rm(AIC_lightning_NDT1_treed, AIC_lightning_NDT1_treed_climate, AIC_lightning_NDT1_treed_infra, AIC_lightning_NDT1_treed_summary, AIC_lightning_NDT1_treed_summary_climate, AIC_lightning_NDT1_treed_summary_climate2, AIC_lightning_NDT1_treed_summary_infra, AIC_lightning_NDT1_treed_summary_infra2, AIC_lightning_NDT1_treed_summary_topo, AIC_lightning_NDT1_treed_summary_topo2, AIC_lightning_NDT1_treed_summary_VRI, AIC_lightning_NDT1_treed_summary_VRI2, AIC_lightning_NDT1_treed_topo, AIC_lightning_NDT1_treed_VRI, AIC_lightning_NDT1_treed_infra, AIC_lightning_NDT2_treed_climate, 
   
   AIC_lightning_NDT2_treed, AIC_lightning_NDT2_treed_climate, AIC_lightning_NDT2_treed_infra, AIC_lightning_NDT2_treed_summary, AIC_lightning_NDT2_treed_summary_climate, AIC_lightning_NDT2_treed_summary_climate2, AIC_lightning_NDT2_treed_summary_infra, AIC_lightning_NDT2_treed_summary_infra2, AIC_lightning_NDT2_treed_summary_topo, AIC_lightning_NDT2_treed_summary_topo2, AIC_lightning_NDT2_treed_summary_VRI, AIC_lightning_NDT2_treed_summary_VRI2, AIC_lightning_NDT2_treed_topo, AIC_lightning_NDT2_treed_VRI, AIC_lightning_NDT2_treed_infra, AIC_lightning_NDT2_treed_climate,
   
   AIC_lightning_NDT3_treed, AIC_lightning_NDT3_treed_climate, AIC_lightning_NDT3_treed_infra, AIC_lightning_NDT3_treed_summary, AIC_lightning_NDT3_treed_summary_climate, AIC_lightning_NDT3_treed_summary_climate2, AIC_lightning_NDT3_treed_summary_infra, AIC_lightning_NDT3_treed_summary_infra2, AIC_lightning_NDT3_treed_summary_topo, AIC_lightning_NDT3_treed_summary_topo2, AIC_lightning_NDT3_treed_summary_VRI, AIC_lightning_NDT3_treed_summary_VRI2, AIC_lightning_NDT3_treed_topo, AIC_lightning_NDT3_treed_VRI, AIC_lightning_NDT3_treed_infra, AIC_lightning_NDT2_treed_climate,
   
   AIC_lightning_NDT4_treed, AIC_lightning_NDT4_treed_climate, AIC_lightning_NDT4_treed_infra, AIC_lightning_NDT4_treed_summary, AIC_lightning_NDT4_treed_summary_climate, AIC_lightning_NDT4_treed_summary_climate2, AIC_lightning_NDT4_treed_summary_infra, AIC_lightning_NDT4_treed_summary_infra2, AIC_lightning_NDT4_treed_summary_topo, AIC_lightning_NDT4_treed_summary_topo2, AIC_lightning_NDT4_treed_summary_VRI, AIC_lightning_NDT4_treed_summary_VRI2, AIC_lightning_NDT4_treed_topo, AIC_lightning_NDT4_treed_VRI, AIC_lightning_NDT4_treed_infra, AIC_lightning_NDT4_treed_climate,
   
   AIC_lightning_NDT5_treed, AIC_lightning_NDT5_treed_climate, AIC_lightning_NDT5_treed_infra, AIC_lightning_NDT5_treed_summary, AIC_lightning_NDT5_treed_summary_climate, AIC_lightning_NDT5_treed_summary_climate2, AIC_lightning_NDT5_treed_summary_infra, AIC_lightning_NDT5_treed_summary_infra2, AIC_lightning_NDT5_treed_summary_topo, AIC_lightning_NDT5_treed_summary_topo2, AIC_lightning_NDT5_treed_summary_VRI, AIC_lightning_NDT5_treed_summary_VRI2, AIC_lightning_NDT5_treed_topo, AIC_lightning_NDT5_treed_VRI, AIC_lightning_NDT5_treed_infra, AIC_lightning_NDT2_treed_climate)

#Now, remove any elements created prior that are also not needed
rm(dat_lightning___, dat_Disturbed, dist.cut.corr, filenames, fire_veg_data_B, fire_veg_data_lighnight_5x, fire_veg_data_lighnight_NA_5x, fire_veg_data_lighnight_NA_5x_, fire_veg_data_NA_5x, fire_veg_data_person_5x, fire_veg_data_person_NA_5x, fire_veg_data_person_NA_5x_, fire_veg_data_unknown_5x, ignition_pres_abs3, ignition_pres_abs4, table.glm.climate.simple180, table.glm.climate.simple1800)
```

Now, we will generate two-way interactions for each of these lists. We cannot make two-way interactions between them all because apparently it will be >2 GB in size.  

DO NOT RUN THIS NEXT CHUNK! The mods.twoway.NDT4 is >2 GB and will not run successfully. You will likely need to skip to the subsequent chunk.
```{r}
twoway.ints <- NULL
for (i in 1:(length(inputs.me.NDT4)-1)) {
  for (j in (i+1):length(inputs.me.NDT4)) {
     twoway.ints <- cbind(twoway.ints, paste(inputs.me.NDT4[i], inputs.me.NDT4[j], sep=":"))
  }
}
twoway.ints
length(twoway.ints) #45

#Create function to determine Powerset for any vector of variable names
## or use rje package
#powerSet <- function(x) {
#   z.list <- NULL
#   for(i in 1:length(x)) {
#      z.list <- append(z.list, combn(x, m=i, simplify=F))
#   }    
#   return(z.list)
#}

#Get variables on own
#complete list of models using non-climate vars
mods.me.tmp <- powerSet(variables_all_NDT4) 
#add climate vars to all of the above
mods.me.NDT4 <- list()
for (i in 1: length(mods.me.tmp)) {
   mods.me.NDT4[[i]] <- c(mods.me.tmp[[i]])
}

mods.me.NDT4
length(mods.me.NDT4) #1024 with only dist_any

## DO NOT RUN BELOW ####
#complete list of two-way interactions
mods.twoway.NDT4 <- powerSet(twoway.ints) #Too large > 2 GB, so cannot perform, with all distances to infrastructure; also too large for smaller subset of data.
length(mods.twoway.NDT4) #
mods.twoway.NDT4
```

ALSO DO NOT RUN THIS CHUNK!
Actually skip to chunk after this one, unless you go back and add DEM back in... but it will also be > 2 GB and unable to write.

```{r}

###########Try with subset: ############## 
twoway.ints <- NULL
for (i in 1:(length(inputs.me.clim_VRI_DEM_NDT4)-1)) {
  for (j in (i+1):length(inputs.me.clim_VRI_DEM_NDT4)) {
     twoway.ints <- cbind(twoway.ints, paste(inputs.me.clim_VRI_DEM_NDT4[i], inputs.me.clim_VRI_DEM_NDT4[j], sep=":"))
  }
}
twoway.ints
length(twoway.ints) #28

#Create function to determine Powerset for any vector of variable names
## or use rje package
#powerSet <- function(x) {
#   z.list <- NULL
#   for(i in 1:length(x)) {
#      z.list <- append(z.list, combn(x, m=i, simplify=F))
#   }    
#   return(z.list)
#}

#Get variables on own
#complete list of models using non-climate vars
mods.me.tmp <- powerSet(variables_clim_VRI_DEM_NDT4) 
#add climate vars to all of the above
mods.me.clim_VRI_DEM_NDT4 <- list()
for (i in 1: length(mods.me.tmp)) {
   mods.me.clim_VRI_DEM_NDT4[[i]] <- c(mods.me.tmp[[i]])
}

mods.me.clim_VRI_DEM_NDT4
length(mods.me.clim_VRI_DEM_NDT4) #256


##Continue from here

#complete list of two-way interactions
mods.twoway.NDT4 <- powerSet(twoway.ints) # File still too large > 2 GB
length(mods.twoway.NDT4) #
mods.twoway.NDT4

#Finding models in mods.me that accommodate/allow interaction terms in each mods.twoway to be added
mods.inter.NDT4 <- list()
counter <- 0
for (i in 1: length(mods.twoway.NDT4)) {
   s1 <- unique(unlist( strsplit(mods.twoway.NDT4[[i]], split=':', fixed=TRUE) ) )
   for (j in 1: length(mods.me.NDT4)) {
      if (all(s1 %in% mods.me.NDT4[[j]])==TRUE) {
        counter <- counter + 1
        both <-  c(mods.me.clim_VRI_DEM_NDT4[[j]], mods.twoway.NDT4[[i]])
        mods.inter.NDT4[[counter]] <- both
      }
   }
}

length(mods.inter.NDT4)
mods.inter.NDT4
```

RUN FROM HERE
```{r}
####Reduce further; remove DEM
twoway.ints <- NULL
for (i in 1:(length(inputs.me.clim_VRI_NDT4)-1)) {
  for (j in (i+1):length(inputs.me.clim_VRI_NDT4)) {
     twoway.ints <- cbind(twoway.ints, paste(inputs.me.clim_VRI_NDT4[i], inputs.me.clim_VRI_NDT4[j], sep=":"))
  }
}
twoway.ints
length(twoway.ints) #10

#Create function to determine Powerset for any vector of variable names
## or use rje package
#powerSet <- function(x) {
#   z.list <- NULL
#   for(i in 1:length(x)) {
#      z.list <- append(z.list, combn(x, m=i, simplify=F))
#   }    
#   return(z.list)
#}

#Get variables on own
#complete list of models using non-climate vars
mods.me.tmp <- powerSet(variables_clim_VRI_NDT4) 
#add climate vars to all of the above
mods.me.clim_VRI_NDT4 <- list()
for (i in 1: length(mods.me.tmp)) {
   mods.me.clim_VRI_NDT4[[i]] <- c(mods.me.tmp[[i]])
}

mods.me.clim_VRI_NDT4
length(mods.me.clim_VRI_NDT4) #32


##Continue from here

#complete list of two-way interactions
mods.twoway.NDT4 <- powerSet(twoway.ints) # Works now!
length(mods.twoway.NDT4) #1024
mods.twoway.NDT4

#Finding models in mods.me that accommodate/allow interaction terms in each mods.twoway to be added
mods.inter.NDT4 <- list()
counter <- 0
for (i in 1: length(mods.twoway.NDT4)) {
   s1 <- unique(unlist( strsplit(mods.twoway.NDT4[[i]], split=':', fixed=TRUE) ) )
   for (j in 1: length(mods.me.clim_VRI_NDT4)) {
      if (all(s1 %in% mods.me.clim_VRI_NDT4[[j]])==TRUE) {
        counter <- counter + 1
        both <-  c(mods.me.clim_VRI_NDT4[[j]], mods.twoway.NDT4[[i]])
        mods.inter.NDT4[[counter]] <- both
      }
   }
}

length(mods.inter.NDT4) #1450: this number is manageable for analyses
mods.inter.NDT4

##Subset 2: Infrastructure and land use ########
#inputs.me.infra_landuse_NDT4
twoway.ints <- NULL
for (i in 1:(length(inputs.me.infra_landuse_NDT4)-1)) {
  for (j in (i+1):length(inputs.me.infra_landuse_NDT4)) {
     twoway.ints <- cbind(twoway.ints, paste(inputs.me.infra_landuse_NDT4[i], inputs.me.infra_landuse_NDT4[j], sep=":"))
  }
}
twoway.ints
length(twoway.ints) #15
#Review. If we do not want interactions between the different distance measurements, but only those between land use and distance, subset those.
twoway.ints
twoway.ints_dist<-twoway.ints[c(5,9,12,14,15)]
twoway.ints_dist


#Create function to determine Powerset for any vector of variable names
## or use rje package
#powerSet <- function(x) {
#   z.list <- NULL
#   for(i in 1:length(x)) {
#      z.list <- append(z.list, combn(x, m=i, simplify=F))
#   }    
#   return(z.list)
#}

#Get variables on own
#complete list of models using non-climate vars
mods.me.tmp <- powerSet(variables_all_infra_landuse_NDT4) 
#add climate vars to all of the above
mods.me.infra_landuse_NDT4 <- list()
for (i in 1: length(mods.me.tmp)) {
   mods.me.infra_landuse_NDT4[[i]] <- c(mods.me.tmp[[i]])
}

mods.me.infra_landuse_NDT4
length(mods.me.infra_landuse_NDT4) #64


#complete list of two-way interactions
mods.twoway.NDT4b <- powerSet(twoway.ints) #
#Or use subset of interactions
mods.twoway.NDT4b <- powerSet(twoway.ints_dist) 
length(mods.twoway.NDT4b) #32768 if use all interactions; 32 if use subset
mods.twoway.NDT4b

#Finding models in mods.me that accommodate/allow interaction terms in each mods.twoway to be added
mods.inter.NDT4b <- list()
counter <- 0
for (i in 1: length(mods.twoway.NDT4b)) {
   s1 <- unique(unlist( strsplit(mods.twoway.NDT4b[[i]], split=':', fixed=TRUE) ) )
   for (j in 1: length(mods.me.infra_landuse_NDT4)) {
      if (all(s1 %in% mods.me.infra_landuse_NDT4[[j]])==TRUE) {
        counter <- counter + 1
        both <-  c(mods.me.infra_landuse_NDT4[[j]], mods.twoway.NDT4b[[i]])
        mods.inter.NDT4b[[counter]] <- both
      }
   }
}

length(mods.inter.NDT4b) #40069 if use all interactions - this is too many to handle; 275 with subset of interactions
mods.inter.NDT4b
```

Make final list of variables to assess.

```{r}
## 1. climate and VRI
#the list of all possible model RHSs. 
all.poss.mods.clim_VRI_NDT4<-c(1, mods.me.clim_VRI_NDT4, mods.inter.NDT4)
all.poss.mods.clim_VRI_NDT4
length(mods.me.clim_VRI_NDT4) #32
all.poss.mods.clim_VRI_NDT4[2]
all.poss.mods.clim_VRI_NDT4[34] #character 0
all.poss.mods.clim_VRI_NDT4<-all.poss.mods.clim_VRI_NDT4[-34]
all.poss.mods.clim_VRI_NDT4<-all.poss.mods.clim_VRI_NDT4[-2] #Use this line only if there is an odd character(0) added to list

##Check and rid of any duplicated models
duplicated(all.poss.mods.clim_VRI_NDT4) #Need to remove #33-63
all.poss.mods.clim_VRI_NDT4b<-all.poss.mods.clim_VRI_NDT4[-(33:63)]
duplicated(all.poss.mods.clim_VRI_NDT4b) 


##2. Infrastructure and land use
all.poss.mods.infra_landuse_NDT4<-c(1,mods.me.infra_landuse_NDT4, mods.inter.NDT4b)

##Check and rid of any duplicated models
duplicated(all.poss.mods.infra_landuse_NDT4) #Need to remove #66-129
all.poss.mods.infra_landuse_NDT4b<-all.poss.mods.infra_landuse_NDT4[-(66:129)]
duplicated(all.poss.mods.infra_landuse_NDT4b) 
all.poss.mods.infra_landuse_NDT4b[2]
all.poss.mods.infra_landuse_NDT4b<-all.poss.mods.infra_landuse_NDT4b[-2] #There is probably another one that needs removing...
all.poss.mods.infra_landuse_NDT4[66] #It was removed! Yay!
duplicated(all.poss.mods.infra_landuse_NDT4b)

###########Using a subset of interactions interactions
all.poss.mods.infra_landuse_NDT4<-c(1,mods.me.infra_landuse_NDT4, mods.inter.NDT4b)

##Check and rid of any duplicated models
duplicated(all.poss.mods.infra_landuse_NDT4) #Need to remove #66-119
all.poss.mods.infra_landuse_NDT4b<-all.poss.mods.infra_landuse_NDT4[-(66:128)]
duplicated(all.poss.mods.infra_landuse_NDT4b) 
all.poss.mods.infra_landuse_NDT4b[2]
all.poss.mods.infra_landuse_NDT4b<-all.poss.mods.infra_landuse_NDT4b[-2] #There is probably another one that needs removing...
duplicated(all.poss.mods.infra_landuse_NDT4b)
length(all.poss.mods.infra_landuse_NDT4b)#276


#If need to determine which ones are character(0), try this:
biglist <- list(list("A","B","C"), "foo", "", character(0), integer(0))
lapply(biglist, function(x) {length(x) == 0L} ) 

#Below does not work
lapply(biglist, all.poss.mods.infra_landuse_NDT4b {length(all.poss.mods.infra_landuse_NDT4b) == 0L} ) 


#Proceed with 
  ## all.poss.mods.clim_VRI_NDT4b
  ## all.poss.mods.infra_landuse_NDT4b

```


#all.poss.mods.clim_VRI_NDT4b
We cannot run the model 100 times without R crashing. Instead, we will run it 25 times, then save the output, then run that another 3 times (for a total of 100 runs). Then we will combine all 100 runs, and calculate the deltaAIC from that.

```{r}
zones1<-"NDT4"

#Create empty table
table.glm.clim_VRI.simple <- data.frame (matrix (ncol = 5, nrow = 0))
colnames (table.glm.clim_VRI.simple) <- c ("model", "edf", "aic", "auc.valid", "NDT")

#
for (g in 1:25){

for (h in 1:length(zones1)) {
  dat2<- dat_lightning_t %>% dplyr::filter(ntrl_ds ==zones1[h])

#for (i in 1: length(all.poss.mods.topo)){
#  print(paste((all.poss.mods.topo[i]), (zones1[h]), sep=" "))
  
for (i in 1: length(zones1)){
  print(paste((all.poss.mods.clim_VRI_NDT4b[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, variables_all[i])
  model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, !!variables_clim_VRI_NDT4)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="fire_pres") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.aic, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.clim_VRI_NDT4b, big.mod, df.train=dat1, df.test=Valid)

#terms in each model
x1.1 <- unlist(sapply(mods.fit, '[', 1))
x1.1
#Aic for models
x3.1 <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3.1
#auc from validation data
x4.1 <- unlist(sapply(mods.fit, '[', 4))
x4.1
#combining all as df
tab.sum.clim_VRI <- cbind.data.frame(model=x1.1, edf=x3.1[,1], aic=x3.1[,2], auc.valid=x4.1)
tab.sum.clim_VRI$NDT<-c("NDT4")
tab.sum.clim_VRI 

table.glm.clim_VRI.simple<-rbind(table.glm.clim_VRI.simple, tab.sum.clim_VRI)

}
}
}
```

For the below chunks, they will need to be run in specific order, with repeating the previous chunk in between. DO NOT RUN THIS CHUNK MORE THAN ONCE! RUN EACH ONE ONCE, AFTER EACH SUBSEQUENT RUN OF THE ABOVE.

```{r}
table.glm.clim_VRI.simple_run1<-table.glm.clim_VRI.simple
head(table.glm.clim_VRI.simple_run1)
```

STOP! RUN the model x25 again.
```{r}
table.glm.clim_VRI.simple_run2<-table.glm.clim_VRI.simple
head(table.glm.clim_VRI.simple_run2)
```

STOP! RUN the model x25 again.
```{r}
table.glm.clim_VRI.simple_run3<-table.glm.clim_VRI.simple
```

STOP! RUN the model x25 again.
```{r}
table.glm.clim_VRI.simple_run4<-table.glm.clim_VRI.simple
```

Now that we have run the model 100 times, we want the average AIC and AUC for each variable combination. First, combine the 4 runs back together.

```{r}
table.glm.clim_VRI.simple<-rbind(table.glm.clim_VRI.simple_run1, table.glm.clim_VRI.simple_run2, table.glm.clim_VRI.simple_run3, table.glm.clim_VRI.simple_run4)
```

Now determine deltaAIC.

```{r}
head(table.glm.clim_VRI.simple)
table(table.glm.clim_VRI.simple$model) # 100 per model

AIC_lightning_NDT4_treed_clim_VRI<-table.glm.clim_VRI.simple

AIC_lightning_NDT4_treed_summary_clim_VRI<- AIC_lightning_NDT4_treed_clim_VRI %>%
  group_by(model) %>%
  summarise(meanAIC=mean(aic),
            meanAUC=mean(auc.valid),
            sdAUC=sd(auc.valid),
            )

AIC_lightning_NDT4_treed_summary_clim_VRI2<- AIC_lightning_NDT4_treed_summary_clim_VRI %>%
  mutate(deltaAIC=meanAIC-min(meanAIC))

head(AIC_lightning_NDT4_treed_summary_clim_VRI2)
```

Save file.
```{r}
write.csv(AIC_lightning_NDT4_treed_summary_clim_VRI2, file="D:\\Fire\\fire_data\\raw_data\\AIC_lightning_NDT4_treed_summary_clim_VRI2.csv")
```

#Assessing models, all had low AUC (~0.55), so these models are barely performing better than 50-50.

#Now repeat for all.poss.mods.infra_landuse_NDT4b

```{r}
########### 2. Distance to Infrastructure ############
#Create empty table
table.glm.infra.lu.simple <- data.frame (matrix (ncol = 5, nrow = 0))
colnames (table.glm.infra.lu.simple) <- c ("model", "edf", "aic", "auc.valid", "NDT")

#
for (g in 1:25){

for (h in 1:length(zones1)) {
  dat2<- dat_lightning_t %>% dplyr::filter(ntrl_ds ==zones1[h])

#for (i in 1: length(all.poss.mods.infra)){
#  print(paste((all.poss.mods.infra[i]), (zones1[h]), sep=" "))
  
for (i in 1: length(zones1)){
  print(paste((all.poss.mods.infra_landuse_NDT4b[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, variables_all[i])
  model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, !!variables_all_infra_landuse_NDT4)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="fire_pres") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.aic, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.infra_landuse_NDT4b, big.mod, df.train=dat1, df.test=Valid)

#terms in each model
x1.1 <- unlist(sapply(mods.fit, '[', 1))
x1.1
#Aic for models
x3.1 <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3.1
#auc from validation data
x4.1 <- unlist(sapply(mods.fit, '[', 4))
x4.1
#combining all as df
tab.sum.infra.lu <- cbind.data.frame(model=x1.1, edf=x3.1[,1], aic=x3.1[,2], auc.valid=x4.1)
tab.sum.infra.lu$NDT<-c("NDT4")
tab.sum.infra.lu 

table.glm.infra.lu.simple<-rbind(table.glm.infra.lu.simple, tab.sum.infra.lu)

}
}
}
```

For the below chunks, they will need to be run in specific order, with repeating the previous chunk in between. DO NOT RUN THIS CHUNK MORE THAN ONCE! RUN EACH ONE ONCE, AFTER EACH SUBSEQUENT RUN OF THE ABOVE.

```{r}
#Check that it ran correctly
table.glm.infra.lu.simple

table.glm.infra.lu.simple_run1<-table.glm.infra.lu.simple
head(table.glm.infra.lu.simple_run1)

```

STOP! RUN the model x25 again.
```{r}
table.glm.infra.lu.simple_run2<-table.glm.infra.lu.simple
head(table.glm.infra.lu.simple_run2)
```

STOP! RUN the model x25 again.
```{r}
table.glm.infra.lu.simple_run3<-table.glm.infra.lu.simple
head(table.glm.infra.lu.simple_run3)
```

STOP! RUN the model x25 again.
```{r}
table.glm.infra.lu.simple_run4<-table.glm.infra.lu.simple
```

Now that we have run the model 100 times, we want the average AIC and AUC for each variable combination. First, combine the 4 runs back together.

```{r}
table.glm.infra.lu.simple<-rbind(table.glm.infra.lu.simple_run1, table.glm.infra.lu.simple_run2, table.glm.infra.lu.simple_run3, table.glm.infra.lu.simple_run4)
```

Now determine deltaAIC.

```{r}
head(table.glm.infra.lu.simple)
table(table.glm.infra.lu.simple$model) # 100 per model

AIC_lightning_NDT4_treed_infra<-table.glm.infra.lu.simple

AIC_lightning_NDT4_treed_summary_infra<- AIC_lightning_NDT4_treed_infra %>%
  group_by(model) %>%
  summarise(meanAIC=mean(aic),
            meanAUC=mean(auc.valid),
            sdAUC=sd(auc.valid),
            )

AIC_lightning_NDT4_treed_summary_infra2<- AIC_lightning_NDT4_treed_summary_infra %>%
  mutate(deltaAIC=meanAIC-min(meanAIC))

head(AIC_lightning_NDT4_treed_summary_infra2)
```

Save to computer.

```{r}
write.csv(AIC_lightning_NDT4_treed_summary_infra2, file="D:\\Fire\\fire_data\\raw_data\\AIC_lightning_NDT4_treed_summary_infra.csv")
```


########################### STAGE THREE ###########################

#STAGE THREE: ALL VARIABLES
Now that we have even more information about how some variables perform with others, we need test them all together... unfortunately, we cannot accomplish this the same as above given that there are so many possible combinations and R cannot write vectors so long. Below, I include code for (1) manual investigation and (2) the full investigation for those who may be able to get R not to crash while attempting it.

##Top variables
1. Top models have live_stand_volume and proj_height with various combinations of interactions with climate 1 and climate 2. Vegtype 2 is not included, but this is important. So we should explore interactions between climate 1, climate 2, live stand volume and projected age, and add vegtype 2 with no interactions separately.

2. Infrastructure and landuse: distance to any and distance to municipality best model. Land use not found important, but I think it is useful to have in model. Try full model with these 3 variables first. AUC low for all (<0.57). No interactions found to be important.

3. DEM: slope + aspect + elevation + slope:aspect was the top model. Include elements of these in but not interactions with other variables unless we have a reason to expect an interaction (perhaps try landuse*elevation, for example; or with slope or aspect)

#Top Models
1. climate1 + climate2 + vegtype2 + climate1:climate2
2. proj_height_1 + live_stand_volume_125
3. slope + aspect + elevation + slope:aspect
4. dist_mun + dist_dam + dist_nat + dist_pow + dist_any1. 

Additional Variabes:
1. bclcs_level_5_2 (land use) (to be added to final investigated model)

#Could consider trying backwards stepwise regression since the code chunk below this one creates an object that is too large and cannot run.
There are a few options from this point. Either, we repeat a similar routine as prior to this step but with running half of one set of variables (since one full set is too much for R to handle), or we try stepwise regression using the step() function or manually. The former approach requires some manual adjustment as well since we need to create training and validation data sets first that remain the same to feed into each of the ha;ves of the possible models. Then we would need to repeat that process several times to be able to get meanAIC and meanAUC. The latter approach also takes time since it is all manual, but it is easier to reason with what inputs are included and why.

```{r}
dat_lightning_t_NDT4<-subset(dat_lightning_t, dat_lightning_t$ntrl_ds=="NDT4")

#Divide data into training and valid
prop<-0.75
# Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(dat_lightning_t_NDT4$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- dat_lightning_t_NDT4[ trainIndex,]
   Valid <- dat_lightning_t_NDT4[-trainIndex,]

#Run model using dat1
model.NDT4<-glm(fire_pres ~ climate1 + climate2 + climate1*climate2 + proj_height_1 + live_stand_volume_125 + proj_height_1*live_stand_volume_125 + climate1*proj_height_1 + climate2*proj_height_1 + climate1*live_stand_volume_125 + climate2*live_stand_volume_125 + slope + aspect + elevation + slope*aspect + slope*elevation + aspect*elevation + dist_any + bclcs_level_5_2 + vegtype2, family = binomial, data = dat1)
#Above does not converge

#Try removing some interactions
model.NDT4<-glm(fire_pres ~ climate1 + climate2 + climate1*climate2 + proj_height_1 + live_stand_volume_125 + proj_height_1*live_stand_volume_125 + climate1*proj_height_1 + climate2*proj_height_1 + climate1*live_stand_volume_125 + climate2*live_stand_volume_125 + slope + aspect + elevation + slope*aspect + slope*elevation + dist_any + bclcs_level_5_2 + vegtype2, family = binomial, data = dat1)


#Below works; no longer with updated bclcs_level_5_2
model.NDT4<-glm(fire_pres ~ climate1 + climate2 + climate1*climate2 + proj_height_1 + live_stand_volume_125 + proj_height_1*live_stand_volume_125 + climate1*proj_height_1 + climate2*proj_height_1 + climate1*live_stand_volume_125 + climate2*live_stand_volume_125 + slope + aspect + elevation + slope*aspect + dist_any + bclcs_level_5_2 + vegtype2, family = binomial, data = dat1)

backwards<-step(model.NDT4) #Model does not converge

#Determine AUC of full model
mod.valid <- predict.glm(model.NDT4, newdata=Valid, type="response")
   roc_obj <- roc(Valid[,"fire_pres"], mod.valid)
   mod.auc <- auc(roc_obj)
   mod.auc #0.5844 --> poor fit
   
#Assess if AUC any better for fewer variables
model.NDT4<-glm(fire_pres ~ climate1 + climate2 + climate1*climate2 + vegtype2 + dist_any + proj_height_1 + live_stand_volume_125 + slope + aspect + elevation + slope*aspect, family = binomial, data = dat1)
#Determine AUC
mod.valid <- predict.glm(model.NDT4, newdata=Valid, type="response")
   roc_obj <- roc(Valid[,"fire_pres"], mod.valid)
   mod.auc <- auc(roc_obj)
   mod.auc # 0.61 --> poor fit
   
   model.NDT4<-glm(fire_pres ~ climate1 + climate2 + climate1*climate2 + proj_height_1 + live_stand_volume_125 + proj_height_1*live_stand_volume_125 + climate1*proj_height_1 + climate2*proj_height_1 + climate1*live_stand_volume_125 + climate2*live_stand_volume_125 + slope + aspect + elevation + slope*aspect + dist_any + vegtype2, family = binomial, data = dat1) #Nearly highest AUC of 0.612. Poor.
   
model.NDT4<-glm(fire_pres ~ climate1 + climate2 + climate1*climate2 + proj_height_1 + live_stand_volume_125 + proj_height_1*live_stand_volume_125 + climate1*proj_height_1 + climate2*proj_height_1 + climate1*live_stand_volume_125 + climate2*live_stand_volume_125 + slope + aspect + elevation + slope*aspect + dist_mun +  dist_dam + dist_nat + dist_pow + vegtype2, family = binomial, data = dat1) #Highest AUC of 0.616. Poor.

#Assess model
library(car)
Anova(model.NDT4, type=3) #Sig variables: climate2, live stand volume, dist_mun, dist_dam, vegtype, climate1*climate2, climate2*projected height, nearly climate1*livestand volume
summary(model.NDT4) #interestingly, all negative relationships for distance to infrastructure. Conifer forest more likely to burn, broadleaf less likely.
AIC(model.NDT4) #6245.033

#remove some of the non-significant interactions
model.NDT4<-glm(fire_pres ~ climate1 + climate2 + climate1*climate2 + proj_height_1 + live_stand_volume_125 + climate1*proj_height_1 + climate2*proj_height_1 + climate1*live_stand_volume_125 + climate2*live_stand_volume_125 + slope + aspect + elevation + slope*aspect + dist_mun +  dist_dam + dist_nat + dist_pow + vegtype2, family = binomial, data = dat1) #Highest AUC of 0.616. Poor.

mod.valid <- predict.glm(model.NDT4, newdata=Valid, type="response")
   roc_obj <- roc(Valid[,"fire_pres"], mod.valid)
   mod.auc <- auc(roc_obj)
   mod.auc # --> poor fit
  
Anova(model.NDT4, type=3) 
AIC(model.NDT4) #6243.53

#remove some of the non-significant interactions
model.NDT4<-glm(fire_pres ~ climate1 + climate2 + climate1*climate2 + proj_height_1 + live_stand_volume_125 + climate2*proj_height_1 + climate1*live_stand_volume_125 + climate2*live_stand_volume_125 + slope + aspect + elevation + slope*aspect + dist_mun +  dist_dam + dist_nat + dist_pow + vegtype2, family = binomial, data = dat1) #Highest AUC of 0.617. Poor.

mod.valid <- predict.glm(model.NDT4, newdata=Valid, type="response")
   roc_obj <- roc(Valid[,"fire_pres"], mod.valid)
   mod.auc <- auc(roc_obj)
   mod.auc # --> poor fit
  
Anova(model.NDT4, type=3) 
AIC(model.NDT4) #6241.56

#remove some of the non-significant interactions
model.NDT4<-glm(fire_pres ~ climate1 + climate2 + climate1*climate2 + proj_height_1 + live_stand_volume_125 + climate2*proj_height_1 + climate1*live_stand_volume_125 + climate2*live_stand_volume_125 + slope + aspect + elevation + dist_mun +  dist_dam + dist_nat + dist_pow + vegtype2, family = binomial, data = dat1) #AUC of 0.617. Poor. Not as good as with prior interaction

mod.valid <- predict.glm(model.NDT4, newdata=Valid, type="response")
   roc_obj <- roc(Valid[,"fire_pres"], mod.valid)
   mod.auc <- auc(roc_obj)
   mod.auc # --> poor fit
  
Anova(model.NDT4, type=3)
AIC(model.NDT4) #6241.3

#remove some of the non-significant interactions
model.NDT4<-glm(fire_pres ~ climate1 + climate2 + climate1*climate2 + proj_height_1 + live_stand_volume_125 + climate2*proj_height_1  + climate2*live_stand_volume_125 + slope + aspect + elevation + dist_mun +  dist_dam + dist_nat + dist_pow + vegtype2, family = binomial, data = dat1) #AUC of 0.612. Poor. 

mod.valid <- predict.glm(model.NDT4, newdata=Valid, type="response")
   roc_obj <- roc(Valid[,"fire_pres"], mod.valid)
   mod.auc <- auc(roc_obj)
   mod.auc # --> poor fit
  
Anova(model.NDT4, type=3)
AIC(model.NDT4) #6247.7 - WORSE!


model.NDT4<-glm(fire_pres ~ climate1 + climate2 + climate1*climate2 + proj_height_1 + live_stand_volume_125 + climate2*proj_height_1 + climate1*live_stand_volume_125 + climate2*live_stand_volume_125 + slope + aspect + elevation + dist_mun +  dist_dam + dist_nat + dist_pow + vegtype2 + bclcs_level_5_2, family = binomial, data = dat1) #AUC of 0.618. Poor. 

mod.valid <- predict.glm(model.NDT4, newdata=Valid, type="response")
   roc_obj <- roc(Valid[,"fire_pres"], mod.valid)
   mod.auc <- auc(roc_obj)
   mod.auc # --> poor fit
  
Anova(model.NDT4, type=3)
AIC(model.NDT4) #6238.6


alias( glm( fire_pres ~ climate1 + climate2 + climate1*climate2 + proj_height_1 + live_stand_volume_125 + climate2*proj_height_1 + climate1*live_stand_volume_125 + climate2*live_stand_volume_125 + slope + aspect + elevation + dist_mun +  dist_dam + dist_nat + dist_pow + vegtype2 + bclcs_level_5_2, family = binomial, data = dat1) )

Anova(model.NDT4, type=3, singular.ok = TRUE)


##
model.NDT4<-glm(fire_pres ~ climate1 + climate2 + climate1*climate2 + proj_height_1 + live_stand_volume_125 + climate2*proj_height_1 + climate1*live_stand_volume_125  + slope + aspect + elevation + dist_mun +  dist_dam + dist_nat + dist_pow + vegtype2 + bclcs_level_5_2, family = binomial, data = dat1) #AUC of 0.615. Poor. 

mod.valid <- predict.glm(model.NDT4, newdata=Valid, type="response")
   roc_obj <- roc(Valid[,"fire_pres"], mod.valid)
   mod.auc <- auc(roc_obj)
   mod.auc # --> poor fit
  
Anova(model.NDT4, type=3,singular.ok = TRUE)
AIC(model.NDT4) #6237.3

##
model.NDT4<-glm(fire_pres ~ climate1 + climate2 + climate1*climate2 + proj_height_1 + live_stand_volume_125 + climate1*live_stand_volume_125  + slope + aspect + elevation + dist_mun +  dist_dam + dist_nat + dist_pow + vegtype2 + bclcs_level_5_2, family = binomial, data = dat1) #AUC of 0.615. 

mod.valid <- predict.glm(model.NDT4, newdata=Valid, type="response")
   roc_obj <- roc(Valid[,"fire_pres"], mod.valid)
   mod.auc <- auc(roc_obj)
   mod.auc # --> poor fit
  
Anova(model.NDT4, type=3,singular.ok = TRUE)
AIC(model.NDT4) #6237.1

##
model.NDT4<-glm(fire_pres ~ climate1 + climate2 + climate1*climate2 + proj_height_1 + live_stand_volume_125 + climate1*live_stand_volume_125  + aspect + elevation + dist_mun +  dist_dam + dist_nat + dist_pow + vegtype2 + bclcs_level_5_2, family = binomial, data = dat1) #AUC of 0.615. Poor. 

mod.valid <- predict.glm(model.NDT4, newdata=Valid, type="response")
   roc_obj <- roc(Valid[,"fire_pres"], mod.valid)
   mod.auc <- auc(roc_obj)
   mod.auc # --> poor fit
  
Anova(model.NDT4, type=3,singular.ok = TRUE)
AIC(model.NDT4) #6235.6



##
model.NDT4<-glm(fire_pres ~ climate1 + climate2 + climate1*climate2 + proj_height_1 + live_stand_volume_125 + climate1*live_stand_volume_125  + aspect + dist_mun +  dist_dam + dist_nat + dist_pow + vegtype2 + bclcs_level_5_2, family = binomial, data = dat1) #AUC of 0.613. Poor. 

mod.valid <- predict.glm(model.NDT4, newdata=Valid, type="response")
   roc_obj <- roc(Valid[,"fire_pres"], mod.valid)
   mod.auc <- auc(roc_obj)
   mod.auc # --> poor fit
  
Anova(model.NDT4, type=3,singular.ok = TRUE)
AIC(model.NDT4) #6234.3

### This is the best model with this specific division of training and validation data. Repeat with new subset and compare AUC.

```

Repeat subsetting data into training and validation datasets.

```{r}
prop<-0.75
# Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(dat_lightning_t_NDT4$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- dat_lightning_t_NDT4[ trainIndex,]
   Valid <- dat_lightning_t_NDT4[-trainIndex,]
```

Get AUC for model again.

```{r}
model.NDT4<-glm(fire_pres ~ climate1 + climate2 + climate1*climate2 + proj_height_1 + live_stand_volume_125 + climate1*live_stand_volume_125  + aspect + dist_mun +  dist_dam + dist_nat + dist_pow + vegtype2 + bclcs_level_5_2, family = binomial, data = dat1) #AUC - Round 2: 0.59. Round 3: 0.59; Round 4: 0.59; Round 5: 0.59; Round 6: 0.6002. 

mod.valid <- predict.glm(model.NDT4, newdata=Valid, type="response")
   roc_obj <- roc(Valid[,"fire_pres"], mod.valid)
   mod.auc <- auc(roc_obj)
   mod.auc # --> poor fit
  
Anova(model.NDT4, type=3,singular.ok = TRUE)
AIC(model.NDT4) #6209.5


##try without aspect
model.NDT4<-glm(fire_pres ~ climate1 + climate2 + climate1*climate2 + proj_height_1 + live_stand_volume_125 + climate1*live_stand_volume_125 + dist_mun +  dist_dam + dist_nat + dist_pow + vegtype2 + bclcs_level_5_2, family = binomial, data = dat1) #AUC 0.60

mod.valid <- predict.glm(model.NDT4, newdata=Valid, type="response")
   roc_obj <- roc(Valid[,"fire_pres"], mod.valid)
   mod.auc <- auc(roc_obj)
   mod.auc # --> poor fit
  
Anova(model.NDT4, type=3,singular.ok = TRUE)
AIC(model.NDT4) #6208
```

NDT4 is the natural disturbance type with frequent stand-maintaining fires. Perhaps it is just an ecosystem where it is hard to predict and there is a lot of stochasticity in ignitions by lightning.

In the original models, they all performed poorly as well (0.52-0.575, with distance to mun, dam, nat, pow and any being best). 

Re-run with na.omit and check diagnostics.

```{r}
#Remove NAs to ensure all same data used so we can compare AICs
NDT4_t<-dat_lightning_t_NDT4 %>% drop_na(climate1, climate2, proj_height_1, live_stand_volume_125, dist_mun,  dist_dam, dist_nat, dist_pow, vegtype2, bclcs_level_5_2)

model.NDT4<-glm(fire_pres ~ climate1 + climate2 + climate1*climate2 + proj_height_1 + live_stand_volume_125 + climate1*live_stand_volume_125 + dist_mun +  dist_dam + dist_nat + dist_pow + vegtype2 + bclcs_level_5_2, family = binomial, data = NDT4_t) 

#Above was not divided, so this does not make sense below
mod.valid <- predict.glm(model.NDT4, newdata=Valid, type="response")
   roc_obj <- roc(Valid[,"fire_pres"], mod.valid)
   mod.auc <- auc(roc_obj)
   mod.auc # 
  
Anova(model.NDT4, type=3,singular.ok = TRUE)
AIC(model.NDT4) #6208

# model diagnostic plots
binnedplot (fitted(model.NDT4), 
            residuals(model.NDT4), 
            nclass = NULL, 
            xlab = "Expected Values", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))


NDT4_t$resids<-resid(model.NDT4)

binnedplot (NDT4_t$live_stand_volume_125, 
            NDT4_t$resids, 
            nclass = NULL, 
            xlab = "live stand volume", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))

binnedplot (NDT4_t$climate1, 
            NDT4_t$resids, 
            nclass = NULL, 
            xlab = "", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))

# Diagnostic plots look good
```


######## Save selected Model as Final Model ############
We will save the coefficients to a table and export it as a csv file. There will be future models that will have other variables, so we will ignore that for now and modify as needed later when combining tables.

```{r}
model.NDT4<-glm(fire_pres ~ climate1 + climate2 + climate1*climate2 + proj_height_1 + live_stand_volume_125 + climate1*live_stand_volume_125 + dist_mun +  dist_dam + dist_nat + dist_pow + vegtype2 + bclcs_level_5_2, family = binomial, data = NDT4_t) 

summary(model.NDT4)

# create model table (only do this once) and add the relevant data
top_mod_table_NDT4_light_t <- data.frame (matrix (ncol = 21, nrow = 0))
colnames (top_mod_table_NDT4_light_t ) <- c ("CAUSE", "NDT", "TREED", "Model_terms", "intercept", "coef_climate_1", "coef_climate_2", "coef_climate_interaction", "coef_stand_height", "coef_live_stand_volume_125", "coef_dist_mun", "coef_dist_dam", "coef_dist_nat", "coef_dist_pow", "coef_vegtypeOP", "coef_vegtypeTB", "coef_vegtypeTC", "coef_vegtypeTM", "coef_bclcs_level_5_2DE", "coef_bclcs_level_5_2OP", "coef_climate1:live_stand_volume_125")


##Add data for NDT4
top_mod_table_NDT4_light_t[1,1]<-"lightning"
top_mod_table_NDT4_light_t[1,2]<-"NDT4"
top_mod_table_NDT4_light_t[1,3]<-"Y"
top_mod_table_NDT4_light_t[1,4]<-"fire_pres ~ climate1 + climate2 + climate1*climate2 + proj_height_1 + live_stand_volume_125 + climate1*live_stand_volume_125 + dist_mun +  dist_dam + dist_nat + dist_pow + vegtype2 + bclcs_level_5_2" 
top_mod_table_NDT4_light_t[1,5]<- coef(model.NDT4)[1] #Intercept
top_mod_table_NDT4_light_t[1,6]<- coef(model.NDT4)[2] #Climate variable 1
top_mod_table_NDT4_light_t[1,7]<- coef(model.NDT4)[3] #Climate variable 2
top_mod_table_NDT4_light_t[1,8]<- coef(model.NDT4)[17] #Interaction climate variables
top_mod_table_NDT4_light_t[1,9]<- coef(model.NDT4)[4] #coef_stand_height
top_mod_table_NDT4_light_t[1,10]<- coef(model.NDT4)[5] #live_stand_volume_125
top_mod_table_NDT4_light_t[1,11]<- coef(model.NDT4)[6] #dist_mun
top_mod_table_NDT4_light_t[1,12]<- coef(model.NDT4)[7] #dist_dam
top_mod_table_NDT4_light_t[1,13]<- coef(model.NDT4)[8] #dist_nat
top_mod_table_NDT4_light_t[1,14]<- coef(model.NDT4)[9] #dist_pow
top_mod_table_NDT4_light_t[1,15]<- coef(model.NDT4)[10] #coefficient vegtypeOP
top_mod_table_NDT4_light_t[1,16]<- coef(model.NDT4)[11] #coefficient vegtypeTB
top_mod_table_NDT4_light_t[1,17]<- coef(model.NDT4)[12] #coefficient vegtypeTC
top_mod_table_NDT4_light_t[1,18]<- coef(model.NDT4)[13] #coefficient vegtypeTM
top_mod_table_NDT4_light_t[1,19]<- coef(model.NDT4)[14] #coefficient bclcs_level_5_2DE
top_mod_table_NDT4_light_t[1,20]<- coef(model.NDT4)[15] #coefficient bclcs_level_5_2OP
top_mod_table_NDT4_light_t[1,21]<- coef(model.NDT4)[18] #coefficient climate1:live_stand_volume_125 
top_mod_table_NDT4_light_t ##Check

########################## NDT4 Model Selection Complete ###################
```
Save coefficient table.
```{r}
write.csv(top_mod_table_NDT4_light_t, file="D:\\Fire\\fire_data\\raw_data\\top_mod_table_NDT4_light_t.csv")
```

We should repeat the above several times and take the mean of the coefficients.

```{r}
top_mod_table_NDT4_light_t_ALL<-top_mod_table_NDT4_light_t 

#Or create a new blank table and get AUC too
top_mod_table_NDT4_light_t_ALL <- data.frame (matrix (ncol = 22, nrow = 0))
colnames (top_mod_table_NDT4_light_t_ALL ) <- c ("CAUSE", "NDT", "TREED", "Model_terms", "intercept", "coef_climate_1", "coef_climate_2", "coef_climate_interaction", "coef_stand_height", "coef_live_stand_volume_125", "coef_dist_mun", "coef_dist_dam", "coef_dist_nat", "coef_dist_pow", "coef_vegtypeOP", "coef_vegtypeTB", "coef_vegtypeTC", "coef_vegtypeTM", "coef_bclcs_level_5_2DE", "coef_bclcs_level_5_2OP", "coef_climate1:live_stand_volume_125", "AUC")
```

Let's run it 500 times to get good mean values.

```{r}

for (g in 1:500){

prop<-0.75
# Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(NDT4_t$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- NDT4_t[ trainIndex,]
   Valid <- NDT4_t[-trainIndex,]
   
#Model   
model.NDT4<-glm(fire_pres ~ climate1 + climate2 + climate1*climate2 + proj_height_1 + live_stand_volume_125 + climate1*live_stand_volume_125 + dist_mun +  dist_dam + dist_nat + dist_pow + vegtype2 + bclcs_level_5_2, family = binomial, data = dat1) 

mod.valid <- predict.glm(model.NDT4, newdata=Valid, type="response")
   roc_obj <- roc(Valid[,"fire_pres"], mod.valid)
   mod.auc <- auc(roc_obj)

# create model table (only do this once) and add the relevant data
top_mod_table_NDT4_light_t <- data.frame (matrix (ncol = 22, nrow = 0))
colnames (top_mod_table_NDT4_light_t ) <- c ("CAUSE", "NDT", "TREED", "Model_terms", "intercept", "coef_climate_1", "coef_climate_2", "coef_climate_interaction", "coef_stand_height", "coef_live_stand_volume_125", "coef_dist_mun", "coef_dist_dam", "coef_dist_nat", "coef_dist_pow", "coef_vegtypeOP", "coef_vegtypeTB", "coef_vegtypeTC", "coef_vegtypeTM", "coef_bclcs_level_5_2DE", "coef_bclcs_level_5_2OP", "coef_climate1:live_stand_volume_125", "AUC")

##Add data for NDT4
top_mod_table_NDT4_light_t[1,1]<-"lightning"
top_mod_table_NDT4_light_t[1,2]<-"NDT4"
top_mod_table_NDT4_light_t[1,3]<-"Y"
top_mod_table_NDT4_light_t[1,4]<-"fire_pres ~ climate1 + climate2 + climate1*climate2 + proj_height_1 + live_stand_volume_125 + climate1*live_stand_volume_125 + dist_mun +  dist_dam + dist_nat + dist_pow + vegtype2 + bclcs_level_5_2" 
top_mod_table_NDT4_light_t[1,5]<- coef(model.NDT4)[1] #Intercept
top_mod_table_NDT4_light_t[1,6]<- coef(model.NDT4)[2] #Climate variable 1
top_mod_table_NDT4_light_t[1,7]<- coef(model.NDT4)[3] #Climate variable 2
top_mod_table_NDT4_light_t[1,8]<- coef(model.NDT4)[18] #Interaction climate variables
top_mod_table_NDT4_light_t[1,9]<- coef(model.NDT4)[4] #coef_stand_height
top_mod_table_NDT4_light_t[1,10]<- coef(model.NDT4)[5] #live_stand_volume_125
top_mod_table_NDT4_light_t[1,11]<- coef(model.NDT4)[6] #dist_mun
top_mod_table_NDT4_light_t[1,12]<- coef(model.NDT4)[7] #dist_dam
top_mod_table_NDT4_light_t[1,13]<- coef(model.NDT4)[8] #dist_nat
top_mod_table_NDT4_light_t[1,14]<- coef(model.NDT4)[9] #dist_pow
top_mod_table_NDT4_light_t[1,15]<- coef(model.NDT4)[10] #coefficient vegtypeOP
top_mod_table_NDT4_light_t[1,16]<- coef(model.NDT4)[11] #coefficient vegtypeTB
top_mod_table_NDT4_light_t[1,17]<- coef(model.NDT4)[12] #coefficient vegtypeTC
top_mod_table_NDT4_light_t[1,18]<- coef(model.NDT4)[13] #coefficient vegtypeTM
top_mod_table_NDT4_light_t[1,19]<- coef(model.NDT4)[14] #coefficient bclcs_level_5_2DE
top_mod_table_NDT4_light_t[1,20]<- coef(model.NDT4)[16] #coefficient bclcs_level_5_2OP
top_mod_table_NDT4_light_t[1,21]<- coef(model.NDT4)[19] #coefficient climate1:live_stand_volume_125 
top_mod_table_NDT4_light_t[1,22]<- mod.auc

top_mod_table_NDT4_light_t_ALL<-rbind(top_mod_table_NDT4_light_t_ALL, top_mod_table_NDT4_light_t)

}

```

Check.
```{r}
head(top_mod_table_NDT4_light_t_ALL)

```

#Save coefficient table

```{r}
write.csv(top_mod_table_NDT4_light_t_ALL, file="D:\\Fire\\fire_data\\raw_data\\top_mod_table_NDT4_light_t_ALL.csv")
```

Get mean values.

```{r}
names(top_mod_table_NDT4_light_t_ALL)
mean(top_mod_table_NDT4_light_t_ALL$AUC) #0.5953

# create model table (only do this once) and add the relevant data
top_mod_table_NDT4_light_t_Means <- data.frame (matrix (ncol = 22, nrow = 0))
colnames (top_mod_table_NDT4_light_t_Means ) <- c ("CAUSE", "NDT", "TREED", "Model_terms", "intercept", "coef_climate_1", "coef_climate_2", "coef_climate_interaction", "coef_stand_height", "coef_live_stand_volume_125", "coef_dist_mun", "coef_dist_dam", "coef_dist_nat", "coef_dist_pow", "coef_vegtypeOP", "coef_vegtypeTB", "coef_vegtypeTC", "coef_vegtypeTM", "coef_bclcs_level_5_2DE", "coef_bclcs_level_5_2OP", "coef_climate1:live_stand_volume_125", "AUC")

head(top_mod_table_NDT4_light_t_Means)

##Add data for NDT4
top_mod_table_NDT4_light_t_Means[1,1]<-"lightning"
top_mod_table_NDT4_light_t_Means[1,2]<-"NDT4"
top_mod_table_NDT4_light_t_Means[1,3]<-"Y"
top_mod_table_NDT4_light_t_Means[1,4]<-"fire_pres ~ climate1 + climate2 + climate1*climate2 + proj_height_1 + live_stand_volume_125 + climate1*live_stand_volume_125 + dist_mun +  dist_dam + dist_nat + dist_pow + vegtype2 + bclcs_level_5_2" 
top_mod_table_NDT4_light_t_Means[1,5]<- mean(top_mod_table_NDT4_light_t_ALL$intercept) #Intercept
top_mod_table_NDT4_light_t_Means[1,6]<- mean(top_mod_table_NDT4_light_t_ALL$coef_climate_1) #Climate variable 1
top_mod_table_NDT4_light_t_Means[1,7]<- mean(top_mod_table_NDT4_light_t_ALL$coef_climate_2) #Climate variable 2
top_mod_table_NDT4_light_t_Means[1,8]<- mean(top_mod_table_NDT4_light_t_ALL$coef_climate_interaction) #Interaction climate variables
top_mod_table_NDT4_light_t_Means[1,9]<- mean(top_mod_table_NDT4_light_t_ALL$coef_stand_height) #coef_stand_height
top_mod_table_NDT4_light_t_Means[1,10]<- mean(top_mod_table_NDT4_light_t_ALL$coef_live_stand_volume_125) #live_stand_volume_125
top_mod_table_NDT4_light_t_Means[1,11]<- mean(top_mod_table_NDT4_light_t_ALL$coef_dist_mun) #dist_mun
top_mod_table_NDT4_light_t_Means[1,12]<- mean(top_mod_table_NDT4_light_t_ALL$coef_dist_dam) #dist_dam
top_mod_table_NDT4_light_t_Means[1,13]<- mean(top_mod_table_NDT4_light_t_ALL$coef_dist_nat) #dist_nat
top_mod_table_NDT4_light_t_Means[1,14]<- mean(top_mod_table_NDT4_light_t_ALL$coef_dist_pow) #dist_pow
top_mod_table_NDT4_light_t_Means[1,15]<- mean(top_mod_table_NDT4_light_t_ALL$coef_vegtypeOP) #coefficient vegtypeOP
top_mod_table_NDT4_light_t_Means[1,16]<- mean(top_mod_table_NDT4_light_t_ALL$coef_vegtypeTB) #coefficient vegtypeTB
top_mod_table_NDT4_light_t_Means[1,17]<- mean(top_mod_table_NDT4_light_t_ALL$coef_vegtypeTC) #coefficient vegtypeTC
top_mod_table_NDT4_light_t_Means[1,18]<- mean(top_mod_table_NDT4_light_t_ALL$coef_vegtypeTM) #coefficient vegtypeTM
top_mod_table_NDT4_light_t_Means[1,19]<- mean(top_mod_table_NDT4_light_t_ALL$coef_bclcs_level_5_2DE) #coefficient bclcs_level_5_2DE
top_mod_table_NDT4_light_t_Means[1,20]<- mean(top_mod_table_NDT4_light_t_ALL$coef_bclcs_level_5_2OP) #coefficient bclcs_level_5_2OP
top_mod_table_NDT4_light_t_Means[1,21]<- mean(top_mod_table_NDT4_light_t_ALL$`coef_climate1:live_stand_volume_125`) #coefficient climate1:live_stand_volume_125 
top_mod_table_NDT4_light_t_Means[1,22]<- mean(top_mod_table_NDT4_light_t_ALL$AUC)

top_mod_table_NDT4_light_t_Means

```

Save mean coefficient table.

```{r}
write.csv(top_mod_table_NDT4_light_t_Means, file="D:\\Fire\\fire_data\\raw_data\\top_mod_table_NDT4_light_t_Means.csv")
```









###### For those who can get below to work, awesome!
#For method 2: try below

Create variable lists.

```{r}
##Create variable lists to be used in the model loop.
variables_all_NDT4<-c(climate1 = "climate1", climate2 = "climate2", vegtype2 = "vegtype2", proj_height_1 = "proj_height_1", live_stand_volume_125 = "live_stand_volume_125", slope = "slope", aspect = "aspect", elevation ="elevation", dist_mun = "dist_mun", dist_any = "dist_any", bclcs_level_5_2 = "bclcs_level_5_2", slope = "slope", aspect = "aspect", elevation ="elevation")

#Too many permutations to be able to include two-way interactions and all possible models, so need to divide into what we think may have interactions and which not.
variables_clim_VRI_NDT4<-c(climate1 = "climate1", climate2 = "climate2", proj_height_1 = "proj_height_1", live_stand_volume_125 = "live_stand_volume_125")

variables_DEM_NDT4<-c(slope = "slope", aspect = "aspect", elevation ="elevation")

#treat slope, aspect and elevation as their own thing.And we have already done this analysis with them.
#slope = "slope", aspect = "aspect", elevation ="elevation")

##
inputs.me.NDT4 <- c(variables_all_NDT4)
#inputs.me.clim_VRI_DEM_NDT4 <- c(variables_clim_VRI_DEM_NDT4)
inputs.me.clim_VRI_NDT4 <- c(variables_clim_VRI_NDT4)
inputs.me.DEM_NDT4 <- c(variables_DEM_NDT4)

```

Form for full model given above constraints.

```{r}
twoway.ints <- NULL
for (i in 1:(length(inputs.me.clim_VRI_NDT4)-1)) {
  for (j in (i+1):length(inputs.me.clim_VRI_NDT4)) {
     twoway.ints <- cbind(twoway.ints, paste(inputs.me.clim_VRI_NDT4[i], inputs.me.clim_VRI_NDT4[j], sep=":"))
  }
}
twoway.ints
length(twoway.ints) #6


twoway.ints.DEM <- NULL
for (i in 1:(length(inputs.me.DEM_NDT4)-1)) {
  for (j in (i+1):length(inputs.me.DEM_NDT4)) {
     twoway.ints.DEM <- cbind(twoway.ints.DEM, paste(inputs.me.DEM_NDT4[i], inputs.me.DEM_NDT4[j], sep=":"))
  }
}
twoway.ints.DEM #3
length(twoway.ints.DEM) #3

#Create function to determine Powerset for any vector of variable names
## or use rje package
#powerSet <- function(x) {
#   z.list <- NULL
#   for(i in 1:length(x)) {
#      z.list <- append(z.list, combn(x, m=i, simplify=F))
#   }    
#   return(z.list)
#}

#Get variables on own and all possible combinations
#complete list of models using all variables
mods.me.tmp <- powerSet(variables_all_NDT4) 
#add climate vars to all of the above
mods.me_NDT4 <- list()
for (i in 1: length(mods.me.tmp)) {
   mods.me_NDT4[[i]] <- c(mods.me.tmp[[i]])
}

mods.me_NDT4
length(mods.me_NDT4) #16384


#complete list of two-way interactions
mods.twoway.NDT4.a <- powerSet(twoway.ints) 
length(mods.twoway.NDT4.a) #64
mods.twoway.NDT4.a

mods.twoway.NDT4.b <- powerSet(twoway.ints.DEM) 
length(mods.twoway.NDT4.b) #8
mods.twoway.NDT4.b

mods.twoway.NDT4<-c(mods.twoway.NDT4.a, mods.twoway.NDT4.b)
mods.twoway.NDT4
length(mods.twoway.NDT4) #72

#Finding models in mods.me that accommodate/allow interaction terms in each mods.twoway to be added
mods.inter.NDT4 <- list()
counter <- 0
for (i in 1: length(mods.twoway.NDT4)) {
   s1 <- unique(unlist( strsplit(mods.twoway.NDT4[[i]], split=':', fixed=TRUE) ) )
   for (j in 1: length(mods.me_NDT4)) {
      if (all(s1 %in% mods.me_NDT4[[j]])==TRUE) {
        counter <- counter + 1
        both <-  c(mods.me_NDT4[[j]], mods.twoway.NDT4[[i]])
        mods.inter.NDT4[[counter]] <- both
      }
   }
}

length(mods.inter.NDT4) #187392.... very large...
mods.inter.NDT4

```

Make final list of variables to assess.

```{r}
## 1. climate and VRI
#the list of all possible model RHSs. 
all.poss.mods.NDT4<-c(1, mods.me_NDT4, mods.inter.NDT4)
all.poss.mods.NDT4
length(all.poss.mods.NDT4) #203,777
#all.poss.mods.clim_VRI_NDT4<-all.poss.mods.clim_VRI_NDT4[-34]
#all.poss.mods.clim_VRI_NDT4<-all.poss.mods.clim_VRI_NDT4[-2] #Use this line only if there is an odd character(0) added to list
length(mods.me_NDT4)
all.poss.mods.NDT4[16386]
all.poss.mods.NDT4<-all.poss.mods.NDT4[-16386]
all.poss.mods.NDT4[2]
all.poss.mods.NDT4<-all.poss.mods.NDT4[-2]

##Check and rid of any duplicated models
duplicated(all.poss.mods.NDT4) #

#If need to determine which ones are character(0), try this:
biglist <- list(list("A","B","C"), "foo", "", character(0), integer(0))
lapply(biglist, function(x) {length(x) == 0L} ) 

#Below does not work
lapply(biglist, all.poss.mods.infra_landuse_NDT4b {length(all.poss.mods.infra_landuse_NDT4b) == 0L} )

```

#Run model selection
Because there are nearly 200,000 models to go through each time, we will do only 1 round at a time. 5 was too many; 2 was even too many. It turns out that even going through it once is too many... try clearing the R space and try once more before dividing it.

```{r}
rm(AIC_lightning_NDT4_treed_summary_topo2, AIC_lightning_NDT4_treed_summary_topo, AIC_lightning_NDT4_treed_topo, AIC_lightning_NDT4_treed_summary_VRI2, AIC_lightning_NDT4_treed_summary_VRI, AIC_lightning_NDT4_treed_VRI, AIC_lightning_NDT4_treed_summary_climate2, AIC_lightning_NDT4_treed_summary_climate, AIC_lightning_NDT4_treed_climate, AIC_lightning_NDT4_treed_clim_VRI, AIC_lightning_NDT4_treed_infra, AIC_lightning_NDT4_treed_summary_clim_VRI, AIC_lightning_NDT4_treed_summary_clim_VRI2, AIC_lightning_NDT4_treed_summary_infra, AIC_lightning_NDT4_treed_summary_infra2, dat1, dat2, spread_150_DEM_roads_wind_10per, spread_150_DEM_roads_wind_2, spread_150_DEM_roads_wind_FIRE, spread_500_DEM)

gc()
```

Split data into training and validation data sets.

```{r}
zones1<-"NDT4"
dat2<- dat_lightning_t %>% dplyr::filter(ntrl_ds ==zones1[h])

model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, !!variables_all_NDT4)

#Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data
prop<-0.75
trainIndex <- createDataPartition(model_dat$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  dat1 <- model_dat[ trainIndex,]
  Valid <- model_dat[-trainIndex,]
  
```

Split the variables into groups. Four groups was still too large.

```{r}
length(all.poss.mods.NDT4)

#If divide into four lists: note, still too large!
all.poss.mods.NDT4_a<-all.poss.mods.NDT4[1:51000]
all.poss.mods.NDT4_b<-all.poss.mods.NDT4[51001:102000]
all.poss.mods.NDT4_c<-all.poss.mods.NDT4[102000:153000]
all.poss.mods.NDT4_d<-all.poss.mods.NDT4[153001:203775]
length(all.poss.mods.NDT4_a)
length(all.poss.mods.NDT4_b)
length(all.poss.mods.NDT4_c)
length(all.poss.mods.NDT4_d)


all.poss.mods.NDT4_a<-all.poss.mods.NDT4[1:25500]
all.poss.mods.NDT4_b<-all.poss.mods.NDT4[25501:51000]
all.poss.mods.NDT4_c<-all.poss.mods.NDT4[51001:76500]
all.poss.mods.NDT4_d<-all.poss.mods.NDT4[76501:102000]
all.poss.mods.NDT4_e<-all.poss.mods.NDT4[102001:127500]
all.poss.mods.NDT4_f<-all.poss.mods.NDT4[127501:153000]
all.poss.mods.NDT4_g<-all.poss.mods.NDT4[153001:178500]
all.poss.mods.NDT4_h<-all.poss.mods.NDT4[178001:203775]
length(all.poss.mods.NDT4_a)
length(all.poss.mods.NDT4_b)
length(all.poss.mods.NDT4_c)
length(all.poss.mods.NDT4_d)
length(all.poss.mods.NDT4_e)
length(all.poss.mods.NDT4_f)
length(all.poss.mods.NDT4_g)
length(all.poss.mods.NDT4_h)

```


Create empty tables for results. Each chunk of potential models will need its own table. We will run this for this first set of training and validation data on all 4 chunks so that AIC is comparable within models.

```{r}
#Create empty table
table.glm.NDT4.simple_set1 <- data.frame (matrix (ncol = 5, nrow = 0))
colnames (table.glm.NDT4.simple_set1) <- c ("model", "edf", "aic", "auc.valid", "NDT")

table.glm.NDT4.simple_set2 <- data.frame (matrix (ncol = 5, nrow = 0))
colnames (table.glm.NDT4.simple_set2) <- c ("model", "edf", "aic", "auc.valid", "NDT")

table.glm.NDT4.simple_set3 <- data.frame (matrix (ncol = 5, nrow = 0))
colnames (table.glm.NDT4.simple_set3) <- c ("model", "edf", "aic", "auc.valid", "NDT")

table.glm.NDT4.simple_set4 <- data.frame (matrix (ncol = 5, nrow = 0))
colnames (table.glm.NDT4.simple_set4) <- c ("model", "edf", "aic", "auc.valid", "NDT")

table.glm.NDT4.simple_set5 <- data.frame (matrix (ncol = 5, nrow = 0))
colnames (table.glm.NDT4.simple_set5) <- c ("model", "edf", "aic", "auc.valid", "NDT")

table.glm.NDT4.simple_set6 <- data.frame (matrix (ncol = 5, nrow = 0))
colnames (table.glm.NDT4.simple_set6) <- c ("model", "edf", "aic", "auc.valid", "NDT")

table.glm.NDT4.simple_set7 <- data.frame (matrix (ncol = 5, nrow = 0))
colnames (table.glm.NDT4.simple_set7) <- c ("model", "edf", "aic", "auc.valid", "NDT")

table.glm.NDT4.simple_set8 <- data.frame (matrix (ncol = 5, nrow = 0))
colnames (table.glm.NDT4.simple_set8) <- c ("model", "edf", "aic", "auc.valid", "NDT")
```

#Run models for each of the quarter chunks with the first set of training and validation data.
Note:set1 works fine, but set2 does not work. 

```{r}
########### Create function ############
big.mod <- function(mods.in, df.train, df.test, dep.var="fire_pres") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.aic, mod.auc))
   
}

#First group
mods.fit_set1 <- lapply(all.poss.mods.NDT4_a, big.mod, df.train=dat1, df.test=Valid)

#terms in each model
x1.1 <- unlist(sapply(mods.fit_set1, '[', 1))
x1.1
#Aic for models
x3.1 <- matrix(unlist(sapply(mods.fit_set1, '[', 3)), ncol=2, byrow=TRUE)
x3.1
#auc from validation data
x4.1 <- unlist(sapply(mods.fit_set1, '[', 4))
x4.1
#combining all as df
tab.sum.NDT4_set1 <- cbind.data.frame(model=x1.1, edf=x3.1[,1], aic=x3.1[,2], auc.valid=x4.1)
tab.sum.NDT4_set1$NDT<-c("NDT4")
tab.sum.NDT4_set1 

table.glm.NDT4.simple_set1<-rbind(table.glm.NDT4.simple_set1, tab.sum.NDT4_set1)
head(table.glm.NDT4.simple_set1)

#Second group
mods.fit_set2 <- lapply(all.poss.mods.NDT4_b, big.mod, df.train=dat1, df.test=Valid)

#terms in each model
x1.1 <- unlist(sapply(mods.fit_set2, '[', 1))
x1.1
#Aic for models
x3.1 <- matrix(unlist(sapply(mods.fit_set2, '[', 3)), ncol=2, byrow=TRUE)
x3.1
#auc from validation data
x4.1 <- unlist(sapply(mods.fit_set2, '[', 4))
x4.1
#combining all as df
tab.sum.NDT4_set2 <- cbind.data.frame(model=x1.1, edf=x3.1[,1], aic=x3.1[,2], auc.valid=x4.1)
tab.sum.NDT4_set2$NDT<-c("NDT4")
tab.sum.NDT4_set2 

table.glm.NDT4.simple_set2<-rbind(table.glm.NDT4.simple_set2, tab.sum.NDT4_set2)

#third group
mods.fit_set3 <- lapply(all.poss.mods.NDT4_c, big.mod, df.train=dat1, df.test=Valid)

#terms in each model
x1.1 <- unlist(sapply(mods.fit_set3, '[', 1))
x1.1
#Aic for models
x3.1 <- matrix(unlist(sapply(mods.fit_set3, '[', 3)), ncol=2, byrow=TRUE)
x3.1
#auc from validation data
x4.1 <- unlist(sapply(mods.fit_set3, '[', 4))
x4.1
#combining all as df
tab.sum.NDT4_set3 <- cbind.data.frame(model=x1.1, edf=x3.1[,1], aic=x3.1[,2], auc.valid=x4.1)
tab.sum.NDT4_set3$NDT<-c("NDT4")
tab.sum.NDT4_set3 

table.glm.NDT4.simple_set3<-rbind(table.glm.NDT4.simple_set3, tab.sum.NDT4_set3)

#Fourth group
mods.fit_set4 <- lapply(all.poss.mods.NDT4_d, big.mod, df.train=dat1, df.test=Valid)

#terms in each model
x1.1 <- unlist(sapply(mods.fit_set4, '[', 1))
x1.1
#Aic for models
x3.1 <- matrix(unlist(sapply(mods.fit_set4, '[', 3)), ncol=2, byrow=TRUE)
x3.1
#auc from validation data
x4.1 <- unlist(sapply(mods.fit_set4, '[', 4))
x4.1
#combining all as df
tab.sum.NDT4_set4 <- cbind.data.frame(model=x1.1, edf=x3.1[,1], aic=x3.1[,2], auc.valid=x4.1)
tab.sum.NDT4_set4$NDT<-c("NDT4")
tab.sum.NDT4_set4 

table.glm.NDT4.simple_set4<-rbind(table.glm.NDT4.simple_set4, tab.sum.NDT4_set4)

#Fifth group
mods.fit_set5 <- lapply(all.poss.mods.NDT4_e, big.mod, df.train=dat1, df.test=Valid)

#terms in each model
x1.1 <- unlist(sapply(mods.fit_set5, '[', 1))
x1.1
#Aic for models
x3.1 <- matrix(unlist(sapply(mods.fit_set5, '[', 3)), ncol=2, byrow=TRUE)
x3.1
#auc from validation data
x4.1 <- unlist(sapply(mods.fit_set5, '[', 4))
x4.1
#combining all as df
tab.sum.NDT4_set5 <- cbind.data.frame(model=x1.1, edf=x3.1[,1], aic=x3.1[,2], auc.valid=x4.1)
tab.sum.NDT4_set5$NDT<-c("NDT4")
tab.sum.NDT4_set5 

table.glm.NDT4.simple_set5<-rbind(table.glm.NDT4.simple_set5, tab.sum.NDT4_set5)

#Sixth group
mods.fit_set6 <- lapply(all.poss.mods.NDT4_f, big.mod, df.train=dat1, df.test=Valid)

#terms in each model
x1.1 <- unlist(sapply(mods.fit_set6, '[', 1))
x1.1
#Aic for models
x3.1 <- matrix(unlist(sapply(mods.fit_set6, '[', 3)), ncol=2, byrow=TRUE)
x3.1
#auc from validation data
x4.1 <- unlist(sapply(mods.fit_set6, '[', 4))
x4.1
#combining all as df
tab.sum.NDT4_set6 <- cbind.data.frame(model=x1.1, edf=x3.1[,1], aic=x3.1[,2], auc.valid=x4.1)
tab.sum.NDT4_set6$NDT<-c("NDT4")
tab.sum.NDT4_set6 

table.glm.NDT4.simple_set6<-rbind(table.glm.NDT4.simple_set6, tab.sum.NDT4_set6)

#Seventh group
mods.fit_set7 <- lapply(all.poss.mods.NDT4_g, big.mod, df.train=dat1, df.test=Valid)

#terms in each model
x1.1 <- unlist(sapply(mods.fit_set7, '[', 1))
x1.1
#Aic for models
x3.1 <- matrix(unlist(sapply(mods.fit_set7, '[', 3)), ncol=2, byrow=TRUE)
x3.1
#auc from validation data
x4.1 <- unlist(sapply(mods.fit_set7, '[', 4))
x4.1
#combining all as df
tab.sum.NDT4_set7 <- cbind.data.frame(model=x1.1, edf=x3.1[,1], aic=x3.1[,2], auc.valid=x4.1)
tab.sum.NDT4_set7$NDT<-c("NDT4")
tab.sum.NDT4_set7 

table.glm.NDT4.simple_set7<-rbind(table.glm.NDT4.simple_set7, tab.sum.NDT4_set7)

#Eigth Group
mods.fit_set8 <- lapply(all.poss.mods.NDT4_h, big.mod, df.train=dat1, df.test=Valid)

#terms in each model
x1.1 <- unlist(sapply(mods.fit_set8, '[', 1))
x1.1
#Aic for models
x3.1 <- matrix(unlist(sapply(mods.fit_set8, '[', 3)), ncol=2, byrow=TRUE)
x3.1
#auc from validation data
x4.1 <- unlist(sapply(mods.fit_set8, '[', 4))
x4.1
#combining all as df
tab.sum.NDT4_set8 <- cbind.data.frame(model=x1.1, edf=x3.1[,1], aic=x3.1[,2], auc.valid=x4.1)
tab.sum.NDT4_set8$NDT<-c("NDT4")
tab.sum.NDT4_set8 

table.glm.NDT4.simple_set8<-rbind(table.glm.NDT4.simple_set8, tab.sum.NDT4_set8)

```

Create new training and validation data sets.

```{r}
#Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data
prop<-0.75
trainIndex <- createDataPartition(model_dat$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  dat1 <- model_dat[ trainIndex,]
  Valid <- model_dat[-trainIndex,]
```

Repeat above if the first round worked. 

```{r}
#First group
mods.fit_set1 <- lapply(all.poss.mods.NDT4_a, big.mod, df.train=dat1, df.test=Valid)

#terms in each model
x1.1 <- unlist(sapply(mods.fit_set1, '[', 1))
x1.1
#Aic for models
x3.1 <- matrix(unlist(sapply(mods.fit_set1, '[', 3)), ncol=2, byrow=TRUE)
x3.1
#auc from validation data
x4.1 <- unlist(sapply(mods.fit_set1, '[', 4))
x4.1
#combining all as df
tab.sum.NDT4_set1 <- cbind.data.frame(model=x1.1, edf=x3.1[,1], aic=x3.1[,2], auc.valid=x4.1)
tab.sum.NDT4_set1$NDT<-c("NDT4")
tab.sum.NDT4_set1 

table.glm.NDT4.simple_set1<-rbind(table.glm.NDT4.simple_set1, tab.sum.NDT4_set1)
head(table.glm.NDT4.simple_set1)

#Second group
mods.fit_set2 <- lapply(all.poss.mods.NDT4_b, big.mod, df.train=dat1, df.test=Valid)

#terms in each model
x1.1 <- unlist(sapply(mods.fit_set2, '[', 1))
x1.1
#Aic for models
x3.1 <- matrix(unlist(sapply(mods.fit_set2, '[', 3)), ncol=2, byrow=TRUE)
x3.1
#auc from validation data
x4.1 <- unlist(sapply(mods.fit_set2, '[', 4))
x4.1
#combining all as df
tab.sum.NDT4_set2 <- cbind.data.frame(model=x1.1, edf=x3.1[,1], aic=x3.1[,2], auc.valid=x4_set2.1)
tab.sum.NDT4_set2$NDT<-c("NDT4")
tab.sum.NDT4_set2 

table.glm.NDT4.simple_set2<-rbind(table.glm.NDT4.simple_set2, tab.sum.NDT4_set2)

#third group
mods.fit_set3 <- lapply(all.poss.mods.NDT4_c, big.mod, df.train=dat1, df.test=Valid)

#terms in each model
x1.1 <- unlist(sapply(mods.fit_set3, '[', 1))
x1.1
#Aic for models
x3.1 <- matrix(unlist(sapply(mods.fit_set3, '[', 3)), ncol=2, byrow=TRUE)
x3.1
#auc from validation data
x4.1 <- unlist(sapply(mods.fit_set3, '[', 4))
x4.1
#combining all as df
tab.sum.NDT4_set3 <- cbind.data.frame(model=x1.1, edf=x3.1[,1], aic=x3.1[,2], auc.valid=x4.1)
tab.sum.NDT4_set3$NDT<-c("NDT4")
tab.sum.NDT4_set3 

table.glm.NDT4.simple_set3<-rbind(table.glm.NDT4.simple_set3, tab.sum.NDT4_set3)

#Fourth group
mods.fit_set4 <- lapply(all.poss.mods.NDT4_d, big.mod, df.train=dat1, df.test=Valid)

#terms in each model
x1.1 <- unlist(sapply(mods.fit_set4, '[', 1))
x1.1
#Aic for models
x3.1 <- matrix(unlist(sapply(mods.fit_set4, '[', 3)), ncol=2, byrow=TRUE)
x3.1
#auc from validation data
x4.1 <- unlist(sapply(mods.fit_set4, '[', 4))
x4.1
#combining all as df
tab.sum.NDT4_set4 <- cbind.data.frame(model=x1.1, edf=x3.1[,1], aic=x3.1[,2], auc.valid=x4.1)
tab.sum.NDT4_set4$NDT<-c("NDT4")
tab.sum.NDT4_set4 

table.glm.NDT4.simple_set4<-rbind(table.glm.NDT4.simple_set4, tab.sum.NDT4_set4)

#Fifth group
mods.fit_set5 <- lapply(all.poss.mods.NDT4_e, big.mod, df.train=dat1, df.test=Valid)

#terms in each model
x1.1 <- unlist(sapply(mods.fit_set5, '[', 1))
x1.1
#Aic for models
x3.1 <- matrix(unlist(sapply(mods.fit_set5, '[', 3)), ncol=2, byrow=TRUE)
x3.1
#auc from validation data
x4.1 <- unlist(sapply(mods.fit_set5, '[', 4))
x4.1
#combining all as df
tab.sum.NDT4_set5 <- cbind.data.frame(model=x1.1, edf=x3.1[,1], aic=x3.1[,2], auc.valid=x4.1)
tab.sum.NDT4_set5$NDT<-c("NDT4")
tab.sum.NDT4_set5 

table.glm.NDT4.simple_set5<-rbind(table.glm.NDT4.simple_set5, tab.sum.NDT4_set5)

#Sixth group
mods.fit_set6 <- lapply(all.poss.mods.NDT4_f, big.mod, df.train=dat1, df.test=Valid)

#terms in each model
x1.1 <- unlist(sapply(mods.fit_set6, '[', 1))
x1.1
#Aic for models
x3.1 <- matrix(unlist(sapply(mods.fit_set6, '[', 3)), ncol=2, byrow=TRUE)
x3.1
#auc from validation data
x4.1 <- unlist(sapply(mods.fit_set6, '[', 4))
x4.1
#combining all as df
tab.sum.NDT4_set6 <- cbind.data.frame(model=x1.1, edf=x3.1[,1], aic=x3.1[,2], auc.valid=x4.1)
tab.sum.NDT4_set6$NDT<-c("NDT4")
tab.sum.NDT4_set6 

table.glm.NDT4.simple_set6<-rbind(table.glm.NDT4.simple_set6, tab.sum.NDT4_set6)

#Seventh group
mods.fit_set7 <- lapply(all.poss.mods.NDT4_g, big.mod, df.train=dat1, df.test=Valid)

#terms in each model
x1.1 <- unlist(sapply(mods.fit_set7, '[', 1))
x1.1
#Aic for models
x3.1 <- matrix(unlist(sapply(mods.fit_set7, '[', 3)), ncol=2, byrow=TRUE)
x3.1
#auc from validation data
x4.1 <- unlist(sapply(mods.fit_set7, '[', 4))
x4.1
#combining all as df
tab.sum.NDT4_set7 <- cbind.data.frame(model=x1.1, edf=x3.1[,1], aic=x3.1[,2], auc.valid=x4.1)
tab.sum.NDT4_set7$NDT<-c("NDT4")
tab.sum.NDT4_set7 

table.glm.NDT4.simple_set7<-rbind(table.glm.NDT4.simple_set7, tab.sum.NDT4_set7)

#Eigth Group
mods.fit_set8 <- lapply(all.poss.mods.NDT4_h, big.mod, df.train=dat1, df.test=Valid)

#terms in each model
x1.1 <- unlist(sapply(mods.fit_set8, '[', 1))
x1.1
#Aic for models
x3.1 <- matrix(unlist(sapply(mods.fit_set8, '[', 3)), ncol=2, byrow=TRUE)
x3.1
#auc from validation data
x4.1 <- unlist(sapply(mods.fit_set8, '[', 4))
x4.1
#combining all as df
tab.sum.NDT4_set8 <- cbind.data.frame(model=x1.1, edf=x3.1[,1], aic=x3.1[,2], auc.valid=x4.1)
tab.sum.NDT4_set8$NDT<-c("NDT4")
tab.sum.NDT4_set8 

table.glm.NDT4.simple_set8<-rbind(table.glm.NDT4.simple_set8, tab.sum.NDT4_set8)

```

#Rerun the above WITH NEW testing and validation data sets and append the data to the bottom of each subsequent run for the respective grouping of variables. 
This needs to be run at a minimum of 5 times initially to see the variation in AUC to determine if that is sufficient. Once the tables are appended from each set, we will then calculate the meanAIC, meanAUC and sdAUC. Hopefully we can append the rows to each new subsequent run to be able to get these values...

Now, append the tables together for each set (set1, set2, set3, set4, set5), and calculate the mean AIC and mean AUC. Put these mean values into a table. Then combine the tables between sets, with the mean values. Then calculate deltaAIC.


```{r}
head(table.glm.NDT4.simple_set1)
table(table.glm.NDT4.simple_set1$model) # check how many models each

table.glm.NDT4.simple_set1_summary<- table.glm.NDT4.simple_set1 %>%
  group_by(model) %>%
  summarise(meanAIC=mean(aic),
            meanAUC=mean(auc.valid),
            sdAUC=sd(auc.valid),
            )
#Repeat above for every set

#Append all sets together
table.glm.NDT4.simple_summary<-rbind(table.glm.NDT4.simple_set1_summary, table.glm.NDT4.simple_set2_summary, table.glm.NDT4.simple_set3_summary, table.glm.NDT4.simple_set4_summary, table.glm.NDT4.simple_set5_summary, table.glm.NDT4.simple_set6_summary, table.glm.NDT4.simple_set7_summary, table.glm.NDT4.simple_set8_summary)

table.glm.NDT4.simple_summary_2<- table.glm.NDT4.simple_summary %>%
  mutate(deltaAIC=meanAIC-min(meanAIC))

head(table.glm.NDT4.simple_summary_2)
```

Save to computer.
```{r}
write.csv(table.glm.NDT4.simple_summary_2, file="D:\\Fire\\fire_data\\raw_data\\AIC_lightning_NDT4_treed_summary_ALLVAR.csv")
```

