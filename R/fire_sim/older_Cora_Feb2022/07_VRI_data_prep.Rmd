---
title: "VRI_data_prep"
author: "Elizabeth Kleynhans"
date: "07/07/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

<!--
Copyright 2021 Province of British Columbia

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and limitations under the License.
-->


#=================================
#  Script Name: 07_vri_data_prep.R
#  Script Version: 1.0
#  Script Purpose: This script creates a table of 1ha x 1ha pixels with vegetation data taken from the VRI for each year for each location.  These locations line up with the locations that I collected climate data from. 
#  Script Author: Elizabeth Kleynhans, Ecological Modeling Specialist, Forest Analysis and Inventory Branch, B.C. Ministry of Forests, Lands, and Natural Resource Operations.
#  Script Contributor: Cora Skaien, Ecological Modeling Specialist, Forest Analysis and Inventory Branch, B.C. Ministry of Forests, Lands, and Natural Resource Operations.
#=================================

#Overview:
In this file, we acquire the VRI (Vegetation Resources Inventory) for each year by location from 2002 to 2020. This is likely already uploaded onto a network and may not need to be redone.
The final product will be a file with veg data along with ignition data and climate data (vegetation, climate and presence/absence of fire data).

The first portion of this code cannot be run on R. Instead, you must use PgAdmin command line.


#### VEGETATION DATA #### 
2002 to 2019 are the only years that VRI data exists, there is no earlier data. I have located a 2020 data file, but it has some too but not all columns for VRI info.

##This first section has been completed on this computer.
from https://catalogue.data.gov.bc.ca/dataset/vri-historical-vegetation-resource-inventory-2002-2019-
I (Liz) then extracted this data and uploaded it into my local postgres database by running the command below in terminal. If running it in the R terminal does not work try run it in here: 
#C:\data\localApps\QGIS10.16\OSGeo4W (the terminal window)

You may get a warning indicating that this will take a long time, or that databases are not supported. You should specify a specific item within the database.
#ogr2ogr -f "PostgreSQL" PG:"host=localhost user=postgres dbname=postgres password=postgres port=5432" C:\\Work\\caribou\\clus_data\\Fire\\VEG_COMP_POLY_AND_LAYER_2020.gdb -overwrite -a_srs EPSG:3005 -progress --config PG_USE_COPY YES -nlt PROMOTE_TO_MULTI

Above is run or each year 2002 to 2020 separately from the data. This is already on the private server, so if you are using the private server, you do not need to run again.

# rename the table in postgres if need be
#ALTER TABLE veg_comp_lyr_r1_poly RENAME TO veg_comp_lyr_r1_poly2017

# When the table name is changed the idx name is not so you might have to change that too so that more files can be uploaded into postgres by running the following command
#ALTER INDEX veg_comp_lyr_r1_poly_shape_geom_idx RENAME TO veg_comp_lyr_r1_poly2019_geometry_geom_idx;
# and if need be change the name of the geometry column from shape to geometry
#ALTER TABLE veg_comp_lyr_r1_poly2019 RENAME COLUMN shape TO geometry;

#### Join ignition data to VRI data ####
Run following query in postgres for all years 2002-2019 except 2007 and 2008. 2020 also has slightly different code. This will need to be done each time new data is generated for random points in file 02. This below code is fast. Note, there are 5 locations in the below code for which to update the year.

Depending on how the file names most recently saved, some changes may need to be made (e.g., ign_mnt versus ign_month).

CREATE TABLE fire_veg_2002_B AS
(SELECT feature_id, bclcs_level_2, bclcs_level_3, bclcs_level_4, bclcs_level_5,
  harvest_date, proj_age_1, proj_height_1, live_stand_volume_125, stand_percentage_dead, 
  fire.idno, fire.fire_yr, fire.fire_cs, fire.fir_typ, fire.ign_month, fire.size_ha, fire.fire,
  fire.zone, fire.subzone, fire.ntrl_ds, fire.tmax05, fire.tmax06, fire.tmax07,
  fire.tmax08, fire.tmax09, fire.tave05, fire.tave06, fire.tave07, fire.tave08,
  fire.tave09, fire.ppt05, fire.ppt06, fire.ppt07, fire.ppt08, fire.ppt09,
  fire.mdc_05, fire.mdc_06, fire.mdc_07, fire.mdc_08, fire.mdc_09, fire.slp_h_b,
  fire.aspct__, fire.dm_h_bc,  fire.shp_ln_, fire.win_sum, 
  fire.win_spg, fire.dist_mun, fire.dist_dam, fire.dist_nat, fire.dist_pow, fire.dist_mine, fire.dist_any,
  veg_comp_lyr_r1_poly2002.geometry FROM veg_comp_lyr_r1_poly2002,
  (SELECT wkb_geometry, idno, fire_yr, fire_cs, fir_typ, ign_month, size_ha, fire, zone,
   subzone, ntrl_ds, tmax05, tmax06, tmax07, tmax08, tmax09, tave05, tave06, tave07,
   tave08, tave09, ppt05, ppt06, ppt07, ppt08, ppt09, mdc_05, mdc_06, mdc_07, mdc_08,
   mdc_09, slp_h_b, aspct__, dm_h_bc,  shp_ln_, win_sum, win_spg,
   dist_mun, dist_dam, dist_nat, dist_pow, dist_mine, dist_any 
   from Data_ignite where fire_yr = '2002') as fire where st_contains
  (veg_comp_lyr_r1_poly2002.geometry, fire.wkb_geometry))


## See specifics of land cover types here: https://www2.gov.bc.ca/assets/gov/environment/natural-resource-stewardship/nr-laws-policy/risc/landcover-02.pdf
bclcs_level_2: The second level of the BC land cover classification scheme classifies the polygon as to the land cover type:
   # treed or non-treed for vegetated polygons; land or water for non-vegetated polygons.
bclcs_level_3: The location of the polygon relative to elevation and drainage, and is described as either alpine, wetland
   # or upland. In rare cases, the polygon may be alpine wetland.
bclcs_level_4: Classifies the vegetation types and non-vegetated cover types (as described by the presence of distinct features
    # upon the land base within the polygon).
bclcs_level_5: Classifies the vegetation density classes and Non-Vegetated categories.



############## 
#For 2020, run this code because no projected age, height or stand volume 
##############
CREATE TABLE fire_veg_2020_B AS
(SELECT feature_id, bclcs_level_2, bclcs_level_3, bclcs_level_4, bclcs_level_5,
  harvest_date,
  fire.idno, fire.fire_yr, fire.fire_cs, fire.fir_typ, fire.ign_month, fire.size_ha, fire.fire,
  fire.zone, fire.subzone, fire.ntrl_ds, fire.tmax05, fire.tmax06, fire.tmax07,
  fire.tmax08, fire.tmax09, fire.tave05, fire.tave06, fire.tave07, fire.tave08,
  fire.tave09, fire.ppt05, fire.ppt06, fire.ppt07, fire.ppt08, fire.ppt09,
  fire.mdc_05, fire.mdc_06, fire.mdc_07, fire.mdc_08, fire.mdc_09, fire. slp_h_b, 
  fire.aspct__, fire.dm_h_bc,  fire.shp_ln_, fire.win_sum, fire.win_spg, fire.dist_mun, fire.dist_dam, fire.dist_nat, fire.dist_pow, fire.dist_mine, fire.dist_any,
  veg_comp_lyr_r1_poly2020.geometry FROM veg_comp_lyr_r1_poly2020,
  (SELECT wkb_geometry, idno, fire_yr, fire_cs, fir_typ, ign_month, size_ha, fire, zone,
   subzone, ntrl_ds, tmax05, tmax06, tmax07, tmax08, tmax09, tave05, tave06, tave07,
   tave08, tave09, ppt05, ppt06, ppt07, ppt08, ppt09, mdc_05, mdc_06, mdc_07, mdc_08,
   mdc_09, slp_h_b, aspct__,dm_h_bc,  shp_ln_, win_sum, win_spg,
   dist_mun, dist_dam, dist_nat, dist_pow, dist_mine, dist_any
   from Data_ignite where fire_yr = '2020') as fire where st_contains
  (veg_comp_lyr_r1_poly2020.geometry, fire.wkb_geometry))


###################
#FOR 2007 run this because some of the names for the VRI_2007 file are different to what they are in other years. In particular:
###################

# bclcs_level_2 = bclcs_lv_2 same for the other bclcs layers
#proj_height_1 = proj_ht_1
#harvest_date = upd_htdate
# live_stand_volume_125 does not exist, so fancy stuff created
# percent_dead does not exist

 CREATE TABLE fire_veg_2007_B AS
 (SELECT feature_id, bclcs_lv_2, bclcs_lv_3, bclcs_lv_4, bclcs_lv_5,
  upd_htdate, proj_age_1, proj_ht_1, COALESCE(volsp1_125,0)+COALESCE(volsp2_125,0)+COALESCE(volsp3_125,0)+COALESCE(volsp4_125,0)+COALESCE(volsp5_125,0) AS live_stand_volume_125, 
  fire.idno, fire.fire_yr, fire.fire_cs, fire.fir_typ, fire.ign_month, fire.size_ha, fire.fire,
  fire.zone, fire.subzone, fire.ntrl_ds, fire.tmax05, fire.tmax06, fire.tmax07,
  fire.tmax08, fire.tmax09, fire.tave05, fire.tave06, fire.tave07, fire.tave08,
  fire.tave09, fire.ppt05, fire.ppt06, fire.ppt07, fire.ppt08, fire.ppt09,
  fire.mdc_05, fire.mdc_06, fire.mdc_07, fire.mdc_08, fire.mdc_09, fire. slp_h_b, 
  fire.aspct__,fire.dm_h_bc,  fire.shp_ln_, fire.win_sum, fire.win_spg, fire.dist_mun, fire.dist_dam, fire.dist_nat, fire.dist_pow, fire.dist_mine, fire.dist_any,
  veg_comp_lyr_r1_poly2007.geometry FROM veg_comp_lyr_r1_poly2007,
  (SELECT wkb_geometry, idno, fire_yr, fire_cs, fir_typ, ign_month, size_ha, fire, zone,
   subzone, ntrl_ds, tmax05, tmax06, tmax07, tmax08, tmax09, tave05, tave06, tave07,
   tave08, tave09, ppt05, ppt06, ppt07, ppt08, ppt09, mdc_05, mdc_06, mdc_07, mdc_08,
   mdc_09, slp_h_b, aspct__, dm_h_bc,  shp_ln_, win_sum, win_spg, 
   dist_mun, dist_dam, dist_nat, dist_pow, dist_mine, dist_any
   from Data_ignite where fire_yr = '2007') 
   as fire where st_contains (veg_comp_lyr_r1_poly2007.geometry, fire.wkb_geometry))


##############################
# FOR 2008 Run this code:
No  stand_percentage_dead, 
##############################
 CREATE TABLE fire_veg_2008_B AS
 (SELECT feature_id, bclcs_level_2, bclcs_level_3, bclcs_level_4, bclcs_level_5,
   harvest_date, proj_age_1, proj_height_1, COALESCE(vol_per_ha_spp1_125,0)+
     COALESCE(vol_per_ha_spp2_125,0)+COALESCE(vol_per_ha_spp3_125,0)+COALESCE(vol_per_ha_spp4_125,0)
   +COALESCE(vol_per_ha_spp5_125,0)+COALESCE(vol_per_ha_spp6_125,0) AS live_stand_volume_125,
   fire.idno, fire.fire_yr, fire.fire_cs, fire.fir_typ, fire.ign_month, fire.size_ha, fire.fire,
   fire.zone, fire.subzone, fire.ntrl_ds, fire.tmax05, fire.tmax06, fire.tmax07,
   fire.tmax08, fire.tmax09, fire.tave05, fire.tave06, fire.tave07, fire.tave08,
   fire.tave09, fire.ppt05, fire.ppt06, fire.ppt07, fire.ppt08, fire.ppt09,
   fire.mdc_05, fire.mdc_06, fire.mdc_07, fire.mdc_08, fire.mdc_09, fire. slp_h_b, 
   fire.aspct__, fire. dm_h_bc,  fire.shp_ln_, fire.win_sum, fire.win_spg, fire.dist_mun, fire.dist_dam, fire.dist_nat, fire.dist_pow, fire.dist_mine, fire.dist_any,
   veg_comp_lyr_r1_poly2008.geometry FROM veg_comp_lyr_r1_poly2008,
   (SELECT wkb_geometry, idno, fire_yr, fire_cs, fir_typ, ign_month, size_ha, fire, zone,
    subzone, ntrl_ds, tmax05, tmax06, tmax07, tmax08, tmax09, tave05, tave06, tave07,
    tave08, tave09, ppt05, ppt06, ppt07, ppt08, ppt09, mdc_05, mdc_06, mdc_07, mdc_08,
    mdc_09, slp_h_b, aspct__, dm_h_bc,  shp_ln_, win_sum, win_spg, 
    dist_mun, dist_dam, dist_nat, dist_pow, dist_mine, dist_any
    from Data_ignite where fire_yr = '2008') 
    as fire where st_contains (veg_comp_lyr_r1_poly2008.geometry, fire.wkb_geometry))


# note that the VRI for 2008 does not have live_stand_volume so I also tried to extract it from the 2009 VRI and put it in here -  assuming that a year would not make much difference to volume. Below is the code i used to try and do this (but note this does not seem to work.... )
### July 2021, when ran, there already is a column for live_stand_volume_125,  so this may not be necessary

#ALTER TABLE fire_veg_2008_B
#ADD COLUMN live_stand_volume_125 double precision;

# INSERT INTO fire_veg_2008_B
# SELECT live_stand_volume_125
# FROM veg_comp_lyr_r1_poly2009,
# (SELECT wkb_geometry from Data_ignite where fire_yr = '2008') as fire where st_contains
# (veg_comp_lyr_r1_poly2009.geometry, fire.wkb_geometry)

#Do for percentage dead as a proxy
ALTER TABLE fire_veg_2008_B
ADD COLUMN stand_percentage_dead double precision;

 INSERT INTO fire_veg_2008_B
 SELECT stand_percentage_dead
 FROM veg_comp_lyr_r1_poly2009,
 (SELECT wkb_geometry from Data_ignite where fire_yr = '2008') as fire where st_contains
 (veg_comp_lyr_r1_poly2009.geometry, fire.wkb_geometry)

#Do for 2007 as well despite not being as accurate because otherwise column names will not match when we append the data.
#Do for percentage dead as a proxy
ALTER TABLE fire_veg_2007_B
ADD COLUMN stand_percentage_dead double precision;

 INSERT INTO fire_veg_2007_B
 SELECT stand_percentage_dead
 FROM veg_comp_lyr_r1_poly2009,
 (SELECT wkb_geometry from Data_ignite where fire_yr = '2007') as fire where st_contains
 (veg_comp_lyr_r1_poly2009.geometry, fire.wkb_geometry)

# Another problem is that fire_veg_2011 has a geometry column that is type MultiPolygonZ instead of MultiPolygon so this needs to be changed with the following query in postgres
 ALTER TABLE fire_veg_2011_B  
 ALTER COLUMN geometry TYPE geometry(MULTIPOLYGON, 3005) 
 USING ST_Force2D(geometry);

Now, we can use R for the next step.

=====================

```{r}
#Load necessary libraries

library(dplyr)
library(tidyr)
library(keyring)
library(sf)
library(DBI)
library(purrr)
library(tidyverse)
library(ggplot2)
library (ggcorrplot)
library (RPostgreSQL)
library (rpostgis)
library (lme4)
library (arm)
library(ggpubr)
library(mgcv)
library(nlme)
library(caret)
library(pROC)

source(here::here("R/functions/R_Postgres.R"))

```

Now we will bring all of the files we made above into R. You may need to create a new connection to bring each one in instead, or at least run line by line and not as a code chunk.

```{r}
#Import all fire_veg
conn <- dbConnect (dbDriver ("PostgreSQL"), 
                   host = "",
                   user = "postgres",
                   dbname = "postgres",
                   password = "postgres",
                   port = "5432")
fire_veg_2002 <- sf::st_read  (dsn = conn, # connKyle
                               query = "SELECT * FROM public.fire_veg_2002_B")
fire_veg_2003 <- sf::st_read  (dsn = conn, # connKyle
                               query = "SELECT * FROM public.fire_veg_2003_B")
fire_veg_2004 <- sf::st_read  (dsn = conn, # connKyle
                               query = "SELECT * FROM public.fire_veg_2004_B")
fire_veg_2005 <- sf::st_read  (dsn = conn, # connKyle
                               query = "SELECT * FROM public.fire_veg_2005_B")
fire_veg_2006 <- sf::st_read  (dsn = conn, # connKyle
                               query = "SELECT * FROM public.fire_veg_2006_B")
fire_veg_2007 <- sf::st_read  (dsn = conn, # connKyle
                               query = "SELECT * FROM public.fire_veg_2007_B")
fire_veg_2008 <- sf::st_read  (dsn = conn, # connKyle
                               query = "SELECT * FROM public.fire_veg_2008_B")
fire_veg_2009 <- sf::st_read  (dsn = conn, # connKyle
                               query = "SELECT * FROM public.fire_veg_2009_B")
fire_veg_2010 <- sf::st_read  (dsn = conn, # connKyle
                               query = "SELECT * FROM public.fire_veg_2010_B")
fire_veg_2011 <- sf::st_read  (dsn = conn, # connKyle
                               query = "SELECT * FROM public.fire_veg_2011_B")
fire_veg_2012 <- sf::st_read  (dsn = conn, # connKyle
                               query = "SELECT * FROM public.fire_veg_2012_B")
fire_veg_2013 <- sf::st_read  (dsn = conn, # connKyle
                               query = "SELECT * FROM public.fire_veg_2013_B")
fire_veg_2014 <- sf::st_read  (dsn = conn, # connKyle
                               query = "SELECT * FROM public.fire_veg_2014_B")
fire_veg_2015 <- sf::st_read  (dsn = conn, # connKyle
                               query = "SELECT * FROM public.fire_veg_2015_B")
fire_veg_2016 <- sf::st_read  (dsn = conn, # connKyle
                               query = "SELECT * FROM public.fire_veg_2016_B")
fire_veg_2017 <- sf::st_read  (dsn = conn, # connKyle
                               query = "SELECT * FROM public.fire_veg_2017_B")
fire_veg_2018 <- sf::st_read  (dsn = conn, # connKyle
                               query = "SELECT * FROM public.fire_veg_2018_B")
fire_veg_2019 <- sf::st_read  (dsn = conn, # connKyle
                               query = "SELECT * FROM public.fire_veg_2019_B")
fire_veg_2020 <- sf::st_read  (dsn = conn, # connKyle
                               query = "SELECT * FROM public.fire_veg_2020_B")


dbDisconnect (conn) # connKyle

```

We need to update naming conventions from the 2007 and 2008 data given that it is different in those VRI files than for other years.

```{r}
# REMEMBER TO CHANGE THE 0 values in the 2007 and 2008 fire_veg datasets for volume to NULL.

# the VRI for 2007 had harvest_date named upd_htdate and proj_height_1, proj_height_2 as proj_ht_1, proj_ht_2. So I need to be renamed these columns
#fire_veg_2007$harvest_date <- NA
names(fire_veg_2007)
names(fire_veg_2002)
fire_veg_2007<- fire_veg_2007 %>% rename(
  bclcs_level_2=bclcs_lv_2,
  bclcs_level_3=bclcs_lv_3,
  bclcs_level_4=bclcs_lv_4,
  bclcs_level_5=bclcs_lv_5,
  proj_height_1=proj_ht_1, 
  harvest_date=upd_htdate)


# change the 0 values in live_stand_volume_125 to NULL for both 2007 and 2008 data

fire_veg_2007$live_stand_volume_125[fire_veg_2007$live_stand_volume_125 == 0] <- NA
fire_veg_2008$live_stand_volume_125[fire_veg_2008$live_stand_volume_125 == 0] <- NA

fire_veg_2020$proj_height_1<-NA
fire_veg_2020$proj_age_1<-NA
fire_veg_2020$live_stand_volume_125<-NA
fire_veg_2020$stand_percentage_dead<-NA

```

Now we must combine all of the files together into one.

```{r}
# join all fire_veg datasets together. This function is faster than a list of rbinds
filenames3<- c("fire_veg_2002", "fire_veg_2003", "fire_veg_2004","fire_veg_2005", "fire_veg_2006", "fire_veg_2007","fire_veg_2008", "fire_veg_2009", "fire_veg_2010","fire_veg_2011", "fire_veg_2012", "fire_veg_2013","fire_veg_2014", "fire_veg_2015", "fire_veg_2016","fire_veg_2017", "fire_veg_2018", "fire_veg_2019", "fire_veg_2020")
filenames3

mkFrameList <- function(nfiles) {
  d <- lapply(seq_len(nfiles),function(i) {
    eval(parse(text=filenames3[i])) # for new files lists change the name at filenames2
  })
  do.call(rbind,d)
}

n<-length(filenames3)
fire_veg_data_B<-mkFrameList(n)

table(fire_veg_data_B$fire_yr, fire_veg_data_B$fire_cs)


#Rename columns for ease of use
head(fire_veg_data_B)
fire_veg_data_B<- fire_veg_data_B %>% rename(
  slope=slp_h_b,
  aspect=aspct__,
  elevation=dm_h_bc,
  roads_km=shp_ln_)
names(fire_veg_data_B)

```
Try saving file, but you will note that it is too large.

```{r}
st_write(fire_veg_data_B, dsn = "D:\\Fire\\fire_data\\raw_data\\ClimateBC_Data\\fire_ignitions_veg_climate_ALL_5x.shp", delete_layer=TRUE)
```

Because we have many large objects open in R, we will close some that we no longer need.

```{r}
##Now we will remove all of the fire_veg_20XX files since we are finished with processing these

rm(fire_veg_2002, fire_veg_2003, fire_veg_2004,fire_veg_2005, fire_veg_2006, fire_veg_2007,fire_veg_2008, fire_veg_2009, fire_veg_2010,fire_veg_2011, fire_veg_2012, fire_veg_2013,fire_veg_2014, fire_veg_2015, fire_veg_2016,fire_veg_2017, fire_veg_2018, fire_veg_2019, fire_veg_2020)

```

Files are too large to save. So we will subsample here before moving on to next file. Some processing must occur first. We will remove all sites that are predominately water, for example.

Note: do we want to remove sites that are predominately water? Might be good to have in? Instead, however, we can mask at the start to remove all sites that are water from being eligible to be on fire.

```{r}
##1. Remove all sites that are predominately water
str(fire_veg_data_B)
ignition_pres_abs3 <-fire_veg_data_B %>%
  filter(bclcs_level_2!="W") %>%
  filter(bclcs_level_2!=" ")
table(ignition_pres_abs3$bclcs_level_2, ignition_pres_abs3$fire_cs) # T=treed, N =  non-treed and L = land.
table(ignition_pres_abs3$fire_yr, ignition_pres_abs3$fire_cs) 
str(ignition_pres_abs3)

#Creating new variable of vegetation type and a description of how open the vegetation is
# TB =  Treed broadleaf, TC = Treed Conifer, TM = Treed mixed, SL = short shrub, ST = tall shrubs, D = disturbed, O = open. I will combine tall and short shrub. We dont estimate shrub cover in our CLUS model so Im not sure how this will influence our results since I dont think I can track it over time. Maybe I should include it in Open or disturbed?

ignition_pres_abs3$bclcs_level_4<- as.factor(ignition_pres_abs3$bclcs_level_4)
ignition_pres_abs4<- ignition_pres_abs3 %>% drop_na(bclcs_level_4) # this drops from 389464 to 389394 locations so I think its ok to remove the NA's
unique(ignition_pres_abs4$bclcs_level_4)

ignition_pres_abs4$vegtype<-"OP" #setting anything that is not one of the categories below to Open.
ignition_pres_abs4 <- ignition_pres_abs4 %>%
  mutate(vegtype = if_else(bclcs_level_4=="TC","TC", # Treed coniferous
                           if_else(bclcs_level_4=="TM", "TM", # Treed mixed
                                   if_else(bclcs_level_4== "TB","TB", #Treed broadleaf
                                           if_else(bclcs_level_4=="SL", "S", # shrub
                                                   if_else(bclcs_level_4=="ST", "S", vegtype))))))
ignition_pres_abs4$vegtype[which(ignition_pres_abs4$proj_age_1 <16)]<-"D" # disturbed -  following Marchal et al 2017 I make anything that is younger than 15 years old to disturbed. This might be something I should check whether this assumption is ok.

#ignition_pres_abs4<- ignition_pres_abs4 %>% filter(fir_typ!="Nuisance Fire") 
table(ignition_pres_abs4$vegtype, ignition_pres_abs4$fire_cs)

# look at vegetation height, volume and age as we track these in CLUS. 
ignition_pres_abs4$proj_age_1<- as.numeric(ignition_pres_abs4$proj_age_1)
hist(ignition_pres_abs4$proj_age_1)
hist(ignition_pres_abs4$proj_height_1) # not sure we have height in CLUS, we do have volume though. So maybe I should include age and volume in my model. This might be a surrogate for height
hist(ignition_pres_abs4$live_stand_volume_125)
hist(log(ignition_pres_abs4$live_stand_volume_125))
```

Try saving file again.

```{r}
st_write(ignition_pres_abs4, dsn = "D:\\Fire\\fire_data\\raw_data\\ClimateBC_Data\\fire_ignitions_veg_climate_ALL_5x_NoW_.shp", delete_layer=TRUE) #File very large > 2 GB, so having saving issues. Perhaps now is a good time to separate the file into lightning, person caused, etc.
```

We will separate into component parts and try to save smaller files as the file is still too big.

```{r}
#fire_veg_data_B_df<-as.data.frame(fire_veg_data_B)
#write.csv(fire_veg_data_B_df, #file="D:\\Fire\\fire_data\\raw_data\\ClimateBC_Data\\fire_ignitions_veg_climate_ALL_df.csv")

table(ignition_pres_abs4$fire_cs)
##Subset data for fire cause of lightning and NA, Person and NA, and Unknown and NA
fire_veg_data_lightning_5x<-ignition_pres_abs4 %>% filter(fire_cs=="Lightning")
table(fire_veg_data_lightning_5x$fire_cs) #15228
fire_veg_data_person_5x<-ignition_pres_abs4 %>% filter(fire_cs=="Person")
table(fire_veg_data_person_5x$fire_cs) #21373
fire_veg_data_NA_5x<-ignition_pres_abs4 %>% filter(fire_cs=="NA")
table(fire_veg_data_NA_5x$fire_cs) #351829
fire_veg_data_unknown_5x<-ignition_pres_abs4 %>% filter(fire_cs=="Unknown")
table(fire_veg_data_unknown_5x$fire_cs) #964

fire_veg_data_lightning_NA_5x<-rbind(fire_veg_data_lightning_5x, fire_veg_data_NA_5x)
table(fire_veg_data_lightning_NA_5x$fire_cs)
table(fire_veg_data_lightning_NA_5x$vegtype)

fire_veg_data_person_NA_5x<-rbind(fire_veg_data_person_5x, fire_veg_data_NA_5x)
table(fire_veg_data_person_NA_5x$fire_cs)

##Write individual files
st_write(fire_veg_data_lightning_5x, dsn = "D:\\Fire\\fire_data\\raw_data\\Fire_climate_DEM_VRI_shape_files\\fire_veg_dem_lightning_5x_NoW.shp", delete_layer=TRUE)

st_write(fire_veg_data_person_5x, dsn = "D:\\Fire\\fire_data\\raw_data\\Fire_climate_DEM_VRI_shape_files\\fire_veg_dem_person_5x_NoW.shp", delete_layer=TRUE)

st_write(fire_veg_data_NA_5x, dsn = "D:\\Fire\\fire_data\\raw_data\\Fire_climate_DEM_VRI_shape_files\\fire_veg_dem_NA_5x_NoW.shp", delete_layer=TRUE) #Get error

##Write aggregated files for lightning and person caused
st_write(fire_veg_data_lightning_NA_5x, dsn = "D:\\Fire\\fire_data\\raw_data\\Fire_climate_DEM_VRI_shape_files\\fire_veg_dem_lightning_NA_5x_NoW.shp", delete_layer=TRUE) #Get error

st_write(fire_veg_data_person_NA_5x, dsn = "D:\\Fire\\fire_data\\raw_data\\Fire_climate_DEM_VRI_shape_files\\fire_veg_dem_person_NA_5x_NoW.shp", delete_layer=TRUE) #Get error

# write final fire ignitions, weather and vegetation types to postgres

##To save to clus, need OsGeo4W
#Modify below with correct credentials and upload on clus as desired
#ogr2ogr -f PostgreSQL PG:"dbname=clus port=5432 user= password= host=DC052586" D:\\Fire\\fire_data\\raw_data\\Fire_climate_DEM_VRI_shape_files\\fire_veg_dem_person_NA_5x_NoW.shp -overwrite -a_srs EPSG:3005 -progress --config PG_USE_COPY YES -nlt PROMOTE_TO_MULTI 

#ogr2ogr -f PostgreSQL PG:"dbname=clus port=5432 user= password= host=DC052586" D:\\Fire\\fire_data\\raw_data\\Fire_climate_DEM_VRI_shape_files\\fire_veg_dem_lightning_NA_5x_NoW.shp -overwrite -a_srs EPSG:3005 -progress --config PG_USE_COPY YES -nlt PROMOTE_TO_MULTI 

```

If you still have many objects open in your Environment, then let's clean the R environment of other elements if we have continued from previous files. This will help R run and not crash. Many methods can be found here: https://stackoverflow.com/questions/6190051/how-can-i-remove-all-objects-but-one-from-the-workspace-in-r

```{r}
ls()

library(gdata)

keep(fire_veg_data_B, ignition_pres_abs4, fire_veg_data_lightning_5x, fire_veg_data_person_5x, fire_veg_data_NA_5x, fire_veg_data_lightning_NA_5x, fire_veg_data_person_NA_5x) #shows you which variables will be removed

keep(fire_veg_data_B, ignition_pres_abs4, fire_veg_data_lightning_5x, fire_veg_data_person_5x, fire_veg_data_NA_5x, fire_veg_data_lightning_NA_5x, fire_veg_data_person_NA_5x, sure = TRUE) # setting sure to TRUE removes variables not in the list
 
ls()
gc(TRUE)

```

Now, we must subsample the data since the sample sizes for the zeros are too large. At least two different papers used 1.5 times the number of presence points as absences. See:
   - Chang et al (2013) Predicting fire occurrence patterns with logistic regression in Heilongjiang Province, China. Landscape Ecology 28, 1989-2004 and
   - Catry et al. (2009) Modeling and mapping wildfire ignition risk in Portugal. International Journal of Wildland Fire 18, 921-931.

# Steps for subsampling:
First, get sample sizes per habitat type and year for the 1's. 
Then sample 2x or some amount more than that value in each of those vegetation, year categories. 
See https://jennybc.github.io/purrr-tutorial/ls12_different-sized-samples.html for an idea on how to do this.

This will be done separately for lightning and person caused fires. 

We must subsample the data since the sample sizes for the zeros are too large. At least two different papers used 1.5 times the number of presence points as absences. See:
   - Chang et al (2013) Predicting fire occurrence patterns with logistic regression in Heilongjiang Province, China. Landscape Ecology 28, 1989-2004 and
   - Catry et al. (2009) Modeling and mapping wildfire ignition risk in Portugal. International Journal of Wildland Fire 18, 921-931.

# Steps for subsampling:
First, get sample sizes per habitat type and year for the 1's. 
Then sample 2x or some amount more than that value in each of those vegetation, year categories. 
See https://jennybc.github.io/purrr-tutorial/ls12_different-sized-samples.html for an idea on how to do this.

This will be done separately for lightning and person caused fires. We will first prepare the tables for both lightning and person caused fires, and then we will perform for each separately.

```{r}
#Set geometry to null for processing below
fire_veg_data_lightning_NA_5x_<-st_set_geometry(fire_veg_data_lightning_NA_5x, NULL)
fire_veg_data_person_NA_5x_<-st_set_geometry(fire_veg_data_person_NA_5x, NULL)
```

The step preparing the tables can take a very long time for the NAs since there are a few hundred thousand. Once you prepare these tables, you do not need to prepare them again as long as they are still saved in your R environment. Once geometry is set to null, however, the processing should be really fast.

```{r}
##Lightning caused - preparing the tables
pre<- fire_veg_data_lightning_NA_5x_ %>%
  filter(fire==1) %>%
  dplyr::select(fire_yr, fire, zone, bclcs_level_2) %>%
  group_by(fire_yr, zone, bclcs_level_2) %>%
  summarize(fire_n=n())
head(pre)

##Get NA points
pre_checkpre<- fire_veg_data_lightning_NA_5x_ %>%
  filter(fire==0) %>%
  dplyr::select(fire_yr, fire, zone, bclcs_level_2) %>%
  group_by(fire_yr, zone, bclcs_level_2) %>%
  summarize(abs_n=n())
head(pre_checkpre)
```

This next chunk also takes quite a bit of time.

```{r}
check<-left_join(pre, pre_checkpre)
check %>% print(n=100) # hmm there are some NA's in the 0 column. I should probably correct that.
```


```{r}
abs_match <- fire_veg_data_lightning_NA_5x_ %>%
  filter(fire == 0) %>%
  group_by(fire_yr, zone, bclcs_level_2) %>%   # prep for work by yr and veg type
  nest() %>%              # --> one row per yr and vegtype
  ungroup()

df<-left_join(check, abs_match) # make sure there are not veg year combinations that are not also in the fire_pres==1 file


# there are several year, zone, subzone combinations with no data in the tibble.  This code below removes the Null values. I should increase my sample of fire absences so that I don't have any combinations with zero data or sample it in a different way. TO DO!
df2 <- df %>% 
  filter(lengths(data)>0)
```

Note: each time you subsample with the code below, you will end up with different random points where fires did not occur. As a result, the results of the subsequent model selection may differ. You may wish to create different random points each a few times to ensure that the same climate variables come out as the top ones for each BEC zone, especially for those with small sample sizes for where fires occurred.

```{r}
# here I sample from the tibble the number of data points I want for the absences
# I should probably have replace = false but there are a few rows where there are more fire ignitions in that subzone than randomly sampled locations which is causing issues with this code. For now I'll leave it like this.
  sampled_df<- df2 %>% 
    mutate(samp = map2(data, ceiling(fire_n*2), sample_n, replace=TRUE)) %>%
    dplyr::select(-data) %>%
    unnest(samp) %>%
    dplyr::select(fire_yr, zone, subzone, bclcs_level_2, feature_id:vegtype)
 
# joining my subsampled absence data back to the fire ignition presence data
pre1<- fire_veg_data_lightning_NA_5x_ %>%
  filter(fire==1)
dim(sampled_df) # 
dim(pre1) #  15228 rows

dat_lightning<- rbind(pre1, as.data.frame(sampled_df))
dim(dat_lightning) # 37673 rows good this worked I think; Cora July 5 has 45656 rows. This is fewer than the >180,000 rows of the data at the end of file 01

head(dat_lightning)
str(dat_lightning)
table(dat_lightning$fire_cs)
```

If all looks good from above, then save data.

```{r}
#Write file
st_write(dat_lightning, dsn = "D:\\Fire\\fire_data\\raw_data\\Fire_climate_DEM_VRI_shape_files\\dat_lightning_for_analysis_.shp", delete_layer=TRUE)

write.csv(dat_lightning, "D:\\Fire\\fire_data\\raw_data\\Fire_climate_DEM_VRI_shape_files\\dat_lightning_for_analysis_.csv")

```

Now we will repeat the process for person-caused fires.

```{r}
##Person caused fires: table preparations
pre2<- fire_veg_data_person_NA_5x_ %>%
  filter(fire==1) %>%
  dplyr::select(fire_yr, fire, zone, bclcs_level_2) %>%
  group_by(fire_yr, zone, bclcs_level_2) %>%
  summarize(fire_n=n())

pre_checkpre<- fire_veg_data_person_NA_5x_ %>%
  filter(fire==0) %>%
  dplyr::select(fire_yr, fire, zone, bclcs_level_2) %>%
  group_by(fire_yr, zone, bclcs_level_2) %>%
  summarize(abs_n=n())

check2<-left_join(pre2, pre_checkpre)
check2 %>% print(n=100) # hmm there are some NA's in the 0 column. I should probably correct that.

abs_match2 <- fire_veg_data_person_NA_5x_ %>%
  filter(fire == 0) %>%
  group_by(fire_yr, zone, bclcs_level_2) %>%   # prep for work by yr and veg type
  nest() %>%              # --> one row per yr and vegtype
  ungroup()

dfp<-left_join(check2, abs_match2) # make sure there are not veg year combinations that are not also in the fire_pres==1 file


# there are several year, zone, subzone combinations with no data in the tibble.  This code below removes the Null values. I should increase my sample of fire absences so that I don't have any combinations with zero data or sample it in a different way. TO DO!
df2 <- dfp %>% 
  filter(lengths(data)>0)
```

Now subsample from the created tables. Once again, if the above tables remain in your R Environment, you can subsample a few times to run the climate variable selection analyses.

```{r}
# here I sample from the tibble the number of data points I want for the absences
# I should probably have replace = false but there are a few rows where there are more fire ignitions in that subzone than randomly sampled locations which is causing issues with this code. For now I'll leave it like this.
  sampled_df<- df2 %>% 
    mutate(samp = map2(data, ceiling(fire_n*2), sample_n, replace=TRUE)) %>%
    dplyr::select(-data) %>%
    unnest(samp) %>%
    dplyr::select(fire_yr, zone, subzone, bclcs_level_2, feature_id:vegtype)
 
# joining my subsampled absence data back to the fire ignition presence data
pre2<- fire_veg_data_person_NA_5x_ %>%
  filter(fire==1)
dim(sampled_df) #  rows
dim(pre2) #   rows

dat_person<- rbind(pre2, as.data.frame(sampled_df))
dim(dat_person) # 

head(dat_person)
str(dat_person)
table(dat_person$fire_cs)
```

If data looks good, save file.

```{r}
#Write file
st_write(dat_person, dsn = "D:\\Fire\\fire_data\\raw_data\\Fire_climate_DEM_VRI_shape_files\\dat_person_for_analysis_.shp", delete_layer=TRUE) 

write.csv(dat_person,"D:\\Fire\\fire_data\\raw_data\\Fire_climate_DEM_VRI_shape_files\\dat_person_for_analysis_.csv")

```


Upload these files to the clus database

```{r}
##Lightning Caused
connKyle <- dbConnect(drv = RPostgreSQL::PostgreSQL(), 
                      host = key_get('dbhost', keyring = 'postgreSQL'),
                      user = key_get('dbuser', keyring = 'postgreSQL'),
                      dbname = key_get('dbname', keyring = 'postgreSQL'),
                      password = key_get('dbpass', keyring = 'postgreSQL'),
                      port = "5432")

st_write (obj = dat_lightning, 
          dsn = connKyle, 
          layer = c ("public", "dat_lightning_for_analysis"))


dbDisconnect (connKyle)


#Person caused
connKyle <- dbConnect(drv = RPostgreSQL::PostgreSQL(), 
                      host = key_get('dbhost', keyring = 'postgreSQL'),
                      user = key_get('dbuser', keyring = 'postgreSQL'),
                      dbname = key_get('dbname', keyring = 'postgreSQL'),
                      password = key_get('dbpass', keyring = 'postgreSQL'),
                      port = "5432")

st_write (obj = dat_person, 
          dsn = connKyle, 
          layer = c ("public", "dat_person_for_analysis"))


dbDisconnect (connKyle)

#probably works better to save via this:

#Save to postgre
#ogr2ogr -f PostgreSQL PG:"host=DC052586 user= dbname=clus password= port=5432" D:\\Fire\\fire_data\\raw_data\\Fire_climate_DEM_VRI_shape_files\\dat_person_for_analysis_.shp -overwrite -a_srs EPSG:3005 -progress --config PG_USE_COPY YES -nlt PROMOTE_TO_MULTI

#ogr2ogr -f "PostgreSQL" PG:"host=localhost user=postgres dbname=postgres password=postgres port=5432" D:\\Fire\\fire_data\\raw_data\\Fire_climate_DEM_VRI_shape_files\\dat_person_for_analysis_.shp -overwrite -a_srs EPSG:3005 -progress --config PG_USE_COPY YES -nlt PROMOTE_TO_MULTI

#ogr2ogr -f PostgreSQL PG:"host=DC052586 user= dbname=clus password= port=5432" D:\\Fire\\fire_data\\raw_data\\Fire_climate_DEM_VRI_shape_files\\dat_lightning_for_analysis_.shp -overwrite -a_srs EPSG:3005 -progress --config PG_USE_COPY YES -nlt PROMOTE_TO_MULTI

#ogr2ogr -f "PostgreSQL" PG:"host=localhost user=postgres dbname=postgres password=postgres port=5432" D:\\Fire\\fire_data\\raw_data\\Fire_climate_DEM_VRI_shape_files\\dat_lightning_for_analysis_.shp -overwrite -a_srs EPSG:3005 -progress --config PG_USE_COPY YES -nlt PROMOTE_TO_MULTI
```


```{r}

##You may wish to clear your environment after this portion
rm(list = ls(all.names = TRUE)) #will clear all objects includes hidden objects.
gc() #free up memory and report the memory usage.
```

############## Now move on to file 08_ignition_climate_variable_selection#############
