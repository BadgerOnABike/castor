---
title: "13a_fire_spread_size_model_selection_NDT1_ALLLANDP_TNT"
author: "Cora Skaien"
date: "01/10/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

#Load relevant libraries
library(sf)
library(tidyverse)
library(ggplot2)
library(ggcorrplot)
library(RPostgreSQL)
library(rpostgis)
library(dplyr)
library(lme4)
library(arm)
library(ggpubr)
library(mgcv)
library(nlme)
library(purrr)
library(tidyr)
library(caret)
library(pROC)
library(keyring)
library(ggcorrplot) 
library(kableExtra)
library(data.table)
library(DBI)
library(here)
library(AICcmodavg)
library(rje)
library(base)
library(car)
library(visreg)
#library(aomisc) #Not available for this version of R

source(here::here("R/functions/R_Postgres.R"))
```

<!--
Copyright 2021 Province of British Columbia

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and limitations under the License.
-->

#=================================
#  Script Name: 13a_fire_spread_size_model_selection_NDT1_ALLLANDP_TNT.R
#  Script Version: 1.0
#  Script Purpose: model selection for fire size (part of spread) by NDT.
#  Script Author: Cora Skaien, Ecological Modeling Specialist, Forest Analysis and Inventory Branch, B.C. Ministry of Forests, Lands, and Natural Resource Operations.
#=================================

#Objective
The objective of this file is to determine the best model for predicting fire size, given climate, topography, infrastructure, etc. Prior models were logistic regression (0/1) and used AUC to assess quality. Here, we will be working with continuous data and will assess model fit via R-squared, root mean squared error, and cross-validation. We will first attempt linear regressions, but may need to consider other distributions.

Note on cross-validation using test and validation data: "When comparing two models, the one that produces the lowest test sample RMSE is the preferred model.
the RMSE and the MAE are measured in the same scale as the outcome variable. Dividing the RMSE by the average value of the outcome variable will give you the prediction error rate, which should be as small as possible." (http://www.sthda.com/english/articles/38-regression-model-validation/157-cross-validation-essentials-in-r/#loading-required-r-packages)

#For fire size, plot observed vs model for both testing data and validation data set.

#Load in the prepped data.
```{r}
spread_data_ALL<-read.csv(file="D:\\Fire\\fire_data\\raw_data\\spread_data_ALL_Dec2021.csv")
head(spread_data_ALL)

```
Remove extra X.1... X.5 labels at start of data.

```{r}
spread_data_ALL<-spread_data_ALL[-1]
head(spread_data_ALL)
```

#Inspect the data
```{r}
min(spread_data_ALL$size_ha) # Minimum 1 ha: this is because we are only quantifying the spread and fire size of those that "spread" (> 1 ha)
hist(spread_data_ALL$size_ha) #Definitely not a normal distribution
hist(log(spread_data_ALL$size_ha)) #Still not a normal distribution; already have a LNsize_ha variable created prior

spread_data_ALL$ntrl_ds<-as.factor(spread_data_ALL$ntrl_ds)
table(spread_data_ALL$ntrl_ds) #Very few in NDT5 (n=23)
```


##Create variables for model selection
First we will create the variable lists that contain all of our variables of interest.

```{r}
##Create variable lists to be used in the model loop.
variables_all<-c(climate1 = "climate1", climate2 = "climate2", mdc_atfire="mdc_atfire", proj_height_1 = "proj_height_1", proj_age_1 = "proj_age_1", live_stand_volume_125 = "live_stand_volume_125", slope = "slope", aspect = "aspect", elevation ="elevation", vegtype2 = "vegtype2",  dist_infra = "dist_infra", wind_atfire = "wind_atfire", roads_km="roads_km", Tdif_atfire="Tdif_atfire", bclcs_level_2 ="bclcs_level_2", fire_cs ="fire_cs") 

vars.clim.vegtype2<-c("climate1", "climate2","vegtype2", "mdc_atfire")
vars.clim.vegtype2b<-c("climate1", "climate2", "mdc_atfire")
vars.oth<-c("proj_height_1", "proj_age_1", "live_stand_volume_125", "bclcs_level_2") 
vars.topo<-c("slope", "aspect", "elevation", "wind_atfire")
vars.infra<-c("dist_infra", "roads_km")
vars.oth2<-c("wind_atfire", "Tdif_atfire")


##Create interaction for climate and vegtype
inputs.me2 <- c(vars.clim.vegtype2)
inputs.me2b <- c(vars.clim.vegtype2b)
```

Now, we will generate two-way interactions for each of these lists. 

```{r}
#####1a. For those with two climate variables and vegtype
#get the names of all possible two-way interactions for climate variable(s) and vegtype.
twoway.ints2 <- NULL
for (i in 1:(length(inputs.me2)-1)) {
  for (j in (i+1):length(inputs.me2)) {
     twoway.ints2 <- cbind(twoway.ints2, paste(inputs.me2[i], inputs.me2[j], sep=":"))
  }
}
twoway.ints2
length(twoway.ints2) #6

#Get variables on own
#complete list of models using non-climate vars
mods.me.tmp <- powerSet(vars.clim.vegtype2) 
#add climate vars to all of the above
mods.me.climate2 <- list()
for (i in 1: length(mods.me.tmp)) {
   mods.me.climate2[[i]] <- c(mods.me.tmp[[i]])
}

mods.me.climate2
mods.me.climate2<-mods.me.climate2[-1] #n = 15

#complete list of two-way interactions
mods.twoway2 <- powerSet(twoway.ints2)
length(mods.twoway2) #64
mods.twoway2[1]
mods.twoway2<-mods.twoway2[-1]

#Finding models in mods.me that accommodate/allow interaction terms in each mods.twoway to be added
mods.inter2 <- list()
counter <- 0
for (i in 1: length(mods.twoway2)) {
   s1 <- unique(unlist( strsplit(mods.twoway2[[i]], split=':', fixed=TRUE) ) )
   for (j in 1: length(mods.me.climate2)) {
      if (all(s1 %in% mods.me.climate2[[j]])==TRUE) {
        counter <- counter + 1
        both <-  c(mods.me.climate2[[j]], mods.twoway2[[i]])
        mods.inter2[[counter]] <- both
      }
   }
}

length(mods.inter2) #97
#mods.inter2
mods.inter2


####1c. Climate variables but no vegtype
#get the names of all possible two-way interactions for climate variable(s) and vegtype.
twoway.ints2b <- NULL
for (i in 1:(length(inputs.me2b)-1)) {
  for (j in (i+1):length(inputs.me2b)) {
     twoway.ints2b <- cbind(twoway.ints2b, paste(inputs.me2b[i], inputs.me2b[j], sep=":"))
  }
}
twoway.ints2b
length(twoway.ints2b) #3

#Get variables on own
#complete list of models using non-climate vars
mods.me.tmp <- powerSet(vars.clim.vegtype2b) 
#add climate vars to all of the above
mods.me.climate2b <- list()
for (i in 1: length(mods.me.tmp)) {
   mods.me.climate2b[[i]] <- c(mods.me.tmp[[i]])
}

mods.me.climate2b
mods.me.climate2b<-mods.me.climate2b[-1]

#complete list of two-way interactions
mods.twoway2b <- powerSet(twoway.ints2b)
length(mods.twoway2b) #8
mods.twoway2b
mods.twoway2b<-mods.twoway2b[-1]

#Finding models in mods.me that accommodate/allow interaction terms in each mods.twoway to be added
mods.inter2b <- list()
counter <- 0
for (i in 1: length(mods.twoway2b)) {
   s1 <- unique(unlist( strsplit(mods.twoway2b[[i]], split=':', fixed=TRUE) ) )
   for (j in 1: length(mods.me.climate2b)) {
      if (all(s1 %in% mods.me.climate2b[[j]])==TRUE) {
        counter <- counter + 1
        both <-  c(mods.me.climate2b[[j]], mods.twoway2b[[i]])
        mods.inter2b[[counter]] <- both
      }
   }
}

length(mods.inter2b) #10
mods.inter2b
```


```{r}
#########2. Now for topography data, get all possible two-way interactions

#get the names of all possible two-way interactions
twoway.intsT <- NULL
for (i in 1:(length(vars.topo)-1)) {
  for (j in (i+1):length(vars.topo)) {
     twoway.intsT <- cbind(twoway.intsT, paste(vars.topo[i], vars.topo[j], sep=":"))
  }
}
twoway.intsT
length(twoway.intsT) #6

#No reason to believe aspect*wind_atfire would have an effect, so remove
twoway.intsT<-twoway.intsT[-5]

#complete list of models using non-climate vars (topo)
mods.me.tmp <- powerSet(vars.topo) 
#add climate vars to all of the above
mods.meT <- list()
for (i in 1: length(mods.me.tmp)) {
   mods.meT[[i]] <- c(mods.me.tmp[[i]])
}

mods.meT
mods.meT<-mods.meT[-1]

#complete list of two-way interactions
mods.twowayT <- powerSet(twoway.intsT)
length(mods.twowayT) #32
mods.twowayT
mods.twowayT<-mods.twowayT[-1]

#Finding models in mods.me that accommodate/allow interaction terms in each mods.twoway to be added

mods.interT <- list()
counter <- 0
for (i in 1: length(mods.twowayT)) {
   s1 <- unique(unlist( strsplit(mods.twowayT[[i]], split=':', fixed=TRUE) ) )
   for (j in 1: length(mods.meT)) {
      if (all(s1 %in% mods.meT[[j]])==TRUE) {
        counter <- counter + 1
        both <-  c(mods.meT[[j]], mods.twowayT[[i]])
        mods.interT[[counter]] <- both
      }
   }
}

length(mods.interT) #56
#mods.interT
```

```{r}
####3.For other VRI data, get without interactions

#complete list of models using VRI - no interactions
mods.me.tmp <- powerSet(vars.oth) 
#add climate vars to all of the above
mods.me.oth <- list()
for (i in 1: length(mods.me.tmp)) {
   mods.me.oth[[i]] <- c(mods.me.tmp[[i]])
}

mods.me.oth
mods.me.oth<-mods.me.oth[-1]

#get the names of all possible two-way interactions
twoway.intsOTH <- NULL
for (i in 1:(length(vars.oth)-1)) {
  for (j in (i+1):length(vars.oth)) {
     twoway.intsOTH <- cbind(twoway.intsOTH, paste(vars.oth[i], vars.oth[j], sep=":"))
  }
}
twoway.intsOTH
length(twoway.intsOTH) #6

#Do not want interactions between VRI variables
twoway.intsOTH<-twoway.intsOTH[c(3,5,6)]
twoway.intsOTH

#complete list of two-way interactions
mods.twowayOTH <- powerSet(twoway.intsOTH)
length(mods.twowayOTH) #8
mods.twowayOTH
mods.twowayOTH<-mods.twowayOTH[-1]

#Finding models in mods.me that accommodate/allow interaction terms in each mods.twoway to be added

mods.inter.OTH <- list()
counter <- 0
for (i in 1: length(mods.twowayOTH)) {
   s1 <- unique(unlist( strsplit(mods.twowayOTH[[i]], split=':', fixed=TRUE) ) )
   for (j in 1: length(mods.me.oth)) {
      if (all(s1 %in% mods.me.oth[[j]])==TRUE) {
        counter <- counter + 1
        both <-  c(mods.me.oth[[j]], mods.twowayOTH[[i]])
        mods.inter.OTH[[counter]] <- both
      }
   }
}

length(mods.inter.OTH) #19
mods.inter.OTH


```

```{r}
#########4. Now for distance to infrastructure data, get all possible two-way interactions

#get the names of all possible two-way interactions
twoway.intsI <- NULL
for (i in 1:(length(vars.infra)-1)) {
  for (j in (i+1):length(vars.infra)) {
     twoway.intsI <- cbind(twoway.intsI, paste(vars.infra[i], vars.infra[j], sep=":"))
  }
}
twoway.intsI
length(twoway.intsI) #1

#complete list of models using non-climate vars (infra)
mods.me.tmp <- powerSet(vars.infra) 
#add climate vars to all of the above
mods.meI <- list()
for (i in 1: length(mods.me.tmp)) {
   mods.meI[[i]] <- c(mods.me.tmp[[i]])
}

mods.meI
mods.meI<-mods.meI[-1]

#complete list of two-way interactions
mods.twowayI <- powerSet(twoway.intsI)
length(mods.twowayI) #2
#mods.twowayI

#Finding models in mods.me that accommodate/allow interaction terms 
mods.interI <- list()
counter <- 0
for (i in 1: length(mods.twowayI)) {
   s1 <- unique(unlist( strsplit(mods.twowayI[[i]], split=':', fixed=TRUE) ) )
   for (j in 1: length(mods.meI)) {
      if (all(s1 %in% mods.meI[[j]])==TRUE) {
        counter <- counter + 1
        both <-  c(mods.meI[[j]], mods.twowayI[[i]])
        mods.interI[[counter]] <- both
      }
   }
}

length(mods.interI) #4
mods.interI
```

```{r}
########5. Lastly for last list of other variables
#get the names of all possible two-way interactions
twoway.ints.O2 <- NULL
for (i in 1:(length(vars.oth2)-1)) {
  for (j in (i+1):length(vars.oth2)) {
     twoway.ints.O2 <- cbind(twoway.ints.O2, paste(vars.oth2[i], vars.oth2[j], sep=":"))
  }
}
twoway.ints.O2
length(twoway.ints.O2) #1

#complete list of models using non-climate vars (infra)
mods.me.tmp <- powerSet(vars.oth2) 
#add climate vars to all of the above
mods.me.O2 <- list()
for (i in 1: length(mods.me.tmp)) {
   mods.me.O2[[i]] <- c(mods.me.tmp[[i]])
}

mods.me.O2
mods.me.O2<-mods.me.O2[-1]

#complete list of two-way interactions
mods.twoway.O2 <- powerSet(twoway.ints.O2)
length(mods.twoway.O2) #2
mods.twowayI
mods.twowayI<-mods.twowayI[-1]

#Finding models in mods.me that accommodate/allow interaction terms 
mods.inter.O2 <- list()
counter <- 0
for (i in 1: length(mods.twoway.O2)) {
   s1 <- unique(unlist( strsplit(mods.twoway.O2[[i]], split=':', fixed=TRUE) ) )
   for (j in 1: length(mods.meI)) {
      if (all(s1 %in% mods.me.O2[[j]])==TRUE) {
        counter <- counter + 1
        both <-  c(mods.me.O2[[j]], mods.twoway.O2[[i]])
        mods.inter.O2[[counter]] <- both
      }
   }
}

length(mods.inter.O2) #4
mods.inter.O2
```

Determine final models for testing.

```{r}
all.poss.mods.clim.vegtype2<-c(1, mods.me.climate2, mods.inter2)
all.poss.mods.clim.vegtype2 #113

all.poss.mods.clim.vegtype2b<-c(1, mods.me.climate2b, mods.inter2b)
all.poss.mods.clim.vegtype2b #18

all.poss.mods.VRI<-c(1, mods.inter.OTH)
all.poss.mods.VRI

all.poss.mods.topo<-c(1, mods.interT)
all.poss.mods.topo

all.poss.mods.infra<-c(1, mods.interI) 
all.poss.mods.infra

all.poss.mods.Oth2<-c(1, mods.inter.O2)
all.poss.mods.Oth2
```


```{r}
#If need to determine which ones are character(0), try this:
biglist <- list(list("A","B","C"), "foo", "", character(0), integer(0))
lapply(biglist, function(x) {length(x) == 0L} ) 


##Check and rid of any duplicated models
duplicated(all.poss.mods.clim.vegtype2)
duplicated(all.poss.mods.clim.vegtype2b)
duplicated(all.poss.mods.VRI)
duplicated(all.poss.mods.topo)
duplicated(all.poss.mods.infra)
duplicated(all.poss.mods.Oth2)

```


############### Determine Top Models ##########

Select: NDT1
#1. Climate1, climate2 and vegtype2

```{r}
ntrl_ds<-c("NDT1") #Do one zone at a time
zones1<-c("NDT1")
prop<-0.75

#Create empty table
table.glm.climate.simple.spread <- data.frame (matrix (ncol = 9, nrow = 0))
colnames (table.glm.climate.simple.spread) <- c ("model", "edf", "aic", "Model.R2", "Adjusted.R2", "Valid.R2", "Valid.RMSE", "Valid.MAE", "NDT")

#Run model x100
for (g in 1:100){
  
for (h in 1:length(zones1)) {
  dat2<- subset(spread_data_ALL, spread_data_ALL$ntrl_ds=="NDT1")

for (i in 1: length(zones1)){
  print(paste((all.poss.mods.clim.vegtype2[i]), (ntrl_ds[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(spread, fire_veg, variables_all[i])
  model_dat<- dat2 %>% dplyr::select(LNsize_ha, fire_veg, !!variables_all)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod_lm <- function(mods.in, df.train, dep.var="LNsize_ha") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   predictions <- mods.fit %>% predict(Valid)
   Model.R2 <- summary(mods.fit)$r.squared
   Valid.R2 <- R2(predictions, Valid$LNsize_ha, na.rm=TRUE)
   Valid.RMSE <- RMSE(predictions, Valid$LNsize_ha, na.rm=TRUE)
   Valid.MAE <- MAE(predictions, Valid$LNsize_ha, na.rm=TRUE)
   Adjusted.R2<-summary(mods.fit)$adj.r.squared 
   return(list(rhs, mod.stuff, mod.aic, Model.R2, Valid.R2, Valid.RMSE, Valid.MAE, Adjusted.R2))
   
}

mods.fit <- lapply(all.poss.mods.clim.vegtype2, big.mod_lm, df.train=dat1)

#terms in each model
x1.1 <- unlist(sapply(mods.fit, '[', 1))
x1.1
#Aic for models
x3.1 <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3.1
#Model.R2
x4.1 <- unlist(sapply(mods.fit, '[', 4))
x4.1
#Validation R2 
x5.1 <- unlist(sapply(mods.fit, '[', 5))
x5.1
#Validation RSME
x6.1 <- unlist(sapply(mods.fit, '[', 6))
x6.1
#Validation MAE
x7.1 <- unlist(sapply(mods.fit, '[', 7))
x7.1
#Adjusted R2
x8.1 <- unlist(sapply(mods.fit, '[', 8))
x8.1
#combining all as df
tab.sum.climate <- cbind.data.frame(model=x1.1, edf=x3.1[,1], aic=x3.1[,2], Model.R2=x4.1, Adjusted.R2=x8.1, Valid.R2=x5.1, Valid.RMSE=x6.1, Valid.MAE=x7.1)
tab.sum.climate$NDT<-c("NDT1")
tab.sum.climate 

table.glm.climate.simple.spread<-rbind(table.glm.climate.simple.spread, tab.sum.climate)

}
}
}
```
Check data.
```{r}
head(table.glm.climate.simple.spread)
```
Now that we have run the model 100 times, we want the average AIC and goodness of fit metrics for each variable combination..

```{r}
head(table.glm.climate.simple.spread)
table(table.glm.climate.simple.spread$model) # 100 per model

AIC_lightning_NDT1_spread_treed_climate<-table.glm.climate.simple.spread

AIC_lightning_NDT1_spread_treed_summary_climate<- AIC_lightning_NDT1_spread_treed_climate %>%
  group_by(model) %>%
  summarise(meanAIC=mean(aic, na.rm=TRUE),
            meanR2=mean(Model.R2, na.rm=TRUE),
            meanAdjustR2=mean(Adjusted.R2, na.rm=TRUE),
            sdR2=sd(Model.R2, na.rm=TRUE),
            meanR2valid=mean(Valid.R2, na.rm=TRUE),
            meanRSMEvalid=mean(Valid.RMSE, na.rm=TRUE),
            meanMAEvalid=mean(Valid.MAE, na.rm=TRUE)
            )

AIC_lightning_NDT1_spread_treed_summary_climate2<- AIC_lightning_NDT1_spread_treed_summary_climate %>%
  mutate(deltaAIC=meanAIC-min(meanAIC))

head(AIC_lightning_NDT1_spread_treed_summary_climate2)
```

#Now repeat for VRI data

```{r}
#Create empty table
table.glm.VRI.simple.spread <- data.frame (matrix (ncol = 9, nrow = 0))
colnames (table.glm.VRI.simple.spread) <- c ("model", "edf", "aic", "Model.R2", "Adjusted.R2", "Valid.R2", "Valid.RMSE", "Valid.MAE", "NDT")

#Run model x100
for (g in 1:100){
  
for (h in 1:length(zones1)) {
  dat2<- subset(spread_data_ALL, spread_data_ALL$ntrl_ds=="NDT1")

for (i in 1: length(zones1)){
  print(paste((all.poss.mods.VRI[i]), (ntrl_ds[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(spread, fire_veg, variables_all[i])
  model_dat<- dat2 %>% dplyr::select(LNsize_ha, fire_veg, !!variables_all)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod_lm <- function(mods.in, df.train, dep.var="LNsize_ha") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   predictions <- mods.fit %>% predict(Valid)
   Model.R2 <- summary(mods.fit)$r.squared
   Valid.R2 <- R2(predictions, Valid$LNsize_ha, na.rm=TRUE)
   Valid.RMSE <- RMSE(predictions, Valid$LNsize_ha, na.rm=TRUE)
   Valid.MAE <- MAE(predictions, Valid$LNsize_ha, na.rm=TRUE)
   Adjusted.R2<-summary(mods.fit)$adj.r.squared 
   return(list(rhs, mod.stuff, mod.aic, Model.R2, Valid.R2, Valid.RMSE, Valid.MAE, Adjusted.R2))
   
}

mods.fit <- lapply(all.poss.mods.VRI, big.mod_lm, df.train=dat1)

#terms in each model
x1.1 <- unlist(sapply(mods.fit, '[', 1))
x1.1
#Aic for models
x3.1 <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3.1
#Model.R2
x4.1 <- unlist(sapply(mods.fit, '[', 4))
x4.1
#Validation R2
x5.1 <- unlist(sapply(mods.fit, '[', 5))
x5.1
#Validation RSME
x6.1 <- unlist(sapply(mods.fit, '[', 6))
x6.1
#Validation MAE
x7.1 <- unlist(sapply(mods.fit, '[', 7))
x7.1
#Adjusted R2
x8.1 <- unlist(sapply(mods.fit, '[', 8))
x8.1
#combining all as df
tab.sum.VRI <- cbind.data.frame(model=x1.1, edf=x3.1[,1], aic=x3.1[,2], Model.R2=x4.1, Adjusted.R2=x8.1, Valid.R2=x5.1, Valid.RMSE=x6.1, Valid.MAE=x7.1)
tab.sum.VRI$NDT<-c("NDT1")
tab.sum.VRI 

table.glm.VRI.simple.spread<-rbind(table.glm.VRI.simple.spread, tab.sum.VRI)

}
}
}
```
Check data.
```{r}
head(table.glm.VRI.simple.spread)
```
Now that we have run the model 100 times, we want the average AIC and goodness of fit metrics for each variable combination..

```{r}
head(table.glm.VRI.simple.spread)
table(table.glm.VRI.simple.spread$model) # 100 per model

AIC_lightning_NDT1_spread_treed_VRI<-table.glm.VRI.simple.spread

AIC_lightning_NDT1_spread_treed_summary_VRI<- AIC_lightning_NDT1_spread_treed_VRI %>%
  group_by(model) %>%
  summarise(meanAIC=mean(aic, na.rm=TRUE),
            meanR2=mean(Model.R2, na.rm=TRUE),
            meanAdjustR2=mean(Adjusted.R2, na.rm=TRUE),
            sdR2=sd(Model.R2, na.rm=TRUE),
            meanR2valid=mean(Valid.R2, na.rm=TRUE),
            meanRSMEvalid=mean(Valid.RMSE, na.rm=TRUE),
            meanMAEvalid=mean(Valid.MAE, na.rm=TRUE)
            )

AIC_lightning_NDT1_spread_treed_summary_VRI2<- AIC_lightning_NDT1_spread_treed_summary_VRI %>%
  mutate(deltaAIC=meanAIC-min(meanAIC))

head(AIC_lightning_NDT1_spread_treed_summary_VRI2)
```
#Now repeat for topography

```{r}
#Create empty table
table.glm.topo.simple.spread <- data.frame (matrix (ncol = 9, nrow = 0))
colnames (table.glm.topo.simple.spread) <- c ("model", "edf", "aic", "Model.R2", "Adjusted.R2", "Valid.R2", "Valid.RMSE", "Valid.MAE", "NDT")

#Run model x100
for (g in 1:100){
  
for (h in 1:length(zones1)) {
  dat2<- subset(spread_data_ALL, spread_data_ALL$ntrl_ds=="NDT1")

for (i in 1: length(zones1)){
  print(paste((all.poss.mods.topo[i]), (ntrl_ds[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(spread, fire_veg, variables_all[i])
  model_dat<- dat2 %>% dplyr::select(LNsize_ha, fire_veg, !!variables_all)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod_lm <- function(mods.in, df.train, dep.var="LNsize_ha") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   predictions <- mods.fit %>% predict(Valid)
   Model.R2 <- summary(mods.fit)$r.squared
   Valid.R2 <- R2(predictions, Valid$LNsize_ha, na.rm=TRUE)
   Valid.RMSE <- RMSE(predictions, Valid$LNsize_ha, na.rm=TRUE)
   Valid.MAE <- MAE(predictions, Valid$LNsize_ha, na.rm=TRUE)
   Adjusted.R2<-summary(mods.fit)$adj.r.squared 
   return(list(rhs, mod.stuff, mod.aic, Model.R2, Valid.R2, Valid.RMSE, Valid.MAE, Adjusted.R2))
   
}

mods.fit <- lapply(all.poss.mods.topo, big.mod_lm, df.train=dat1)

#terms in each model
x1.1 <- unlist(sapply(mods.fit, '[', 1))
x1.1
#Aic for models
x3.1 <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3.1
#Model.R2
x4.1 <- unlist(sapply(mods.fit, '[', 4))
x4.1
#Validation R2
x5.1 <- unlist(sapply(mods.fit, '[', 5))
x5.1
#Validation RSME
x6.1 <- unlist(sapply(mods.fit, '[', 6))
x6.1
#Validation MAE
x7.1 <- unlist(sapply(mods.fit, '[', 7))
x7.1
#Adjusted R2
x8.1 <- unlist(sapply(mods.fit, '[', 8))
x8.1
#combining all as df
tab.sum.topo <- cbind.data.frame(model=x1.1, edf=x3.1[,1], aic=x3.1[,2], Model.R2=x4.1, Adjusted.R2=x8.1, Valid.R2=x5.1, Valid.RMSE=x6.1, Valid.MAE=x7.1)
tab.sum.topo$NDT<-c("NDT1")
tab.sum.topo 

table.glm.topo.simple.spread<-rbind(table.glm.topo.simple.spread, tab.sum.topo)

}
}
}
```
Check data.
```{r}
head(table.glm.topo.simple.spread)
```
Now that we have run the model 100 times, we want the average AIC and goodness of fit metrics for each variable combination..

```{r}
head(table.glm.topo.simple.spread)
table(table.glm.topo.simple.spread$model) # 100 per model

AIC_lightning_NDT1_spread_treed_topo<-table.glm.topo.simple.spread

AIC_lightning_NDT1_spread_treed_summary_topo<- AIC_lightning_NDT1_spread_treed_topo %>%
  group_by(model) %>%
  summarise(meanAIC=mean(aic, na.rm=TRUE),
            meanR2=mean(Model.R2, na.rm=TRUE),
            meanAdjustR2=mean(Adjusted.R2, na.rm=TRUE),
            sdR2=sd(Model.R2, na.rm=TRUE),
            meanR2valid=mean(Valid.R2, na.rm=TRUE),
            meanRSMEvalid=mean(Valid.RMSE, na.rm=TRUE),
            meanMAEvalid=mean(Valid.MAE, na.rm=TRUE)
            )

AIC_lightning_NDT1_spread_treed_summary_topo2<- AIC_lightning_NDT1_spread_treed_summary_topo %>%
  mutate(deltaAIC=meanAIC-min(meanAIC))

head(AIC_lightning_NDT1_spread_treed_summary_topo2)
```

#Now repeat for infrastructure

```{r}
#Create empty table
table.glm.infra.simple.spread <- data.frame (matrix (ncol = 9, nrow = 0))
colnames (table.glm.infra.simple.spread) <- c ("model", "edf", "aic", "Model.R2", "Adjusted.R2", "Valid.R2", "Valid.RMSE", "Valid.MAE", "NDT")

#Run model x100
for (g in 1:100){
  
for (h in 1:length(zones1)) {
  dat2<- subset(spread_data_ALL, spread_data_ALL$ntrl_ds=="NDT1")

for (i in 1: length(zones1)){
  print(paste((all.poss.mods.infra[i]), (ntrl_ds[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(spread, fire_veg, variables_all[i])
  model_dat<- dat2 %>% dplyr::select(LNsize_ha, fire_veg, !!variables_all)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod_lm <- function(mods.in, df.train, dep.var="LNsize_ha") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   predictions <- mods.fit %>% predict(Valid)
   Model.R2 <- summary(mods.fit)$r.squared
   Valid.R2 <- R2(predictions, Valid$LNsize_ha, na.rm=TRUE)
   Valid.RMSE <- RMSE(predictions, Valid$LNsize_ha, na.rm=TRUE)
   Valid.MAE <- MAE(predictions, Valid$LNsize_ha, na.rm=TRUE)
   Adjusted.R2<-summary(mods.fit)$adj.r.squared 
   return(list(rhs, mod.stuff, mod.aic, Model.R2, Valid.R2, Valid.RMSE, Valid.MAE, Adjusted.R2))
   
}

mods.fit <- lapply(all.poss.mods.infra, big.mod_lm, df.train=dat1)

#terms in each model
x1.1 <- unlist(sapply(mods.fit, '[', 1))
x1.1
#Aic for models
x3.1 <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3.1
#Model.R2
x4.1 <- unlist(sapply(mods.fit, '[', 4))
x4.1
#Validation R2
x5.1 <- unlist(sapply(mods.fit, '[', 5))
x5.1
#Validation RSME
x6.1 <- unlist(sapply(mods.fit, '[', 6))
x6.1
#Validation MAE
x7.1 <- unlist(sapply(mods.fit, '[', 7))
x7.1
#Adjusted R2
x8.1 <- unlist(sapply(mods.fit, '[', 8))
x8.1
#combining all as df
tab.sum.infra <- cbind.data.frame(model=x1.1, edf=x3.1[,1], aic=x3.1[,2], Model.R2=x4.1, Adjusted.R2=x8.1, Valid.R2=x5.1, Valid.RMSE=x6.1, Valid.MAE=x7.1)
tab.sum.infra$NDT<-c("NDT1")
tab.sum.infra 

table.glm.infra.simple.spread<-rbind(table.glm.infra.simple.spread, tab.sum.infra)

}
}
}
```
Check data.
```{r}
head(table.glm.infra.simple.spread)
```
Now that we have run the model 100 times, we want the average AIC and goodness of fit metrics for each variable combination..

```{r}
head(table.glm.infra.simple.spread)
table(table.glm.infra.simple.spread$model) # 100 per model 

AIC_lightning_NDT1_spread_treed_infra<-table.glm.infra.simple.spread

AIC_lightning_NDT1_spread_treed_summary_infra<- AIC_lightning_NDT1_spread_treed_infra %>%
  group_by(model) %>%
  summarise(meanAIC=mean(aic, na.rm=TRUE),
            meanR2=mean(Model.R2, na.rm=TRUE),
            meanAdjustR2=mean(Adjusted.R2, na.rm=TRUE),
            sdR2=sd(Model.R2, na.rm=TRUE),
            meanR2valid=mean(Valid.R2, na.rm=TRUE),
            meanRSMEvalid=mean(Valid.RMSE, na.rm=TRUE),
            meanMAEvalid=mean(Valid.MAE, na.rm=TRUE)
            )

AIC_lightning_NDT1_spread_treed_summary_infra2<- AIC_lightning_NDT1_spread_treed_summary_infra %>%
  mutate(deltaAIC=meanAIC-min(meanAIC))

head(AIC_lightning_NDT1_spread_treed_summary_infra2)
```

Combine together
```{r}
NDT1_l_treed_spread<-rbind(AIC_lightning_NDT1_spread_treed_summary_climate2, AIC_lightning_NDT1_spread_treed_summary_infra2, AIC_lightning_NDT1_spread_treed_summary_topo2, AIC_lightning_NDT1_spread_treed_summary_VRI2)

NDT1_l_treed_spread$NDT<-"NDT1"

head(NDT1_l_treed_spread)
```

Save data.
```{r}
write.csv(NDT1_l_treed_spread, file="D:\\Fire\\fire_data\\raw_data\\Firesize_NDT1_models_spread_Dec.csv")
```

##Determine Best Models.
For best models, we will look at R-square of the model, and then within the top R-square, we will assess which had lowest AIC.

1. proj_height_1 + live_stand_volume_125 + bclcs_level_2 + proj_height_1:bclcs_level_2
2. dist_infra + roads_km
3. slope + aspect + wind_atfire + slope:wind_atfire
4. climate1 + climate2 + mdc_atfire

Note: R-square values were all very low, all <0.06, and adjusted Rsquare all < 0.06.


##################### Begin Manual Exploration ##################
Begin manual exploration from here. We will use the above variables, plus additional interactions: wind_atfire + climate1:proj_height_1 + climate1:proj_age_1 + climate1:live_stand_volume_125 + climate1:elevation + climate1:wind_atfire + slope:wind_atfire + elevation:wind_atfire + vegtype2:wind_atfire + Tdif_atfire + Tdif_atfire:wind_atfire + Tdif_atfire:live_stand_volume_125


```{r}
spread_NDT1<-subset(spread_data_ALL, spread_data_ALL$ntrl_ds=="NDT1")

prop<-0.75

#Partition data into training and validation
 trainIndex <- createDataPartition(spread_NDT1$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- spread_NDT1[ trainIndex,]
   Valid <- spread_NDT1[-trainIndex,]
  
#Run model using dat1
model.NDT1<-glm(LNsize_ha ~ proj_height_1 + live_stand_volume_125 + bclcs_level_2 + proj_height_1:bclcs_level_2 + dist_infra + roads_km + slope + aspect + wind_atfire + slope:wind_atfire + climate1 + climate2 + mdc_atfire + climate1:proj_height_1 + climate1*proj_age_1 + climate1*live_stand_volume_125 + climate1*elevation + climate1*wind_atfire + slope*wind_atfire + elevation*wind_atfire + vegtype2*wind_atfire + Tdif_atfire + Tdif_atfire*wind_atfire + Tdif_atfire*live_stand_volume_125, data = dat1)

AIC(model.NDT1) #2066.653
summary(model.NDT1)$r.squared #0.22
summary(model.NDT1)$adj.r.squared #0.16

predictions <- model.NDT1 %>% predict(Valid)
R2(predictions, Valid$LNsize_ha, na.rm=TRUE) #0.07
RMSE(predictions, Valid$LNsize_ha, na.rm=TRUE) #2.07
MAE(predictions, Valid$LNsize_ha, na.rm=TRUE) #1.72

summary(model.NDT1)
Anova(model.NDT1, type=3)

#Remove least sig
model.NDT1<-glm(LNsize_ha ~ proj_height_1 + live_stand_volume_125 + bclcs_level_2 + proj_height_1:bclcs_level_2 + dist_infra + roads_km + slope + aspect + wind_atfire + slope:wind_atfire + climate1 + climate2 + mdc_atfire + climate1:proj_height_1 + climate1*proj_age_1 + climate1*live_stand_volume_125 + climate1*wind_atfire + slope*wind_atfire + elevation*wind_atfire + vegtype2*wind_atfire + Tdif_atfire + Tdif_atfire*live_stand_volume_125, data = dat1)

AIC(model.NDT1) #2062.7
summary(model.NDT1)$r.squared #0.22
summary(model.NDT1)$adj.r.squared #0.17

predictions <- model.NDT1 %>% predict(Valid)
R2(predictions, Valid$LNsize_ha, na.rm=TRUE) #0.07
RMSE(predictions, Valid$LNsize_ha, na.rm=TRUE) #2.07
MAE(predictions, Valid$LNsize_ha, na.rm=TRUE) #1.72

summary(model.NDT1)
Anova(model.NDT1, type=3)

#Remove least sig
model.NDT1<-glm(LNsize_ha ~ proj_height_1 + live_stand_volume_125 + bclcs_level_2 + proj_height_1:bclcs_level_2 + dist_infra + roads_km + slope + aspect + wind_atfire + slope:wind_atfire + climate1 + climate2 + mdc_atfire + climate1*live_stand_volume_125 + climate1*wind_atfire + slope*wind_atfire + elevation*wind_atfire + vegtype2*wind_atfire + Tdif_atfire + Tdif_atfire*live_stand_volume_125, data = dat1)

AIC(model.NDT1) #2057.1
summary(model.NDT1)$r.squared #0.22
summary(model.NDT1)$adj.r.squared #0.17

predictions <- model.NDT1 %>% predict(Valid)
R2(predictions, Valid$LNsize_ha, na.rm=TRUE) #0.08
RMSE(predictions, Valid$LNsize_ha, na.rm=TRUE) #2.06
MAE(predictions, Valid$LNsize_ha, na.rm=TRUE) #1.71

summary(model.NDT1)
Anova(model.NDT1, type=3)

#Remove least sig
model.NDT1<-glm(LNsize_ha ~ proj_height_1 + live_stand_volume_125 + bclcs_level_2 + proj_height_1:bclcs_level_2 + dist_infra + roads_km + slope + aspect + wind_atfire + slope:wind_atfire + climate1 + climate2 + mdc_atfire + climate1*live_stand_volume_125 + slope*wind_atfire + elevation*wind_atfire + vegtype2*wind_atfire + Tdif_atfire, data = dat1)

AIC(model.NDT1) #2054.6
summary(model.NDT1)$r.squared #0.22
summary(model.NDT1)$adj.r.squared #0.17

predictions <- model.NDT1 %>% predict(Valid)
R2(predictions, Valid$LNsize_ha, na.rm=TRUE) #0.07
RMSE(predictions, Valid$LNsize_ha, na.rm=TRUE) #2.07
MAE(predictions, Valid$LNsize_ha, na.rm=TRUE) #1.72

summary(model.NDT1)
Anova(model.NDT1, type=3)

#Remove least sig
model.NDT1<-glm(LNsize_ha ~ proj_height_1 + live_stand_volume_125 + bclcs_level_2 + proj_height_1:bclcs_level_2 + dist_infra + roads_km + slope + aspect + wind_atfire + slope:wind_atfire + climate1 + climate2 + mdc_atfire + elevation*wind_atfire + vegtype2*wind_atfire + Tdif_atfire, data = dat1)

AIC(model.NDT1) #2053.9
summary(model.NDT1)$r.squared #0.21
summary(model.NDT1)$adj.r.squared #0.17

predictions <- model.NDT1 %>% predict(Valid)
R2(predictions, Valid$LNsize_ha, na.rm=TRUE) #0.08
RMSE(predictions, Valid$LNsize_ha, na.rm=TRUE) #2.07
MAE(predictions, Valid$LNsize_ha, na.rm=TRUE) #1.71

summary(model.NDT1)
Anova(model.NDT1, type=3)

#Remove least sig
model.NDT1<-glm(LNsize_ha ~ proj_height_1 + live_stand_volume_125 + bclcs_level_2 + proj_height_1:bclcs_level_2 + dist_infra + roads_km + slope + aspect + wind_atfire + climate1 + climate2 + mdc_atfire + elevation*wind_atfire + vegtype2*wind_atfire + Tdif_atfire, data = dat1)

AIC(model.NDT1) #2053.3
summary(model.NDT1)$r.squared #0.21
summary(model.NDT1)$adj.r.squared #0.17

predictions <- model.NDT1 %>% predict(Valid)
R2(predictions, Valid$LNsize_ha, na.rm=TRUE) #0.07
RMSE(predictions, Valid$LNsize_ha, na.rm=TRUE) #2.07
MAE(predictions, Valid$LNsize_ha, na.rm=TRUE) #1.72

summary(model.NDT1)
Anova(model.NDT1, type=3)

#Remove least sig
model.NDT1<-glm(LNsize_ha ~ proj_height_1 + live_stand_volume_125 + bclcs_level_2 + proj_height_1:bclcs_level_2  + roads_km + slope + aspect + wind_atfire + climate1 + climate2 + mdc_atfire + elevation*wind_atfire + vegtype2*wind_atfire + Tdif_atfire, data = dat1)

AIC(model.NDT1) #2051.4
summary(model.NDT1)$r.squared #0.21
summary(model.NDT1)$adj.r.squared #0.17

predictions <- model.NDT1 %>% predict(Valid)
R2(predictions, Valid$LNsize_ha, na.rm=TRUE) #0.08
RMSE(predictions, Valid$LNsize_ha, na.rm=TRUE) #2.07
MAE(predictions, Valid$LNsize_ha, na.rm=TRUE) #1.72

summary(model.NDT1)
Anova(model.NDT1, type=3)

#Remove least sig
model.NDT1<-glm(LNsize_ha ~ proj_height_1 + live_stand_volume_125 + bclcs_level_2 + proj_height_1:bclcs_level_2 + slope + aspect + wind_atfire + climate1 + climate2 + mdc_atfire + elevation*wind_atfire + vegtype2*wind_atfire + Tdif_atfire, data = dat1)

AIC(model.NDT1) #2049.98
summary(model.NDT1)$r.squared #0.21
summary(model.NDT1)$adj.r.squared #0.17

predictions <- model.NDT1 %>% predict(Valid)
R2(predictions, Valid$LNsize_ha, na.rm=TRUE) #0.07
RMSE(predictions, Valid$LNsize_ha, na.rm=TRUE) #2.07
MAE(predictions, Valid$LNsize_ha, na.rm=TRUE) #1.72

summary(model.NDT1)
Anova(model.NDT1, type=3)


```
Remove NAs and run multiple times.

```{r}
#Remove NAs to ensure all same data used so we can compare AICs
NDT1_spread_size<-spread_NDT1 %>% drop_na(proj_height_1 , live_stand_volume_125, bclcs_level_2, slope , aspect , climate1 , climate2, vegtype2, wind_atfire, elevation, Tdif_atfire)

#Run Model again with this data; but uses all data here
model.NDT1.Spread<-glm(LNsize_ha ~ proj_height_1 + live_stand_volume_125 + bclcs_level_2 + proj_height_1:bclcs_level_2 + slope + aspect + wind_atfire + climate1 + climate2 + mdc_atfire + elevation*wind_atfire + vegtype2*wind_atfire + Tdif_atfire, data = NDT1_spread_size)

#Anova(model.NDT1.Spread, type=3)
Anova(model.NDT1.Spread, type=3, singular.ok = TRUE)

# model diagnostic plots
binnedplot (fitted(model.NDT1.Spread), 
            residuals(model.NDT1.Spread), 
            nclass = NULL, 
            xlab = "Expected Values", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))


NDT1_spread_size$resids<-resid(model.NDT1.Spread)

binnedplot (NDT1_spread_size$live_stand_volume_125, 
            NDT1_spread_size$resids, 
            nclass = NULL, 
            xlab = "live stand volume", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))

binnedplot (NDT1_spread_size$climate1, 
            NDT1_spread_size$resids, 
            nclass = NULL, 
            xlab = "", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))

# Diagnostic plots look good

#Partial Residuals
#LNsize_ha ~ proj_height_1 + live_stand_volume_125 + bclcs_level_2 + proj_height_1:bclcs_level_2 + slope + aspect + wind_atfire + climate1 + climate2 + mdc_atfire + elevation*wind_atfire + vegtype2*wind_atfire + Tdif_atfire

visreg(model.NDT1.Spread, "proj_height_1")
visreg(model.NDT1.Spread, "live_stand_volume_125")

visreg(model.NDT1.Spread, "dist_mine")
visreg(model.NDT1.Spread, "roads_km", by="bclcs_level_5_2", overlay=TRUE)
visreg(model.NDT1.Spread, "bclcs_level_5_2", by="roads_km")

visreg(model.NDT1.Spread, "slope")
visreg(model.NDT1.Spread, "aspect")
visreg(model.NDT1.Spread, "elevation", by="climate1")
visreg(model.NDT1.Spread, "elevation", by="wind_atfire")
#climate1 + vegtype2 + wind_atfire  + elevation + climate1:elevation + elevation:wind_atfire + vegtype2:wind_atfire

visreg(model.NDT1.Spread, "climate1", by="elevation")
visreg(model.NDT1.Spread, "vegtype2", by="wind_atfire")

visreg(model.NDT1.Spread, "wind_atfire", by="vegtype2", overlay=TRUE)
visreg(model.NDT1.Spread, "wind_atfire", by="elevation")

```
We should repeat the above several times and take the mean of the coefficients.

```{r}
summary(model.NDT1.Spread)

#Create a new blank table and get AUC too
top_mod_table_NDT1_lightning_t_ALL <- data.frame (matrix (ncol = 30, nrow = 0))
colnames (top_mod_table_NDT1_lightning_t_ALL ) <- c ("CAUSE", "NDT", "TREED", "Model_terms", "intercept", "coef_proj_height_1", "coef_live_stand_volume_125", "coef_dist_mine", "coef_roads_km", "coef_bclcs_level_5_2OP", "coef_bclcs_level_5_2SP", "coef_slope", "coef_aspect", "coef_climate_1", "coef_vegtypeTC", "coef_vegtypeTM", "coef_wind_atfire", "coef_elevation", "coef_roads_km:bclcs_level_5_2OP", "coef_roads_km:bclcs_level_5_2SP", "coef_climate1:elevation", "coef_wind_atfire:elevation", "coef_vegtype2TC:wind_atfire", "coef_vegtype2TM:wind_atfire", "AIC", "Model.R2", "Valid.R2", "Valid.RSME", "Valid.MAE", "Adjusted.R2")

```

Let's run it 500 times to get good mean values.

```{r}

for (g in 1:500){

prop<-0.75
# Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(NDT1_spread_size$vegtype2, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- NDT1_spread_size[ trainIndex,]
   Valid <- NDT1_spread_size[-trainIndex,]
   
#Model   
model.NDT1.Spread<-glm(LNsize_ha ~ proj_height_1 + live_stand_volume_125  + dist_mine + roads_km + bclcs_level_5_2 + roads_km:bclcs_level_5_2 + slope + aspect + climate1 + vegtype2 + wind_atfire + elevation + climate1:elevation + elevation:wind_atfire + vegtype2:wind_atfire, data = dat1) 

predictions <- model.NDT1.Spread %>% predict(Valid)

# create model table (only do this once) and add the relevant data
top_mod_table_NDT1_lightning_t <- data.frame (matrix (ncol = 30, nrow = 0))
colnames (top_mod_table_NDT1_lightning_t ) <- c ("CAUSE", "NDT", "TREED", "Model_terms", "intercept", "coef_proj_height_1", "coef_live_stand_volume_125", "coef_dist_mine", "coef_roads_km", "coef_bclcs_level_5_2OP", "coef_bclcs_level_5_2SP", "coef_slope", "coef_aspect", "coef_climate_1", "coef_vegtypeTC", "coef_vegtypeTM", "coef_wind_atfire", "coef_elevation", "coef_roads_km:bclcs_level_5_2OP", "coef_roads_km:bclcs_level_5_2SP", "coef_climate1:elevation", "coef_wind_atfire:elevation", "coef_vegtype2TC:wind_atfire", "coef_vegtype2TM:wind_atfire", "AIC", "Model.R2", "Valid.R2", "Valid.RSME", "Valid.MAE", "Adjusted.R2")

##Add data for NDT1
top_mod_table_NDT1_lightning_t[1,1]<-"lightning"
top_mod_table_NDT1_lightning_t[1,2]<-"NDT1"
top_mod_table_NDT1_lightning_t[1,3]<-"Y"
top_mod_table_NDT1_lightning_t[1,4]<-"LNsize_ha ~ proj_height_1 + live_stand_volume_125  + dist_mine + roads_km + bclcs_level_5_2 + roads_km:bclcs_level_5_2 + slope + aspect + climate1 + vegtype2 + wind_atfire + elevation + climate1:elevation + elevation:wind_atfire + vegtype2:wind_atfire" 
top_mod_table_NDT1_lightning_t[1,5]<- coef(model.NDT1.Spread)[1] #Intercept
top_mod_table_NDT1_lightning_t[1,6]<- coef(model.NDT1.Spread)[2] #C
top_mod_table_NDT1_lightning_t[1,7]<- coef(model.NDT1.Spread)[3] #C
top_mod_table_NDT1_lightning_t[1,8]<- coef(model.NDT1.Spread)[4] #co
top_mod_table_NDT1_lightning_t[1,9]<- coef(model.NDT1.Spread)[5] #co
top_mod_table_NDT1_lightning_t[1,10]<- coef(model.NDT1.Spread)[6] #c
top_mod_table_NDT1_lightning_t[1,11]<- coef(model.NDT1.Spread)[7] #l
top_mod_table_NDT1_lightning_t[1,12]<- coef(model.NDT1.Spread)[8] #co
top_mod_table_NDT1_lightning_t[1,13]<- coef(model.NDT1.Spread)[9] #c
top_mod_table_NDT1_lightning_t[1,14]<- coef(model.NDT1.Spread)[10] #coeff
top_mod_table_NDT1_lightning_t[1,15]<- coef(model.NDT1.Spread)[11] #co
top_mod_table_NDT1_lightning_t[1,16]<- coef(model.NDT1.Spread)[12] #coe
top_mod_table_NDT1_lightning_t[1,17]<- coef(model.NDT1.Spread)[13] #co
top_mod_table_NDT1_lightning_t[1,18]<- coef(model.NDT1.Spread)[14] #co
top_mod_table_NDT1_lightning_t[1,19]<- coef(model.NDT1.Spread)[15] #
top_mod_table_NDT1_lightning_t[1,20]<- coef(model.NDT1.Spread)[16] # cl
top_mod_table_NDT1_lightning_t[1,21]<- coef(model.NDT1.Spread)[17] # c
top_mod_table_NDT1_lightning_t[1,22]<- coef(model.NDT1.Spread)[18] #coefficien
top_mod_table_NDT1_lightning_t[1,23]<- coef(model.NDT1.Spread)[19] #coefficien
top_mod_table_NDT1_lightning_t[1,24]<- coef(model.NDT1.Spread)[20] #coefficien
top_mod_table_NDT1_lightning_t[1,25]<- AIC(model.NDT1.Spread)
top_mod_table_NDT1_lightning_t[1,26]<- summary(model.NDT1.Spread)$r.squared
top_mod_table_NDT1_lightning_t[1,27]<- R2(predictions, Valid$LNsize_ha, na.rm=TRUE)
top_mod_table_NDT1_lightning_t[1,28]<- RMSE(predictions, Valid$LNsize_ha, na.rm=TRUE)
top_mod_table_NDT1_lightning_t[1,29]<- MAE(predictions, Valid$LNsize_ha, na.rm=TRUE)
top_mod_table_NDT1_lightning_t[1,30]<- summary(model.NDT1.Spread)$adj.r.squared

top_mod_table_NDT1_lightning_t_ALL<-rbind(top_mod_table_NDT1_lightning_t_ALL, top_mod_table_NDT1_lightning_t)

}

```

Check.
```{r}
head(top_mod_table_NDT1_lightning_t_ALL)

```

#Save coefficient table

```{r}
write.csv(top_mod_table_NDT1_lightning_t_ALL, file="D:\\Fire\\fire_data\\raw_data\\top_mod_model.NDT1.Spread_firesize_lightning_t.csv")
```


#Get Mean Values

```{r}
names(top_mod_table_NDT1_lightning_t_ALL)

top_mod_table_NDT1_model.NDT1.Spreadlightning_t_means<-top_mod_table_NDT1_lightning_t_ALL %>% summarise_each(funs( mean( .,na.rm = TRUE)))
top_mod_table_NDT1_model.NDT1.Spreadlightning_t_means

top_mod_table_NDT1_model.NDT1.Spreadlightning_t_means[1,1]<-"lightning"
top_mod_table_NDT1_model.NDT1.Spreadlightning_t_means[1,2]<-"NDT1"
top_mod_table_NDT1_model.NDT1.Spreadlightning_t_means[1,3]<-"Treed"
top_mod_table_NDT1_model.NDT1.Spreadlightning_t_means[1,4]<- "LNsize_ha ~ proj_height_1 + live_stand_volume_125  + dist_mine + roads_km + bclcs_level_5_2 + roads_km:bclcs_level_5_2 + slope + aspect + climate1 + vegtype2 + wind_atfire + elevation + climate1:elevation + elevation:wind_atfire + vegtype2:wind_atfire" 
top_mod_table_NDT1_model.NDT1.Spreadlightning_t_means
```
Save table.

```{r}
write.csv(top_mod_table_NDT1_model.NDT1.Spreadlightning_t_means, file="D:\\Fire\\fire_data\\raw_data\\top_mod_model.NDT1.Spread_firesize_lightning_t_Means.csv")
```

Standard deviation.

```{r}
top_mod_table_NDT1_model.NDT1.Spreadlightning_t_sd<-top_mod_table_NDT1_lightning_t_ALL %>% summarise_each(funs( sd( .,na.rm = TRUE)))
top_mod_table_NDT1_model.NDT1.Spreadlightning_t_sd

top_mod_table_NDT1_model.NDT1.Spreadlightning_t_sd[1,1]<-"lightning"
top_mod_table_NDT1_model.NDT1.Spreadlightning_t_sd[1,2]<-"NDT1"
top_mod_table_NDT1_model.NDT1.Spreadlightning_t_sd[1,3]<-"Treed"
top_mod_table_NDT1_model.NDT1.Spreadlightning_t_sd[1,4]<-"LNsize_ha ~ proj_height_1 + live_stand_volume_125  + dist_mine + roads_km + bclcs_level_5_2 + roads_km:bclcs_level_5_2 + slope + aspect + climate1 + vegtype2 + wind_atfire + elevation + climate1:elevation + elevation:wind_atfire + vegtype2:wind_atfire" 
top_mod_table_NDT1_model.NDT1.Spreadlightning_t_sd
```

Save sd coefficient table.

```{r}
write.csv(top_mod_table_NDT1_model.NDT1.Spreadlightning_t_sd, file="D:\\Fire\\fire_data\\raw_data\\top_mod_model.NDT1.Spread_firesize_lightning_t_SD.csv")
```



#Compare to transformation of variables?

```{r}
spread_NDT1b<- spread_NDT1 %>% drop_na(LNstand_height, LNstand_volume, LNdist_mine, roads_km, bclcs_level_5_2, slope, aspect, climate1, vegtype2, LNwind)

#Partition data into training and validation
 trainIndex <- createDataPartition(spread_NDT1$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- spread_NDT1[ trainIndex,]
   Valid <- spread_NDT1[-trainIndex,]
   
#Best model without transformations
model.NDT1<-glm(LNsize_ha ~ proj_height_1 + live_stand_volume_125  + dist_mine + roads_km + bclcs_level_5_2 + roads_km:bclcs_level_5_2 + slope + aspect + climate1 + vegtype2 + wind_atfire  + climate1:elevation + elevation:wind_atfire + vegtype2:wind_atfire, data = dat1)

AIC(model.NDT1) #1652.5
summary(model.NDT1)$r.squared #0.24
summary(model.NDT1)$adj.r.squared #0.20

predictions <- model.NDT1 %>% predict(Valid)
R2(predictions, Valid$LNsize_ha, na.rm=TRUE) #0.03
RMSE(predictions, Valid$LNsize_ha, na.rm=TRUE) #2.16
MAE(predictions, Valid$LNsize_ha, na.rm=TRUE) #1.84

summary(model.NDT1)
Anova(model.NDT1, type=3)

#Transformations
model.NDT1<-glm(LNsize_ha ~ LNstand_height  + live_stand_volume_125 + LNdist_mine + roads_km + bclcs_level_5_2 + roads_km:bclcs_level_5_2 + slope + aspect + climate1 + vegtype2 + LNwind  + climate1:elevation + elevation:LNwind + vegtype2:LNwind, data = dat1)

AIC(model.NDT1) #1668.7
summary(model.NDT1)$r.squared #0.20
summary(model.NDT1)$adj.r.squared #0.17

predictions <- model.NDT1 %>% predict(Valid)
R2(predictions, Valid$LNsize_ha, na.rm=TRUE) #0.03
RMSE(predictions, Valid$LNsize_ha, na.rm=TRUE) #2.16
MAE(predictions, Valid$LNsize_ha, na.rm=TRUE) #1.82

summary(model.NDT1)
Anova(model.NDT1, type=3)


```

