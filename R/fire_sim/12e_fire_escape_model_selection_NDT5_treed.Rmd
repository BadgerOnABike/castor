---
title: "12e_fire_escape_model_selection_NDT5"
author: "Cora Skaien"
date: "28/09/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

#Load relevant libraries
library(sf)
library(tidyverse)
library(ggplot2)
library (ggcorrplot)
library (RPostgreSQL)
library (rpostgis)
library (dplyr)
library (lme4)
library (arm)
library(ggpubr)
library(mgcv)
library(nlme)
library(purrr)
library(tidyr)
library(caret)
library(pROC)
library(keyring)
library(ggcorrplot) 
library (kableExtra)
library (data.table)
library (DBI)
library (RPostgreSQL)
library (dplyr)
library (ggplot2)
library (here)
library(AICcmodavg)
library(caret)
library(pROC)
library(rje)
library(base)
library(car)

source(here::here("R/functions/R_Postgres.R"))
```

<!--
Copyright 2021 Province of British Columbia

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and limitations under the License.
-->

Load in the prepped data.

```{r}
Escape_data_lightning_t<-read.csv(file="D:\\Fire\\fire_data\\raw_data\\ClimateBC_Data\\escape_data_lightning_trees_NDT.csv")

head(Escape_data_lightning_t)

```

Check how mnay data points there are for NDT5, lightning, treed models. The data may be too low to really do the below selection process.

```{r}
Escape_data_lightning_t_NDT5<-subset(Escape_data_lightning_t, Escape_data_lightning_t$ntrl_ds=="NDT5")

str(Escape_data_lightning_t_NDT5) #116 observations...
table(Escape_data_lightning_t_NDT5$escape) #97 not escaped, 19 escaped. 

table(Escape_data_lightning_t_NDT5$vegtype2) #All TC, so cannot include vegtype as a variable

```

#Note: with so few occurences, we will be limited to very few variables, otherwise we will overfit. We may be able to have 3-4 ideally. So investigate different ones and look for strongest patterns Must avoid overfitting.

################ PART 1: Lightning Caused Fires ################

We will make a loop that does something very similar to our last loop, but with the selected climate variable plus other variables of interest. For lightning caused fires with trees, the variables of interest include:

1. Climate variable(s)
2. Projected Height (proj_height_1)
3. projected age (proj_age_1)  
4. live_stand_volume_125
5. vegtype2
6. slope
7. aspect (cos)
8. elevation
9. Various distance to infrastructure variables (dist_mun, dist_dam, dist_nat, dist_pow, dist_mine) - no interactions
10. Land use (bclcs_level_5_2)
11. windspeed (wind_atfire)
12. roads_km (road density, which may relate to ability to fight fires)

Interactions of interest: two-way interactions between climate (1) and vegtype (5); two-way interactions between topography measures (6-8). 

This will be done separately for trees and non-treed areas. 

##We will do each loop separately for each NDT zone given the large number of possible models for each zone.

First we will create the variable lists that contain all of our variables of interest.

```{r}
##Create variable lists to be used in the model loop.
variables_all<-c(climate1 = "climate1", climate2 = "climate2", proj_height_1 = "proj_height_1", proj_age_1 = "proj_age_1", live_stand_volume_125 = "live_stand_volume_125", slope = "slope", aspect = "aspect", elevation ="elevation", vegtype2 = "vegtype2", bclcs_level_5_2 = "bclcs_level_5_2", dist_mun = "dist_mun", dist_dam ="dist_dam", dist_nat = "dist_nat", dist_pow = "dist_pow", dist_mine = "dist_mine", wind_atfire = "wind_atfire", roads_km="roads_km") 

variables_all_c1<-c(climate1 = "climate1", proj_height_1 = "proj_height_1", proj_age_1 = "proj_age_1", live_stand_volume_125 = "live_stand_volume_125", slope = "slope", aspect = "aspect", elevation ="elevation", vegtype2 = "vegtype2", bclcs_level_5_2 = "bclcs_level_5_2", dist_mun = "dist_mun", dist_dam ="dist_dam", dist_nat = "dist_nat", dist_pow = "dist_pow", dist_mine = "dist_mine", wind_atfire = "wind_atfire", roads_km="roads_km") 


vars.clim<-c("climate1")
vars.clim.vegtype<-c("climate1", "vegtype2")
vars.oth<-c("proj_height_1", "proj_age_1", "live_stand_volume_125") 
vars.topo<-c("slope", "aspect", "elevation", "wind_atfire")
vars.infra<-c("dist_mun", "dist_dam", "dist_nat", "dist_pow", "dist_mine", "roads_km")

#Also for later with 2 climate variables
vars.clim.vegtype2<-c("climate1", "climate2","vegtype2")
vars.clim.vegtype2b<-c("climate1", "climate2")

##Create interaction for climate and vegtype
inputs.me <- c(vars.clim.vegtype)
inputs.me2 <- c(vars.clim.vegtype2)
inputs.me2b <- c(vars.clim.vegtype2b)
```


Now, we will generate two-way interactions for each of these lists. 

```{r}

#####1a. For those with one climate variable
#get the names of all possible two-way interactions for climate variable(s) and vegtype.
twoway.ints <- NULL
for (i in 1:(length(inputs.me)-1)) {
  for (j in (i+1):length(inputs.me)) {
     twoway.ints <- cbind(twoway.ints, paste(inputs.me[i], inputs.me[j], sep=":"))
  }
}
twoway.ints
length(twoway.ints)#1

#
#Create function to determine Powerset for any vector of variable names
## or use rje package
#powerSet <- function(x) {
#   z.list <- NULL
#   for(i in 1:length(x)) {
#      z.list <- append(z.list, combn(x, m=i, simplify=F))
#   }    
#   return(z.list)
#}


#Get variables on own
#complete list of models using non-climate vars
mods.me.tmp <- powerSet(vars.clim.vegtype) 
#add climate vars to all of the above
mods.me.climate <- list()
for (i in 1: length(mods.me.tmp)) {
   mods.me.climate[[i]] <- c(mods.me.tmp[[i]])
}

mods.me.climate
mods.me.climate<-mods.me.climate[-1]

#####1b. For those with two climate variables
#get the names of all possible two-way interactions for climate variable(s) and vegtype.
twoway.ints2 <- NULL
for (i in 1:(length(inputs.me2)-1)) {
  for (j in (i+1):length(inputs.me2)) {
     twoway.ints2 <- cbind(twoway.ints2, paste(inputs.me2[i], inputs.me2[j], sep=":"))
  }
}
twoway.ints2
length(twoway.ints2) #3

#Get variables on own
#complete list of models using non-climate vars
mods.me.tmp <- powerSet(vars.clim.vegtype2) 
#add climate vars to all of the above
mods.me.climate2 <- list()
for (i in 1: length(mods.me.tmp)) {
   mods.me.climate2[[i]] <- c(mods.me.tmp[[i]])
}

mods.me.climate2
mods.me.climate2<-mods.me.climate2[-1]

#complete list of two-way interactions
mods.twoway2 <- powerSet(twoway.ints2)
length(mods.twoway2) #8
mods.twoway2
mods.twoway2<-mods.twoway2[-1]

#Finding models in mods.me that accommodate/allow interaction terms in each mods.twoway to be added
mods.inter2 <- list()
counter <- 0
for (i in 1: length(mods.twoway2)) {
   s1 <- unique(unlist( strsplit(mods.twoway2[[i]], split=':', fixed=TRUE) ) )
   for (j in 1: length(mods.me.climate2)) {
      if (all(s1 %in% mods.me.climate2[[j]])==TRUE) {
        counter <- counter + 1
        both <-  c(mods.me.climate2[[j]], mods.twoway2[[i]])
        mods.inter2[[counter]] <- both
      }
   }
}

length(mods.inter2) #10
#mods.inter2
mods.inter2


####1c. Two variables, no variation in vegtype
#get the names of all possible two-way interactions for climate variable(s) and vegtype.
twoway.ints2b <- NULL
for (i in 1:(length(inputs.me2b)-1)) {
  for (j in (i+1):length(inputs.me2b)) {
     twoway.ints2b <- cbind(twoway.ints2b, paste(inputs.me2b[i], inputs.me2b[j], sep=":"))
  }
}
twoway.ints2b
length(twoway.ints2b) #1

#Get variables on own
#complete list of models using non-climate vars
mods.me.tmp <- powerSet(vars.clim.vegtype2b) 
#add climate vars to all of the above
mods.me.climate2b <- list()
for (i in 1: length(mods.me.tmp)) {
   mods.me.climate2b[[i]] <- c(mods.me.tmp[[i]])
}

mods.me.climate2b
mods.me.climate2b<-mods.me.climate2b[-1]

#complete list of two-way interactions
mods.twoway2b <- powerSet(twoway.ints2b)
length(mods.twoway2b) #2
mods.twoway2b
mods.twoway2b<-mods.twoway2b[-1]

#Finding models in mods.me that accommodate/allow interaction terms in each mods.twoway to be added
mods.inter2b <- list()
counter <- 0
for (i in 1: length(mods.twoway2b)) {
   s1 <- unique(unlist( strsplit(mods.twoway2b[[i]], split=':', fixed=TRUE) ) )
   for (j in 1: length(mods.me.climate2b)) {
      if (all(s1 %in% mods.me.climate2b[[j]])==TRUE) {
        counter <- counter + 1
        both <-  c(mods.me.climate2b[[j]], mods.twoway2b[[i]])
        mods.inter2b[[counter]] <- both
      }
   }
}

length(mods.inter2b)
#mods.inter2b


#########2. Now for topography data, get all possible two-way interactions

#get the names of all possible two-way interactions
twoway.intsT <- NULL
for (i in 1:(length(vars.topo)-1)) {
  for (j in (i+1):length(vars.topo)) {
     twoway.intsT <- cbind(twoway.intsT, paste(vars.topo[i], vars.topo[j], sep=":"))
  }
}
twoway.intsT
length(twoway.intsT) #6

#complete list of models using non-climate vars (topo)
mods.me.tmp <- powerSet(vars.topo) 
#add climate vars to all of the above
mods.meT <- list()
for (i in 1: length(mods.me.tmp)) {
   mods.meT[[i]] <- c(mods.me.tmp[[i]])
}

mods.meT
mods.meT<-mods.meT[-1]

#complete list of two-way interactions
mods.twowayT <- powerSet(twoway.intsT)
length(mods.twowayT) #64
mods.twowayT
mods.twowayT<-mods.twowayT[-1]

#Finding models in mods.me that accommodate/allow interaction terms in each mods.twoway to be added

mods.interT <- list()
counter <- 0
for (i in 1: length(mods.twowayT)) {
   s1 <- unique(unlist( strsplit(mods.twowayT[[i]], split=':', fixed=TRUE) ) )
   for (j in 1: length(mods.meT)) {
      if (all(s1 %in% mods.meT[[j]])==TRUE) {
        counter <- counter + 1
        both <-  c(mods.meT[[j]], mods.twowayT[[i]])
        mods.interT[[counter]] <- both
      }
   }
}

length(mods.interT) #97
#mods.interT


####3.For other VRI data, get without interactions

#complete list of models using VRI - no interactions
mods.me.tmp <- powerSet(vars.oth) 
#add climate vars to all of the above
mods.me.oth <- list()
for (i in 1: length(mods.me.tmp)) {
   mods.me.oth[[i]] <- c(mods.me.tmp[[i]])
}

mods.me.oth
mods.me.oth<-mods.me.oth[-1]


#########4. Now for distance to infrastructure data, get all possible two-way interactions

#get the names of all possible two-way interactions
twoway.intsI <- NULL
for (i in 1:(length(vars.infra)-1)) {
  for (j in (i+1):length(vars.infra)) {
     twoway.intsI <- cbind(twoway.intsI, paste(vars.infra[i], vars.infra[j], sep=":"))
  }
}
twoway.intsI
length(twoway.intsI) #15

#complete list of models using non-climate vars (infra)
mods.me.tmp <- powerSet(vars.infra) 
#add climate vars to all of the above
mods.meI <- list()
for (i in 1: length(mods.me.tmp)) {
   mods.meI[[i]] <- c(mods.me.tmp[[i]])
}

mods.meI
mods.meI<-mods.meI[-1]

#complete list of two-way interactions
mods.twowayI <- powerSet(twoway.intsI)
length(mods.twowayI) #32768 -
#mods.twowayI

#Finding models in mods.me that accommodate/allow interaction terms in each mods.twoway to be added

mods.interI <- list()
counter <- 0
for (i in 1: length(mods.twowayI)) {
   s1 <- unique(unlist( strsplit(mods.twowayI[[i]], split=':', fixed=TRUE) ) )
   for (j in 1: length(mods.meI)) {
      if (all(s1 %in% mods.meI[[j]])==TRUE) {
        counter <- counter + 1
        both <-  c(mods.meI[[j]], mods.twowayI[[i]])
        mods.interI[[counter]] <- both
      }
   }
}

length(mods.interI) #80136
#mods.interI


#the list of all possible model RHSs. 
#all.poss.mods <- c(1, vars.clim, twoway.ints, mods.me.oth, mods.me2, mods.inter2)
#all.poss.mods

all.poss.mods.clim.vegtype<-c(1, mods.me.climate, twoway.ints)
all.poss.mods.clim.vegtype 

all.poss.mods.clim.vegtype2<-c(1, mods.me.climate2, mods.inter2)
all.poss.mods.clim.vegtype2

all.poss.mods.clim.vegtype2b<-c(1, mods.me.climate2b, mods.inter2b)
all.poss.mods.clim.vegtype2b

all.poss.mods.VRI<-c(1, mods.me.oth)
all.poss.mods.VRI

all.poss.mods.topo<-c(1, mods.interT)
all.poss.mods.topo

all.poss.mods.infra<-c(1, mods.meI) #I don't think we want interactions here actually... we will in the next stage when we include bclcs_level_5_2 after some initial pattern exploration


#If need to determine which ones are character(0), try this:
biglist <- list(list("A","B","C"), "foo", "", character(0), integer(0))
lapply(biglist, function(x) {length(x) == 0L} ) 


##Check and rid of any duplicated models
duplicated(all.poss.mods.clim.vegtype) #None duplicated
duplicated(all.poss.mods.clim.vegtype2)
duplicated(all.poss.mods.clim.vegtype2b)
duplicated(all.poss.mods.VRI)
duplicated(all.poss.mods.topo)
duplicated(all.poss.mods.infra)

```

############### Part 1 of 4 Model Series: Lightning Caused Fires, Trees ##########

Because of the large number of models with all variables included, we will test the climate and vegtype first, then the VRI variables, then the topography variables. Then we will test the top models together in additional combinations, with determining best AIC model from there. Or perhaps we will just combine the top models for each together, and eliminate models if the intercept was the best predictor.

Select NDT: NDT5

```{r}
zones1<-c("NDT5") #Do one zone at a time

prop<-0.75

#Create empty table
table.glm.climate.simple <- data.frame (matrix (ncol = 5, nrow = 0))
colnames (table.glm.climate.simple) <- c ("model", "edf", "aic", "auc.valid", "NDT")

########### 1. Climate and vegtype ############
for (g in 1:100){

for (h in 1:length(zones1)) {
  dat2<- Escape_data_lightning_t %>% dplyr::filter(ntrl_ds ==zones1[h])
  
for (i in 1: length(zones1)){
  print(paste((all.poss.mods.clim.vegtype2b[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(escape, veg_escape, variables_all[i])
  model_dat<- dat2 %>% dplyr::select(escape, veg_escape, !!variables_all)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$veg_escape, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="escape") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.aic, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.clim.vegtype2b, big.mod, df.train=dat1, df.test=Valid)

#terms in each model
x1.1 <- unlist(sapply(mods.fit, '[', 1))
x1.1
#Aic for models
x3.1 <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3.1
#auc from validation data
x4.1 <- unlist(sapply(mods.fit, '[', 4))
x4.1
#combining all as df
tab.sum.climate <- cbind.data.frame(model=x1.1, edf=x3.1[,1], aic=x3.1[,2], auc.valid=x4.1)
tab.sum.climate$NDT<-c("NDT5")
tab.sum.climate 

table.glm.climate.simple<-rbind(table.glm.climate.simple, tab.sum.climate)

}
}
}


```

Now that we have run the model 100 times, we want the average AIC and AUC for each variable combination.

```{r}
head(table.glm.climate.simple)
table(table.glm.climate.simple$model) # 100 per model

AIC_lightning_NDT5_treed_climate<-table.glm.climate.simple

AIC_lightning_NDT5_treed_summary_climate<- AIC_lightning_NDT5_treed_climate %>%
  group_by(model) %>%
  summarise(meanAIC=mean(aic),
            meanAUC=mean(auc.valid),
            sdAUC=sd(auc.valid),
            )

AIC_lightning_NDT5_treed_summary_climate2<- AIC_lightning_NDT5_treed_summary_climate %>%
  mutate(deltaAIC=meanAIC-min(meanAIC))

head(AIC_lightning_NDT5_treed_summary_climate2)
```

#Now repeat for VRI data

```{r}
########### 2. VRI ############
#Create empty table
table.glm.VRI.simple <- data.frame (matrix (ncol = 5, nrow = 0))
colnames (table.glm.VRI.simple) <- c ("model", "edf", "aic", "auc.valid", "NDT")

####
for (g in 1:100){

for (h in 1:length(zones1)) {
  dat2<- Escape_data_lightning_t %>% dplyr::filter(ntrl_ds ==zones1[h])

#for (i in 1: length(all.poss.mods.VRI)){
#  print(paste((all.poss.mods.VRI[i]), (zones1[h]), sep=" "))
  
for (i in 1: length(zones1)){
  print(paste((all.poss.mods.VRI[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(escape, veg_escape, variables_all[i])
  model_dat<- dat2 %>% dplyr::select(escape, veg_escape, !!variables_all)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$veg_escape, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="escape") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.aic, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.VRI, big.mod, df.train=dat1, df.test=Valid)

#terms in each model
x1.1 <- unlist(sapply(mods.fit, '[', 1))
x1.1
#Aic for models
x3.1 <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3.1
#auc from validation data
x4.1 <- unlist(sapply(mods.fit, '[', 4))
x4.1
#combining all as df
tab.sum.VRI <- cbind.data.frame(model=x1.1, edf=x3.1[,1], aic=x3.1[,2], auc.valid=x4.1)
tab.sum.VRI$NDT<-c("NDT5")
tab.sum.VRI 

table.glm.VRI.simple<-rbind(table.glm.VRI.simple, tab.sum.VRI)

}
}
}
```

Now that we have run the model 100 times, we want the average AIC and AUC for each variable combination.

```{r}
head(table.glm.VRI.simple)
table(table.glm.VRI.simple$model) # 100 per model

AIC_lightning_NDT5_treed_VRI<-table.glm.VRI.simple

AIC_lightning_NDT5_treed_summary_VRI<- AIC_lightning_NDT5_treed_VRI %>%
  group_by(model) %>%
  summarise(meanAIC=mean(aic),
            meanAUC=mean(auc.valid),
            sdAUC=sd(auc.valid),
            )

AIC_lightning_NDT5_treed_summary_VRI2<- AIC_lightning_NDT5_treed_summary_VRI %>%
  mutate(deltaAIC=meanAIC-min(meanAIC))

head(AIC_lightning_NDT5_treed_summary_VRI2)
```

#Now repeat for topography

```{r}
########### 3. topo ############
#Create empty table
table.glm.topo.simple <- data.frame (matrix (ncol = 5, nrow = 0))
colnames (table.glm.topo.simple) <- c ("model", "edf", "aic", "auc.valid", "NDT")

#
for (g in 1:100){

for (h in 1:length(zones1)) {
  dat2<- Escape_data_lightning_t %>% dplyr::filter(ntrl_ds ==zones1[h])

#for (i in 1: length(all.poss.mods.topo)){
#  print(paste((all.poss.mods.topo[i]), (zones1[h]), sep=" "))
  
for (i in 1: length(zones1)){
  print(paste((all.poss.mods.topo[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(escape, veg_escape, variables_all[i])
  model_dat<- dat2 %>% dplyr::select(escape, veg_escape, !!variables_all)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$veg_escape, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="escape") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.aic, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.topo, big.mod, df.train=dat1, df.test=Valid)

#terms in each model
x1.1 <- unlist(sapply(mods.fit, '[', 1))
x1.1
#Aic for models
x3.1 <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3.1
#auc from validation data
x4.1 <- unlist(sapply(mods.fit, '[', 4))
x4.1
#combining all as df
tab.sum.topo <- cbind.data.frame(model=x1.1, edf=x3.1[,1], aic=x3.1[,2], auc.valid=x4.1)
tab.sum.topo$NDT<-c("NDT5")
tab.sum.topo 

table.glm.topo.simple<-rbind(table.glm.topo.simple, tab.sum.topo)

}
}
}
```

Now that we have run the model 100 times, we want the average AIC and AUC for each variable combination.

```{r}
head(table.glm.topo.simple)
table(table.glm.topo.simple$model) # 100 per model

AIC_lightning_NDT5_treed_topo<-table.glm.topo.simple

AIC_lightning_NDT5_treed_summary_topo<- AIC_lightning_NDT5_treed_topo %>%
  group_by(model) %>%
  summarise(meanAIC=mean(aic),
            meanAUC=mean(auc.valid),
            sdAUC=sd(auc.valid),
            )

AIC_lightning_NDT5_treed_summary_topo2<- AIC_lightning_NDT5_treed_summary_topo %>%
  mutate(deltaAIC=meanAIC-min(meanAIC))

head(AIC_lightning_NDT5_treed_summary_topo2)
```

#Now repeat for infrastructure

```{r}
########### 4. Distance to Infrastructure ############
#Create empty table
table.glm.infra.simple <- data.frame (matrix (ncol = 5, nrow = 0))
colnames (table.glm.infra.simple) <- c ("model", "edf", "aic", "auc.valid", "NDT")

#
for (g in 1:100){

for (h in 1:length(zones1)) {
  dat2<- Escape_data_lightning_t %>% dplyr::filter(ntrl_ds ==zones1[h])

#for (i in 1: length(all.poss.mods.infra)){
#  print(paste((all.poss.mods.infra[i]), (zones1[h]), sep=" "))
  
for (i in 1: length(zones1)){
  print(paste((all.poss.mods.infra[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(escape, veg_escape, variables_all[i])
  model_dat<- dat2 %>% dplyr::select(escape, veg_escape, !!variables_all)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$veg_escape, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="escape") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.aic, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.infra, big.mod, df.train=dat1, df.test=Valid)

#terms in each model
x1.1 <- unlist(sapply(mods.fit, '[', 1))
x1.1
#Aic for models
x3.1 <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3.1
#auc from validation data
x4.1 <- unlist(sapply(mods.fit, '[', 4))
x4.1
#combining all as df
tab.sum.infra <- cbind.data.frame(model=x1.1, edf=x3.1[,1], aic=x3.1[,2], auc.valid=x4.1)
tab.sum.infra$NDT<-c("NDT5")
tab.sum.infra 

table.glm.infra.simple<-rbind(table.glm.infra.simple, tab.sum.infra)

}
}
}
```

Now that we have run the model 100 times, we want the average AIC and AUC for each variable combination.

```{r}
head(table.glm.infra.simple)
table(table.glm.infra.simple$model) # 100 per model

AIC_lightning_NDT5_treed_infra<-table.glm.infra.simple

AIC_lightning_NDT5_treed_summary_infra<- AIC_lightning_NDT5_treed_infra %>%
  group_by(model) %>%
  summarise(meanAIC=mean(aic),
            meanAUC=mean(auc.valid),
            sdAUC=sd(auc.valid),
            )

AIC_lightning_NDT5_treed_summary_infra2<- AIC_lightning_NDT5_treed_summary_infra %>%
  mutate(deltaAIC=meanAIC-min(meanAIC))

head(AIC_lightning_NDT5_treed_summary_infra2)

```

#Now combine the datatables and save to computer

```{r}
NDT5_l_models_treed<-rbind(AIC_lightning_NDT5_treed_summary_climate2, AIC_lightning_NDT5_treed_summary_VRI2, AIC_lightning_NDT5_treed_summary_topo2, AIC_lightning_NDT5_treed_summary_infra2)
NDT5_l_models_treed
NDT5_l_models_treed$NDT<-"NDT5"

write.csv(NDT5_l_models_treed, file="D:\\Fire\\fire_data\\raw_data\\NDT5_lightning_models_treed_escape.csv")
```

################################ STAGE TWO ########################

#STAGE TWO: PUT TOGETHER MORE VARIABLES
Now choose the top variables and create final model. The below code will need to be updated manually, depending on what the results of the above analyses are. From the top models, we will re-create two-way interactions for the variables selected from each model, plus the other variables listed as needed to be included. We will assess each set to ensure only interactions that make sense are investigated ultimately, given that sample sizes will be an issues.

Top Models:
1. climate1 + climate2 + climate1:climate2
2. live_stand_volume_125
3. dist_dam (some others maybe, but AUC dropped dramatically)
4. No DEM model in top deltaAIC<2

Additional Variables:
1. bclcs_level_5_2 (land use) (to be added to final investigated model)

Because there are few variables to explore for NDT5, we will step to manual model investigation utilizing the above variables and relevant interactions.

#Next investigation

```{r}
escape_lightning_t_NDT5<-subset(Escape_data_lightning_t, Escape_data_lightning_t$ntrl_ds=="NDT5")

#Divide data into training and valid
prop<-0.75
# Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(escape_lightning_t_NDT5$escape, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- escape_lightning_t_NDT5[ trainIndex,]
   Valid <- escape_lightning_t_NDT5[-trainIndex,]

#Run model using dat1
model.NDT5<-glm(escape ~ climate1 + climate2 + climate1:climate2 + live_stand_volume_125 + dist_dam + bclcs_level_5_2 + dist_dam:bclcs_level_5_2 + roads_km + wind_atfire, family = binomial, data = dat1)

AIC(model.NDT5) #78.5

#Determine AUC of full model
mod.valid <- predict.glm(model.NDT5, newdata=Valid, type="response")
   roc_obj <- roc(Valid[,"escape"], mod.valid)
   mod.auc <- auc(roc_obj)
   mod.auc #0.63 
   
Anova(model.NDT5, type=3)
Anova(model.NDT5, type=3, singular.ok = TRUE)

#Remove least significant variables
model.NDT5<-glm(escape ~ climate1 + climate2 + climate1:climate2 + live_stand_volume_125 + dist_dam + bclcs_level_5_2 + dist_dam:bclcs_level_5_2 + roads_km, family = binomial, data = dat1)

AIC(model.NDT5) #76.5

#Determine AUC of full model
mod.valid <- predict.glm(model.NDT5, newdata=Valid, type="response")
   roc_obj <- roc(Valid[,"escape"], mod.valid)
   mod.auc <- auc(roc_obj)
   mod.auc #0.63 
   
Anova(model.NDT5, type=3)
Anova(model.NDT5, type=3, singular.ok = TRUE)

#Remove least significant variables
model.NDT5<-glm(escape ~ climate1 + climate2 + climate1:climate2 + live_stand_volume_125  + bclcs_level_5_2 + dist_dam:bclcs_level_5_2 + roads_km, family = binomial, data = dat1)

AIC(model.NDT5) #76.5

#Determine AUC of full model
mod.valid <- predict.glm(model.NDT5, newdata=Valid, type="response")
   roc_obj <- roc(Valid[,"escape"], mod.valid)
   mod.auc <- auc(roc_obj)
   mod.auc #0.63 
   
Anova(model.NDT5, type=3)
Anova(model.NDT5, type=3, singular.ok = TRUE)


#Remove least significant variables
model.NDT5<-glm(escape ~ climate1 + climate2 + climate1:climate2 + live_stand_volume_125  + bclcs_level_5_2 + roads_km, family = binomial, data = dat1)

AIC(model.NDT5) #71.7

#Determine AUC of full model
mod.valid <- predict.glm(model.NDT5, newdata=Valid, type="response")
   roc_obj <- roc(Valid[,"escape"], mod.valid)
   mod.auc <- auc(roc_obj)
   mod.auc #0.64 
   
Anova(model.NDT5, type=3)
Anova(model.NDT5, type=3, singular.ok = TRUE)


#Remove least significant variables
model.NDT5<-glm(escape ~ climate1 + climate2 + climate1:climate2  + bclcs_level_5_2 + roads_km, family = binomial, data = dat1)

AIC(model.NDT5) #82.3 (BAD!)

#Determine AUC of full model
mod.valid <- predict.glm(model.NDT5, newdata=Valid, type="response")
   roc_obj <- roc(Valid[,"escape"], mod.valid)
   mod.auc <- auc(roc_obj)
   mod.auc #0.64 
   
Anova(model.NDT5, type=3)
Anova(model.NDT5, type=3, singular.ok = TRUE)


#Revert; then Remove least significant variables
model.NDT5<-glm(escape ~ climate1 + climate2 + climate1:climate2 + live_stand_volume_125  + bclcs_level_5_2, family = binomial, data = dat1)

AIC(model.NDT5) #70.2

#Determine AUC of full model
mod.valid <- predict.glm(model.NDT5, newdata=Valid, type="response")
   roc_obj <- roc(Valid[,"escape"], mod.valid)
   mod.auc <- auc(roc_obj)
   mod.auc #0.7
   
Anova(model.NDT5, type=3)
Anova(model.NDT5, type=3, singular.ok = TRUE)


#Remove least significant variables
model.NDT5<-glm(escape ~ climate1 + climate2 + climate1:climate2 + live_stand_volume_125, family = binomial, data = dat1)

AIC(model.NDT5) #66.8

#Determine AUC of full model
mod.valid <- predict.glm(model.NDT5, newdata=Valid, type="response")
   roc_obj <- roc(Valid[,"escape"], mod.valid)
   mod.auc <- auc(roc_obj)
   mod.auc #0.72
   
Anova(model.NDT5, type=3)
Anova(model.NDT5, type=3, singular.ok = TRUE)

#Try to remove live stand volume again

#Remove least significant variables
model.NDT5<-glm(escape ~ climate1 + climate2 + climate1:climate2, family = binomial, data = dat1)

AIC(model.NDT5) #77.7

#Determine AUC of full model
mod.valid <- predict.glm(model.NDT5, newdata=Valid, type="response")
   roc_obj <- roc(Valid[,"escape"], mod.valid)
   mod.auc <- auc(roc_obj)
   mod.auc #0.73
   
Anova(model.NDT5, type=3)
Anova(model.NDT5, type=3, singular.ok = TRUE)

#Best AIC despite live stand volume not significant:
model.NDT5<-glm(escape ~ climate1 + climate2 + climate1:climate2 + live_stand_volume_125, family = binomial, data = dat1)

```


Remove NAs and tun multiple times.

```{r}
#Remove NAs to ensure all same data used so we can compare AICs
NDT5_escape_t<-escape_lightning_t_NDT5 %>% drop_na(climate1, climate2, live_stand_volume_125)

#Run Model again with this data; but uses all data here
model.NDT5<-glm(escape ~ climate1 + climate2 + climate1:climate2 + live_stand_volume_125, family = binomial, data = NDT5_escape_t)

Anova(model.NDT5, type=3)

# model diagnostic plots
binnedplot (fitted(model.NDT5), 
            residuals(model.NDT5), 
            nclass = NULL, 
            xlab = "Expected Values", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))


NDT5_escape_t$resids<-resid(model.NDT5)

binnedplot (NDT5_escape_t$live_stand_volume_125, 
            NDT5_escape_t$resids, 
            nclass = NULL, 
            xlab = "live stand volume", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))

binnedplot (NDT5_escape_t$climate1, 
            NDT5_escape_t$resids, 
            nclass = NULL, 
            xlab = "", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))

# Diagnostic plots look good
```

We should repeat the above several times and take the mean of the coefficients.

```{r}
summary(model.NDT5)

#Create a new blank table and get AUC too
top_mod_table_NDT5_light_t_ALL <- data.frame (matrix (ncol = 10, nrow = 0))
colnames (top_mod_table_NDT5_light_t_ALL ) <- c ("CAUSE", "NDT", "TREED", "Model_terms", "intercept", "coef_climate_1", "coef_climate_2", "coef_live_stand_volume_125", "coef_climate1:climate2", "AUC")
```

Let's run it 500 times to get good mean values. Had to change proportion to 0.7 instead of 0.75 because otherwise insufficient division of 0/1.

```{r}

for (g in 1:500){

prop<-0.7
# Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(NDT5_escape_t$escape, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- NDT5_escape_t[ trainIndex,]
   Valid <- NDT5_escape_t[-trainIndex,]
   
#Model   
model.NDT5<-glm(escape ~ climate1 + climate2 + climate1:climate2 + live_stand_volume_125, family = binomial, data = dat1) 

mod.valid <- predict.glm(model.NDT5, newdata=Valid, type="response")
   roc_obj <- roc(Valid[,"escape"], mod.valid)
   mod.auc <- auc(roc_obj)

# create model table (only do this once) and add the relevant data
top_mod_table_NDT5_light_t <- data.frame (matrix (ncol = 10, nrow = 0))
colnames (top_mod_table_NDT5_light_t ) <- c ("CAUSE", "NDT", "TREED", "Model_terms", "intercept", "coef_climate_1", "coef_climate_2", "coef_live_stand_volume_125", "coef_climate1:climate2", "AUC")

##Add data for NDT5
top_mod_table_NDT5_light_t[1,1]<-"lightning"
top_mod_table_NDT5_light_t[1,2]<-"NDT5"
top_mod_table_NDT5_light_t[1,3]<-"Y"
top_mod_table_NDT5_light_t[1,4]<-"escape ~ climate1 + climate2 + climate1:climate2 + live_stand_volume_125" 
top_mod_table_NDT5_light_t[1,5]<- coef(model.NDT5)[1] #Intercept
top_mod_table_NDT5_light_t[1,6]<- coef(model.NDT5)[2] #Climate variable 1
top_mod_table_NDT5_light_t[1,7]<- coef(model.NDT5)[3] #Climate variable 2
top_mod_table_NDT5_light_t[1,8]<- coef(model.NDT5)[4] #coefficient live_stand_volume_125
top_mod_table_NDT5_light_t[1,9]<- coef(model.NDT5)[5] #coefficient climate1:climate2
top_mod_table_NDT5_light_t[1,10]<- mod.auc

top_mod_table_NDT5_light_t_ALL<-rbind(top_mod_table_NDT5_light_t_ALL, top_mod_table_NDT5_light_t)

}

```

Check.
```{r}
head(top_mod_table_NDT5_light_t_ALL)

```

#Save coefficient table

```{r}
write.csv(top_mod_table_NDT5_light_t_ALL, file="D:\\Fire\\fire_data\\raw_data\\top_mod_escape_NDT5_light_t_ALL.csv")
```

Get mean values.

```{r}
names(top_mod_table_NDT5_light_t_ALL)
mean(top_mod_table_NDT5_light_t_ALL$AUC) #0.67

# create model table (only do this once) and add the relevant data
top_mod_table_NDT5_light_t_Means <- data.frame (matrix (ncol = 10, nrow = 0))
colnames (top_mod_table_NDT5_light_t_Means ) <- c ("CAUSE", "NDT", "TREED", "Model_terms", "intercept", "coef_climate_1", "coef_climate_2", "coef_live_stand_volume_125", "coef_climate1:climate2", "AUC")

head(top_mod_table_NDT5_light_t_Means)

##Add data for NDT5
top_mod_table_NDT5_light_t_Means[1,1]<-"lightning"
top_mod_table_NDT5_light_t_Means[1,2]<-"NDT5"
top_mod_table_NDT5_light_t_Means[1,3]<-"Y"
top_mod_table_NDT5_light_t_Means[1,4]<-"escape ~ climate1 + climate2 + climate1:climate2 + live_stand_volume_125" 
top_mod_table_NDT5_light_t_Means[1,5]<- mean(top_mod_table_NDT5_light_t_ALL$intercept) #Intercept
top_mod_table_NDT5_light_t_Means[1,6]<- mean(top_mod_table_NDT5_light_t_ALL$coef_climate_1, na.rm=TRUE) #Climate variable 1
top_mod_table_NDT5_light_t_Means[1,7]<- mean(top_mod_table_NDT5_light_t_ALL$coef_climate_2, na.rm=TRUE) #Climate variable 2
top_mod_table_NDT5_light_t_Means[1,8]<- mean(top_mod_table_NDT5_light_t_ALL$coef_live_stand_volume_125, na.rm=TRUE) #
top_mod_table_NDT5_light_t_Means[1,9]<- mean(top_mod_table_NDT5_light_t_ALL$`coef_climate1:climate2`, na.rm=TRUE) #
top_mod_table_NDT5_light_t_Means[1,10]<- mean(top_mod_table_NDT5_light_t_ALL$AUC, na.rm=TRUE)

top_mod_table_NDT5_light_t_Means

```

Save mean coefficient table.

```{r}
write.csv(top_mod_table_NDT5_light_t_Means, file="D:\\Fire\\fire_data\\raw_data\\top_mod_escape_NDT5_light_t_Means.csv")
```


Get sd values.

```{r}
# create model table (only do this once) and add the relevant data
top_mod_table_NDT5_light_t_SD <- data.frame (matrix (ncol = 10, nrow = 0))
colnames (top_mod_table_NDT5_light_t_SD ) <- c ("CAUSE", "NDT", "TREED", "Model_terms", "intercept", "coef_climate_1", "coef_climate_2", "coef_live_stand_volume_125", "coef_climate1:climate2", "AUC")

head(top_mod_table_NDT5_light_t_SD)

##Add data for NDT5
top_mod_table_NDT5_light_t_SD[1,1]<-"lightning"
top_mod_table_NDT5_light_t_SD[1,2]<-"NDT5"
top_mod_table_NDT5_light_t_SD[1,3]<-"Y"
top_mod_table_NDT5_light_t_SD[1,4]<-"escape ~ climate1 + climate2 + climate1:climate2 + live_stand_volume_125" 
top_mod_table_NDT5_light_t_SD[1,5]<- sd(top_mod_table_NDT5_light_t_ALL$intercept) #Intercept
top_mod_table_NDT5_light_t_SD[1,6]<- sd(top_mod_table_NDT5_light_t_ALL$coef_climate_1, na.rm=TRUE) #Climate variable 1
top_mod_table_NDT5_light_t_SD[1,7]<- sd(top_mod_table_NDT5_light_t_ALL$coef_climate_2, na.rm=TRUE) #Climate variable 2
top_mod_table_NDT5_light_t_SD[1,8]<- sd(top_mod_table_NDT5_light_t_ALL$coef_live_stand_volume_125, na.rm=TRUE) #
top_mod_table_NDT5_light_t_SD[1,9]<- sd(top_mod_table_NDT5_light_t_ALL$`coef_climate1:climate2`, na.rm=TRUE) #
top_mod_table_NDT5_light_t_SD[1,10]<- sd(top_mod_table_NDT5_light_t_ALL$AUC, na.rm=TRUE)

top_mod_table_NDT5_light_t_SD

```

Save sd coefficient table.

```{r}
write.csv(top_mod_table_NDT5_light_t_SD, file="D:\\Fire\\fire_data\\raw_data\\top_mod_escape_NDT5_light_t_SD.csv")
```

