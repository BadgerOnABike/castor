---
title: "09b_2_fire_ignition_model_selection_NDT2_lightning_NotTreed"
author: "Cora Skaien"
date: "04/10/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library (data.table)
library (DBI)
library (RPostgreSQL)
library (dplyr)
library (ggplot2)
library (here)
library(ggpubr)
library(arm)
library(tidyr)
library(AICcmodavg)
library(keyring)
library(caret)
library(pROC)
library(rje)
library(car)
library(visreg)

source(here::here("R/functions/R_Postgres.R"))
```

<!--
Copyright 2021 Province of British Columbia

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and limitations under the License.
-->

#=================================
#  Script Name: 09b_2_fire_ignition_model_selection_NDT2_lightning_NotTreed.R
#  Script Version: 1.0
#  Script Purpose: Model selection, using various initial models to inform the final model selection.
#  Script Author: Cora Skaien, Ecological Modeling Specialist, Forest Analysis and Inventory Branch, B.C. Ministry of Forests, Lands, and Natural Resource Operations.
#=================================

#Load data back in if starting from here
Note: depending where your geometry column was located when saved as a csv (and turned into a dataframe), you may need to manually correct column headings on the csv file before loading back in. This has been performed for the below files.

```{r}
dat_lightning_nt<-read.csv(file="D:\\Fire\\fire_data\\raw_data\\ClimateBC_Data\\data_lightning_notrees_NDT_Oct.csv")
head(dat_lightning_nt)

```

######################### ANALYSES: NOT TREED, LIGHTNING #########################

Now, we will make a loop that does something very similar to our last loop, but with the selected climate variable plus other variables of interest. For lightning caused fires with trees, the variables of interest include:

1. Climate variable(s)
2. vegtype2 (with additional categories)
3. slope
4. aspect_cos (cos)
5. elevation
6. Various distance to infrastructure variables (dist_mun, dist_dam, dist_nat, dist_pow, dist_mine) - no interactions
7. Some measure of death or mountain pine beetle damage -- TBD

Variables to be added after initial model selection for next round model selection:
1. bclcs_level_5_2 (land use) (to be added to final investigated model)

Interactions of interest: two-way interactions between climate (1) and vegtype (6); two-way interactions between topography measures (7-9).

This will be done separately for trees and non-treed areas. Note that there is no VRI data used for polygons deemed to be not treed. However, some data points will have VRI variables, and this is because there may still be trees within the polygon, but the trees cover <50% of the polygon and thus the entire polygon is deemed not treed.

##We will do each loop separately for each NDT zone given the large number of possible models for each zone.

First we will create the variable lists that contain all of our variables of interest.

```{r}
##Create variable lists to be used in the model loop.
variables_all_nt<-c(climate1 = "climate1", climate2 = "climate2", slope = "slope", aspect_cos = "aspect_cos", elevation ="elevation", vegtype2 = "vegtype2", dist_mun = "dist_mun", dist_dam = "dist_dam", dist_nat = "dist_nat", dist_pow = "dist_pow", dist_mine = "dist_mine", bclcs_level_5_2 = "bclcs_level_5_2") #heatload="heatload",

variables_all_nt_c1<-c(climate1 = "climate1", slope = "slope", aspect_cos = "aspect_cos", elevation ="elevation", vegtype2 = "vegtype2", dist_mun = "dist_mun", dist_dam = "dist_dam", dist_nat = "dist_nat", dist_pow = "dist_pow", dist_mine = "dist_mine", bclcs_level_5_2 = "bclcs_level_5_2") #heatload="heatload",

vars.nt.clim<-c("climate1")
vars.nt.clim.vegtype<-c("climate1", "vegtype2")
vars.nt.clim.vegtype2<-c("climate1", "climate2","vegtype2")
vars.nt.clim.vegtype2b<-c("climate1", "climate2")

vars.nt.topo<-c("slope", "aspect_cos", "elevation")
vars.nt.infra<-c("dist_mun", "dist_dam", "dist_nat", "dist_pow", "dist_mine", bclcs_level_5_2 = "bclcs_level_5_2")


##Create interaction for climate and vegtype
inputs.me <- c(vars.nt.clim.vegtype)
inputs.me2 <- c(vars.nt.clim.vegtype2)
inputs.me2b <- c(vars.nt.clim.vegtype2b)
```

Now, we will generate two-way interactions for each of these lists. 

```{r}
#####1a. For those with one climate variable
#get the names of all possible two-way interactions for climate variable(s) and vegtype.
twoway.ints <- NULL
for (i in 1:(length(inputs.me)-1)) {
  for (j in (i+1):length(inputs.me)) {
     twoway.ints <- cbind(twoway.ints, paste(inputs.me[i], inputs.me[j], sep=":"))
  }
}
twoway.ints
length(twoway.ints)

#
#Create function to determine Powerset for any vector of variable names
## or use rje package
#powerSet <- function(x) {
#   z.list <- NULL
#   for(i in 1:length(x)) {
#      z.list <- append(z.list, combn(x, m=i, simplify=F))
#   }    
#   return(z.list)
#}


#Get variables on own
#complete list of models using non-climate vars
mods.me.tmp <- powerSet(vars.nt.clim.vegtype) 
#add climate vars to all of the above
mods.me.climate <- list()
for (i in 1: length(mods.me.tmp)) {
   mods.me.climate[[i]] <- c(mods.me.tmp[[i]])
}

mods.me.climate
mods.me.climate<-mods.me.climate[-1]


#####1b. For those with two climate variables
#get the names of all possible two-way interactions for climate variable(s) and vegtype.
twoway.ints2 <- NULL
for (i in 1:(length(inputs.me2)-1)) {
  for (j in (i+1):length(inputs.me2)) {
     twoway.ints2 <- cbind(twoway.ints2, paste(inputs.me2[i], inputs.me2[j], sep=":"))
  }
}
twoway.ints2
length(twoway.ints2)

#Get variables on own
#complete list of models using non-climate vars
mods.me.tmp <- powerSet(vars.nt.clim.vegtype2) 
#add climate vars to all of the above
mods.me.climate2 <- list()
for (i in 1: length(mods.me.tmp)) {
   mods.me.climate2[[i]] <- c(mods.me.tmp[[i]])
}

mods.me.climate2

#complete list of two-way interactions
mods.twoway2 <- powerSet(twoway.ints2)
length(mods.twoway2) #7
mods.twoway2

#Finding models in mods.me that accommodate/allow interaction terms in each mods.twoway to be added
mods.inter2 <- list()
counter <- 0
for (i in 1: length(mods.twoway2)) {
   s1 <- unique(unlist( strsplit(mods.twoway2[[i]], split=':', fixed=TRUE) ) )
   for (j in 1: length(mods.me.climate2)) {
      if (all(s1 %in% mods.me.climate2[[j]])==TRUE) {
        counter <- counter + 1
        both <-  c(mods.me.climate2[[j]], mods.twoway2[[i]])
        mods.inter2[[counter]] <- both
      }
   }
}

length(mods.inter2) #18
mods.inter2
mods.inter2<-mods.inter2[-1]

####1c. Two variables, no variation in vegtype
#get the names of all possible two-way interactions for climate variable(s) and vegtype.
twoway.ints2b <- NULL
for (i in 1:(length(inputs.me2b)-1)) {
  for (j in (i+1):length(inputs.me2b)) {
     twoway.ints2b <- cbind(twoway.ints2b, paste(inputs.me2b[i], inputs.me2b[j], sep=":"))
  }
}
twoway.ints2b
length(twoway.ints2b)

#Get variables on own
#complete list of models using non-climate vars
mods.me.tmp <- powerSet(vars.nt.clim.vegtype2b) 
#add climate vars to all of the above
mods.me.climate2b <- list()
for (i in 1: length(mods.me.tmp)) {
   mods.me.climate2b[[i]] <- c(mods.me.tmp[[i]])
}

mods.me.climate2b

#complete list of two-way interactions
mods.twoway2b <- powerSet(twoway.ints2b)
length(mods.twoway2b) #7
mods.twoway2b

#Finding models in mods.me that accommodate/allow interaction terms in each mods.twoway to be added
mods.inter2b <- list()
counter <- 0
for (i in 1: length(mods.twoway2b)) {
   s1 <- unique(unlist( strsplit(mods.twoway2b[[i]], split=':', fixed=TRUE) ) )
   for (j in 1: length(mods.me.climate2b)) {
      if (all(s1 %in% mods.me.climate2b[[j]])==TRUE) {
        counter <- counter + 1
        both <-  c(mods.me.climate2b[[j]], mods.twoway2b[[i]])
        mods.inter2b[[counter]] <- both
      }
   }
}

length(mods.inter2b) #5
mods.inter2b
mods.inter2b<-mods.inter2b[-1]
```


```{r}
#########2. Now for topography data, get all possible two-way interactions

#get the names of all possible two-way interactions
twoway.intsT <- NULL
for (i in 1:(length(vars.nt.topo)-1)) {
  for (j in (i+1):length(vars.nt.topo)) {
     twoway.intsT <- cbind(twoway.intsT, paste(vars.nt.topo[i], vars.nt.topo[j], sep=":"))
  }
}
twoway.intsT
length(twoway.intsT)

#complete list of models using non-climate vars (topo)
mods.me.tmp <- powerSet(vars.nt.topo) 
#add climate vars to all of the above
mods.meT <- list()
for (i in 1: length(mods.me.tmp)) {
   mods.meT[[i]] <- c(mods.me.tmp[[i]])
}

mods.meT
mods.meT<-mods.meT[-1]

#complete list of two-way interactions
mods.twowayT <- powerSet(twoway.intsT)
length(mods.twowayT) #8
mods.twowayT
mods.twowayT<-mods.twowayT[-1]

#Finding models in mods.me that accommodate/allow interaction terms in each mods.twoway to be added

mods.interT <- list()
counter <- 0
for (i in 1: length(mods.twowayT)) {
   s1 <- unique(unlist( strsplit(mods.twowayT[[i]], split=':', fixed=TRUE) ) )
   for (j in 1: length(mods.meT)) {
      if (all(s1 %in% mods.meT[[j]])==TRUE) {
        counter <- counter + 1
        both <-  c(mods.meT[[j]], mods.twowayT[[i]])
        mods.interT[[counter]] <- both
      }
   }
}

length(mods.interT) #10
mods.interT

```

```{r}
#########3. Infrastructure and land use ########
twoway.ints <- NULL
for (i in 1:(length(vars.nt.infra)-1)) {
  for (j in (i+1):length(vars.nt.infra)) {
     twoway.ints <- cbind(twoway.ints, paste(vars.nt.infra[i], vars.nt.infra[j], sep=":"))
  }
}
twoway.ints
length(twoway.ints) #15
#Review. If we do not want interactions between the different distance measurements, but only those between land use and distance, subset those.
twoway.ints
twoway.ints_dist<-twoway.ints[c(5,9,12,14,15)]
twoway.ints_dist


#Create function to determine Powerset for any vector of variable names
## or use rje package
#powerSet <- function(x) {
#   z.list <- NULL
#   for(i in 1:length(x)) {
#      z.list <- append(z.list, combn(x, m=i, simplify=F))
#   }    
#   return(z.list)
#}

#Get variables on own
#complete list of models using non-climate vars
mods.me.tmp <- powerSet(vars.nt.infra) 
#add climate vars to all of the above
mods.me.infra_landuse_NDT2 <- list()
for (i in 1: length(mods.me.tmp)) {
   mods.me.infra_landuse_NDT2[[i]] <- c(mods.me.tmp[[i]])
}

mods.me.infra_landuse_NDT2
length(mods.me.infra_landuse_NDT2) #128


#Or use subset of interactions
mods.twoway.NDT2b <- powerSet(twoway.ints_dist) 
length(mods.twoway.NDT2b) #64
mods.twoway.NDT2b

#Finding models in mods.me that accommodate/allow interaction terms in each mods.twoway to be added
mods.inter.NDT2b <- list()
counter <- 0
for (i in 1: length(mods.twoway.NDT2b)) {
   s1 <- unique(unlist( strsplit(mods.twoway.NDT2b[[i]], split=':', fixed=TRUE) ) )
   for (j in 1: length(mods.me.infra_landuse_NDT2)) {
      if (all(s1 %in% mods.me.infra_landuse_NDT2[[j]])==TRUE) {
        counter <- counter + 1
        both <-  c(mods.me.infra_landuse_NDT2[[j]], mods.twoway.NDT2b[[i]])
        mods.inter.NDT2b[[counter]] <- both
      }
   }
}

length(mods.inter.NDT2b) #275
#mods.inter.NDT2b
mods.inter.NDT2b[1]
mods.inter.NDT2b<-mods.inter.NDT2b[-1]
```


```{r}
#the list of all possible model RHSs. 
#all.poss.mods.nt <- c(1, vars.nt.clim, twoway.ints, mods.me.oth, mods.me2, mods.inter2)
#all.poss.mods.nt

all.poss.mods.nt.clim.vegtype<-c(1, mods.me.climate, twoway.ints)
all.poss.mods.nt.clim.vegtype 

all.poss.mods.nt.clim.vegtype2<-c(1, mods.inter2)
all.poss.mods.nt.clim.vegtype2

all.poss.mods.nt.clim.vegtype2b<-c(1, mods.inter2b)
all.poss.mods.nt.clim.vegtype2b

#all.poss.mods.nt.topo<-c(1, mods.meT, mods.interT)
all.poss.mods.nt.topo<-c(1, mods.interT)
all.poss.mods.nt.topo

all.poss.mods.nt.infra<-c(1, mods.inter.NDT2b) 
#all.poss.mods.nt.infra
```


```{r}
#If need to determine which ones are character(0), try this:
biglist <- list(list("A","B","C"), "foo", "", character(0), integer(0))
lapply(biglist, function(x) {length(x) == 0L} ) 


##Check and rid of any duplicated models
duplicated(all.poss.mods.nt.clim.vegtype) #None duplicated
duplicated(all.poss.mods.nt.clim.vegtype2)
duplicated(all.poss.mods.nt.clim.vegtype2b)
duplicated(all.poss.mods.nt.topo)
duplicated(all.poss.mods.nt.infra)

```



############### Part 1 of 4 Model Series: Lightning Caused Fires, Trees ##########

Because of the large number of models with all variables included, we will test the climate and vegtype first, then the VRI variables, then the topography variables. Then we will test the top models together, with determining best AIC model from there. Or perhaps we will just combine the top models for each together, and eliminate models if the intercept was the best predictor.

Select NDT: NDT2

```{r}
zones1<-c("NDT2") #Do one zone at a time

prop<-0.75

#Create empty table
table.glm.climate.simple <- data.frame (matrix (ncol = 5, nrow = 0))
colnames (table.glm.climate.simple) <- c ("model", "edf", "AIC", "auc.valid", "NDT")

########### 1. Climate and vegtype ############
for (g in 1:100){

for (h in 1:length(zones1)) {
  dat2<- dat_lightning_nt %>% dplyr::filter(ntrl_ds ==zones1[h])

#for (i in 1: length(all.poss.mods.nt.clim.vegtype2)){
#  print(paste((all.poss.mods.nt.clim.vegtype2[i]), (zones1[h]), sep=" "))
  
for (i in 1: length(zones1)){
  print(paste((all.poss.mods.nt.clim.vegtype2[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, variables_all_nt[i])
  model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, !!variables_all_nt)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="fire_pres") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.AIC <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.AIC, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.nt.clim.vegtype2, big.mod, df.train=dat1, df.test=Valid)

#terms in each model
x1.1 <- unlist(sapply(mods.fit, '[', 1))
x1.1
#AIC for models
x3.1 <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3.1
#auc from validation data
x4.1 <- unlist(sapply(mods.fit, '[', 4))
x4.1
#combining all as df
tab.sum.climate <- cbind.data.frame(model=x1.1, edf=x3.1[,1], AIC=x3.1[,2], auc.valid=x4.1)
tab.sum.climate$NDT<-c("NDT2")
tab.sum.climate 

table.glm.climate.simple<-rbind(table.glm.climate.simple, tab.sum.climate)

}
}
}


```

Now that we have run the model 100 times, we want the average AIC and AUC for each variable combination.

```{r}
head(table.glm.climate.simple)
table(table.glm.climate.simple$model) # 100 per model

AIC_nt_lightning_NDT2_ntreed_climate<-table.glm.climate.simple

AIC_nt_lightning_NDT2_ntreed_summary_climate<- AIC_nt_lightning_NDT2_ntreed_climate %>%
  group_by(model) %>%
  summarise(meanAIC=mean(AIC),
            meanAUC=mean(auc.valid),
            sdAUC=sd(auc.valid),
            )

AIC_nt_lightning_NDT2_ntreed_summary_climate2<- AIC_nt_lightning_NDT2_ntreed_summary_climate %>%
  mutate(deltaAIC=meanAIC-min(meanAIC))

head(AIC_nt_lightning_NDT2_ntreed_summary_climate2)
```

#Now repeat for topography

```{r}
########### 2. Topography ############
#Create empty table
table.glm.topo.simple <- data.frame (matrix (ncol = 5, nrow = 0))
colnames (table.glm.topo.simple) <- c ("model", "edf", "AIC", "auc.valid", "NDT")

#
for (g in 1:100){

for (h in 1:length(zones1)) {
  dat2<- dat_lightning_nt %>% dplyr::filter(ntrl_ds ==zones1[h])

#for (i in 1: length(all.poss.mods.nt.topo)){
#  print(paste((all.poss.mods.nt.topo[i]), (zones1[h]), sep=" "))
  
for (i in 1: length(zones1)){
  print(paste((all.poss.mods.nt.topo[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, variables_all_nt[i])
  model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, !!variables_all_nt)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="fire_pres") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.AIC <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.AIC, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.nt.topo, big.mod, df.train=dat1, df.test=Valid)

#terms in each model
x1.1 <- unlist(sapply(mods.fit, '[', 1))
x1.1
#AIC for models
x3.1 <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3.1
#auc from validation data
x4.1 <- unlist(sapply(mods.fit, '[', 4))
x4.1
#combining all as df
tab.sum.topo <- cbind.data.frame(model=x1.1, edf=x3.1[,1], AIC=x3.1[,2], auc.valid=x4.1)
tab.sum.topo$NDT<-c("NDT2")
tab.sum.topo 

table.glm.topo.simple<-rbind(table.glm.topo.simple, tab.sum.topo)

}
}
}
```

Now that we have run the model 100 times, we want the average AIC and AUC for each variable combination.

```{r}
head(table.glm.topo.simple)
table(table.glm.topo.simple$model) # 100 per model

AIC_nt_lightning_NDT2_ntreed_topo<-table.glm.topo.simple

AIC_nt_lightning_NDT2_ntreed_summary_topo<- AIC_nt_lightning_NDT2_ntreed_topo %>%
  group_by(model) %>%
  summarise(meanAIC=mean(AIC),
            meanAUC=mean(auc.valid),
            sdAUC=sd(auc.valid),
            )

AIC_nt_lightning_NDT2_ntreed_summary_topo2<- AIC_nt_lightning_NDT2_ntreed_summary_topo %>%
  mutate(deltaAIC=meanAIC-min(meanAIC))

head(AIC_nt_lightning_NDT2_ntreed_summary_topo2)
```

#Now repeat for infrastructure

```{r}
########### 3. Distance to Infrastructure ############
#Create empty table
table.glm.infra.simple <- data.frame (matrix (ncol = 5, nrow = 0))
colnames (table.glm.infra.simple) <- c ("model", "edf", "AIC", "auc.valid", "NDT")

#
for (g in 1:100){

for (h in 1:length(zones1)) {
  dat2<- dat_lightning_nt %>% dplyr::filter(ntrl_ds ==zones1[h])

#for (i in 1: length(all.poss.mods.nt.infra)){
#  print(paste((all.poss.mods.nt.infra[i]), (zones1[h]), sep=" "))
  
for (i in 1: length(zones1)){
  print(paste((all.poss.mods.nt.infra[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, variables_all_nt[i])
  model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, !!variables_all_nt)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="fire_pres") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.AIC <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.AIC, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.nt.infra, big.mod, df.train=dat1, df.test=Valid)

#terms in each model
x1.1 <- unlist(sapply(mods.fit, '[', 1))
x1.1
#AIC for models
x3.1 <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3.1
#auc from validation data
x4.1 <- unlist(sapply(mods.fit, '[', 4))
x4.1
#combining all as df
tab.sum.infra <- cbind.data.frame(model=x1.1, edf=x3.1[,1], AIC=x3.1[,2], auc.valid=x4.1)
tab.sum.infra$NDT<-c("NDT2")
tab.sum.infra 

table.glm.infra.simple<-rbind(table.glm.infra.simple, tab.sum.infra)

}
}
}
```

Now that we have run the model 100 times, we want the average AIC and AUC for each variable combination.

```{r}
head(table.glm.infra.simple)
table(table.glm.infra.simple$model) # 100 per model

AIC_nt_lightning_NDT2_ntreed_infra<-table.glm.infra.simple

AIC_nt_lightning_NDT2_ntreed_summary_infra<- AIC_nt_lightning_NDT2_ntreed_infra %>%
  group_by(model) %>%
  summarise(meanAIC=mean(AIC),
            meanAUC=mean(auc.valid),
            sdAUC=sd(auc.valid),
            )

AIC_nt_lightning_NDT2_ntreed_summary_infra2<- AIC_nt_lightning_NDT2_ntreed_summary_infra %>%
  mutate(deltaAIC=meanAIC-min(meanAIC))

head(AIC_nt_lightning_NDT2_ntreed_summary_infra2)

```

#Now combine the datatables and save to computer

```{r}
NDT2_l_models_NotTreed<-rbind(AIC_nt_lightning_NDT2_ntreed_summary_climate2, AIC_nt_lightning_NDT2_ntreed_summary_topo2, AIC_nt_lightning_NDT2_ntreed_summary_infra2)
NDT2_l_models_NotTreed
NDT2_l_models_NotTreed$NDT<-"NDT2"

write.csv(NDT2_l_models_NotTreed, file="D:\\Fire\\fire_data\\raw_data\\NDT2_lightning_models_NotTreed.csv")
```


################################ STAGE TWO ########################

#STAGE TWO: PUT TOGETHER MORE VARIABLES
Now choose the top variables and create final model. The below code will need to be updated manually, depending on what the results of the above analyses are. From the top models, we will re-create two-way interactions for the variables selected from each model, plus the other variables listed as needed to be included. We will assess each set to ensure only interactions that make sense are investigated ultimately, given that sample sizes will be an issues.

Top Models:
1. climate1 + climate2 + vegtype2 + climate1:climate2
2. slope + aspect_cos + elevation + slope:elevation + aspect_cos:elevation
3. dist_mun + dist_nat + dist_mine

#Next investigation
Because there would be far too many models to investigate including all variables and their interactions, we will start with the above and make educated guesses for what may need to be enhanced. Add climate1:elevation + climate2:elevation into initial investigation.

```{r}
dat_lightning_nt_NDT2<-subset(dat_lightning_nt, dat_lightning_nt$ntrl_ds=="NDT2")

#Divide data into training and valid
prop<-0.75
# Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(dat_lightning_nt_NDT2$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- dat_lightning_nt_NDT2[ trainIndex,]
   Valid <- dat_lightning_nt_NDT2[-trainIndex,]

#Run model using dat1
model.NDT2<-glm(fire_pres ~ climate1 + climate2 + vegtype2 + climate1:climate2 + slope + aspect_cos + elevation + slope:elevation + aspect_cos:elevation +  dist_mun + dist_nat + dist_mine + climate1:elevation + climate2:elevation, family = binomial, data = dat1)

AIC(model.NDT2) #707.2

#Determine AUC of full model
mod.valid <- predict.glm(model.NDT2, newdata=Valid, type="response")
   roc_obj <- roc(Valid[,"fire_pres"], mod.valid)
   mod.auc <- auc(roc_obj)
   mod.auc #0.64
   
Anova(model.NDT2, type=3)
#Anova(model.NDT2, type=3, singular.ok = TRUE)

#Begin removing least significant interaction
model.NDT2<-glm(fire_pres ~ climate1 + climate2 + vegtype2 + climate1:climate2 + slope + aspect_cos + elevation + slope:elevation + aspect_cos:elevation +  dist_mun + dist_nat + dist_mine + climate1:elevation, family = binomial, data = dat1)

AIC(model.NDT2) #705.3

#Determine AUC of full model
mod.valid <- predict.glm(model.NDT2, newdata=Valid, type="response")
   roc_obj <- roc(Valid[,"fire_pres"], mod.valid)
   mod.auc <- auc(roc_obj)
   mod.auc #0.64
   
Anova(model.NDT2, type=3)
#Anova(model.NDT2, type=3, singular.ok = TRUE)

#Begin removing least significant interaction
model.NDT2<-glm(fire_pres ~ climate1 + climate2 + vegtype2 + slope + aspect_cos + elevation + slope:elevation + aspect_cos:elevation +  dist_mun + dist_nat + dist_mine + climate1:elevation, family = binomial, data = dat1)

AIC(model.NDT2) #703.5

#Determine AUC of full model
mod.valid <- predict.glm(model.NDT2, newdata=Valid, type="response")
   roc_obj <- roc(Valid[,"fire_pres"], mod.valid)
   mod.auc <- auc(roc_obj)
   mod.auc #0.64
   
Anova(model.NDT2, type=3)
#Anova(model.NDT2, type=3, singular.ok = TRUE)

#Remove least significant
model.NDT2<-glm(fire_pres ~ climate1 + vegtype2 + slope + aspect_cos + elevation + slope:elevation + aspect_cos:elevation +  dist_mun + dist_nat + dist_mine + climate1:elevation, family = binomial, data = dat1)

AIC(model.NDT2) #701.5

#Determine AUC of full model
mod.valid <- predict.glm(model.NDT2, newdata=Valid, type="response")
   roc_obj <- roc(Valid[,"fire_pres"], mod.valid)
   mod.auc <- auc(roc_obj)
   mod.auc #0.64
   
Anova(model.NDT2, type=3)
#Anova(model.NDT2, type=3, singular.ok = TRUE)

#Remove least significant
model.NDT2<-glm(fire_pres ~ climate1 + vegtype2 + slope + aspect_cos + elevation + slope:elevation + aspect_cos:elevation +  dist_mun + dist_nat + climate1:elevation, family = binomial, data = dat1)

AIC(model.NDT2) #699.9

#Determine AUC of full model
mod.valid <- predict.glm(model.NDT2, newdata=Valid, type="response")
   roc_obj <- roc(Valid[,"fire_pres"], mod.valid)
   mod.auc <- auc(roc_obj)
   mod.auc #0.64
   
Anova(model.NDT2, type=3)
#Anova(model.NDT2, type=3, singular.ok = TRUE)

#Remove least significant
model.NDT2<-glm(fire_pres ~ climate1 + vegtype2 + slope + aspect_cos + elevation + slope:elevation + aspect_cos:elevation +  dist_mun + dist_nat, family = binomial, data = dat1)

AIC(model.NDT2) #698.99

#Determine AUC of full model
mod.valid <- predict.glm(model.NDT2, newdata=Valid, type="response")
   roc_obj <- roc(Valid[,"fire_pres"], mod.valid)
   mod.auc <- auc(roc_obj)
   mod.auc #0.64
   
Anova(model.NDT2, type=3)
#Anova(model.NDT2, type=3, singular.ok = TRUE)

#Remove least significant
model.NDT2<-glm(fire_pres ~ climate1 + vegtype2 + slope + aspect_cos + elevation + slope:elevation +  dist_mun + dist_nat, family = binomial, data = dat1)

AIC(model.NDT2) #698.3

#Determine AUC of full model
mod.valid <- predict.glm(model.NDT2, newdata=Valid, type="response")
   roc_obj <- roc(Valid[,"fire_pres"], mod.valid)
   mod.auc <- auc(roc_obj)
   mod.auc #0.63
   
Anova(model.NDT2, type=3)
#Anova(model.NDT2, type=3, singular.ok = TRUE)

#Remove least significant
model.NDT2<-glm(fire_pres ~ climate1 + slope + aspect_cos + elevation + slope:elevation +  dist_mun + dist_nat, family = binomial, data = dat1)

AIC(model.NDT2) #696.4

#Determine AUC of full model
mod.valid <- predict.glm(model.NDT2, newdata=Valid, type="response")
   roc_obj <- roc(Valid[,"fire_pres"], mod.valid)
   mod.auc <- auc(roc_obj)
   mod.auc #0.62
   
Anova(model.NDT2, type=3)
#Anova(model.NDT2, type=3, singular.ok = TRUE)

#Previous top model
model.NDT2<-glm(fire_pres ~ climate1 + climate2  + climate1:climate2 + slope + elevation + slope:elevation +  dist_mun, family = binomial, data = dat1)

AIC(model.NDT2) #706.5

#Determine AUC of full model
mod.valid <- predict.glm(model.NDT2, newdata=Valid, type="response")
   roc_obj <- roc(Valid[,"fire_pres"], mod.valid)
   mod.auc <- auc(roc_obj)
   mod.auc #0.66

Anova(model.NDT2, type=3)
#Anova(model.NDT2, type=3, singular.ok = TRUE)

#Simplest model above, and dist_nat we do not have as trong biological reason to think that ignitions would be affected. So use this final model.

#Top model
model.NDT2<-glm(fire_pres ~ climate1 + slope + aspect_cos + elevation + slope:elevation +  dist_mun + dist_nat, family = binomial, data = dat1)

AIC(model.NDT2) #696.4

#Determine AUC of full model
mod.valid <- predict.glm(model.NDT2, newdata=Valid, type="response")
   roc_obj <- roc(Valid[,"fire_pres"], mod.valid)
   mod.auc <- auc(roc_obj)
   mod.auc #0.62
   
Anova(model.NDT2, type=3)
#Anova(model.NDT2, type=3, singular.ok = TRUE)

```

Remove NAs and tun multiple times.

```{r}
#Remove NAs to ensure all same data used so we can compare AIC_nts
NDT2_nt<-dat_lightning_nt_NDT2 %>% drop_na(climate1, dist_mun, dist_nat, slope, elevation, aspect_cos)

#Run Model again with this data; but uses all data here
model.NDT2<-glm(fire_pres ~ climate1 + slope + aspect_cos + elevation + slope:elevation +  dist_mun + dist_nat, family = binomial, data = NDT2_nt)

Anova(model.NDT2, type=3)
#Anova(model.NDT2, type=3, singular.ok = TRUE)

# model diagnostic plots
binnedplot (fitted(model.NDT2), 
            residuals(model.NDT2), 
            nclass = NULL, 
            xlab = "Expected Values", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))


NDT2_nt$resids<-resid(model.NDT2)

binnedplot (NDT2_nt$climate1, 
            NDT2_nt$resids, 
            nclass = NULL, 
            xlab = "", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))

# Diagnostic plots look good
# climate1 + slope + aspect_cos + elevation + slope:elevation +  dist_mun + dist_nat
visreg(model.NDT2, "climate1")

visreg(model.NDT2, "slope", by="elevation")
visreg(model.NDT2, "aspect_cos")
visreg(model.NDT2, "elevation", by="slope")

visreg(model.NDT2, "dist_mun")
visreg(model.NDT2, "dist_nat")


```

We should repeat the above several times and take the mean of the coefficients.

```{r}
summary(model.NDT2)

#Create a new blank table and get AUC too
top_mod_table_NDT2_light_nt_ALL <- data.frame (matrix (ncol = 13, nrow = 0))
colnames (top_mod_table_NDT2_light_nt_ALL ) <- c ("CAUSE", "NDT", "TREED", "Model_terms", "intercept", "coef_climate_1", "coef_slope", "coef_aspect_cos", "coef_elevation", "coef_dist_mun", "coef_dist_nat", "coef_slope:elevation", "AUC")
```

Let's run it 500 times to get good mean values.

```{r}

for (g in 1:500){

prop<-0.75
# Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(NDT2_nt$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- NDT2_nt[ trainIndex,]
   Valid <- NDT2_nt[-trainIndex,]
   
#Model   
model.NDT2<-glm(fire_pres ~ climate1 + slope + aspect_cos + elevation + slope:elevation +  dist_mun + dist_nat, family = binomial, data = dat1) 

mod.valid <- predict.glm(model.NDT2, newdata=Valid, type="response")
   roc_obj <- roc(Valid[,"fire_pres"], mod.valid)
   mod.auc <- auc(roc_obj)

# create model table (only do this once) and add the relevant data
top_mod_table_NDT2_light_nt <- data.frame (matrix (ncol = 13, nrow = 0))
colnames (top_mod_table_NDT2_light_nt ) <- c ("CAUSE", "NDT", "TREED", "Model_terms", "intercept", "coef_climate_1", "coef_slope", "coef_aspect_cos", "coef_elevation", "coef_dist_mun", "coef_dist_nat", "coef_slope:elevation", "AUC")

##Add data for NDT2
top_mod_table_NDT2_light_nt[1,1]<-"lightning"
top_mod_table_NDT2_light_nt[1,2]<-"NDT2"
top_mod_table_NDT2_light_nt[1,3]<-"N"
top_mod_table_NDT2_light_nt[1,4]<-"fire_pres ~ climate1 + slope + aspect_cos + elevation + slope:elevation +  dist_mun + dist_nat" 
top_mod_table_NDT2_light_nt[1,5]<- coef(model.NDT2)[1] #Intercept
top_mod_table_NDT2_light_nt[1,6]<- coef(model.NDT2)[2] #Climate variable 1
top_mod_table_NDT2_light_nt[1,7]<- coef(model.NDT2)[3] #Climate variable 2
top_mod_table_NDT2_light_nt[1,8]<- coef(model.NDT2)[4] #slope
top_mod_table_NDT2_light_nt[1,9]<- coef(model.NDT2)[5] #elevation
top_mod_table_NDT2_light_nt[1,10]<- coef(model.NDT2)[6] #dist_mun
top_mod_table_NDT2_light_nt[1,11]<- coef(model.NDT2)[7] #climate1:climate2 
top_mod_table_NDT2_light_nt[1,12]<- coef(model.NDT2)[8] #slope:elevation
top_mod_table_NDT2_light_nt[1,13]<- mod.auc

top_mod_table_NDT2_light_nt_ALL<-rbind(top_mod_table_NDT2_light_nt_ALL, top_mod_table_NDT2_light_nt)

}

```

Check.
```{r}
head(top_mod_table_NDT2_light_nt_ALL)

```

#Save coefficient table

```{r}
write.csv(top_mod_table_NDT2_light_nt_ALL, file="D:\\Fire\\fire_data\\raw_data\\top_mod_table_NDT2_light_nt_ALL.csv")
```

Get mean values.

```{r}
names(top_mod_table_NDT2_light_nt_ALL)
mean(top_mod_table_NDT2_light_nt_ALL$AUC) #0.66

# create model table (only do this once) and add the relevant data
top_mod_table_NDT2_light_nt_Means <- data.frame (matrix (ncol = 13, nrow = 0))
colnames (top_mod_table_NDT2_light_nt_Means ) <- c ("CAUSE", "NDT", "TREED", "Model_terms", "intercept", "coef_climate_1", "coef_slope", "coef_aspect_cos", "coef_elevation", "coef_dist_mun", "coef_dist_nat", "coef_slope:elevation", "AUC")

head(top_mod_table_NDT2_light_nt_Means)

##Add data for NDT2
top_mod_table_NDT2_light_nt_Means[1,1]<-"lightning"
top_mod_table_NDT2_light_nt_Means[1,2]<-"NDT2"
top_mod_table_NDT2_light_nt_Means[1,3]<-"N"
top_mod_table_NDT2_light_nt_Means[1,4]<-"fire_pres ~ climate1 + slope + aspect_cos + elevation + slope:elevation +  dist_mun + dist_nat" 
top_mod_table_NDT2_light_nt_Means[1,5]<- mean(top_mod_table_NDT2_light_nt_ALL$intercept) #
top_mod_table_NDT2_light_nt_Means[1,6]<- mean(top_mod_table_NDT2_light_nt_ALL$coef_climate_1, na.rm=TRUE) #
top_mod_table_NDT2_light_nt_Means[1,7]<- mean(top_mod_table_NDT2_light_nt_ALL$coef_climate_2, na.rm=TRUE) #
top_mod_table_NDT2_light_nt_Means[1,8]<- mean(top_mod_table_NDT2_light_nt_ALL$coef_slope, na.rm=TRUE) #
top_mod_table_NDT2_light_nt_Means[1,9]<- mean(top_mod_table_NDT2_light_nt_ALL$coef_elevation, na.rm=TRUE) #
top_mod_table_NDT2_light_nt_Means[1,10]<- mean(top_mod_table_NDT2_light_nt_ALL$coef_dist_mun, na.rm=TRUE) #
top_mod_table_NDT2_light_nt_Means[1,11]<- mean(top_mod_table_NDT2_light_nt_ALL$`coef_climate1:climate2`, na.rm=TRUE) #
top_mod_table_NDT2_light_nt_Means[1,12]<- mean(top_mod_table_NDT2_light_nt_ALL$`coef_slope:elevation`, na.rm=TRUE) #
top_mod_table_NDT2_light_nt_Means[1,13]<- mean(top_mod_table_NDT2_light_nt_ALL$AUC, na.rm=TRUE)

top_mod_table_NDT2_light_nt_Means

```

Save mean coefficient table.

```{r}
write.csv(top_mod_table_NDT2_light_nt_Means, file="D:\\Fire\\fire_data\\raw_data\\top_mod_table_NDT2_light_nt_Means.csv")
```

Get sd values.

```{r}
# create model table (only do this once) and add the relevant data
top_mod_table_NDT2_light_nt_SD <- data.frame (matrix (ncol = 13, nrow = 0))
colnames (top_mod_table_NDT2_light_nt_SD ) <- c ("CAUSE", "NDT", "TREED", "Model_terms", "intercept", "coef_climate_1", "coef_slope", "coef_aspect_cos", "coef_elevation", "coef_dist_mun", "coef_dist_nat", "coef_slope:elevation", "AUC")

head(top_mod_table_NDT2_light_nt_SD)

##Add data for NDT2
top_mod_table_NDT2_light_nt_SD[1,1]<-"lightning"
top_mod_table_NDT2_light_nt_SD[1,2]<-"NDT2"
top_mod_table_NDT2_light_nt_SD[1,3]<-"N"
top_mod_table_NDT2_light_nt_SD[1,4]<-"fire_pres ~ climate1 + slope + aspect_cos + elevation + slope:elevation +  dist_mun + dist_nat" 
top_mod_table_NDT2_light_nt_SD[1,5]<- sd(top_mod_table_NDT2_light_nt_ALL$intercept) #
top_mod_table_NDT2_light_nt_SD[1,6]<- sd(top_mod_table_NDT2_light_nt_ALL$coef_climate_1, na.rm=TRUE) #
top_mod_table_NDT2_light_nt_SD[1,7]<- sd(top_mod_table_NDT2_light_nt_ALL$coef_climate_2, na.rm=TRUE) #
top_mod_table_NDT2_light_nt_SD[1,8]<- sd(top_mod_table_NDT2_light_nt_ALL$coef_slope, na.rm=TRUE) #
top_mod_table_NDT2_light_nt_SD[1,9]<- sd(top_mod_table_NDT2_light_nt_ALL$coef_elevation, na.rm=TRUE) #
top_mod_table_NDT2_light_nt_SD[1,10]<- sd(top_mod_table_NDT2_light_nt_ALL$coef_dist_mun, na.rm=TRUE) #
top_mod_table_NDT2_light_nt_SD[1,11]<- sd(top_mod_table_NDT2_light_nt_ALL$`coef_climate1:climate2`, na.rm=TRUE) #
top_mod_table_NDT2_light_nt_SD[1,12]<- sd(top_mod_table_NDT2_light_nt_ALL$`coef_slope:elevation`, na.rm=TRUE) #
top_mod_table_NDT2_light_nt_SD[1,13]<- sd(top_mod_table_NDT2_light_nt_ALL$AUC, na.rm=TRUE)

top_mod_table_NDT2_light_nt_SD

```

```{r}
write.csv(top_mod_table_NDT2_light_nt_SD, file="D:\\Fire\\fire_data\\raw_data\\top_mod_table_NDT2_light_nt_SD.csv")
```


