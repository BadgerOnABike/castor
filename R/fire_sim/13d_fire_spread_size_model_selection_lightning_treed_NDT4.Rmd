---
title: "13d_fire_spread_size_model_selection_lightning_treed_NDT4"
author: "Cora Skaien"
date: "01/12/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

#Load relevant libraries
library(sf)
library(tidyverse)
library(ggplot2)
library(ggcorrplot)
library(RPostgreSQL)
library(rpostgis)
library(dplyr)
library(lme4)
library(arm)
library(ggpubr)
library(mgcv)
library(nlme)
library(purrr)
library(tidyr)
library(caret)
library(pROC)
library(keyring)
library(ggcorrplot) 
library(kableExtra)
library(data.table)
library(DBI)
library(here)
library(AICcmodavg)
library(rje)
library(base)
library(car)
library(visreg)
#library(aomisc) #Not available for this version of R

source(here::here("R/functions/R_Postgres.R"))
```

<!--
Copyright 2021 Province of British Columbia

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and limitations under the License.
-->

#=================================
#  Script Name: 13d_fire_spread_size_model_selection_lightning_treed_NDT4.R
#  Script Version: 1.0
#  Script Purpose: model selection for fire size (part of spread) by NDT.
#  Script Author: Cora Skaien, Ecological Modeling Specialist, Forest Analysis and Inventory Branch, B.C. Ministry of Forests, Lands, and Natural Resource Operations.
#=================================

#Objective
The objective of this file is to determine the best model for predicting fire size, given climate, topography, infrastructure, etc. Prior models were logistic regression (0/1) and used AUC to assess quality. Here, we will be working with continuous data and will assess model fit via R-squared, root mean squared error, and cross-validation. We will first attempt linear regressions, but may need to consider other distributions.

Note on cross-validation using test and validation data: "When comparing two models, the one that produces the lowest test sample RMSE is the preferred model.
the RMSE and the MAE are measured in the same scale as the outcome variable. Dividing the RMSE by the average value of the outcome variable will give you the prediction error rate, which should be as small as possible." (http://www.sthda.com/english/articles/38-regression-model-validation/157-cross-validation-essentials-in-r/#loading-required-r-packages)

#For fire size, plot observed vs model for both testing data and validation data set.

#Load in the prepped data.
```{r}
spread_data_lightning_t<-read.csv(file="D:\\Fire\\fire_data\\raw_data\\spread_data_lightning_t_Nov.csv")

head(spread_data_lightning_t)
```
#Inspect the data
```{r}
min(spread_data_lightning_t$size_ha) # Minimum 1 ha: this is because we are only quantifying the spread and fire size of those that "spreadd" (> 1 ha)
hist(spread_data_lightning_t$size_ha) #Definitely not a normal distribution
hist(log(spread_data_lightning_t$size_ha)) #Still not a normal distribution; already have a LNsize_ha variable created prior

spread_data_lightning_t$ntrl_ds<-as.factor(spread_data_lightning_t$ntrl_ds)
table(spread_data_lightning_t$ntrl_ds) #Very few in NDT5 (n=19)
```

##Create variables for model selection
First we will create the variable lists that contain all of our variables of interest.

```{r}
##Create variable lists to be used in the model loop.
variables_all<-c(climate1 = "climate1", climate2 = "climate2", proj_height_1 = "proj_height_1", proj_age_1 = "proj_age_1", live_stand_volume_125 = "live_stand_volume_125", slope = "slope", aspect = "aspect", elevation ="elevation", vegtype2 = "vegtype2", wind_atfire = "wind_atfire", dist_dam = "dist_dam", dist_nat = "dist_nat", dist_mine = "dist_mine", dist_mun = "dist_mun", dist_pow = "dist_pow", roads_km = "roads_km", bclcs_level_5_2 = "bclcs_level_5_2") 

variables_all_c1<-c(climate1 = "climate1", proj_height_1 = "proj_height_1", proj_age_1 = "proj_age_1", live_stand_volume_125 = "live_stand_volume_125", slope = "slope", aspect = "aspect", elevation ="elevation", vegtype2 = "vegtype2", wind_atfire = "wind_atfire", dist_dam = "dist_dam", dist_nat = "dist_nat", dist_mine = "dist_mine", dist_mun = "dist_mun", dist_pow = "dist_pow", roads_km = "roads_km", bclcs_level_5_2 = "bclcs_level_5_2") 

variables_all_infra_landuse<-c(dist_mun = "dist_mun", dist_dam = "dist_dam", dist_nat = "dist_nat", dist_mine = "dist_mine", roads_km = "roads_km", bclcs_level_5_2 = "bclcs_level_5_2")

vars.clim<-c("climate1")
vars.clim.vegtype2<-c("climate1", "vegtype2")
vars.oth<-c("proj_height_1", "proj_age_1", "live_stand_volume_125") 
vars.topo<-c("slope", "aspect", "elevation")
vars.wind<-c("wind_atfire")

#Also for later with 2 climate variables
vars.clim.vegtype22<-c("climate1", "climate2","vegtype2")
vars.clim.vegtype22b<-c("climate1", "climate2")


##Create interaction for climate and vegtype2
inputs.me <- c(vars.clim.vegtype2)
inputs.me2 <- c(vars.clim.vegtype22)
inputs.me2b <- c(vars.clim.vegtype22b)
inputs.me.infra_landuse <- c(variables_all_infra_landuse)
```

Now, we will generate two-way interactions for each of these lists. 

```{r}
#####1a. For those with one climate variable
#get the names of all possible two-way interactions for climate variable(s) and vegtype2.
twoway.ints <- NULL
for (i in 1:(length(inputs.me)-1)) {
  for (j in (i+1):length(inputs.me)) {
     twoway.ints <- cbind(twoway.ints, paste(inputs.me[i], inputs.me[j], sep=":"))
  }
}
twoway.ints
length(twoway.ints)

#
#Create function to determine Powerset for any vector of variable names
## or use rje package
#powerSet <- function(x) {
#   z.list <- NULL
#   for(i in 1:length(x)) {
#      z.list <- append(z.list, combn(x, m=i, simplify=F))
#   }    
#   return(z.list)
#}


#Get variables on own
#complete list of models using non-climate vars
mods.me.tmp <- powerSet(vars.clim.vegtype2) 
#add climate vars to all of the above
mods.me.climate <- list()
for (i in 1: length(mods.me.tmp)) {
   mods.me.climate[[i]] <- c(mods.me.tmp[[i]])
}

mods.me.climate

#complete list of two-way interactions
mods.twoway <- powerSet(twoway.ints)
length(mods.twoway) #7
mods.twoway

#Finding models in mods.me that accommodate/allow interaction terms in each mods.twoway to be added
mods.inter <- list()
counter <- 0
for (i in 1: length(mods.twoway)) {
   s1 <- unique(unlist( strsplit(mods.twoway[[i]], split=':', fixed=TRUE) ) )
   for (j in 1: length(mods.me.climate)) {
      if (all(s1 %in% mods.me.climate[[j]])==TRUE) {
        counter <- counter + 1
        both <-  c(mods.me.climate[[j]], mods.twoway[[i]])
        mods.inter[[counter]] <- both
      }
   }
}

length(mods.inter)
mods.inter


#####1b. For those with two climate variables
#get the names of all possible two-way interactions for climate variable(s) and vegtype2.
twoway.ints2 <- NULL
for (i in 1:(length(inputs.me2)-1)) {
  for (j in (i+1):length(inputs.me2)) {
     twoway.ints2 <- cbind(twoway.ints2, paste(inputs.me2[i], inputs.me2[j], sep=":"))
  }
}
twoway.ints2
length(twoway.ints2)

#Get variables on own
#complete list of models using non-climate vars
mods.me.tmp <- powerSet(vars.clim.vegtype22) 
#add climate vars to all of the above
mods.me.climate2 <- list()
for (i in 1: length(mods.me.tmp)) {
   mods.me.climate2[[i]] <- c(mods.me.tmp[[i]])
}

mods.me.climate2

#complete list of two-way interactions
mods.twoway2 <- powerSet(twoway.ints2)
length(mods.twoway2) #7
mods.twoway2

#Finding models in mods.me that accommodate/allow interaction terms in each mods.twoway to be added
mods.inter2 <- list()
counter <- 0
for (i in 1: length(mods.twoway2)) {
   s1 <- unique(unlist( strsplit(mods.twoway2[[i]], split=':', fixed=TRUE) ) )
   for (j in 1: length(mods.me.climate2)) {
      if (all(s1 %in% mods.me.climate2[[j]])==TRUE) {
        counter <- counter + 1
        both <-  c(mods.me.climate2[[j]], mods.twoway2[[i]])
        mods.inter2[[counter]] <- both
      }
   }
}

length(mods.inter2)
mods.inter2

####1c. Two variables, no variation in vegtype2
#get the names of all possible two-way interactions for climate variable(s) and vegtype2.
twoway.ints2b <- NULL
for (i in 1:(length(inputs.me2b)-1)) {
  for (j in (i+1):length(inputs.me2b)) {
     twoway.ints2b <- cbind(twoway.ints2b, paste(inputs.me2b[i], inputs.me2b[j], sep=":"))
  }
}
twoway.ints2b
length(twoway.ints2b)

#Get variables on own
#complete list of models using non-climate vars
mods.me.tmp <- powerSet(vars.clim.vegtype22b) 
#add climate vars to all of the above
mods.me.climate2b <- list()
for (i in 1: length(mods.me.tmp)) {
   mods.me.climate2b[[i]] <- c(mods.me.tmp[[i]])
}

mods.me.climate2b

#complete list of two-way interactions
mods.twoway2b <- powerSet(twoway.ints2b)
length(mods.twoway2b) #7
mods.twoway2b

#Finding models in mods.me that accommodate/allow interaction terms in each mods.twoway to be added
mods.inter2b <- list()
counter <- 0
for (i in 1: length(mods.twoway2b)) {
   s1 <- unique(unlist( strsplit(mods.twoway2b[[i]], split=':', fixed=TRUE) ) )
   for (j in 1: length(mods.me.climate2b)) {
      if (all(s1 %in% mods.me.climate2b[[j]])==TRUE) {
        counter <- counter + 1
        both <-  c(mods.me.climate2b[[j]], mods.twoway2b[[i]])
        mods.inter2b[[counter]] <- both
      }
   }
}

length(mods.inter2b)
mods.inter2b
```


```{r}
#########2. Now for topography data, get all possible two-way interactions

#get the names of all possible two-way interactions
twoway.intsT <- NULL
for (i in 1:(length(vars.topo)-1)) {
  for (j in (i+1):length(vars.topo)) {
     twoway.intsT <- cbind(twoway.intsT, paste(vars.topo[i], vars.topo[j], sep=":"))
  }
}
twoway.intsT
length(twoway.intsT)

#complete list of models using non-climate vars (topo)
mods.me.tmp <- powerSet(vars.topo) 
#add climate vars to all of the above
mods.meT <- list()
for (i in 1: length(mods.me.tmp)) {
   mods.meT[[i]] <- c(mods.me.tmp[[i]])
}

mods.meT

#complete list of two-way interactions
mods.twowayT <- powerSet(twoway.intsT)
length(mods.twowayT) #7
mods.twowayT


#Finding models in mods.me that accommodate/allow interaction terms in each mods.twoway to be added

mods.interT <- list()
counter <- 0
for (i in 1: length(mods.twowayT)) {
   s1 <- unique(unlist( strsplit(mods.twowayT[[i]], split=':', fixed=TRUE) ) )
   for (j in 1: length(mods.meT)) {
      if (all(s1 %in% mods.meT[[j]])==TRUE) {
        counter <- counter + 1
        both <-  c(mods.meT[[j]], mods.twowayT[[i]])
        mods.interT[[counter]] <- both
      }
   }
}

length(mods.interT)
mods.interT
```


```{r}
####3.For other VRI data, get without interactions

#complete list of models using VRI - no interactions
mods.me.tmp <- powerSet(vars.oth) 
#add climate vars to all of the above
mods.me.oth <- list()
for (i in 1: length(mods.me.tmp)) {
   mods.me.oth[[i]] <- c(mods.me.tmp[[i]])
}

mods.me.oth
```


```{r}
#the list of all possible model RHSs. 
all.poss.mods.clim.vegtype<-c(1, mods.inter)
all.poss.mods.clim.vegtype 
all.poss.mods.clim.vegtype<-all.poss.mods.clim.vegtype [-2] #Use this line only if there is an odd character(0) added to list
all.poss.mods.clim.vegtype2<-c(1, mods.inter2)
all.poss.mods.clim.vegtype2
all.poss.mods.clim.vegtype2<-all.poss.mods.clim.vegtype2[-2]
duplicated(all.poss.mods.clim.vegtype2)

all.poss.mods.clim.vegtype2b<-c(1, mods.inter2b)
all.poss.mods.clim.vegtype2b
all.poss.mods.clim.vegtype2b<-all.poss.mods.clim.vegtype2b[-2]
duplicated(all.poss.mods.clim.vegtype2b) 

all.poss.mods.VRI<-c(1, mods.me.oth)
all.poss.mods.VRI
all.poss.mods.VRI<-all.poss.mods.VRI[-2]
duplicated(all.poss.mods.VRI)

all.poss.mods.topo2<-c(1, mods.interT)
all.poss.mods.topo2
all.poss.mods.topo2<-all.poss.mods.topo2[-2]
duplicated(all.poss.mods.topo2)


```

Then also for infrastructure.

```{r}
##Subset 2: Infrastructure and land use ########
#inputs.me.infra_landuse
twoway.ints.in <- NULL
for (i in 1:(length(inputs.me.infra_landuse)-1)) {
  for (j in (i+1):length(inputs.me.infra_landuse)) {
     twoway.ints.in <- cbind(twoway.ints.in, paste(inputs.me.infra_landuse[i], inputs.me.infra_landuse[j], sep=":"))
  }
}
twoway.ints.in
length(twoway.ints.in) #15
#Review. If we do not want interactions between the different distance measurements, but only those between land use and distance, subset those.
twoway.ints.in
twoway.ints.in_dist<-twoway.ints.in[c(4,5,8,9,11,12,13,14,15)]
twoway.ints.in_dist


#Create function to determine Powerset for any vector of variable names
## or use rje package
#powerSet <- function(x) {
#   z.list <- NULL
#   for(i in 1:length(x)) {
#      z.list <- append(z.list, combn(x, m=i, simplify=F))
#   }    
#   return(z.list)
#}

#Get variables on own
#complete list of models using non-climate vars
mods.me.tmp.in <- powerSet(variables_all_infra_landuse) 
#add climate vars to all of the above
mods.me.infra_landuse <- list()
for (i in 1: length(mods.me.tmp.in)) {
   mods.me.infra_landuse[[i]] <- c(mods.me.tmp.in[[i]])
}

mods.me.infra_landuse
length(mods.me.infra_landuse) #64


#complete list of two-way interactions
#mods.twoway.in.b <- powerSet(twoway.in.ints.in) #
#Or use subset of interactions
mods.twoway.in.b <- powerSet(twoway.ints.in_dist) 
length(mods.twoway.in.b) #512
#mods.twoway.in.b
mods.twoway.in.b[1]
mods.twoway.in.b<-mods.twoway.in.b[-1]

#Finding models in mods.me that accommodate/allow interaction terms in each mods.twoway.in to be added
mods.inter.b.in <- list()
counter <- 0
for (i in 1: length(mods.twoway.in.b)) {
   s1 <- unique(unlist( strsplit(mods.twoway.in.b[[i]], split=':', fixed=TRUE) ) )
   for (j in 1: length(mods.me.infra_landuse)) {
      if (all(s1 %in% mods.me.infra_landuse[[j]])==TRUE) {
        counter <- counter + 1
        both <-  c(mods.me.infra_landuse[[j]], mods.twoway.in.b[[i]])
        mods.inter.b.in[[counter]] <- both
      }
   }
}

length(mods.inter.b.in) #1364
#mods.inter.b.in

#####2. Infrastructure and land use
all.poss.mods.infra_landuse<-c(1,mods.me.infra_landuse, mods.inter.b.in)
all.poss.mods.infra_landuse[2]
all.poss.mods.infra_landuse<-all.poss.mods.infra_landuse[-2]

##Check and rid of any duplicated models
duplicated(all.poss.mods.infra_landuse) 
```


############### Part 1 of 4 Model Series: Lightning Caused Fires, Trees ##########

NDT 2 has 2 climate variables, and NDT 1, 3, 4 and 5 have one.

Select: NDT4
#1. Climate1 and vegtype2
Only has climate1, no climate2. Use all.poss.mods.clim.vegtype. NDT1,3, 4 and 5 only have one climate variables. NDT4 has two.

```{r}
ntrl_ds<-c("NDT4") #Do one zone at a time
zones1<-c("NDT4")
prop<-0.75

#Create empty table
table.glm.climate.simple.spread <- data.frame (matrix (ncol = 9, nrow = 0))
colnames (table.glm.climate.simple.spread) <- c ("model", "edf", "aic", "Model.R2", "Adjusted.R2", "Valid.R2", "Valid.RMSE", "Valid.MAE", "NDT")

#Run model x100
for (g in 1:100){
  
for (h in 1:length(zones1)) {
  dat2<- subset(spread_data_lightning_t, spread_data_lightning_t$ntrl_ds=="NDT4")

for (i in 1: length(zones1)){
  print(paste((all.poss.mods.clim.vegtype[i]), (ntrl_ds[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(spread, fire_veg, variables_all[i])
  model_dat<- dat2 %>% dplyr::select(LNsize_ha, vegtype2, !!variables_all)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$vegtype2, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod_lm <- function(mods.in, df.train, dep.var="LNsize_ha") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- lm(form, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   predictions <- mods.fit %>% predict(Valid)
   Model.R2 <- summary(mods.fit)$r.squared
   Valid.R2 <- R2(predictions, Valid$LNsize_ha, na.rm=TRUE)
   Valid.RMSE <- RMSE(predictions, Valid$LNsize_ha, na.rm=TRUE)
   Valid.MAE <- MAE(predictions, Valid$LNsize_ha, na.rm=TRUE)
   Adjusted.R2<-summary(mods.fit)$adj.r.squared 
   return(list(rhs, mod.stuff, mod.aic, Model.R2, Valid.R2, Valid.RMSE, Valid.MAE, Adjusted.R2))
   
}

mods.fit <- lapply(all.poss.mods.clim.vegtype, big.mod_lm, df.train=dat1)

#terms in each model
x1.1 <- unlist(sapply(mods.fit, '[', 1))
x1.1
#Aic for models
x3.1 <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3.1
#Model.R2
x4.1 <- unlist(sapply(mods.fit, '[', 4))
x4.1
#Validation R2 
x5.1 <- unlist(sapply(mods.fit, '[', 5))
x5.1
#Validation RSME
x6.1 <- unlist(sapply(mods.fit, '[', 6))
x6.1
#Validation MAE
x7.1 <- unlist(sapply(mods.fit, '[', 7))
x7.1
#Adjusted R2
x8.1 <- unlist(sapply(mods.fit, '[', 8))
x8.1
#combining all as df
tab.sum.climate <- cbind.data.frame(model=x1.1, edf=x3.1[,1], aic=x3.1[,2], Model.R2=x4.1, Adjusted.R2=x8.1, Valid.R2=x5.1, Valid.RMSE=x6.1, Valid.MAE=x7.1)
tab.sum.climate$NDT<-c("NDT4")
tab.sum.climate 

table.glm.climate.simple.spread<-rbind(table.glm.climate.simple.spread, tab.sum.climate)

}
}
}
```

Check data.

```{r}
head(table.glm.climate.simple.spread)
```
Now that we have run the model 100 times, we want the average AIC and AUC for each variable combination.

```{r}
head(table.glm.climate.simple.spread)
table(table.glm.climate.simple.spread$model) # 100 per model

AIC_lightning_NDT4_spread_treed_climate<-table.glm.climate.simple.spread

AIC_lightning_NDT4_spread_treed_summary_climate<- AIC_lightning_NDT4_spread_treed_climate %>%
  group_by(model) %>%
  summarise(meanAIC=mean(aic, na.rm=TRUE),
            meanR2=mean(Model.R2, na.rm=TRUE),
            meanAdjustR2=mean(Adjusted.R2, na.rm=TRUE),
            sdR2=sd(Model.R2, na.rm=TRUE),
            meanR2valid=mean(Valid.R2, na.rm=TRUE),
            meanRSMEvalid=mean(Valid.RMSE, na.rm=TRUE),
            meanMAEvalid=mean(Valid.MAE, na.rm=TRUE)
            )

AIC_lightning_NDT4_spread_treed_summary_climate2<- AIC_lightning_NDT4_spread_treed_summary_climate %>%
  mutate(deltaAIC=meanAIC-min(meanAIC))

head(AIC_lightning_NDT4_spread_treed_summary_climate2)
```


##WORK IN PROGRESS FOR GAMMA #########

#Compare to using a Gamma distribution

```{r}
ntrl_ds<-c("NDT4") #Do one zone at a time
zones1<-c("NDT4")
prop<-0.75

#Create empty table
table.glm.climate.simple.spread.gamma <- data.frame (matrix (ncol = 8, nrow = 0))
colnames (table.glm.climate.simple.spread.gamma) <- c ("model", "edf", "aic", "Model.R2", "Valid.R2", "Valid.RMSE", "Valid.MAE", "NDT")

#Run model x100
for (g in 1:100){
  
for (h in 1:length(zones1)) {
  dat2<- subset(spread_data_lightning_t, spread_data_lightning_t$ntrl_ds=="NDT4")

for (i in 1: length(zones1)){
  print(paste((all.poss.mods.clim.vegtype[i]), (ntrl_ds[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(spread, fire_veg, variables_all[i])
  model_dat<- dat2 %>% dplyr::select(LNsize_ha, size_ha, escape10, !!variables_all)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$escape10, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod_lm <- function(mods.in, df.train, dep.var="size_ha") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, data=df.train, family=Gamma(link="identity") )
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   predictions <- mods.fit %>% predict(Valid)
   Model.R2 <- summary(mods.fit)$r.squared
   Valid.R2 <- R2(predictions, Valid$LNsize_ha, na.rm=TRUE)
   Valid.RMSE <- RMSE(predictions, Valid$LNsize_ha, na.rm=TRUE)
   Valid.MAE <- MAE(predictions, Valid$LNsize_ha, na.rm=TRUE)
   return(list(rhs, mod.stuff, mod.aic, Model.R2, Valid.R2, Valid.RMSE, Valid.MAE))
   
}

mods.fit <- lapply(all.poss.mods.clim.vegtype, big.mod_lm, df.train=dat1)

#terms in each model
x1.1 <- unlist(sapply(mods.fit, '[', 1))
x1.1
#Aic for models
x3.1 <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3.1
#Model.R2
x4.1 <- unlist(sapply(mods.fit, '[', 4))
x4.1
#Validation R2
x5.1 <- unlist(sapply(mods.fit, '[', 5))
x5.1
#Validation RSME
x6.1 <- unlist(sapply(mods.fit, '[', 6))
x6.1
#Validation MAE
x7.1 <- unlist(sapply(mods.fit, '[', 7))
x7.1
#combining all as df
tab.sum.climate <- cbind.data.frame(model=x1.1, edf=x3.1[,1], aic=x3.1[,2], Model.R2=x4.1, Valid.R2=x5.1, Valid.RMSE=x6.1, Valid.MAE=x7.1)
tab.sum.climate$NDT<-c("NDT4")
tab.sum.climate 

table.glm.climate.simple.spread.gamma<-rbind(table.glm.climate.simple.spread, tab.sum.climate)

}
}
}
```
Check data.
```{r}
head(table.glm.climate.simple.spread.gamma)
```
Now that we have run the model 100 times, we want the average AIC and AUC for each variable combination.

```{r}
head(table.glm.climate.simple.spread.gamma)
table(table.glm.climate.simple.spread.gamma$model) # 100 per model

AIC_lightning_NDT4_spread_treed_climate_gamma<-table.glm.climate.simple.spread.gamma

AIC_lightning_NDT4_spread_treed_summary_climate_gamma<- AIC_lightning_NDT4_spread_treed_climate_gamma %>%
  group_by(model) %>%
  summarise(meanAIC=mean(aic, na.rm=TRUE),
            meanR2=mean(Model.R2, na.rm=TRUE),
            sdR2=sd(Model.R2, na.rm=TRUE),
            meanR2valid=mean(Valid.R2, na.rm=TRUE),
            meanRSMEvalid=mean(Valid.RMSE, na.rm=TRUE),
            meanMAEvalid=mean(Valid.MAE, na.rm=TRUE)
            )

AIC_lightning_NDT4_spread_treed_summary_climate_gamma2<- AIC_lightning_NDT4_spread_treed_summary_climate_gamma %>%
  mutate(deltaAIC=meanAIC-min(meanAIC))

head(AIC_lightning_NDT4_spread_treed_summary_climate_gamma2)
```




#Now repeat for VRI data

```{r}
#Create empty table
table.glm.VRI.simple.spread <- data.frame (matrix (ncol = 9, nrow = 0))
colnames (table.glm.VRI.simple.spread) <- c ("model", "edf", "aic", "Model.R2", "Adjusted.R2", "Valid.R2", "Valid.RMSE", "Valid.MAE", "NDT")

#Run model x100
for (g in 1:100){
  
for (h in 1:length(zones1)) {
  dat2<- subset(spread_data_lightning_t, spread_data_lightning_t$ntrl_ds=="NDT4")

for (i in 1: length(zones1)){
  print(paste((all.poss.mods.VRI[i]), (ntrl_ds[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(spread, fire_veg, variables_all[i])
  model_dat<- dat2 %>% dplyr::select(LNsize_ha, escape10, !!variables_all)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$escape10, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod_lm <- function(mods.in, df.train, dep.var="LNsize_ha") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- lm(form, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   predictions <- mods.fit %>% predict(Valid)
   Model.R2 <- summary(mods.fit)$r.squared
   Valid.R2 <- R2(predictions, Valid$LNsize_ha, na.rm=TRUE)
   Valid.RMSE <- RMSE(predictions, Valid$LNsize_ha, na.rm=TRUE)
   Valid.MAE <- MAE(predictions, Valid$LNsize_ha, na.rm=TRUE)
   Adjusted.R2<-summary(mods.fit)$adj.r.squared 
   return(list(rhs, mod.stuff, mod.aic, Model.R2, Valid.R2, Valid.RMSE, Valid.MAE, Adjusted.R2))
   
}

mods.fit <- lapply(all.poss.mods.VRI, big.mod_lm, df.train=dat1)

#terms in each model
x1.1 <- unlist(sapply(mods.fit, '[', 1))
x1.1
#Aic for models
x3.1 <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3.1
#Model.R2
x4.1 <- unlist(sapply(mods.fit, '[', 4))
x4.1
#Validation R2
x5.1 <- unlist(sapply(mods.fit, '[', 5))
x5.1
#Validation RSME
x6.1 <- unlist(sapply(mods.fit, '[', 6))
x6.1
#Validation MAE
x7.1 <- unlist(sapply(mods.fit, '[', 7))
x7.1
#Adjusted R2
x8.1 <- unlist(sapply(mods.fit, '[', 8))
x8.1
#combining all as df
tab.sum.VRI <- cbind.data.frame(model=x1.1, edf=x3.1[,1], aic=x3.1[,2], Model.R2=x4.1, Adjusted.R2=x8.1, Valid.R2=x5.1, Valid.RMSE=x6.1, Valid.MAE=x7.1)
tab.sum.VRI$NDT<-c("NDT4")
tab.sum.VRI 

table.glm.VRI.simple.spread<-rbind(table.glm.VRI.simple.spread, tab.sum.VRI)

}
}
}
```
Check data.
```{r}
head(table.glm.VRI.simple.spread)
```
Now that we have run the model 100 times, we want the average AIC and AUC for each variable combination.

```{r}
head(table.glm.VRI.simple.spread)
table(table.glm.VRI.simple.spread$model) # 100 per model

AIC_lightning_NDT4_spread_treed_VRI<-table.glm.VRI.simple.spread

AIC_lightning_NDT4_spread_treed_summary_VRI<- AIC_lightning_NDT4_spread_treed_VRI %>%
  group_by(model) %>%
  summarise(meanAIC=mean(aic, na.rm=TRUE),
            meanR2=mean(Model.R2, na.rm=TRUE),
            meanAdjustR2=mean(Adjusted.R2, na.rm=TRUE),
            sdR2=sd(Model.R2, na.rm=TRUE),
            meanR2valid=mean(Valid.R2, na.rm=TRUE),
            meanRSMEvalid=mean(Valid.RMSE, na.rm=TRUE),
            meanMAEvalid=mean(Valid.MAE, na.rm=TRUE)
            )

AIC_lightning_NDT4_spread_treed_summary_VRI2<- AIC_lightning_NDT4_spread_treed_summary_VRI %>%
  mutate(deltaAIC=meanAIC-min(meanAIC))

head(AIC_lightning_NDT4_spread_treed_summary_VRI2)
```
#Now repeat for topography

```{r}
#Create empty table
table.glm.topo.simple.spread <- data.frame (matrix (ncol = 9, nrow = 0))
colnames (table.glm.topo.simple.spread) <- c ("model", "edf", "aic", "Model.R2", "Adjusted.R2", "Valid.R2", "Valid.RMSE", "Valid.MAE", "NDT")

#Run model x100
for (g in 1:100){
  
for (h in 1:length(zones1)) {
  dat2<- subset(spread_data_lightning_t, spread_data_lightning_t$ntrl_ds=="NDT4")

for (i in 1: length(zones1)){
  print(paste((all.poss.mods.topo[i]), (ntrl_ds[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(spread, fire_veg, variables_all[i])
  model_dat<- dat2 %>% dplyr::select(LNsize_ha, escape10, !!variables_all)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$escape10, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod_lm <- function(mods.in, df.train, dep.var="LNsize_ha") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- lm(form, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   predictions <- mods.fit %>% predict(Valid)
   Model.R2 <- summary(mods.fit)$r.squared
   Valid.R2 <- R2(predictions, Valid$LNsize_ha, na.rm=TRUE)
   Valid.RMSE <- RMSE(predictions, Valid$LNsize_ha, na.rm=TRUE)
   Valid.MAE <- MAE(predictions, Valid$LNsize_ha, na.rm=TRUE)
   Adjusted.R2<-summary(mods.fit)$adj.r.squared 
   return(list(rhs, mod.stuff, mod.aic, Model.R2, Valid.R2, Valid.RMSE, Valid.MAE, Adjusted.R2))
   
}

mods.fit <- lapply(all.poss.mods.topo, big.mod_lm, df.train=dat1)

#terms in each model
x1.1 <- unlist(sapply(mods.fit, '[', 1))
x1.1
#Aic for models
x3.1 <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3.1
#Model.R2
x4.1 <- unlist(sapply(mods.fit, '[', 4))
x4.1
#Validation R2
x5.1 <- unlist(sapply(mods.fit, '[', 5))
x5.1
#Validation RSME
x6.1 <- unlist(sapply(mods.fit, '[', 6))
x6.1
#Validation MAE
x7.1 <- unlist(sapply(mods.fit, '[', 7))
x7.1
#Adjusted R2
x8.1 <- unlist(sapply(mods.fit, '[', 8))
x8.1
#combining all as df
tab.sum.topo <- cbind.data.frame(model=x1.1, edf=x3.1[,1], aic=x3.1[,2], Model.R2=x4.1, Adjusted.R2=x8.1, Valid.R2=x5.1, Valid.RMSE=x6.1, Valid.MAE=x7.1)
tab.sum.topo$NDT<-c("NDT4")
tab.sum.topo 

table.glm.topo.simple.spread<-rbind(table.glm.topo.simple.spread, tab.sum.topo)

}
}
}
```
Check data.
```{r}
head(table.glm.topo.simple.spread)
```
Now that we have run the model 100 times, we want the average AIC and AUC for each variable combination.

```{r}
head(table.glm.topo.simple.spread)
table(table.glm.topo.simple.spread$model) # 100 per model

AIC_lightning_NDT4_spread_treed_topo<-table.glm.topo.simple.spread

AIC_lightning_NDT4_spread_treed_summary_topo<- AIC_lightning_NDT4_spread_treed_topo %>%
  group_by(model) %>%
  summarise(meanAIC=mean(aic, na.rm=TRUE),
            meanR2=mean(Model.R2, na.rm=TRUE),
            meanAdjustR2=mean(Adjusted.R2, na.rm=TRUE),
            sdR2=sd(Model.R2, na.rm=TRUE),
            meanR2valid=mean(Valid.R2, na.rm=TRUE),
            meanRSMEvalid=mean(Valid.RMSE, na.rm=TRUE),
            meanMAEvalid=mean(Valid.MAE, na.rm=TRUE)
            )

AIC_lightning_NDT4_spread_treed_summary_topo2<- AIC_lightning_NDT4_spread_treed_summary_topo %>%
  mutate(deltaAIC=meanAIC-min(meanAIC))

head(AIC_lightning_NDT4_spread_treed_summary_topo2)
```

#Now repeat for infrastructure

```{r}
#Create empty table
table.glm.infra.simple.spread <- data.frame (matrix (ncol = 9, nrow = 0))
colnames (table.glm.infra.simple.spread) <- c ("model", "edf", "aic", "Model.R2", "Adjusted.R2", "Valid.R2", "Valid.RMSE", "Valid.MAE", "NDT")

#Run model x100
for (g in 1:100){
  
for (h in 1:length(zones1)) {
  dat2<- subset(spread_data_lightning_t, spread_data_lightning_t$ntrl_ds=="NDT4")

for (i in 1: length(zones1)){
  print(paste((all.poss.mods.infra_landuse[i]), (ntrl_ds[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(spread, fire_veg, variables_all[i])
  model_dat<- dat2 %>% dplyr::select(LNsize_ha, bclcs_level_5_2, !!variables_all)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$bclcs_level_5_2 , p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod_lm <- function(mods.in, df.train, dep.var="LNsize_ha") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- lm(form, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   predictions <- mods.fit %>% predict(Valid)
   Model.R2 <- summary(mods.fit)$r.squared
   Valid.R2 <- R2(predictions, Valid$LNsize_ha, na.rm=TRUE)
   Valid.RMSE <- RMSE(predictions, Valid$LNsize_ha, na.rm=TRUE)
   Valid.MAE <- MAE(predictions, Valid$LNsize_ha, na.rm=TRUE)
   Adjusted.R2<-summary(mods.fit)$adj.r.squared 
   return(list(rhs, mod.stuff, mod.aic, Model.R2, Valid.R2, Valid.RMSE, Valid.MAE, Adjusted.R2))
   
}

mods.fit <- lapply(all.poss.mods.infra_landuse, big.mod_lm, df.train=dat1)

#terms in each model
x1.1 <- unlist(sapply(mods.fit, '[', 1))
x1.1
#Aic for models
x3.1 <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3.1
#Model.R2
x4.1 <- unlist(sapply(mods.fit, '[', 4))
x4.1
#Validation R2
x5.1 <- unlist(sapply(mods.fit, '[', 5))
x5.1
#Validation RSME
x6.1 <- unlist(sapply(mods.fit, '[', 6))
x6.1
#Validation MAE
x7.1 <- unlist(sapply(mods.fit, '[', 7))
x7.1
#Adjusted R2
x8.1 <- unlist(sapply(mods.fit, '[', 8))
x8.1
#combining all as df
tab.sum.infra <- cbind.data.frame(model=x1.1, edf=x3.1[,1], aic=x3.1[,2], Model.R2=x4.1, Adjusted.R2=x8.1, Valid.R2=x5.1, Valid.RMSE=x6.1, Valid.MAE=x7.1)
tab.sum.infra$NDT<-c("NDT4")
tab.sum.infra 

table.glm.infra.simple.spread<-rbind(table.glm.infra.simple.spread, tab.sum.infra)

}
}
}
```
Check data.
```{r}
head(table.glm.infra.simple.spread)
```
Now that we have run the model 100 times, we want the average AIC and AUC for each variable combination.

```{r}
head(table.glm.infra.simple.spread)
table(table.glm.infra.simple.spread$model) # 100 per model 

AIC_lightning_NDT4_spread_treed_infra<-table.glm.infra.simple.spread

AIC_lightning_NDT4_spread_treed_summary_infra<- AIC_lightning_NDT4_spread_treed_infra %>%
  group_by(model) %>%
  summarise(meanAIC=mean(aic, na.rm=TRUE),
            meanR2=mean(Model.R2, na.rm=TRUE),
            meanAdjustR2=mean(Adjusted.R2, na.rm=TRUE),
            sdR2=sd(Model.R2, na.rm=TRUE),
            meanR2valid=mean(Valid.R2, na.rm=TRUE),
            meanRSMEvalid=mean(Valid.RMSE, na.rm=TRUE),
            meanMAEvalid=mean(Valid.MAE, na.rm=TRUE)
            )

AIC_lightning_NDT4_spread_treed_summary_infra2<- AIC_lightning_NDT4_spread_treed_summary_infra %>%
  mutate(deltaAIC=meanAIC-min(meanAIC))

head(AIC_lightning_NDT4_spread_treed_summary_infra2)
```

Combine together
```{r}
NDT4_l_treed_spread<-rbind(AIC_lightning_NDT4_spread_treed_summary_climate2, AIC_lightning_NDT4_spread_treed_summary_infra2, AIC_lightning_NDT4_spread_treed_summary_topo2, AIC_lightning_NDT4_spread_treed_summary_VRI2)

NDT4_l_treed_spread$NDT<-"NDT4"

head(NDT4_l_treed_spread)
```

Save data.
```{r}
write.csv(NDT4_l_treed_spread, file="D:\\Fire\\fire_data\\raw_data\\NDT4_lightning_models_treed_spread_Nov.csv")
```

##Determine Best Models.
For best models, we will look at R-square of the model, and then within the top R-square, we will assess which had lowest AIC.

1. proj_age_1 + live_stand_volume_125
2. dist_mun + roads_km
3. elevation
4. climate1 + vegtype2

##################### Begin Manual Exploration ##################
Begin manual exploration from here. We will use the above variables, plus additional interactions: wind_atfire + climate1:proj_height_1 + climate1:proj_age_1 + climate1:live_stand_volume_125 + climate1:elevation + climate1:wind_atfire + slope:wind_atfire + elevation:wind_atfire + vegtype2:wind_atfire + Tdif_atfire + Tdif_atfire:wind_atfire + Tdif_atfire:live_stand_volume_125


```{r}
spread_lightning_t_NDT4<-subset(spread_data_lightning_t, spread_data_lightning_t$ntrl_ds=="NDT4")

prop<-0.75

#Partition data into training and validation
 trainIndex <- createDataPartition(spread_lightning_t_NDT4$escape10, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- spread_lightning_t_NDT4[ trainIndex,]
   Valid <- spread_lightning_t_NDT4[-trainIndex,]
  
#Run model using dat1
model.NDT4<-lm(LNsize_ha ~ proj_age_1 + live_stand_volume_125 + dist_mun +  roads_km + elevation + climate1 + vegtype2 + wind_atfire + climate1:proj_age_1 + climate1:live_stand_volume_125 + climate1:elevation + climate1:wind_atfire + slope + slope:wind_atfire + elevation:wind_atfire + vegtype2:wind_atfire + Tdif_atfire + Tdif_atfire:wind_atfire + Tdif_atfire:live_stand_volume_125, data = dat1)

AIC(model.NDT4) #847.4
summary(model.NDT4)$r.squared #0.31
summary(model.NDT4)$adj.r.squared #0.20

predictions <- model.NDT4 %>% predict(Valid)
R2(predictions, Valid$LNsize_ha, na.rm=TRUE) #0.04
RMSE(predictions, Valid$LNsize_ha, na.rm=TRUE) #2.45
MAE(predictions, Valid$LNsize_ha, na.rm=TRUE) #1.92

summary(model.NDT4)
Anova(model.NDT4, type=3)
Anova(model.NDT4, type=3, singular.ok = TRUE)


#Remove least sig
model.NDT4<-lm(LNsize_ha ~ proj_age_1 + live_stand_volume_125 + dist_mun +  roads_km + elevation + climate1 + vegtype2 + wind_atfire + climate1:live_stand_volume_125 + climate1:elevation + climate1:wind_atfire + slope + slope:wind_atfire + elevation:wind_atfire + Tdif_atfire + Tdif_atfire:wind_atfire + Tdif_atfire:live_stand_volume_125, data = dat1)

AIC(model.NDT4) #840.7
summary(model.NDT4)$r.squared #0.30
summary(model.NDT4)$adj.r.squared #0.22

predictions <- model.NDT4 %>% predict(Valid)
R2(predictions, Valid$LNsize_ha, na.rm=TRUE) #0.04
RMSE(predictions, Valid$LNsize_ha, na.rm=TRUE) #2.45
MAE(predictions, Valid$LNsize_ha, na.rm=TRUE) #1.92

summary(model.NDT4)
Anova(model.NDT4, type=3)
Anova(model.NDT4, type=3, singular.ok = TRUE)

#Remove least sig
model.NDT4<-lm(LNsize_ha ~ proj_age_1 + live_stand_volume_125 + dist_mun +  roads_km + elevation + climate1 + vegtype2 + wind_atfire + climate1:elevation + climate1:wind_atfire + slope + slope:wind_atfire + elevation:wind_atfire + Tdif_atfire + Tdif_atfire:wind_atfire, data = dat1)

AIC(model.NDT4) #836.9
summary(model.NDT4)$r.squared #0.30
summary(model.NDT4)$adj.r.squared #0.23

predictions <- model.NDT4 %>% predict(Valid)
R2(predictions, Valid$LNsize_ha, na.rm=TRUE) #0.04
RMSE(predictions, Valid$LNsize_ha, na.rm=TRUE) #2.45
MAE(predictions, Valid$LNsize_ha, na.rm=TRUE) #1.92

summary(model.NDT4)
Anova(model.NDT4, type=3)
Anova(model.NDT4, type=3, singular.ok = TRUE)

#Remove least sig
model.NDT4<-lm(LNsize_ha ~ proj_age_1 + live_stand_volume_125 + dist_mun + elevation + climate1 + wind_atfire + climate1:elevation + climate1:wind_atfire + slope + slope:wind_atfire + elevation:wind_atfire + Tdif_atfire + Tdif_atfire:wind_atfire, data = dat1)

AIC(model.NDT4) #829.6
summary(model.NDT4)$r.squared #0.30
summary(model.NDT4)$adj.r.squared #0.24

predictions <- model.NDT4 %>% predict(Valid)
R2(predictions, Valid$LNsize_ha, na.rm=TRUE) #0.04
RMSE(predictions, Valid$LNsize_ha, na.rm=TRUE) #2.45
MAE(predictions, Valid$LNsize_ha, na.rm=TRUE) #1.92

summary(model.NDT4)
Anova(model.NDT4, type=3)
Anova(model.NDT4, type=3, singular.ok = TRUE)

#Remove least sig
model.NDT4<-lm(LNsize_ha ~ proj_age_1  + dist_mun + elevation + climate1 + wind_atfire + climate1:elevation + climate1:wind_atfire + slope + slope:wind_atfire + elevation:wind_atfire + Tdif_atfire + Tdif_atfire:wind_atfire, data = dat1)

AIC(model.NDT4) #865.2 -> bad increase
summary(model.NDT4)$r.squared #0.27
summary(model.NDT4)$adj.r.squared #0.21

predictions <- model.NDT4 %>% predict(Valid)
R2(predictions, Valid$LNsize_ha, na.rm=TRUE) #0.05
RMSE(predictions, Valid$LNsize_ha, na.rm=TRUE) #2.34
MAE(predictions, Valid$LNsize_ha, na.rm=TRUE) #1.83

summary(model.NDT4)
Anova(model.NDT4, type=3)
Anova(model.NDT4, type=3, singular.ok = TRUE)

#Remove proj age instead
model.NDT4<-lm(LNsize_ha ~  live_stand_volume_125 + dist_mun + elevation + climate1 + wind_atfire + climate1:elevation + climate1:wind_atfire + slope + slope:wind_atfire + elevation:wind_atfire + Tdif_atfire + Tdif_atfire:wind_atfire, data = dat1)

AIC(model.NDT4) #828.1
summary(model.NDT4)$r.squared #0.30
summary(model.NDT4)$adj.r.squared #0.25

predictions <- model.NDT4 %>% predict(Valid)
R2(predictions, Valid$LNsize_ha, na.rm=TRUE) #0.03
RMSE(predictions, Valid$LNsize_ha, na.rm=TRUE) #2.46
MAE(predictions, Valid$LNsize_ha, na.rm=TRUE) #1.94

summary(model.NDT4)
Anova(model.NDT4, type=3)
Anova(model.NDT4, type=3, singular.ok = TRUE)
```
Remove NAs and run multiple times.

```{r}
#Remove NAs to ensure all same data used so we can compare AICs
NDT4_spread_size_t<-spread_lightning_t_NDT4 %>% drop_na(proj_age_1, live_stand_volume_125 , dist_mun, climate1, wind_atfire, elevation, Tdif_atfire)

#Run Model again with this data; but uses all data here
model.NDT4.Spread<-lm(LNsize_ha ~ proj_age_1 + live_stand_volume_125 + dist_mun + elevation + climate1 + wind_atfire + climate1:elevation + climate1:wind_atfire + slope + slope:wind_atfire + elevation:wind_atfire + Tdif_atfire + Tdif_atfire:wind_atfire, data = NDT4_spread_size_t)

AIC(model.NDT4.Spread) #1101.1
summary(model.NDT4.Spread)$r.squared #0.23
summary(model.NDT4.Spread)$adj.r.squared #0.19

#Anova(model.NDT4.Spread, type=3)
Anova(model.NDT4.Spread, type=3, singular.ok = TRUE)

#Compare to fewer interactions
model.NDT4.Spread<-lm(LNsize_ha ~ proj_age_1 + live_stand_volume_125 + dist_mun + elevation + climate1 + wind_atfire + climate1:elevation  + slope + slope:wind_atfire + elevation:wind_atfire + Tdif_atfire + Tdif_atfire:wind_atfire, data = NDT4_spread_size_t)

AIC(model.NDT4.Spread) #1099.4
summary(model.NDT4.Spread)$r.squared #0.23
summary(model.NDT4.Spread)$adj.r.squared #0.19

#Anova(model.NDT4.Spread, type=3)
Anova(model.NDT4.Spread, type=3, singular.ok = TRUE)

#Compare to fewer interactions
model.NDT4.Spread<-lm(LNsize_ha ~ proj_age_1 + live_stand_volume_125 + dist_mun + elevation + climate1 + wind_atfire + climate1:elevation  + slope + slope:wind_atfire + elevation:wind_atfire + Tdif_atfire, data = NDT4_spread_size_t)

AIC(model.NDT4.Spread) #1098.4
summary(model.NDT4.Spread)$r.squared #0.23
summary(model.NDT4.Spread)$adj.r.squared #0.19

#Anova(model.NDT4.Spread, type=3)
Anova(model.NDT4.Spread, type=3, singular.ok = TRUE)

#
model.NDT4.Spread<-lm(LNsize_ha ~ proj_age_1 + live_stand_volume_125 + dist_mun + elevation + climate1 + wind_atfire + climate1:elevation  + slope + slope:wind_atfire + elevation:wind_atfire, data = NDT4_spread_size_t)

AIC(model.NDT4.Spread) #1096.98
summary(model.NDT4.Spread)$r.squared #0.23
summary(model.NDT4.Spread)$adj.r.squared #0.19

#Anova(model.NDT4.Spread, type=3)
Anova(model.NDT4.Spread, type=3, singular.ok = TRUE)

# model diagnostic plots
binnedplot (fitted(model.NDT4.Spread), 
            residuals(model.NDT4.Spread), 
            nclass = NULL, 
            xlab = "Expected Values", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))


NDT4_spread_size_t$resids<-resid(model.NDT4.Spread)

binnedplot (NDT4_spread_size_t$live_stand_volume_125, 
            NDT4_spread_size_t$resids, 
            nclass = NULL, 
            xlab = "live stand volume", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))

binnedplot (NDT4_spread_size_t$climate1, 
            NDT4_spread_size_t$resids, 
            nclass = NULL, 
            xlab = "", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))

# Diagnostic plots look good

#Partial Residuals
#proj_age_1 + live_stand_volume_125 + dist_mun + elevation + climate1 + wind_atfire + climate1:elevation  + slope + slope:wind_atfire + elevation:wind_atfire
visreg(model.NDT4.Spread, "proj_age_1")
visreg(model.NDT4.Spread, "live_stand_volume_125")

visreg(model.NDT4.Spread, "dist_mun")
visreg(model.NDT4.Spread, "elevation", by="climate1")
visreg(model.NDT4.Spread, "elevation", by="wind_atfire")
visreg(model.NDT4.Spread, "slope", by="wind_atfire")

visreg(model.NDT4.Spread, "climate1", by="elevation")

visreg(model.NDT4.Spread, "wind_atfire", by="elevation")
visreg(model.NDT4.Spread, "wind_atfire", by="slope")

```
We should repeat the above several times and take the mean of the coefficients.

```{r}
summary(model.NDT4.Spread)

#Create a new blank table and get AUC too
top_mod_table_NDT4_lightning_t_ALL <- data.frame (matrix (ncol = 21, nrow = 0))
colnames (top_mod_table_NDT4_lightning_t_ALL ) <- c ("CAUSE", "NDT", "TREED", "Model_terms", "intercept", "coef_proj_age_1", "coef_live_stand_volume_125", "coef_dist_mun", "coef_elevation", "coef_climate_1", "coef_wind_atfire", "coef_slope", "coef_elevation:climate1", "coef_wind_atfire:slope", "coef_elevation:wind_atfire", "AIC", "Model.R2", "Valid.R2", "Valid.RSME", "Valid.MAE", "Adjusted.R2")

```

Let's run it 500 times to get good mean values.

```{r}

for (g in 1:500){

prop<-0.75
# Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(NDT4_spread_size_t$vegtype2, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- NDT4_spread_size_t[ trainIndex,]
   Valid <- NDT4_spread_size_t[-trainIndex,]
   
#Model   
model.NDT4.Spread<-lm(LNsize_ha ~ proj_age_1 + live_stand_volume_125 + dist_mun + elevation + climate1 + wind_atfire + climate1:elevation  + slope + slope:wind_atfire + elevation:wind_atfire, data = dat1) 

predictions <- model.NDT4.Spread %>% predict(Valid)

# create model table (only do this once) and add the relevant data
top_mod_table_NDT4_lightning_t <- data.frame (matrix (ncol = 21, nrow = 0))
colnames (top_mod_table_NDT4_lightning_t ) <- c ("CAUSE", "NDT", "TREED", "Model_terms", "intercept", "coef_proj_age_1", "coef_live_stand_volume_125", "coef_dist_mun", "coef_elevation", "coef_climate_1", "coef_wind_atfire", "coef_slope", "coef_elevation:climate1", "coef_wind_atfire:slope", "coef_elevation:wind_atfire", "AIC", "Model.R2", "Valid.R2", "Valid.RSME", "Valid.MAE", "Adjusted.R2")

##Add data for NDT4
top_mod_table_NDT4_lightning_t[1,1]<-"lightning"
top_mod_table_NDT4_lightning_t[1,2]<-"NDT4"
top_mod_table_NDT4_lightning_t[1,3]<-"Y"
top_mod_table_NDT4_lightning_t[1,4]<-"LNsize_ha ~ proj_age_1 + live_stand_volume_125 + dist_mun + elevation + climate1 + wind_atfire + climate1:elevation  + slope + slope:wind_atfire + elevation:wind_atfire" 
top_mod_table_NDT4_lightning_t[1,5]<- coef(model.NDT4.Spread)[1] #Intercept
top_mod_table_NDT4_lightning_t[1,6]<- coef(model.NDT4.Spread)[2] #C
top_mod_table_NDT4_lightning_t[1,7]<- coef(model.NDT4.Spread)[3] #C
top_mod_table_NDT4_lightning_t[1,8]<- coef(model.NDT4.Spread)[4] #co
top_mod_table_NDT4_lightning_t[1,9]<- coef(model.NDT4.Spread)[5] #co
top_mod_table_NDT4_lightning_t[1,10]<- coef(model.NDT4.Spread)[6] #c
top_mod_table_NDT4_lightning_t[1,11]<- coef(model.NDT4.Spread)[7] #l
top_mod_table_NDT4_lightning_t[1,12]<- coef(model.NDT4.Spread)[8] #co
top_mod_table_NDT4_lightning_t[1,13]<- coef(model.NDT4.Spread)[9] #c
top_mod_table_NDT4_lightning_t[1,14]<- coef(model.NDT4.Spread)[10] #coeff
top_mod_table_NDT4_lightning_t[1,15]<- coef(model.NDT4.Spread)[11] #co
top_mod_table_NDT4_lightning_t[1,16]<- AIC(model.NDT4.Spread)
top_mod_table_NDT4_lightning_t[1,17]<- summary(model.NDT4.Spread)$r.squared
top_mod_table_NDT4_lightning_t[1,18]<- R2(predictions, Valid$LNsize_ha, na.rm=TRUE)
top_mod_table_NDT4_lightning_t[1,19]<- RMSE(predictions, Valid$LNsize_ha, na.rm=TRUE)
top_mod_table_NDT4_lightning_t[1,20]<- MAE(predictions, Valid$LNsize_ha, na.rm=TRUE)
top_mod_table_NDT4_lightning_t[1,21]<- summary(model.NDT4.Spread)$adj.r.squared

top_mod_table_NDT4_lightning_t_ALL<-rbind(top_mod_table_NDT4_lightning_t_ALL, top_mod_table_NDT4_lightning_t)

}

```

Check.
```{r}
head(top_mod_table_NDT4_lightning_t_ALL)

```

#Save coefficient table

```{r}
write.csv(top_mod_table_NDT4_lightning_t_ALL, file="D:\\Fire\\fire_data\\raw_data\\top_mod_model.NDT4.Spread_firesize_lightning_t.csv")
```


#Get Mean Values

```{r}
names(top_mod_table_NDT4_lightning_t_ALL)

top_mod_table_NDT4_model.NDT4.Spreadlightning_t_means<-top_mod_table_NDT4_lightning_t_ALL %>% summarise_each(funs( mean( .,na.rm = TRUE)))
top_mod_table_NDT4_model.NDT4.Spreadlightning_t_means

top_mod_table_NDT4_model.NDT4.Spreadlightning_t_means[1,1]<-"lightning"
top_mod_table_NDT4_model.NDT4.Spreadlightning_t_means[1,2]<-"NDT4"
top_mod_table_NDT4_model.NDT4.Spreadlightning_t_means[1,3]<-"Treed"
top_mod_table_NDT4_model.NDT4.Spreadlightning_t_means[1,4]<- "LNsize_ha ~ proj_age_1 + live_stand_volume_125 + dist_mun + elevation + climate1 + wind_atfire + climate1:elevation  + slope + slope:wind_atfire + elevation:wind_atfire" 
top_mod_table_NDT4_model.NDT4.Spreadlightning_t_means
```
Save table.

```{r}
write.csv(top_mod_table_NDT4_model.NDT4.Spreadlightning_t_means, file="D:\\Fire\\fire_data\\raw_data\\top_mod_model.NDT4.Spread_firesize_lightning_t_Means.csv")
```

Standard deviation.

```{r}
top_mod_table_NDT4_model.NDT4.Spreadlightning_t_sd<-top_mod_table_NDT4_lightning_t_ALL %>% summarise_each(funs( sd( .,na.rm = TRUE)))
top_mod_table_NDT4_model.NDT4.Spreadlightning_t_sd

top_mod_table_NDT4_model.NDT4.Spreadlightning_t_sd[1,1]<-"lightning"
top_mod_table_NDT4_model.NDT4.Spreadlightning_t_sd[1,2]<-"NDT4"
top_mod_table_NDT4_model.NDT4.Spreadlightning_t_sd[1,3]<-"Treed"
top_mod_table_NDT4_model.NDT4.Spreadlightning_t_sd[1,4]<-"LNsize_ha ~ proj_age_1 + live_stand_volume_125 + dist_mun + elevation + climate1 + wind_atfire + climate1:elevation  + slope + slope:wind_atfire + elevation:wind_atfire" 
top_mod_table_NDT4_model.NDT4.Spreadlightning_t_sd
```

Save sd coefficient table.

```{r}
write.csv(top_mod_table_NDT4_model.NDT4.Spreadlightning_t_sd, file="D:\\Fire\\fire_data\\raw_data\\top_mod_model.NDT4.Spread_firesize_lightning_t_SD.csv")
```
