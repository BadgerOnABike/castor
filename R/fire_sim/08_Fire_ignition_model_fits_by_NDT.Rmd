---
title: "08_Fire ignition model fit by BEC zone"
author: "Elizabeth Kleynhans and Cora Skaien"
contributor: "Peter Ott"
date: "20/04/2021"
output: html_document
editor_options: 
  chunk_output_type: console
---

editor_options:
  chunk_output_type: console
  
<style> 
p.caption {
  font-size: 1.2em;
}
</style>


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library (kableExtra)
library (data.table)
library (DBI)
library (RPostgreSQL)
library (dplyr)
library (ggplot2)
library (here)
library(ggpubr)
library(arm)
library(tidyr)
library(AICcmodavg)
library(keyring)
library(caret)
library(pROC)
library(rje)

source(here::here("R/functions/R_Postgres.R"))
```

<!--
Copyright 2021 Province of British Columbia

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and limitations under the License.
-->

## Introduction

Here, we are running a glm for each separate bec zone to develop a predictive equation so that we can extrapolate fire ignitions into the future. The data that we include in these glms is both vegetation and climate date. The top climate variable for each BEC zone was determined in the script "06_ignition_climate_variable_selection.R". 

Firstly, in each BEC zone, we split the data into treed and non-treed then run a glm with climate and vegetation for areas that are classified as treed in the VRI and another separate analysis for areas that are classified as not treed. The fixed effects we include in these analyses are slightly different, i.e. no age, volume or height data in the non-treed areas, which is why we split the analyses up.  

# climate variable selection
In the script "06_ignition_climate_variable_selection.R", we performed an AIC and ROC analysis for each BEC zone including presence/available fire ignition points and a variety of climate variables. For this analysis, we split the data into a training and a validation data set where 75% of the data was used for training and 25% was used for validation. We then fit the model and extracted the AIC and AUC values. This was repeated 100 times and at the end we calculated the average AIC and AUC values. We then also used a different subset of non-fire locations from the initial pruned numbers and repeated the previous step 3-5 times to get consistent results per BEC zone. The climate variable that consistently resulted in the lowest average AIC value is used in this analysis. We will load tables for person and lightning caused is a summary of which climate variables fitted best for each BEC zone. 

Note: Some climate variables resulted in delta AIC values that were very similar and had much less than 2 points difference. Also, the variable with the smallest AIC value did not always have the best AUC value. Regardless of these two issues, we decided to take the climate variable with the smallest average AIC for simplicity. Results will be loaded in for each AIC table. These files were manipulated manually and then saved on to the drive before being uploaded (i.e., it is a simplified table from that generated in the last file, 06_ignition_climate_variable_selection; code for uploading not included prior).


```{r, AIC table, echo = F, message = F, eval = T}

climate_variables_lightning<-read.csv("D:/Fire/fire_data/raw_data/ClimateBC_Data/Final_Selected_Climate_Variables_Lightning_NDT.csv")
climate_variables_person<-read.csv("D://Fire//fire_data//raw_data//ClimateBC_Data//Final_Selected_Climate_Variables_Person_NDT.csv")

head(climate_variables_lightning) 
head(climate_variables_person) 

kable (climate_variables_lightning,
       caption = "<b>Table 1. Top candidate climate variables for lightning caused fires as selected through an AIC analysis for each BEC zone.<b>",
       digits = 2) %>%
  kable_styling (position = "left",
                 bootstrap_options = c("striped", "hover"),
                 fixed_thead = T,
                 full_width = F,
                 font_size = 11)

kable (climate_variables_person,
       caption = "<b>Table 2. Top candidate climate variables for person caused fires as selected through an AIC analysis for each BEC zone.<b>",
       digits = 2) %>%
  kable_styling (position = "left",
                 bootstrap_options = c("striped", "hover"),
                 fixed_thead = T,
                 full_width = F,
                 font_size = 11)

```

## Pull in the data for both lightning and person caused fires. Note, below seems to not be working and currently I am bringing it in from my local computer.

```{r}
connKyle <- dbConnect(drv = RPostgreSQL::PostgreSQL(), 
                      host = key_get('dbhost', keyring = 'postgreSQL'),
                      user = key_get('dbuser', keyring = 'postgreSQL'),
                      dbname = key_get('dbname', keyring = 'postgreSQL'),
                      password = key_get('dbpass', keyring = 'postgreSQL'),
                      port = "5432")
dat_lightning_ <- sf::st_read  (dsn = connKyle, # connKyle
                               query = "SELECT * FROM Data_Lightning")
dbDisconnect (connKyle)

head(dat_lightning_)

```


```{r}
connKyle <- dbConnect(drv = RPostgreSQL::PostgreSQL(), 
                      host = key_get('dbhost', keyring = 'postgreSQL'),
                      user = key_get('dbuser', keyring = 'postgreSQL'),
                      dbname = key_get('dbname', keyring = 'postgreSQL'),
                      password = key_get('dbpass', keyring = 'postgreSQL'),
                      port = "5432")
dat_person_ <- sf::st_read  (dsn = connKyle, # connKyle
                               query = "SELECT * FROM Data_Person")
dbDisconnect (connKyle)

head(dat_person_)

```


When doing the below analyses, it was noticed that disturbed areas often get eliminated when NAs are removed from the final data used for the model. Here, we investigate what variables are missing.

```{r}
dat_Disturbed<-subset(dat_lightning_, dat_lightning_$vegtype=="D")
head(dat_Disturbed)
dat_Disturbed$live_stand_volume_125
table(dat_Disturbed$live_stand_volume_125)
## We see that live_stand_volume does not exist for most disturbed sites (and when it does, it is 0, and one that is 3.103)

hist(dat_Disturbed$proj_age_1) #All under 15 years, as expected given the classification of disturbed if below 15 years

hist(dat_Disturbed$proj_height_1) #When not NA, Mostly all 0-5 m, a small number ~7 m.

##Change all NA for this vegtype to 0
dat_lightning_ <- within(dat_lightning_, live_stand_volume_125[is.na(live_stand_volume_125) & vegtype == 'D'] <- 0)
dat_person_ <- within(dat_person_, live_stand_volume_125[is.na(live_stand_volume_125) & vegtype == 'D'] <- 0)
##Because there will be no effect of stand volume on disturbed veg type, an interaction between these two variables should be included when both are in the model.

```


Now we will create additional columns that have the climate1 and climate2 variables indicated as the top variables for climate. 

```{r}
#View top variable
climate_variables_lightning
names(dat_lightning_)
unique(dat_lightning_$ntrl_ds)
dat_lightning_$ntrl_ds<-as.factor(dat_lightning_$ntrl_ds)
dat_lightning_$ntrl_ds_numeric<-as.numeric(dat_lightning_$ntrl_ds)
table(dat_lightning_$ntrl_ds_numeric)

dat_lightning_$ntrl_ds_codes<-paste(dat_lightning_$ntrl_ds, dat_lightning_$ntrl_ds_numeric)
unique(dat_lightning_$ntrl_ds_codes)

## Create empty vector
dat_lightning_$climate1<-0
head(dat_lightning_)

dat_lightning_<-dat_lightning_ %>%
    mutate(climate1 = case_when(ntrl_ds_numeric == 1 ~ tmax07, # NDT1
                                ntrl_ds_numeric == 2 ~ tave08, #NDT2
                                ntrl_ds_numeric == 3 ~ tave07, #NDT3
                                ntrl_ds_numeric == 4 ~ tmax07, # NDT4
                                ntrl_ds_numeric == 5 ~ tmax07, # NDT5
                                TRUE ~ NA_real_))

#Repeat for climate 2
dat_lightning_$climate2<-0
dat_lightning_$ppt07<-as.numeric(dat_lightning_$ppt07)
dat_lightning_$ppt08<-as.numeric(dat_lightning_$ppt08)

#Perform mutate to get the applicable variable for each row
dat_lightning_<-dat_lightning_ %>%
    mutate(climate2 = case_when(ntrl_ds_numeric == 1 ~ ppt07, # NDT1
                                ntrl_ds_numeric == 2 ~ ppt08, #NDT2
                                ntrl_ds_numeric == 3 ~ ppt07, #NDT3
                                ntrl_ds_numeric == 4 ~ ppt07, # NDT4
                                ntrl_ds_numeric == 5 ~ ppt07, # NDT5
                                TRUE ~ NA_real_))

head(dat_lightning_)

##Change vegtype to factor
dat_lightning_$vegtype<-as.factor(dat_lightning_$vegtype)

#create new column
dat_lightning_$fire_veg<-paste(dat_lightning_$fire_pres, dat_lightning_$vegtype)

```

Repeat for person-caused fires.

```{r}
#View top variable
climate_variables_person
names(dat_person_)
unique(dat_person_$ntrl_ds)
dat_person_$ntrl_ds<-as.factor(dat_person_$ntrl_ds)
dat_person_$ntrl_ds_numeric<-as.numeric(dat_person_$ntrl_ds)
table(dat_person_$ntrl_ds_numeric)

dat_person_$ntrl_ds_codes<-paste(dat_person_$ntrl_ds, dat_person_$ntrl_ds_numeric)
unique(dat_person_$ntrl_ds_codes)
#Compare codes to lightning
unique(dat_lightning_$ntrl_ds_codes) #they are the same

## Create empty vector
dat_person_$climate1<-0
head(dat_person_)

dat_person_<-dat_person_ %>%
    mutate(climate1 = case_when(ntrl_ds_numeric == 1 ~ tmax08, # NDT1
                                ntrl_ds_numeric == 2 ~ mean_tave08_tave09, #NDT2
                                ntrl_ds_numeric == 3 ~ mean_tmax05_tmax06_tmax07_tmax08_tmax09, #NDT3
                                ntrl_ds_numeric == 4 ~ tmax08, # NDT4
                                ntrl_ds_numeric == 5 ~ tave08, # NDT5
                                TRUE ~ NA_real_))

#Repeat for climate 2
dat_person_$climate2<-0

#Perform mutate to get the applicable variable for each row
dat_person_<-dat_person_ %>%
    mutate(climate2 = case_when(ntrl_ds_numeric == 1 ~ ppt08, # NDT1
                                #ntrl_ds_numeric == 2 ~ , #NDT2
                                #ntrl_ds_numeric == 3 ~ , #NDT3
                                ntrl_ds_numeric == 4 ~ ppt08, # NDT4
                                ntrl_ds_numeric == 5 ~ ppt08, # NDT5
                                TRUE ~ NA_real_))

head(dat_person_)

##Change vegtype to factor
dat_person_$vegtype<-as.factor(dat_person_$vegtype)

##Create new variable for fire presence by vegtype
dat_person_$fire_veg<-paste(dat_person_$fire_pres, dat_person_$vegtype)
str(dat_person_$fire_veg)
str(dat_person_$fire_pres)

```

Add some transformations to some of the variables.

```{r}
#Before transformations, must convert degrees to radians
dat_lightning_$aspect_radians<-(dat_lightning_$aspect*pi)/180
hist(dat_lightning_$aspect_radians)

dat_lightning_$aspect_cos<-cos(dat_lightning_$aspect_radians) #try cos because I hypothesize that southern aspects would be most likely to have higher likelihood of fire. 180 degrees is -1 with cos, and north is plus 1.
```

View plots

```{r}
p <- ggplot(dat_lightning_, aes(aspect, as.numeric(fire_pres))) +
  geom_smooth(method="glm", formula=y~x,
              method.args=list(family="binomial"),
              alpha=0.3, size=1) +
  geom_point(position=position_jitter(height=0.03, width=0)) +
  xlab("aspect") + ylab("Pr (ignition)")
p

p <- ggplot(dat_lightning_, aes(aspect_cos, as.numeric(fire_pres))) +
  geom_smooth(method="glm", formula=y~x,
              method.args=list(family="binomial"),
              alpha=0.3, size=1) +
  geom_point(position=position_jitter(height=0.03, width=0)) +
  xlab("aspect_cos") + ylab("Pr (ignition)")
p
##Seems to be minimal relationship with aspect overall

p <- ggplot(dat_lightning_, aes(slope, as.numeric(fire_pres))) +
  geom_smooth(method="glm", formula=y~x,
              method.args=list(family="binomial"),
              alpha=0.3, size=1) +
  geom_point(position=position_jitter(height=0.03, width=0)) +
  xlab("slope") + ylab("Pr (ignition)")
p
#positive association

ggplot(dat_lightning_, aes(x = slope)) +
  geom_histogram(fill = "white", colour = "black") +
  facet_grid(fire_pres ~ .)
##Seeing distribution of ignitions by slope makes me believe that slope is not a big factor for ignitions despite seemingly positive trend prior.


#
p <- ggplot(dat_lightning_, aes(aspect_cos*slope, as.numeric(fire_pres))) +
  geom_smooth(method="glm", formula=y~x,
              method.args=list(family="binomial"),
              alpha=0.3, size=1) +
  geom_point(position=position_jitter(height=0.03, width=0)) +
  xlab("aspect_cos*slope") + ylab("Pr (ignition)")
p


p <- ggplot(dat_lightning_, aes(elevation, as.numeric(fire_pres))) +
  geom_smooth(method="glm", formula=y~x,
              method.args=list(family="binomial"),
              alpha=0.3, size=1) +
  geom_point(position=position_jitter(height=0.03, width=0)) +
  xlab("elevation") + ylab("Pr (ignition)")
p
```


```{r}
##########Repeat for person-caused fires
dat_person_$aspect_radians<-(dat_person_$aspect*pi)/180
hist(dat_person_$aspect_radians)

dat_person_$aspect_cos<-cos(dat_person_$aspect_radians)
```
 
 View plots.

```{r}
p <- ggplot(dat_person_, aes(aspect, as.numeric(fire_pres))) +
  geom_smooth(method="glm", formula=y~x,
              method.args=list(family="binomial"),
              alpha=0.3, size=1) +
  geom_point(position=position_jitter(height=0.03, width=0)) +
  xlab("aspect") + ylab("Pr (ignition)")
p

p <- ggplot(dat_person_, aes(aspect_cos, as.numeric(fire_pres))) +
  geom_smooth(method="glm", formula=y~x,
              method.args=list(family="binomial"),
              alpha=0.3, size=1) +
  geom_point(position=position_jitter(height=0.03, width=0)) +
  xlab("aspect_cos") + ylab("Pr (ignition)")
p

##Seems to be minimal relationship with aspect overall

p <- ggplot(dat_person_, aes(slope, as.numeric(fire_pres))) +
  geom_smooth(method="glm", formula=y~x,
              method.args=list(family="binomial"),
              alpha=0.3, size=1) +
  geom_point(position=position_jitter(height=0.03, width=0)) +
  xlab("slope") + ylab("Pr (ignition)")
p
#strong negative correlation

ggplot(dat_person_, aes(x = slope)) +
  geom_histogram(fill = "white", colour = "black") +
  facet_grid(fire_pres ~ .)


p <- ggplot(dat_person_, aes(elevation, as.numeric(fire_pres))) +
  geom_smooth(method="glm", formula=y~x,
              method.args=list(family="binomial"),
              alpha=0.3, size=1) +
  geom_point(position=position_jitter(height=0.03, width=0)) +
  xlab("elevation") + ylab("Pr (ignition)")
p

p <- ggplot(dat_person_, aes(roads_km, as.numeric(fire_pres))) +
  geom_smooth(method="glm", formula=y~x,
              method.args=list(family="binomial"),
              alpha=0.3, size=1) +
  geom_point(position=position_jitter(height=0.03, width=0)) +
  xlab("Road Density") + ylab("Pr (ignition)")
p
```

Make cos(aspect in degrees) to be the default aspect.

```{r}
##cos makes more sense for aspect, so make this the default in analyses
dat_person_$aspect_degrees<-dat_person_$aspect
dat_person_$aspect<-dat_person_$aspect_cos

dat_lightning_$aspect_degrees<-dat_lightning_$aspect
dat_lightning_$aspect<-dat_lightning_$aspect_cos

```


#Save data here in case get disconnected from R

```{r}
write.csv(dat_lightning_, "D:\\Fire\\fire_data\\raw_data\\ClimateBC_Data\\Lightning_data_July.csv")

write.csv(dat_person_, "D:\\Fire\\fire_data\\raw_data\\ClimateBC_Data\\Person_data_July.csv")
```


## Examining correlation between stand level variables
```{r}
# Examining the relationship between some stand level variables. Volume and height are fairly correlated (0.67) but age and volume are not (0.28) and neither are age and height (0.44). Because volume and height are very close to 0.7 in correlation I will leave out this combination of variables from my treed models. 
table(dat_lightning_$bclcs_level_2) ##What is L? It is Land, exclude and do not use.
dat_lightning_$fire_pres<-as.numeric(dat_lightning_$fire)

dat_lightning_t<- dat_lightning_ %>% dplyr::filter(bclcs_level_2=="T")
dat_lightning_nt<- dat_lightning_ %>% dplyr::filter(bclcs_level_2=="N")
dat_lightning_l<- dat_lightning_ %>% dplyr::filter(bclcs_level_2=="L")

table(dat_lightning_$vegtype)
table(dat_lightning_t$vegtype) #either disturbed, open, treed broadleaf, treed conifer, or treed mixed broadleaf and conifer
table(dat_lightning_nt$vegtype) #either disturbed, open or shrub

ggscatter(dat_lightning_t, x = "live_stand_volume_125", y = "proj_age_1", 
          add = "reg.line", conf.int = TRUE, 
          cor.coef = TRUE, cor.method = "kendall",
          xlab = "live stand volume", ylab = "Stand age")

ggscatter(dat_lightning_t, x = "live_stand_volume_125", y = "proj_height_1", 
          add = "reg.line", conf.int = TRUE, 
          cor.coef = TRUE, cor.method = "kendall",
          xlab = "live stand volume", ylab = "Stand height")

ggscatter(dat_lightning_t, x = "proj_age_1", y = "proj_height_1", 
          add = "reg.line", conf.int = TRUE, 
          cor.coef = TRUE, cor.method = "kendall",
          xlab = "proj_age_1", ylab = "Stand height")


##Note that some no tree areas also have tree attributes. This is likely because the majority of the polygon has no trees, but part of the polygon might have trees which are given attributes.
hist(dat_lightning_nt$proj_height_1)
hist(dat_lightning_nt$proj_age_1)
hist(dat_lightning_nt$live_stand_volume_125) #Pretty much all NAs. Can likely assume 0.
dat_lightning_nt$proj_height_1 #Also many NAs. 
dat_lightning_nt$proj_age_1 # Also many NAs. 

hist(dat_lightning_l$proj_height_1)
hist(dat_lightning_l$proj_age_1)
hist(dat_lightning_l$live_stand_volume_125)
## This is ok. Still exclude from models, because majority of polygon will not be treed

head(dat_lightning_t)

```

#Repeat for person caused fires
## Examining correlation between stand level variables
```{r}
# Examining the relationship between some stand level variables. Volume and height are fairly correlated (0.67) but age and volume are not (0.28) and neither are age and height (0.44). Because volume and height are very close to 0.7 in correlation I will leave out this combination of variables from my treed models. 
table(dat_person_$bclcs_level_2) ##What is L? It is Land, exclude and do not use.
dat_person_$fire_pres<-as.numeric(dat_person_$fire)

dat_person_t<- dat_person_ %>% dplyr::filter(bclcs_level_2=="T")
dat_person_nt<- dat_person_ %>% dplyr::filter(bclcs_level_2=="N")
dat_person_l<- dat_person_ %>% dplyr::filter(bclcs_level_2=="L")

table(dat_person_$vegtype)
table(dat_person_t$vegtype) #either disturbed, open, treed broadleaf, treed conifer, or treed mixed broadleaf and conifer
table(dat_person_nt$vegtype) #either disturbed, open or shrub

ggscatter(dat_person_t, x = "live_stand_volume_125", y = "proj_age_1", 
          add = "reg.line", conf.int = TRUE, 
          cor.coef = TRUE, cor.method = "kendall",
          xlab = "live stand volume", ylab = "Stand age")

ggscatter(dat_person_t, x = "live_stand_volume_125", y = "proj_height_1", 
          add = "reg.line", conf.int = TRUE, 
          cor.coef = TRUE, cor.method = "kendall",
          xlab = "live stand volume", ylab = "Stand height")

ggscatter(dat_person_t, x = "proj_age_1", y = "proj_height_1", 
          add = "reg.line", conf.int = TRUE, 
          cor.coef = TRUE, cor.method = "kendall",
          xlab = "proj_age_1", ylab = "Stand height")

##Note that some no tree areas also have tree attributes. This is likely because the majority of the polygon has no trees, but part of the polygon might have trees which are given attributes.
hist(dat_person_nt$proj_height_1)
hist(dat_person_nt$proj_age_1)
hist(dat_person_nt$live_stand_volume_125) #Pretty much all NAs. Can likely assume 0.
dat_person_nt$proj_height_1 #Also many NAs. 
dat_person_nt$proj_age_1 # Also many NAs. 

hist(dat_person_l$proj_height_1)
hist(dat_person_l$proj_age_1)
hist(dat_person_l$live_stand_volume_125)
## This is ok. Still exclude from models, because majority of polygon will not be treed

```

Save the prepped data

```{r}

write.csv(dat_lightning_t, file="D:\\Fire\\fire_data\\raw_data\\ClimateBC_Data\\data_lightning_trees_NDT.csv")

write.csv(dat_lightning_nt, file="D:\\Fire\\fire_data\\raw_data\\ClimateBC_Data\\data_lightning_notrees_NDT.csv")

write.csv(dat_person_t, file="D:\\Fire\\fire_data\\raw_data\\ClimateBC_Data\\data_person_trees_NDT.csv")

write.csv(dat_person_nt, file="D:\\Fire\\fire_data\\raw_data\\ClimateBC_Data\\data_person_notrees_NDT.csv")

```


#################### ANALYSES #########################

Now, we will make a loop that does something very similar to our last loop, but with the selected climate variable plus other variables of interest. For lightning caused fires with trees, the variables of interest include:

1. Climate variable(s)
2. Projected Height (proj_height_1)
3. projected age (proj_age_1)  
4. live_stand_volume_125
5. vegtype
6. slope
7. aspect (cos)
8. elevation
9. heatload

Interactions of interest: two-way interactions between climate (1) and vegtype (5); two-way interactions between topography measures (6-8).

This will be done separately for trees and non-treed areas. 

First, let's do this for treed areas (with the lightning-caused fires dataset).

##We will do each loop separately for each NDT zone given the large number of possible models for each zone.

First we will create the variable lists that contain all of our variables of interest.

```{r}
##Create variable lists to be used in the model loop.
variables_all<-c(climate1 = "climate1", climate2 = "climate2", proj_height_1 = "proj_height_1", proj_age_1 = "proj_age_1", live_stand_volume_125 = "live_stand_volume_125", slope = "slope", aspect = "aspect", elevation ="elevation", vegtype = "vegtype", heatload="heatload") 

variables_all_c1<-c(climate1 = "climate1", proj_height_1 = "proj_height_1", proj_age_1 = "proj_age_1", live_stand_volume_125 = "live_stand_volume_125", slope = "slope", aspect = "aspect", elevation ="elevation", vegtype = "vegtype", heatload="heatload") 

vars.clim<-c("climate1")
vars.clim.vegtype<-c("climate1", "vegtype")
vars.oth<-c("proj_height_1", "proj_age_1", "live_stand_volume_125") 
vars.topo<-c("slope", "aspect", "elevation")
vars.heatload<-c("heatload")

#Also for later with 2 climate variables
vars.clim.vegtype2<-c("climate1", "climate2","vegtype")
vars.clim.vegtype2b<-c("climate1", "climate2")

##Create interaction for climate and vegtype
inputs.me <- c(vars.clim.vegtype)
inputs.me2 <- c(vars.clim.vegtype2)
inputs.me2b <- c(vars.clim.vegtype2b)
```

Now, we will generate two-way interactions for each of these lists. 

```{r}

#####1a. For those with one climate variable
#get the names of all possible two-way interactions for climate variable(s) and vegtype.
twoway.ints <- NULL
for (i in 1:(length(inputs.me)-1)) {
  for (j in (i+1):length(inputs.me)) {
     twoway.ints <- cbind(twoway.ints, paste(inputs.me[i], inputs.me[j], sep=":"))
  }
}
twoway.ints
length(twoway.ints)

#
#Create function to determine Powerset for any vector of variable names
## or use rje package
#powerSet <- function(x) {
#   z.list <- NULL
#   for(i in 1:length(x)) {
#      z.list <- append(z.list, combn(x, m=i, simplify=F))
#   }    
#   return(z.list)
#}


#Get variables on own
#complete list of models using non-climate vars
mods.me.tmp <- powerSet(vars.clim.vegtype) 
#add climate vars to all of the above
mods.me.climate <- list()
for (i in 1: length(mods.me.tmp)) {
   mods.me.climate[[i]] <- c(mods.me.tmp[[i]])
}

mods.me.climate


#####1b. For those with two climate variables
#get the names of all possible two-way interactions for climate variable(s) and vegtype.
twoway.ints2 <- NULL
for (i in 1:(length(inputs.me2)-1)) {
  for (j in (i+1):length(inputs.me2)) {
     twoway.ints2 <- cbind(twoway.ints2, paste(inputs.me2[i], inputs.me2[j], sep=":"))
  }
}
twoway.ints2
length(twoway.ints2)

#Get variables on own
#complete list of models using non-climate vars
mods.me.tmp <- powerSet(vars.clim.vegtype2) 
#add climate vars to all of the above
mods.me.climate2 <- list()
for (i in 1: length(mods.me.tmp)) {
   mods.me.climate2[[i]] <- c(mods.me.tmp[[i]])
}

mods.me.climate2

#complete list of two-way interactions
mods.twoway2 <- powerSet(twoway.ints2)
length(mods.twoway2) #7
mods.twoway2

#Finding models in mods.me that accommodate/allow interaction terms in each mods.twoway to be added
mods.inter2 <- list()
counter <- 0
for (i in 1: length(mods.twoway2)) {
   s1 <- unique(unlist( strsplit(mods.twoway2[[i]], split=':', fixed=TRUE) ) )
   for (j in 1: length(mods.me.climate2)) {
      if (all(s1 %in% mods.me.climate2[[j]])==TRUE) {
        counter <- counter + 1
        both <-  c(mods.me.climate2[[j]], mods.twoway2[[i]])
        mods.inter2[[counter]] <- both
      }
   }
}

length(mods.inter2)
mods.inter2


####1c. Two variables, no variation in vegtype
#get the names of all possible two-way interactions for climate variable(s) and vegtype.
twoway.ints2b <- NULL
for (i in 1:(length(inputs.me2b)-1)) {
  for (j in (i+1):length(inputs.me2b)) {
     twoway.ints2b <- cbind(twoway.ints2b, paste(inputs.me2b[i], inputs.me2b[j], sep=":"))
  }
}
twoway.ints2b
length(twoway.ints2b)

#Get variables on own
#complete list of models using non-climate vars
mods.me.tmp <- powerSet(vars.clim.vegtype2b) 
#add climate vars to all of the above
mods.me.climate2b <- list()
for (i in 1: length(mods.me.tmp)) {
   mods.me.climate2b[[i]] <- c(mods.me.tmp[[i]])
}

mods.me.climate2b

#complete list of two-way interactions
mods.twoway2b <- powerSet(twoway.ints2b)
length(mods.twoway2b) #7
mods.twoway2b

#Finding models in mods.me that accommodate/allow interaction terms in each mods.twoway to be added
mods.inter2b <- list()
counter <- 0
for (i in 1: length(mods.twoway2b)) {
   s1 <- unique(unlist( strsplit(mods.twoway2b[[i]], split=':', fixed=TRUE) ) )
   for (j in 1: length(mods.me.climate2b)) {
      if (all(s1 %in% mods.me.climate2b[[j]])==TRUE) {
        counter <- counter + 1
        both <-  c(mods.me.climate2b[[j]], mods.twoway2b[[i]])
        mods.inter2b[[counter]] <- both
      }
   }
}

length(mods.inter2b)
mods.inter2b




#########2. Now for topography data, get all possible two-way interactions

#get the names of all possible two-way interactions
twoway.intsT <- NULL
for (i in 1:(length(vars.topo)-1)) {
  for (j in (i+1):length(vars.topo)) {
     twoway.intsT <- cbind(twoway.intsT, paste(vars.topo[i], vars.topo[j], sep=":"))
  }
}
twoway.intsT
length(twoway.intsT)

#complete list of models using non-climate vars (topo)
mods.me.tmp <- powerSet(vars.topo) 
#add climate vars to all of the above
mods.meT <- list()
for (i in 1: length(mods.me.tmp)) {
   mods.meT[[i]] <- c(mods.me.tmp[[i]])
}

mods.meT

#complete list of two-way interactions
mods.twowayT <- powerSet(twoway.intsT)
length(mods.twowayT) #7
mods.twowayT

#Finding models in mods.me that accommodate/allow interaction terms in each mods.twoway to be added

mods.interT <- list()
counter <- 0
for (i in 1: length(mods.twowayT)) {
   s1 <- unique(unlist( strsplit(mods.twowayT[[i]], split=':', fixed=TRUE) ) )
   for (j in 1: length(mods.meT)) {
      if (all(s1 %in% mods.meT[[j]])==TRUE) {
        counter <- counter + 1
        both <-  c(mods.meT[[j]], mods.twowayT[[i]])
        mods.interT[[counter]] <- both
      }
   }
}

length(mods.interT)
mods.interT
mods.interTb<-c(mods.interT,vars.heatload)
mods.interTb

####3.For other VRI data, get without interactions

#complete list of models using VRI - no interactions
mods.me.tmp <- powerSet(vars.oth) 
#add climate vars to all of the above
mods.me.oth <- list()
for (i in 1: length(mods.me.tmp)) {
   mods.me.oth[[i]] <- c(mods.me.tmp[[i]])
}

mods.me.oth

#the list of all possible model RHSs. 
#all.poss.mods <- c(1, vars.clim, twoway.ints, mods.me.oth, mods.me2, mods.inter2)
#all.poss.mods

all.poss.mods.clim.vegtype<-c(1, mods.me.climate, twoway.ints)
all.poss.mods.clim.vegtype 
#all.poss.mods.clim.vegtype<-all.poss.mods.clim.vegtype [-2] #Use this line only if there is an odd character(0) added to list
all.poss.mods.clim.vegtype2<-c(1, mods.me.climate2, mods.inter2)
all.poss.mods.clim.vegtype2
#all.poss.mods.clim.vegtype2<-all.poss.mods.clim.vegtype2[-2]
#all.poss.mods.clim.vegtype2<-all.poss.mods.clim.vegtype2[-9]
all.poss.mods.clim.vegtype2b<-c(1, mods.me.climate2b, mods.inter2b)
all.poss.mods.clim.vegtype2b

all.poss.mods.VRI<-c(1, mods.me.oth)
all.poss.mods.VRI
#all.poss.mods.VRI<-all.poss.mods.VRI[-2]
all.poss.mods.topo<-c(1, mods.meT, mods.interTb)
all.poss.mods.topo
#all.poss.mods.topo<-all.poss.mods.topo[-10]
#all.poss.mods.topo<-all.poss.mods.topo[-2]

```

Let's work with one NDT at a time. 

Because of the large number of models with all variables included, we will test the climate and vegtype first, then the VRI variables, then the topography variables. Then we will test the top models together, with determining best AIC model from there. Or perhaps we will just combine the top models for each together, and eliminate models if the intercept was the best predictor.


############### Part 1 of 4 Model Series: Lightning Caused Fires, Trees ##########

Select first NDT: NDT4 

```{r}
zones1<-c("NDT4") #Do one zone at a time

filenames<-list()
prop<-0.75

########### 1. Climate and vegtype ############
for (g in 1:100){

for (h in 1:length(zones1)) {
  dat2<- dat_lightning_t %>% dplyr::filter(ntrl_ds ==zones1[h])

for (i in 1: length(all.poss.mods.clim.vegtype2)){
  print(paste((all.poss.mods.clim.vegtype2[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, variables_all[i])
  model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, !!variables_all)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="fire_pres") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.aic, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.clim.vegtype2, big.mod, df.train=dat1, df.test=Valid)

}
}
}


```

Now extract elements from the output .

```{r}
#terms in each model
x1 <- unlist(sapply(mods.fit, '[', 1))
x1
#Aic for models
x3 <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3
#auc from validation data
x4 <- unlist(sapply(mods.fit, '[', 4))
x4
#combining all as df
tab.sum.climate <- cbind.data.frame(model=x1, edf=x3[,1], aic=x3[,2], auc.valid=x4)
tab.sum.climate$NDT<-c("NDT4")
tab.sum.climate$delta.aic<- tab.sum.climate$aic - (min(tab.sum.climate$aic))
tab.sum.climate 

```


#Now repeat for VRI data


```{r}

########### 2. VRI ############
for (g in 1:100){

for (h in 1:length(zones1)) {
  dat2<- dat_lightning_t %>% dplyr::filter(ntrl_ds ==zones1[h])

for (i in 1: length(all.poss.mods.VRI)){
  print(paste((all.poss.mods.VRI[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, variables_all[i])
  model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, !!variables_all)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="fire_pres") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.aic, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.VRI, big.mod, df.train=dat1, df.test=Valid)

}
}
}


```

Now extract elements from the output .

```{r}
#terms in each model
x1b <- unlist(sapply(mods.fit, '[', 1))
x1b
#Aic for models
x3b <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3b
#auc from validation data
x4b <- unlist(sapply(mods.fit, '[', 4))
x4b
#combining all as df
tab.sum.VRI <- cbind.data.frame(model=x1b, edf=x3b[,1], aic=x3b[,2], auc.valid=x4b)
tab.sum.VRI$NDT<-c("NDT4")
tab.sum.VRI$delta.aic<- tab.sum.VRI$aic - (min(tab.sum.VRI$aic))
tab.sum.VRI 

```


#Now repeat for topography

```{r}

########### 3. Topography ############
for (g in 1:100){

for (h in 1:length(zones1)) {
 dat2<- dat_lightning_t %>% dplyr::filter(ntrl_ds ==zones1[h])

for (i in 1: length(all.poss.mods.topo)){
  print(paste((all.poss.mods.topo[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, variables_all[i])
  model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, !!variables_all)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="fire_pres") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.aic, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.topo, big.mod, df.train=dat1, df.test=Valid)

}
}
}


```

Now extract elements from the output .

```{r}
#terms in each model
x1c <- unlist(sapply(mods.fit, '[', 1))
x1c
#Aic for models
x3c <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3c
#auc from validation data
x4c <- unlist(sapply(mods.fit, '[', 4))
x4c
#combining all as df
tab.sum.topo <- cbind.data.frame(model=x1c, edf=x3c[,1], aic=x3c[,2], auc.valid=x4c)
tab.sum.topo$NDT<-c("NDT4")
tab.sum.topo$delta.aic<- tab.sum.topo$aic - (min(tab.sum.topo$aic))
tab.sum.topo
```

#Below code is for ammendement now that heatload has been added as a variable

```{r}
write.csv(tab.sum.topo, file="D:\\Fire\\fire_data\\raw_data\\NDT4_tab.sum.topo.csv")

```

#Now combine the datatables and save to computer

```{r}
NDT4_l_models<-rbind(tab.sum.climate, tab.sum.VRI, tab.sum.topo)
NDT4_l_models

write.csv(NDT4_l_models, file="D:\\Fire\\fire_data\\raw_data\\NDT4_lightning_models.csv")
```

Now choose the top variables and create final model. The below code will need to be updated manually, depending on what the results of the above analyses are.

######## UPDATE BELOW #########

```{r}
##### TOP MODEL####
NDT4_t<-dat_lightning_t %>%
  filter(ntrl_ds=="NDT4")

NDT4_t2<-NDT4_t %>% drop_na(live_stand_volume_125, vegtype, climate1, climate2, proj_height_1)

glm_best_NDT4<- glm(fire_pres ~ scale(climate1)*scale(climate2) +
             scale(live_stand_volume_125) +
               scale(proj_height_1) +
               vegtype, 
           data= NDT4_t2,
           family = binomial,
           na.action=na.omit)

summary(glm_best_NDT4)

# model diagnostic plots
binnedplot (fitted(glm_best_NDT4), 
            residuals(glm_best_NDT4), 
            nclass = NULL, 
            xlab = "Expected Values", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))


NDT4_t2$resids<-resid(glm_best_NDT4)

binnedplot (NDT4_t2$live_stand_volume_125, 
            NDT4_t2$resids, 
            nclass = NULL, 
            xlab = "live stand volume", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))

binnedplot (NDT4_t2$climate1, 
            NDT4_t2$resids, 
            nclass = NULL, 
            xlab = "", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))

# Diagnostic plots look good

# Looking at effect of forest height at the average amount of rainfall in September
plot(NDT4_t2$live_stand_volume_125,NDT4_t2$fire_pres)
curve(invlogit(coef(glm_best_NDT4)[1] +coef(glm_best_NDT4)[2]*mean(NDT4_t2$climate1) + coef(glm_best_NDT4)[3]*x), add=TRUE)

# looking at effect of climate1 at the average forest height.
plot(NDT4_t2$climate1,NDT4_t2$fire_pres)
curve(invlogit(coef(glm_best_NDT4)[1] +coef(glm_best_NDT4)[2]*x + coef(glm_best_NDT4)[3]*mean(NDT4_t2$live_stand_volume_125)), add=TRUE)


# create model table (only do this once) and add the relevant data
top_mod_table <- data.frame (matrix (ncol = 16, nrow = 0))
colnames (top_mod_table) <- c ("ZONE", "TREED", "Model_terms", "intercept", "coef_climate_1", "coef_climate_2", "coef_climate_interaction", "coef_stand_height", "coef_live_stand_volume_125", "coef_proj_age", "coef_vegtypeD", "coef_vegtypeOP", "coef_vegtypeS", "coef_vegtypeTB", "coef_vegtypeTC", "coef_vegtypeTM")



##STILL NEED TO ADD DATA FOR TABLE

##Add data for NDT4
top_mod_table[1,1]<-"NDT4"
top_mod_table[1,2]<-"Y"
top_mod_table[1,3]<-"fire_pres ~ ppt09 + proj_height_1" ######### UPDATE
top_mod_table[1,4]<- coef(glm_best_NDT4)[1] #Intercept
top_mod_table[1,5]<- coef(glm_best_NDT4)[2] #Climate variable 1
#top_mod_table[1,6]<- coef(glm_best_NDT4)[2] #Climate variable 2
#top_mod_table[1,7]<- coef(glm_best_NDT4)[3] #Interaction climate variables
#top_mod_table[1,8]<- coef(glm_best_NDT4)[3] #coef_stand_height
#top_mod_table[1,9]<- coef(glm_best_NDT4)[3] #live_stand_volume_125
#top_mod_table[1,10]<- coef(glm_best_NDT4)[4] #proj_age_1
#top_mod_table[1,11]<- coef(glm_best_NDT4)[4] #coefficient vegtypeD
#top_mod_table[1,12]<- coef(glm_best_NDT4)[4] #coefficient vegtypeOP
#top_mod_table[1,13]<- coef(glm_best_NDT4)[4] #coefficient vegtypeS
#top_mod_table[1,14]<- coef(glm_best_NDT4)[4] #coefficient vegtypeTB
#top_mod_table[1,15]<- coef(glm_best_NDT4)[4] #coefficient vegtypeTC
#top_mod_table[1,16]<- coef(glm_best_NDT4)[5] #coefficient vegtypeTM
top_mod_table ##Determine if better way to represent categories for vegtype, and if each climate variable should have its own column

########################## NDT4 Model Selection Complete ###################

```
 


############### Now choose the next NDT zone and repeat ########
Note: currently doing  those with one climate variable)
Models complete above: NDT4
Models to still do henceforth:NDT1, NDT2, NDT3, NDT5


Select next zone: NDT1


```{r}
zones1<-c("NDT1") #Do one zone at a time

filenames<-list()
prop<-0.75

########### 1. Climate and vegtype ############
for (g in 1:100){

for (h in 1:length(zones1)) {
  dat2<- dat_lightning_t %>% dplyr::filter(ntrl_ds ==zones1[h])

for (i in 1: length(all.poss.mods.clim.vegtype2)){
  print(paste((all.poss.mods.clim.vegtype2[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, variables_all[i])
  model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, !!variables_all)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="fire_pres") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.aic, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.clim.vegtype2, big.mod, df.train=dat1, df.test=Valid)

}
}
}


```

Now extract elements from the output .

```{r}
#terms in each model
x1.1 <- unlist(sapply(mods.fit, '[', 1))
x1.1
#Aic for models
x3.1 <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3.1
#auc from validation data
x4.1 <- unlist(sapply(mods.fit, '[', 4))
x4.1
#combining all as df
tab.sum.climate <- cbind.data.frame(model=x1.1, edf=x3.1[,1], aic=x3.1[,2], auc.valid=x4.1)
tab.sum.climate$NDT<-c("NDT1")
tab.sum.climate$delta.aic<- tab.sum.climate$aic - (min(tab.sum.climate$aic))
tab.sum.climate 

```


#Now repeat for VRI data


```{r}

########### 2. VRI ############
for (g in 1:100){

for (h in 1:length(zones1)) {
  dat2<- dat_lightning_t %>% dplyr::filter(ntrl_ds ==zones1[h])

for (i in 1: length(all.poss.mods.VRI)){
  print(paste((all.poss.mods.VRI[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, variables_all[i])
  model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, !!variables_all)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="fire_pres") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.aic, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.VRI, big.mod, df.train=dat1, df.test=Valid)

}
}
}


```

Now extract elements from the output .

```{r}
#terms in each model
x1.1b <- unlist(sapply(mods.fit, '[', 1))
x1.1b
#Aic for models
x3.1b <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3.1b
#auc from validation data
x4.1b <- unlist(sapply(mods.fit, '[', 4))
x4.1b
#combining all as df
tab.sum.VRI <- cbind.data.frame(model=x1.1b, edf=x3.1b[,1], aic=x3.1b[,2], auc.valid=x4.1b)
tab.sum.VRI$NDT<-c("NDT1")
tab.sum.VRI$delta.aic<- tab.sum.VRI$aic - (min(tab.sum.VRI$aic))
tab.sum.VRI 

```


#Now repeat for topography

```{r}

########### 3. Topography ############
for (g in 1:100){

for (h in 1:length(zones1)) {
 dat2<- dat_lightning_t %>% dplyr::filter(ntrl_ds ==zones1[h])

for (i in 1: length(all.poss.mods.topo)){
  print(paste((all.poss.mods.topo[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, variables_all[i])
  model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, !!variables_all)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="fire_pres") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.aic, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.topo, big.mod, df.train=dat1, df.test=Valid)

}
}
}


```

Now extract elements from the output.

```{r}
#terms in each model
x1.1c <- unlist(sapply(mods.fit, '[', 1))
x1.1c
#Aic for models
x3.1c <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3.1c
#auc from validation data
x4.1c <- unlist(sapply(mods.fit, '[', 4))
x4.1c
#combining all as df
tab.sum.topo <- cbind.data.frame(model=x1.1c, edf=x3.1c[,1], aic=x3.1c[,2], auc.valid=x4.1c)
tab.sum.topo$NDT<-c("NDT1")
tab.sum.topo$delta.aic<- tab.sum.topo$aic - (min(tab.sum.topo$aic))
tab.sum.topo

```


#Below code is for ammendement now that heatload has been added as a variable

```{r}
write.csv(tab.sum.topo, file="D:\\Fire\\fire_data\\raw_data\\NDT1_tab.sum.topo.csv")

```


#Now combine the datatables and save to computer

```{r}
NDT1_l_models<-rbind(tab.sum.climate, tab.sum.VRI, tab.sum.topo)
NDT1_l_models

write.csv(NDT1_l_models, file="D:\\Fire\\fire_data\\raw_data\\NDT1_lightning_models.csv")
```

Now choose the top variables and create final model. The below code will need to be updated manually, depending on what the results of the above analyses are.

######## UPDATE BELOW #########

```{r}
##### TOP MODEL####
NDT1_t<-dat_lightning_t %>%
  filter(ntrl_ds=="NDT1")

NDT1_t2<-NDT1_t %>% drop_na(live_stand_volume_125, vegtype, climate1, climate2, proj_height_1)

glm_best_NDT1<- glm(fire_pres ~ scale(climate1)*scale(climate2) +
             scale(live_stand_volume_125) +
               scale(proj_height_1) +
               vegtype, 
           data= NDT1_t2,
           family = binomial,
           na.action=na.omit)

summary(glm_best_NDT1)

# model diagnostic plots
binnedplot (fitted(glm_best_NDT1), 
            residuals(glm_best_NDT1), 
            nclass = NULL, 
            xlab = "Expected Values", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))


NDT1_t2$resids<-resid(glm_best_NDT1)

binnedplot (NDT1_t2$live_stand_volume_125, 
            NDT1_t2$resids, 
            nclass = NULL, 
            xlab = "live stand volume", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))

binnedplot (NDT1_t2$climate1, 
            NDT1_t2$resids, 
            nclass = NULL, 
            xlab = "", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))

# Diagnostic plots look good

# Looking at effect of forest height at the average amount of rainfall in September
plot(NDT1_t2$live_stand_volume_125,NDT1_t2$fire_pres)
curve(invlogit(coef(glm_best_NDT1)[1] +coef(glm_best_NDT1)[2]*mean(NDT1_t2$climate1) + coef(glm_best_NDT1)[3]*x), add=TRUE)

# looking at effect of climate1 at the average forest height.
plot(NDT1_t2$climate1,NDT1_t2$fire_pres)
curve(invlogit(coef(glm_best_NDT1)[1] +coef(glm_best_NDT1)[2]*x + coef(glm_best_NDT1)[3]*mean(NDT1_t2$live_stand_volume_125)), add=TRUE)


# create model table (only do this once) and add the relevant data
top_mod_table <- data.frame (matrix (ncol = 16, nrow = 0))
colnames (top_mod_table) <- c ("ZONE", "TREED", "Model_terms", "intercept", "coef_climate_1", "coef_climate_2", "coef_climate_interaction", "coef_stand_height", "coef_live_stand_volume_125", "coef_proj_age", "coef_vegtypeD", "coef_vegtypeOP", "coef_vegtypeS", "coef_vegtypeTB", "coef_vegtypeTC", "coef_vegtypeTM")



##STILL NEED TO ADD DATA FOR TABLE

##Add data for NDT1
top_mod_table[1,1]<-"NDT1"
top_mod_table[1,2]<-"Y"
top_mod_table[1,3]<-"fire_pres ~ ppt09 + proj_height_1" ######### UPDATE
top_mod_table[1,4]<- coef(glm_best_NDT1)[1] #Intercept
top_mod_table[1,5]<- coef(glm_best_NDT1)[2] #Climate variable 1
#top_mod_table[1,6]<- coef(glm_best_NDT1)[2] #Climate variable 2
#top_mod_table[1,7]<- coef(glm_best_NDT1)[3] #Interaction climate variables
#top_mod_table[1,8]<- coef(glm_best_NDT1)[3] #coef_stand_height
#top_mod_table[1,9]<- coef(glm_best_NDT1)[3] #live_stand_volume_125
#top_mod_table[1,10]<- coef(glm_best_NDT1)[4] #proj_age_1
#top_mod_table[1,11]<- coef(glm_best_NDT1)[4] #coefficient vegtypeD
#top_mod_table[1,12]<- coef(glm_best_NDT1)[4] #coefficient vegtypeOP
#top_mod_table[1,13]<- coef(glm_best_NDT1)[4] #coefficient vegtypeS
#top_mod_table[1,14]<- coef(glm_best_NDT1)[4] #coefficient vegtypeTB
#top_mod_table[1,15]<- coef(glm_best_NDT1)[4] #coefficient vegtypeTC
#top_mod_table[1,16]<- coef(glm_best_NDT1)[5] #coefficient vegtypeTM
top_mod_table ##Determine if better way to represent categories for vegtype, and if each climate variable should have its own column

########################## NDT1 Model Selection Complete ###################



```



############### Now choose the next NDT zone and repeat ########
Note: currently doing  those with one climate variable)
Models complete above: NDT4, NDT1
Models to still do henceforth:NDT2, NDT3, NDT5


Select next zone: NDT2


```{r}
zones1<-c("NDT2") #Do one zone at a time

filenames<-list()
prop<-0.75

########### 1. Climate and vegtype ############
for (g in 1:100){

for (h in 1:length(zones1)) {
  dat2<- dat_lightning_t %>% dplyr::filter(ntrl_ds ==zones1[h])

for (i in 1: length(all.poss.mods.clim.vegtype2)){
  print(paste((all.poss.mods.clim.vegtype2[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, variables_all[i])
  model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, !!variables_all)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="fire_pres") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.aic, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.clim.vegtype2, big.mod, df.train=dat1, df.test=Valid)

}
}
}


```

Now extract elements from the output .

```{r}
#terms in each model
x1.2 <- unlist(sapply(mods.fit, '[', 1))
x1.2
#Aic for models
x3.2 <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3.2
#auc from validation data
x4.2 <- unlist(sapply(mods.fit, '[', 4))
x4.2
#combining all as df
tab.sum.climate <- cbind.data.frame(model=x1.2, edf=x3.2[,1], aic=x3.2[,2], auc.valid=x4.2)
tab.sum.climate$NDT<-c("NDT2")
tab.sum.climate$delta.aic<- tab.sum.climate$aic - (min(tab.sum.climate$aic))
tab.sum.climate 

```


#Now repeat for VRI data


```{r}

########### 2. VRI ############
for (g in 1:100){

for (h in 1:length(zones1)) {
  dat2<- dat_lightning_t %>% dplyr::filter(ntrl_ds ==zones1[h])

for (i in 1: length(all.poss.mods.VRI)){
  print(paste((all.poss.mods.VRI[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, variables_all[i])
  model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, !!variables_all)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="fire_pres") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.aic, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.VRI, big.mod, df.train=dat1, df.test=Valid)

}
}
}


```

Now extract elements from the output .

```{r}
#terms in each model
x1.2b <- unlist(sapply(mods.fit, '[', 1))
x1.2b
#Aic for models
x3.2b <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3.2b
#auc from validation data
x4.2b <- unlist(sapply(mods.fit, '[', 4))
x4.2b
#combining all as df
tab.sum.VRI <- cbind.data.frame(model=x1.2b, edf=x3.2b[,1], aic=x3.2b[,2], auc.valid=x4.2b)
tab.sum.VRI$NDT<-c("NDT2")
tab.sum.VRI$delta.aic<- tab.sum.VRI$aic - (min(tab.sum.VRI$aic))
tab.sum.VRI 

```


#Now repeat for topography

```{r}

########### 3. Topography ############
for (g in 1:100){

for (h in 1:length(zones1)) {
 dat2<- dat_lightning_t %>% dplyr::filter(ntrl_ds ==zones1[h])

for (i in 1: length(all.poss.mods.topo)){
  print(paste((all.poss.mods.topo[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, variables_all[i])
  model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, !!variables_all)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="fire_pres") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.aic, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.topo, big.mod, df.train=dat1, df.test=Valid)

}
}
}


```

Now extract elements from the output .

```{r}
#terms in each model
x1.2c <- unlist(sapply(mods.fit, '[', 1))
x1.2c
#Aic for models
x3.2c <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3.2c
#auc from validation data
x4.2c <- unlist(sapply(mods.fit, '[', 4))
x4.2c
#combining all as df
tab.sum.topo <- cbind.data.frame(model=x1.2c, edf=x3.2c[,1], aic=x3.2c[,2], auc.valid=x4.2c)
tab.sum.topo$NDT<-c("NDT2")
tab.sum.topo$delta.aic<- tab.sum.topo$aic - (min(tab.sum.topo$aic))
tab.sum.topo

```


#Below code is for ammendement now that heatload has been added as a variable

```{r}
write.csv(tab.sum.topo, file="D:\\Fire\\fire_data\\raw_data\\NDT2_tab.sum.topo.csv")

```


#Now combine the datatables and save to computer

```{r}
NDT2_l_models<-rbind(tab.sum.climate, tab.sum.VRI, tab.sum.topo)
NDT2_l_models

write.csv(NDT2_l_models, file="D:\\Fire\\fire_data\\raw_data\\NDT2_lightning_models.csv")
```

Now choose the top variables and create final model. The below code will need to be updated manually, depending on what the results of the above analyses are.

######## UPDATE BELOW #########

```{r}
##### TOP MODEL####
NDT2_t<-dat_lightning_t %>%
  filter(ntrl_ds=="NDT2")

NDT2_t2<-NDT2_t %>% drop_na(live_stand_volume_125, vegtype, climate1, climate2, proj_height_1)

glm_best_NDT2<- glm(fire_pres ~ scale(climate1)*scale(climate2) +
             scale(live_stand_volume_125) +
               scale(proj_height_1) +
               vegtype, 
           data= NDT2_t2,
           family = binomial,
           na.action=na.omit)

summary(glm_best_NDT2)

# model diagnostic plots
binnedplot (fitted(glm_best_NDT2), 
            residuals(glm_best_NDT2), 
            nclass = NULL, 
            xlab = "Expected Values", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))


NDT2_t2$resids<-resid(glm_best_NDT2)

binnedplot (NDT2_t2$live_stand_volume_125, 
            NDT2_t2$resids, 
            nclass = NULL, 
            xlab = "live stand volume", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))

binnedplot (NDT2_t2$climate1, 
            NDT2_t2$resids, 
            nclass = NULL, 
            xlab = "", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))

# Diagnostic plots look good

# Looking at effect of forest height at the average amount of rainfall in September
plot(NDT2_t2$live_stand_volume_125,NDT2_t2$fire_pres)
curve(invlogit(coef(glm_best_NDT2)[1] +coef(glm_best_NDT2)[2]*mean(NDT2_t2$climate1) + coef(glm_best_NDT2)[3]*x), add=TRUE)

# looking at effect of climate1 at the average forest height.
plot(NDT2_t2$climate1,NDT2_t2$fire_pres)
curve(invlogit(coef(glm_best_NDT2)[1] +coef(glm_best_NDT2)[2]*x + coef(glm_best_NDT2)[3]*mean(NDT2_t2$live_stand_volume_125)), add=TRUE)


# create model table (only do this once) and add the relevant data
top_mod_table <- data.frame (matrix (ncol = 16, nrow = 0))
colnames (top_mod_table) <- c ("ZONE", "TREED", "Model_terms", "intercept", "coef_climate_1", "coef_climate_2", "coef_climate_interaction", "coef_stand_height", "coef_live_stand_volume_125", "coef_proj_age", "coef_vegtypeD", "coef_vegtypeOP", "coef_vegtypeS", "coef_vegtypeTB", "coef_vegtypeTC", "coef_vegtypeTM")



##STILL NEED TO ADD DATA FOR TABLE

##Add data for NDT2
top_mod_table[1,1]<-"NDT2"
top_mod_table[1,2]<-"Y"
top_mod_table[1,3]<-"fire_pres ~ ppt09 + proj_height_1" ######### UPDATE
top_mod_table[1,4]<- coef(glm_best_NDT2)[1] #Intercept
top_mod_table[1,5]<- coef(glm_best_NDT2)[2] #Climate variable 1
#top_mod_table[1,6]<- coef(glm_best_NDT2)[2] #Climate variable 2
#top_mod_table[1,7]<- coef(glm_best_NDT2)[3] #Interaction climate variables
#top_mod_table[1,8]<- coef(glm_best_NDT2)[3] #coef_stand_height
#top_mod_table[1,9]<- coef(glm_best_NDT2)[3] #live_stand_volume_125
#top_mod_table[1,10]<- coef(glm_best_NDT2)[4] #proj_age_1
#top_mod_table[1,11]<- coef(glm_best_NDT2)[4] #coefficient vegtypeD
#top_mod_table[1,12]<- coef(glm_best_NDT2)[4] #coefficient vegtypeOP
#top_mod_table[1,13]<- coef(glm_best_NDT2)[4] #coefficient vegtypeS
#top_mod_table[1,14]<- coef(glm_best_NDT2)[4] #coefficient vegtypeTB
#top_mod_table[1,15]<- coef(glm_best_NDT2)[4] #coefficient vegtypeTC
#top_mod_table[1,16]<- coef(glm_best_NDT2)[5] #coefficient vegtypeTM
top_mod_table ##Determine if better way to represent categories for vegtype, and if each climate variable should have its own column

########################## NDT2 Model Selection Complete ###################



```






############### Now choose the next NDT zone and repeat ########
Note: currently doing  those with one climate variable)
Models complete above: NDT4, NDT1, NDT2
Models to still do henceforth: NDT3, NDT5


Select next zone: NDT3


```{r}
zones1<-c("NDT3") #Do one zone at a time

filenames<-list()
prop<-0.75

########### 1. Climate and vegtype ############
for (g in 1:100){

for (h in 1:length(zones1)) {
  dat2<- dat_lightning_t %>% dplyr::filter(ntrl_ds ==zones1[h])

for (i in 1: length(all.poss.mods.clim.vegtype2)){
  print(paste((all.poss.mods.clim.vegtype2[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, variables_all[i])
  model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, !!variables_all)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="fire_pres") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.aic, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.clim.vegtype2, big.mod, df.train=dat1, df.test=Valid)

}
}
}


```

Now extract elements from the output .

```{r}
#terms in each model
x1.3 <- unlist(sapply(mods.fit, '[', 1))
x1.3
#Aic for models
x3.3 <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3.3
#auc from validation data
x4.3 <- unlist(sapply(mods.fit, '[', 4))
x4.3
#combining all as df
tab.sum.climate <- cbind.data.frame(model=x1.3, edf=x3.3[,1], aic=x3.3[,2], auc.valid=x4.3)
tab.sum.climate$NDT<-c("NDT3")
tab.sum.climate$delta.aic<- tab.sum.climate$aic - (min(tab.sum.climate$aic))
tab.sum.climate 

```


#Now repeat for VRI data


```{r}

########### 2. VRI ############
for (g in 1:100){

for (h in 1:length(zones1)) {
  dat2<- dat_lightning_t %>% dplyr::filter(ntrl_ds ==zones1[h])

for (i in 1: length(all.poss.mods.VRI)){
  print(paste((all.poss.mods.VRI[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, variables_all[i])
  model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, !!variables_all)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="fire_pres") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.aic, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.VRI, big.mod, df.train=dat1, df.test=Valid)

}
}
}


```

Now extract elements from the output .

```{r}
#terms in each model
x1.3b <- unlist(sapply(mods.fit, '[', 1))
x1.3b
#Aic for models
x3.3b <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3.3b
#auc from validation data
x4.3b <- unlist(sapply(mods.fit, '[', 4))
x4.3b
#combining all as df
tab.sum.VRI <- cbind.data.frame(model=x1.3b, edf=x3.3b[,1], aic=x3.3b[,2], auc.valid=x4.3b)
tab.sum.VRI$NDT<-c("NDT3")
tab.sum.VRI$delta.aic<- tab.sum.VRI$aic - (min(tab.sum.VRI$aic))
tab.sum.VRI 

```


#Now repeat for topography

```{r}

########### 3. Topography ############
for (g in 1:100){

for (h in 1:length(zones1)) {
 dat2<- dat_lightning_t %>% dplyr::filter(ntrl_ds ==zones1[h])

for (i in 1: length(all.poss.mods.topo)){
  print(paste((all.poss.mods.topo[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, variables_all[i])
  model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, !!variables_all)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="fire_pres") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.aic, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.topo, big.mod, df.train=dat1, df.test=Valid)

}
}
}


```

Now extract elements from the output .

```{r}
#terms in each model
x1.3c <- unlist(sapply(mods.fit, '[', 1))
x1.3c
#Aic for models
x3.3c <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3.3c
#auc from validation data
x4.3c <- unlist(sapply(mods.fit, '[', 4))
x4.3c
#combining all as df
tab.sum.topo <- cbind.data.frame(model=x1.3c, edf=x3.3c[,1], aic=x3.3c[,2], auc.valid=x4.3c)
tab.sum.topo$NDT<-c("NDT3")
tab.sum.topo$delta.aic<- tab.sum.topo$aic - (min(tab.sum.topo$aic))
tab.sum.topo

```


#Below code is for ammendement now that heatload has been added as a variable

```{r}
write.csv(tab.sum.topo, file="D:\\Fire\\fire_data\\raw_data\\NDT3_tab.sum.topo.csv")

```


#Now combine the datatables and save to computer

```{r}
NDT3_l_models<-rbind(tab.sum.climate, tab.sum.VRI, tab.sum.topo)
NDT3_l_models

write.csv(NDT3_l_models, file="D:\\Fire\\fire_data\\raw_data\\NDT3_lightning_models.csv")
```

Now choose the top variables and create final model. The below code will need to be updated manually, depending on what the results of the above analyses are.

######## UPDATE BELOW #########

```{r}
##### TOP MODEL####
NDT3_t<-dat_lightning_t %>%
  filter(ntrl_ds=="NDT3")

NDT3_t2<-NDT3_t %>% drop_na(live_stand_volume_125, vegtype, climate1, climate2, proj_height_1)

glm_best_NDT3<- glm(fire_pres ~ scale(climate1)*scale(climate2) +
             scale(live_stand_volume_125) +
               scale(proj_height_1) +
               vegtype, 
           data= NDT3_t2,
           family = binomial,
           na.action=na.omit)

summary(glm_best_NDT3)

# model diagnostic plots
binnedplot (fitted(glm_best_NDT3), 
            residuals(glm_best_NDT3), 
            nclass = NULL, 
            xlab = "Expected Values", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))


NDT3_t2$resids<-resid(glm_best_NDT3)

binnedplot (NDT3_t2$live_stand_volume_125, 
            NDT3_t2$resids, 
            nclass = NULL, 
            xlab = "live stand volume", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))

binnedplot (NDT3_t2$climate1, 
            NDT3_t2$resids, 
            nclass = NULL, 
            xlab = "", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))

# Diagnostic plots look good

# Looking at effect of forest height at the average amount of rainfall in September
plot(NDT3_t2$live_stand_volume_125,NDT3_t2$fire_pres)
curve(invlogit(coef(glm_best_NDT3)[1] +coef(glm_best_NDT3)[2]*mean(NDT3_t2$climate1) + coef(glm_best_NDT3)[3]*x), add=TRUE)

# looking at effect of climate1 at the average forest height.
plot(NDT3_t2$climate1,NDT3_t2$fire_pres)
curve(invlogit(coef(glm_best_NDT3)[1] +coef(glm_best_NDT3)[2]*x + coef(glm_best_NDT3)[3]*mean(NDT3_t2$live_stand_volume_125)), add=TRUE)


# create model table (only do this once) and add the relevant data
top_mod_table <- data.frame (matrix (ncol = 16, nrow = 0))
colnames (top_mod_table) <- c ("ZONE", "TREED", "Model_terms", "intercept", "coef_climate_1", "coef_climate_2", "coef_climate_interaction", "coef_stand_height", "coef_live_stand_volume_125", "coef_proj_age", "coef_vegtypeD", "coef_vegtypeOP", "coef_vegtypeS", "coef_vegtypeTB", "coef_vegtypeTC", "coef_vegtypeTM")



##STILL NEED TO ADD DATA FOR TABLE

##Add data for NDT3
top_mod_table[1,1]<-"NDT3"
top_mod_table[1,2]<-"Y"
top_mod_table[1,3]<-"fire_pres ~ ppt09 + proj_height_1" ######### UPDATE
top_mod_table[1,4]<- coef(glm_best_NDT3)[1] #Intercept
top_mod_table[1,5]<- coef(glm_best_NDT3)[2] #Climate variable 1
#top_mod_table[1,6]<- coef(glm_best_NDT3)[2] #Climate variable 2
#top_mod_table[1,7]<- coef(glm_best_NDT3)[3] #Interaction climate variables
#top_mod_table[1,8]<- coef(glm_best_NDT3)[3] #coef_stand_height
#top_mod_table[1,9]<- coef(glm_best_NDT3)[3] #live_stand_volume_125
#top_mod_table[1,10]<- coef(glm_best_NDT3)[4] #proj_age_1
#top_mod_table[1,11]<- coef(glm_best_NDT3)[4] #coefficient vegtypeD
#top_mod_table[1,12]<- coef(glm_best_NDT3)[4] #coefficient vegtypeOP
#top_mod_table[1,13]<- coef(glm_best_NDT3)[4] #coefficient vegtypeS
#top_mod_table[1,14]<- coef(glm_best_NDT3)[4] #coefficient vegtypeTB
#top_mod_table[1,15]<- coef(glm_best_NDT3)[4] #coefficient vegtypeTC
#top_mod_table[1,16]<- coef(glm_best_NDT3)[5] #coefficient vegtypeTM
top_mod_table ##Determine if better way to represent categories for vegtype, and if each climate variable should have its own column

########################## NDT3 Model Selection Complete ###################



```



############### Now choose the next NDT zone and repeat ########
Note: currently doing  those with one climate variable)
Models complete above: NDT4, NDT1, NDT2, NDT3
Models to still do henceforth: NDT5


Select next zone: NDT5

```{r}
#Code no longer works for NDT5. It appears that there is no variation in vegtype (all TC).
dat_lightning_t_NDT5<-subset(dat_lightning_t, dat_lightning_t$ntrl_ds=="NDT5")
table(dat_lightning_t_NDT5$vegtype)
table(dat_lightning_t_NDT5$fire_veg)

table(dat_lightning_$ntrl_ds, dat_lightning_$vegtype)

dat_lightning_t_NDT5<-subset(dat_lightning_t_NDT5,dat_lightning_t_NDT5$vegtype!="TB")
str(dat_lightning_t_NDT5$fire_veg)
dat_lightning_t_NDT5$fire_veg<-as.factor(dat_lightning_t_NDT5$fire_veg)

str(dat_lightning_t_NDT5$climate1)
str(dat_lightning_t_NDT5$climate2)
str(dat_lightning_t_NDT5$vegtype)
dat_lightning_t_NDT5$vegtype<-as.factor(as.character(dat_lightning_t_NDT5$vegtype))
table(dat_lightning_t_NDT5$vegtype)
```


```{r}
zones1<-c("NDT5") #Do one zone at a time

filenames<-list()
prop<-0.75

########### 1. Climate and vegtype ############
for (g in 1:100){

for (h in 1:length(zones1)) {
  dat2<- dat_lightning_t_NDT5 %>% dplyr::filter(ntrl_ds ==zones1[h])

for (i in 1: length(all.poss.mods.clim.vegtype2b)){
  print(paste((all.poss.mods.clim.vegtype2b[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, variables_all[i])
  model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, !!variables_all)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_pres, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="fire_pres") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.aic, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.clim.vegtype2b, big.mod, df.train=dat1, df.test=Valid)

}
}
}


```

Now extract elements from the output .

```{r}
#terms in each model
x1.5 <- unlist(sapply(mods.fit, '[', 1))
x1.5
#Aic for models
x3.5 <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3.5
#auc from validation data
x4.5 <- unlist(sapply(mods.fit, '[', 4))
x4.5
#combining all as df
tab.sum.climate <- cbind.data.frame(model=x1.5, edf=x3.5[,1], aic=x3.5[,2], auc.valid=x4.5)
tab.sum.climate$NDT<-c("NDT5")
tab.sum.climate$delta.aic<- tab.sum.climate$aic - (min(tab.sum.climate$aic))
tab.sum.climate 

```


#Now repeat for VRI data


```{r}

########### 2. VRI ############
for (g in 1:100){

for (h in 1:length(zones1)) {
  dat2<- dat_lightning_t_NDT5 %>% dplyr::filter(ntrl_ds ==zones1[h])

for (i in 1: length(all.poss.mods.VRI)){
  print(paste((all.poss.mods.VRI[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, variables_all[i])
  model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, !!variables_all)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="fire_pres") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.aic, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.VRI, big.mod, df.train=dat1, df.test=Valid)

}
}
}


```

Now extract elements from the output .

```{r}
#terms in each model
x1.5b <- unlist(sapply(mods.fit, '[', 1))
x1.5b
#Aic for models
x3.5b <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3.5b
#auc from validation data
x4.5b <- unlist(sapply(mods.fit, '[', 4))
x4.5b
#combining all as df
tab.sum.VRI <- cbind.data.frame(model=x1.5b, edf=x3.5b[,1], aic=x3.5b[,2], auc.valid=x4.5b)
tab.sum.VRI$NDT<-c("NDT5")
tab.sum.VRI$delta.aic<- tab.sum.VRI$aic - (min(tab.sum.VRI$aic))
tab.sum.VRI 

```


#Now repeat for topography

```{r}

########### 3. Topography ############
for (g in 1:100){

for (h in 1:length(zones1)) {
 dat2<- dat_lightning_t_NDT5 %>% dplyr::filter(ntrl_ds ==zones1[h])

for (i in 1: length(all.poss.mods.topo)){
  print(paste((all.poss.mods.topo[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, variables_all[i])
  model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, !!variables_all)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="fire_pres") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.aic, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.topo, big.mod, df.train=dat1, df.test=Valid)

}
}
}


```

Now extract elements from the output .

```{r}
#terms in each model
x1.5c <- unlist(sapply(mods.fit, '[', 1))
x1.5c
#Aic for models
x3.5c <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3.5c
#auc from validation data
x4.5c <- unlist(sapply(mods.fit, '[', 4))
x4.5c
#combining all as df
tab.sum.topo <- cbind.data.frame(model=x1.5c, edf=x3.5c[,1], aic=x3.5c[,2], auc.valid=x4.5c)
tab.sum.topo$NDT<-c("NDT5")
tab.sum.topo$delta.aic<- tab.sum.topo$aic - (min(tab.sum.topo$aic))
tab.sum.topo

```


#Below code is for ammendement now that heatload has been added as a variable

```{r}
write.csv(tab.sum.topo, file="D:\\Fire\\fire_data\\raw_data\\NDT5_tab.sum.topo.csv")

```


#Now combine the datatables and save to computer

```{r}
NDT5_l_models<-rbind(tab.sum.climate, tab.sum.VRI, tab.sum.topo)
NDT5_l_models

write.csv(NDT5_l_models, file="D:\\Fire\\fire_data\\raw_data\\NDT5_lightning_models.csv")
```

Now choose the top variables and create final model. The below code will need to be updated manually, depending on what the results of the above analyses are.

######## UPDATE BELOW #########

```{r}
##### TOP MODEL####
NDT5_t<-dat_lightning_t %>%
  filter(ntrl_ds=="NDT5")

NDT5_t2<-NDT5_t %>% drop_na(live_stand_volume_125, vegtype, climate1, climate2, proj_height_1)

glm_best_NDT5<- glm(fire_pres ~ scale(climate1)*scale(climate2) +
             scale(live_stand_volume_125) +
               scale(proj_height_1) +
               vegtype, 
           data= NDT5_t2,
           family = binomial,
           na.action=na.omit)

summary(glm_best_NDT5)

# model diagnostic plots
binnedplot (fitted(glm_best_NDT5), 
            residuals(glm_best_NDT5), 
            nclass = NULL, 
            xlab = "Expected Values", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))


NDT5_t2$resids<-resid(glm_best_NDT5)

binnedplot (NDT5_t2$live_stand_volume_125, 
            NDT5_t2$resids, 
            nclass = NULL, 
            xlab = "live stand volume", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))

binnedplot (NDT5_t2$climate1, 
            NDT5_t2$resids, 
            nclass = NULL, 
            xlab = "", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))

# Diagnostic plots look good

# Looking at effect of forest height at the average amount of rainfall in September
plot(NDT5_t2$live_stand_volume_125,NDT5_t2$fire_pres)
curve(invlogit(coef(glm_best_NDT5)[1] +coef(glm_best_NDT5)[2]*mean(NDT5_t2$climate1) + coef(glm_best_NDT5)[3]*x), add=TRUE)

# looking at effect of climate1 at the average forest height.
plot(NDT5_t2$climate1,NDT5_t2$fire_pres)
curve(invlogit(coef(glm_best_NDT5)[1] +coef(glm_best_NDT5)[2]*x + coef(glm_best_NDT5)[3]*mean(NDT5_t2$live_stand_volume_125)), add=TRUE)


# create model table (only do this once) and add the relevant data
top_mod_table <- data.frame (matrix (ncol = 16, nrow = 0))
colnames (top_mod_table) <- c ("ZONE", "TREED", "Model_terms", "intercept", "coef_climate_1", "coef_climate_2", "coef_climate_interaction", "coef_stand_height", "coef_live_stand_volume_125", "coef_proj_age", "coef_vegtypeD", "coef_vegtypeOP", "coef_vegtypeS", "coef_vegtypeTB", "coef_vegtypeTC", "coef_vegtypeTM")



##STILL NEED TO ADD DATA FOR TABLE

##Add data for NDT5
top_mod_table[1,1]<-"NDT5"
top_mod_table[1,2]<-"Y"
top_mod_table[1,3]<-"fire_pres ~ ppt09 + proj_height_1" ######### UPDATE
top_mod_table[1,4]<- coef(glm_best_NDT5)[1] #Intercept
top_mod_table[1,5]<- coef(glm_best_NDT5)[2] #Climate variable 1
#top_mod_table[1,6]<- coef(glm_best_NDT5)[2] #Climate variable 2
#top_mod_table[1,7]<- coef(glm_best_NDT5)[3] #Interaction climate variables
#top_mod_table[1,8]<- coef(glm_best_NDT5)[3] #coef_stand_height
#top_mod_table[1,9]<- coef(glm_best_NDT5)[3] #live_stand_volume_125
#top_mod_table[1,10]<- coef(glm_best_NDT5)[4] #proj_age_1
#top_mod_table[1,11]<- coef(glm_best_NDT5)[4] #coefficient vegtypeD
#top_mod_table[1,12]<- coef(glm_best_NDT5)[4] #coefficient vegtypeOP
#top_mod_table[1,13]<- coef(glm_best_NDT5)[4] #coefficient vegtypeS
#top_mod_table[1,14]<- coef(glm_best_NDT5)[4] #coefficient vegtypeTB
#top_mod_table[1,15]<- coef(glm_best_NDT5)[4] #coefficient vegtypeTC
#top_mod_table[1,16]<- coef(glm_best_NDT5)[5] #coefficient vegtypeTM
top_mod_table ##Determine if better way to represent categories for vegtype, and if each climate variable should have its own column

########################## NDT5 Model Selection Complete ###################



```






############### Part 2 of 4 Model Series: Lightning Caused Fires, No Trees ##########

Because these areas are predominately not full of trees, we will ignore the VRI. Some locations will still have some VRI attributes because trees may exist on <50% of the plot, but many plots will have no VRI attributes. So we will ignore the VRI results for this section.

For lightning caused fires with no trees, the variables of interest include:

1. Climate variable(s)
2. vegtype
3. slope
4. aspect (cos)
5. elevation
6. Heatload

Interactions of interest: two-way interactions between climate (1) and vegtype (5); two-way interactions between topography measures (6-8).

===

Select first NDT: NDT4 

```{r}
zones1<-c("NDT4") #Do one zone at a time

filenames<-list()
prop<-0.75

########### 1. Climate and vegtype ############
for (g in 1:100){

for (h in 1:length(zones1)) {
  dat2<- dat_lightning_nt %>% dplyr::filter(ntrl_ds ==zones1[h])

for (i in 1: length(all.poss.mods.clim.vegtype2)){
  print(paste((all.poss.mods.clim.vegtype2[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, variables_all[i])
  model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, !!variables_all)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="fire_pres") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.aic, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.clim.vegtype2, big.mod, df.train=dat1, df.test=Valid)

}
}
}


```

Now extract elements from the output .

```{r}
#terms in each model
x1 <- unlist(sapply(mods.fit, '[', 1))
x1
#Aic for models
x3 <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3
#auc from validation data
x4 <- unlist(sapply(mods.fit, '[', 4))
x4
#combining all as df
tab.sum.climate.nt <- cbind.data.frame(model=x1, edf=x3[,1], aic=x3[,2], auc.valid=x4)
tab.sum.climate.nt$NDT<-c("NDT4 No trees")
tab.sum.climate.nt$delta.aic<- tab.sum.climate.nt$aic - (min(tab.sum.climate.nt$aic))
tab.sum.climate.nt 

```


#Now repeat for topography

```{r}

########### 2. Topography ############
for (g in 1:100){

for (h in 1:length(zones1)) {
 dat2<- dat_lightning_nt %>% dplyr::filter(ntrl_ds ==zones1[h])

for (i in 1: length(all.poss.mods.topo)){
  print(paste((all.poss.mods.topo[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, variables_all[i])
  model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, !!variables_all)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="fire_pres") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.aic, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.topo, big.mod, df.train=dat1, df.test=Valid)

}
}
}


```

Now extract elements from the output .

```{r}
#terms in each model
x1c <- unlist(sapply(mods.fit, '[', 1))
x1c
#Aic for models
x3c <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3c
#auc from validation data
x4c <- unlist(sapply(mods.fit, '[', 4))
x4c
#combining all as df
tab.sum.topo.nt <- cbind.data.frame(model=x1c, edf=x3c[,1], aic=x3c[,2], auc.valid=x4c)
tab.sum.topo.nt$NDT<-c("NDT4 No trees")
tab.sum.topo.nt$delta.aic<- tab.sum.topo.nt$aic - (min(tab.sum.topo.nt$aic))
tab.sum.topo.nt

```


```{r}
write.csv(tab.sum.topo, file="D:\\Fire\\fire_data\\raw_data\\NDT4_tab.sum.topo_NT.csv")

```

#Now combine the datatables and save to computer

```{r}
NDT4_l_models_nt<-rbind(tab.sum.climate.nt, tab.sum.topo.nt)
NDT4_l_models_nt

write.csv(NDT4_l_models_nt, file="D:\\Fire\\fire_data\\raw_data\\NDT4_lightning_models_nt.csv")
```

Now choose the top variables and create final model. The below code will need to be updated manually, depending on what the results of the above analyses are.

######## UPDATE BELOW #########

```{r}
##### TOP MODEL####
NDT4_t<-dat_lightning_nt %>%
  filter(ntrl_ds=="NDT4")

NDT4_t2<-NDT4_t %>% drop_na(live_stand_volume_125, vegtype, climate1, climate2, proj_height_1)

glm_best_NDT4<- glm(fire_pres ~ scale(climate1)*scale(climate2) +
             scale(live_stand_volume_125) +
               scale(proj_height_1) +
               vegtype, 
           data= NDT4_t2,
           family = binomial,
           na.action=na.omit)

summary(glm_best_NDT4)

# model diagnostic plots
binnedplot (fitted(glm_best_NDT4), 
            residuals(glm_best_NDT4), 
            nclass = NULL, 
            xlab = "Expected Values", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))


NDT4_t2$resids<-resid(glm_best_NDT4)

binnedplot (NDT4_t2$live_stand_volume_125, 
            NDT4_t2$resids, 
            nclass = NULL, 
            xlab = "live stand volume", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))

binnedplot (NDT4_t2$climate1, 
            NDT4_t2$resids, 
            nclass = NULL, 
            xlab = "", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))

# Diagnostic plots look good

# Looking at effect of forest height at the average amount of rainfall in September
plot(NDT4_t2$live_stand_volume_125,NDT4_t2$fire_pres)
curve(invlogit(coef(glm_best_NDT4)[1] +coef(glm_best_NDT4)[2]*mean(NDT4_t2$climate1) + coef(glm_best_NDT4)[3]*x), add=TRUE)

# looking at effect of climate1 at the average forest height.
plot(NDT4_t2$climate1,NDT4_t2$fire_pres)
curve(invlogit(coef(glm_best_NDT4)[1] +coef(glm_best_NDT4)[2]*x + coef(glm_best_NDT4)[3]*mean(NDT4_t2$live_stand_volume_125)), add=TRUE)


# create model table (only do this once) and add the relevant data
top_mod_table <- data.frame (matrix (ncol = 16, nrow = 0))
colnames (top_mod_table) <- c ("ZONE", "TREED", "Model_terms", "intercept", "coef_climate_1", "coef_climate_2", "coef_climate_interaction", "coef_stand_height", "coef_live_stand_volume_125", "coef_proj_age", "coef_vegtypeD", "coef_vegtypeOP", "coef_vegtypeS", "coef_vegtypeTB", "coef_vegtypeTC", "coef_vegtypeTM")



##STILL NEED TO ADD DATA FOR TABLE

##Add data for NDT4
top_mod_table[1,1]<-"NDT4"
top_mod_table[1,2]<-"Y"
top_mod_table[1,3]<-"fire_pres ~ ppt09 + proj_height_1" ######### UPDATE
top_mod_table[1,4]<- coef(glm_best_NDT4)[1] #Intercept
top_mod_table[1,5]<- coef(glm_best_NDT4)[2] #Climate variable 1
#top_mod_table[1,6]<- coef(glm_best_NDT4)[2] #Climate variable 2
#top_mod_table[1,7]<- coef(glm_best_NDT4)[3] #Interaction climate variables
#top_mod_table[1,8]<- coef(glm_best_NDT4)[3] #coef_stand_height
#top_mod_table[1,9]<- coef(glm_best_NDT4)[3] #live_stand_volume_125
#top_mod_table[1,10]<- coef(glm_best_NDT4)[4] #proj_age_1
#top_mod_table[1,11]<- coef(glm_best_NDT4)[4] #coefficient vegtypeD
#top_mod_table[1,12]<- coef(glm_best_NDT4)[4] #coefficient vegtypeOP
#top_mod_table[1,13]<- coef(glm_best_NDT4)[4] #coefficient vegtypeS
#top_mod_table[1,14]<- coef(glm_best_NDT4)[4] #coefficient vegtypeTB
#top_mod_table[1,15]<- coef(glm_best_NDT4)[4] #coefficient vegtypeTC
#top_mod_table[1,16]<- coef(glm_best_NDT4)[5] #coefficient vegtypeTM
top_mod_table ##Determine if better way to represent categories for vegtype, and if each climate variable should have its own column

########################## NDT4 Model Selection Complete ###################

```
 
############### Now choose the next NDT zone and repeat ########
Note: currently doing  those with one climate variable)
Models complete above: NDT4
Models to still do henceforth:NDT1, NDT2, NDT3, NDT5


Select next zone: NDT1


```{r}
zones1<-c("NDT1") #Do one zone at a time

filenames<-list()
prop<-0.75

########### 1. Climate and vegtype ############
for (g in 1:100){

for (h in 1:length(zones1)) {
  dat2<- dat_lightning_nt %>% dplyr::filter(ntrl_ds ==zones1[h])

for (i in 1: length(all.poss.mods.clim.vegtype2)){
  print(paste((all.poss.mods.clim.vegtype2[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, variables_all[i])
  model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, !!variables_all)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="fire_pres") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.aic, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.clim.vegtype2, big.mod, df.train=dat1, df.test=Valid)

}
}
}


```

Now extract elements from the output .

```{r}
#terms in each model
x1.1 <- unlist(sapply(mods.fit, '[', 1))
x1.1
#Aic for models
x3.1 <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3.1
#auc from validation data
x4.1 <- unlist(sapply(mods.fit, '[', 4))
x4.1
#combining all as df
tab.sum.climate.nt <- cbind.data.frame(model=x1.1, edf=x3.1[,1], aic=x3.1[,2], auc.valid=x4.1)
tab.sum.climate.nt$NDT<-c("NDT1 No trees")
tab.sum.climate.nt$delta.aic<- tab.sum.climate.nt$aic - (min(tab.sum.climate.nt$aic))
tab.sum.climate.nt 

```


#Now repeat for topography

```{r}

########### 2. Topography ############
for (g in 1:100){

for (h in 1:length(zones1)) {
 dat2<- dat_lightning_nt %>% dplyr::filter(ntrl_ds ==zones1[h])

for (i in 1: length(all.poss.mods.topo)){
  print(paste((all.poss.mods.topo[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, variables_all[i])
  model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, !!variables_all)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="fire_pres") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.aic, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.topo, big.mod, df.train=dat1, df.test=Valid)

}
}
}


```


Now extract elements from the output.

```{r}
#terms in each model
x1.1c <- unlist(sapply(mods.fit, '[', 1))
x1.1c
#Aic for models
x3.1c <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3.1c
#auc from validation data
x4.1c <- unlist(sapply(mods.fit, '[', 4))
x4.1c
#combining all as df
tab.sum.topo.nt <- cbind.data.frame(model=x1.1c, edf=x3.1c[,1], aic=x3.1c[,2], auc.valid=x4.1c)
tab.sum.topo.nt$NDT<-c("NDT1 No trees")
tab.sum.topo.nt$delta.aic<- tab.sum.topo.nt$aic - (min(tab.sum.topo.nt$aic))
tab.sum.topo.nt

```


```{r}
write.csv(tab.sum.topo, file="D:\\Fire\\fire_data\\raw_data\\NDT1_tab.sum.topo_NT.csv")

```

#Now combine the datatables and save to computer

```{r}
NDT1_l_models_nt<-rbind(tab.sum.climate.nt, tab.sum.topo.nt)
NDT1_l_models_nt

write.csv(NDT1_l_models_nt, file="D:\\Fire\\fire_data\\raw_data\\NDT1_lightning_models_nt.csv")
```

Now choose the top variables and create final model. The below code will need to be updated manually, depending on what the results of the above analyses are.

######## UPDATE BELOW #########

```{r}
##### TOP MODEL####
NDT1_t<-dat_lightning_nt %>%
  filter(ntrl_ds=="NDT1")

NDT1_t2<-NDT1_t %>% drop_na(live_stand_volume_125, vegtype, climate1, climate2, proj_height_1)

glm_best_NDT1<- glm(fire_pres ~ scale(climate1)*scale(climate2) +
             scale(live_stand_volume_125) +
               scale(proj_height_1) +
               vegtype, 
           data= NDT1_t2,
           family = binomial,
           na.action=na.omit)

summary(glm_best_NDT1)

# model diagnostic plots
binnedplot (fitted(glm_best_NDT1), 
            residuals(glm_best_NDT1), 
            nclass = NULL, 
            xlab = "Expected Values", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))


NDT1_t2$resids<-resid(glm_best_NDT1)

binnedplot (NDT1_t2$live_stand_volume_125, 
            NDT1_t2$resids, 
            nclass = NULL, 
            xlab = "live stand volume", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))

binnedplot (NDT1_t2$climate1, 
            NDT1_t2$resids, 
            nclass = NULL, 
            xlab = "", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))

# Diagnostic plots look good

# Looking at effect of forest height at the average amount of rainfall in September
plot(NDT1_t2$live_stand_volume_125,NDT1_t2$fire_pres)
curve(invlogit(coef(glm_best_NDT1)[1] +coef(glm_best_NDT1)[2]*mean(NDT1_t2$climate1) + coef(glm_best_NDT1)[3]*x), add=TRUE)

# looking at effect of climate1 at the average forest height.
plot(NDT1_t2$climate1,NDT1_t2$fire_pres)
curve(invlogit(coef(glm_best_NDT1)[1] +coef(glm_best_NDT1)[2]*x + coef(glm_best_NDT1)[3]*mean(NDT1_t2$live_stand_volume_125)), add=TRUE)


# create model table (only do this once) and add the relevant data
top_mod_table <- data.frame (matrix (ncol = 16, nrow = 0))
colnames (top_mod_table) <- c ("ZONE", "TREED", "Model_terms", "intercept", "coef_climate_1", "coef_climate_2", "coef_climate_interaction", "coef_stand_height", "coef_live_stand_volume_125", "coef_proj_age", "coef_vegtypeD", "coef_vegtypeOP", "coef_vegtypeS", "coef_vegtypeTB", "coef_vegtypeTC", "coef_vegtypeTM")



##STILL NEED TO ADD DATA FOR TABLE

##Add data for NDT1
top_mod_table[1,1]<-"NDT1"
top_mod_table[1,2]<-"Y"
top_mod_table[1,3]<-"fire_pres ~ ppt09 + proj_height_1" ######### UPDATE
top_mod_table[1,4]<- coef(glm_best_NDT1)[1] #Intercept
top_mod_table[1,5]<- coef(glm_best_NDT1)[2] #Climate variable 1
#top_mod_table[1,6]<- coef(glm_best_NDT1)[2] #Climate variable 2
#top_mod_table[1,7]<- coef(glm_best_NDT1)[3] #Interaction climate variables
#top_mod_table[1,8]<- coef(glm_best_NDT1)[3] #coef_stand_height
#top_mod_table[1,9]<- coef(glm_best_NDT1)[3] #live_stand_volume_125
#top_mod_table[1,10]<- coef(glm_best_NDT1)[4] #proj_age_1
#top_mod_table[1,11]<- coef(glm_best_NDT1)[4] #coefficient vegtypeD
#top_mod_table[1,12]<- coef(glm_best_NDT1)[4] #coefficient vegtypeOP
#top_mod_table[1,13]<- coef(glm_best_NDT1)[4] #coefficient vegtypeS
#top_mod_table[1,14]<- coef(glm_best_NDT1)[4] #coefficient vegtypeTB
#top_mod_table[1,15]<- coef(glm_best_NDT1)[4] #coefficient vegtypeTC
#top_mod_table[1,16]<- coef(glm_best_NDT1)[5] #coefficient vegtypeTM
top_mod_table ##Determine if better way to represent categories for vegtype, and if each climate variable should have its own column

########################## NDT1 Model Selection Complete ###################



```



############### Now choose the next NDT zone and repeat ########
Note: currently doing  those with one climate variable)
Models complete above: NDT4, NDT1
Models to still do henceforth:NDT2, NDT3, NDT5


Select next zone: NDT2


```{r}
zones1<-c("NDT2") #Do one zone at a time

filenames<-list()
prop<-0.75

########### 1. Climate and vegtype ############
for (g in 1:100){

for (h in 1:length(zones1)) {
  dat2<- dat_lightning_nt %>% dplyr::filter(ntrl_ds ==zones1[h])

for (i in 1: length(all.poss.mods.clim.vegtype2)){
  print(paste((all.poss.mods.clim.vegtype2[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, variables_all[i])
  model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, !!variables_all)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="fire_pres") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.aic, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.clim.vegtype2, big.mod, df.train=dat1, df.test=Valid)

}
}
}


```

Now extract elements from the output .

```{r}
#terms in each model
x1.2 <- unlist(sapply(mods.fit, '[', 1))
x1.2
#Aic for models
x3.2 <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3.2
#auc from validation data
x4.2 <- unlist(sapply(mods.fit, '[', 4))
x4.2
#combining all as df
tab.sum.climate.nt <- cbind.data.frame(model=x1.2, edf=x3.2[,1], aic=x3.2[,2], auc.valid=x4.2)
tab.sum.climate.nt$NDT<-c("NDT2 No trees")
tab.sum.climate.nt$delta.aic<- tab.sum.climate.nt$aic - (min(tab.sum.climate.nt$aic))
tab.sum.climate.nt 

```


#Now repeat for topography

```{r}

########### 2. Topography ############
for (g in 1:100){

for (h in 1:length(zones1)) {
 dat2<- dat_lightning_nt %>% dplyr::filter(ntrl_ds ==zones1[h])

for (i in 1: length(all.poss.mods.topo)){
  print(paste((all.poss.mods.topo[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, variables_all[i])
  model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, !!variables_all)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="fire_pres") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.aic, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.topo, big.mod, df.train=dat1, df.test=Valid)

}
}
}


```

Now extract elements from the output .

```{r}
#terms in each model
x1.2c <- unlist(sapply(mods.fit, '[', 1))
x1.2c
#Aic for models
x3.2c <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3.2c
#auc from validation data
x4.2c <- unlist(sapply(mods.fit, '[', 4))
x4.2c
#combining all as df
tab.sum.topo.nt <- cbind.data.frame(model=x1.2c, edf=x3.2c[,1], aic=x3.2c[,2], auc.valid=x4.2c)
tab.sum.topo.nt$NDT<-c("NDT2 No trees")
tab.sum.topo.nt$delta.aic<- tab.sum.topo.nt$aic - (min(tab.sum.topo.nt$aic))
tab.sum.topo.nt

```

#Now combine the datatables and save to computer

```{r}
NDT2_l_models_nt<-rbind(tab.sum.climate.nt, tab.sum.topo.nt)
NDT2_l_models_nt

write.csv(NDT2_l_models_nt, file="D:\\Fire\\fire_data\\raw_data\\NDT2_lightning_models_nt.csv")
```

Now choose the top variables and create final model. The below code will need to be updated manually, depending on what the results of the above analyses are.

######## UPDATE BELOW #########

```{r}
##### TOP MODEL####
NDT2_t<-dat_lightning_nt %>%
  filter(ntrl_ds=="NDT2")

NDT2_t2<-NDT2_t %>% drop_na(live_stand_volume_125, vegtype, climate1, climate2, proj_height_1)

glm_best_NDT2<- glm(fire_pres ~ scale(climate1)*scale(climate2) +
             scale(live_stand_volume_125) +
               scale(proj_height_1) +
               vegtype, 
           data= NDT2_t2,
           family = binomial,
           na.action=na.omit)

summary(glm_best_NDT2)

# model diagnostic plots
binnedplot (fitted(glm_best_NDT2), 
            residuals(glm_best_NDT2), 
            nclass = NULL, 
            xlab = "Expected Values", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))


NDT2_t2$resids<-resid(glm_best_NDT2)

binnedplot (NDT2_t2$live_stand_volume_125, 
            NDT2_t2$resids, 
            nclass = NULL, 
            xlab = "live stand volume", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))

binnedplot (NDT2_t2$climate1, 
            NDT2_t2$resids, 
            nclass = NULL, 
            xlab = "", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))

# Diagnostic plots look good

# Looking at effect of forest height at the average amount of rainfall in September
plot(NDT2_t2$live_stand_volume_125,NDT2_t2$fire_pres)
curve(invlogit(coef(glm_best_NDT2)[1] +coef(glm_best_NDT2)[2]*mean(NDT2_t2$climate1) + coef(glm_best_NDT2)[3]*x), add=TRUE)

# looking at effect of climate1 at the average forest height.
plot(NDT2_t2$climate1,NDT2_t2$fire_pres)
curve(invlogit(coef(glm_best_NDT2)[1] +coef(glm_best_NDT2)[2]*x + coef(glm_best_NDT2)[3]*mean(NDT2_t2$live_stand_volume_125)), add=TRUE)


# create model table (only do this once) and add the relevant data
top_mod_table <- data.frame (matrix (ncol = 16, nrow = 0))
colnames (top_mod_table) <- c ("ZONE", "TREED", "Model_terms", "intercept", "coef_climate_1", "coef_climate_2", "coef_climate_interaction", "coef_stand_height", "coef_live_stand_volume_125", "coef_proj_age", "coef_vegtypeD", "coef_vegtypeOP", "coef_vegtypeS", "coef_vegtypeTB", "coef_vegtypeTC", "coef_vegtypeTM")



##STILL NEED TO ADD DATA FOR TABLE

##Add data for NDT2
top_mod_table[1,1]<-"NDT2"
top_mod_table[1,2]<-"Y"
top_mod_table[1,3]<-"fire_pres ~ ppt09 + proj_height_1" ######### UPDATE
top_mod_table[1,4]<- coef(glm_best_NDT2)[1] #Intercept
top_mod_table[1,5]<- coef(glm_best_NDT2)[2] #Climate variable 1
#top_mod_table[1,6]<- coef(glm_best_NDT2)[2] #Climate variable 2
#top_mod_table[1,7]<- coef(glm_best_NDT2)[3] #Interaction climate variables
#top_mod_table[1,8]<- coef(glm_best_NDT2)[3] #coef_stand_height
#top_mod_table[1,9]<- coef(glm_best_NDT2)[3] #live_stand_volume_125
#top_mod_table[1,10]<- coef(glm_best_NDT2)[4] #proj_age_1
#top_mod_table[1,11]<- coef(glm_best_NDT2)[4] #coefficient vegtypeD
#top_mod_table[1,12]<- coef(glm_best_NDT2)[4] #coefficient vegtypeOP
#top_mod_table[1,13]<- coef(glm_best_NDT2)[4] #coefficient vegtypeS
#top_mod_table[1,14]<- coef(glm_best_NDT2)[4] #coefficient vegtypeTB
#top_mod_table[1,15]<- coef(glm_best_NDT2)[4] #coefficient vegtypeTC
#top_mod_table[1,16]<- coef(glm_best_NDT2)[5] #coefficient vegtypeTM
top_mod_table ##Determine if better way to represent categories for vegtype, and if each climate variable should have its own column

########################## NDT2 Model Selection Complete ###################



```


############### Now choose the next NDT zone and repeat ########
Note: currently doing  those with one climate variable)
Models complete above: NDT4, NDT1, NDT2
Models to still do henceforth: NDT3, NDT5


Select next zone: NDT3


```{r}
zones1<-c("NDT3") #Do one zone at a time

filenames<-list()
prop<-0.75

########### 1. Climate and vegtype ############
for (g in 1:100){

for (h in 1:length(zones1)) {
  dat2<- dat_lightning_nt %>% dplyr::filter(ntrl_ds ==zones1[h])

for (i in 1: length(all.poss.mods.clim.vegtype2)){
  print(paste((all.poss.mods.clim.vegtype2[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, variables_all[i])
  model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, !!variables_all)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="fire_pres") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.aic, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.clim.vegtype2, big.mod, df.train=dat1, df.test=Valid)

}
}
}


```

Now extract elements from the output .

```{r}
#terms in each model
x1.3 <- unlist(sapply(mods.fit, '[', 1))
x1.3
#Aic for models
x3.3 <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3.3
#auc from validation data
x4.3 <- unlist(sapply(mods.fit, '[', 4))
x4.3
#combining all as df
tab.sum.climate.nt <- cbind.data.frame(model=x1.3, edf=x3.3[,1], aic=x3.3[,2], auc.valid=x4.3)
tab.sum.climate.nt$NDT<-c("NDT3 No trees")
tab.sum.climate.nt$delta.aic<- tab.sum.climate.nt$aic - (min(tab.sum.climate.nt$aic))
tab.sum.climate.nt 

```

#Now repeat for topography

```{r}

########### 2. Topography ############
for (g in 1:100){

for (h in 1:length(zones1)) {
 dat2<- dat_lightning_nt %>% dplyr::filter(ntrl_ds ==zones1[h])

for (i in 1: length(all.poss.mods.topo)){
  print(paste((all.poss.mods.topo[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, variables_all[i])
  model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, !!variables_all)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="fire_pres") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.aic, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.topo, big.mod, df.train=dat1, df.test=Valid)

}
}
}


```

Now extract elements from the output .

```{r}
#terms in each model
x1.3c <- unlist(sapply(mods.fit, '[', 1))
x1.3c
#Aic for models
x3.3c <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3.3c
#auc from validation data
x4.3c <- unlist(sapply(mods.fit, '[', 4))
x4.3c
#combining all as df
tab.sum.topo.nt <- cbind.data.frame(model=x1.3c, edf=x3.3c[,1], aic=x3.3c[,2], auc.valid=x4.3c)
tab.sum.topo.nt$NDT<-c("NDT3 No trees")
tab.sum.topo.nt$delta.aic<- tab.sum.topo.nt$aic - (min(tab.sum.topo.nt$aic))
tab.sum.topo.nt

```

#Now combine the datatables and save to computer

```{r}
NDT3_l_models_nt<-rbind(tab.sum.climate.nt, tab.sum.topo.nt)
NDT3_l_models_nt

write.csv(NDT3_l_models_nt, file="D:\\Fire\\fire_data\\raw_data\\NDT3_lightning_models_nt.csv")
```

Now choose the top variables and create final model. The below code will need to be updated manually, depending on what the results of the above analyses are.

######## UPDATE BELOW #########

```{r}
##### TOP MODEL####
NDT3_t<-dat_lightning_nt %>%
  filter(ntrl_ds=="NDT3")

NDT3_t2<-NDT3_t %>% drop_na(live_stand_volume_125, vegtype, climate1, climate2, proj_height_1)

glm_best_NDT3<- glm(fire_pres ~ scale(climate1)*scale(climate2) +
             scale(live_stand_volume_125) +
               scale(proj_height_1) +
               vegtype, 
           data= NDT3_t2,
           family = binomial,
           na.action=na.omit)

summary(glm_best_NDT3)

# model diagnostic plots
binnedplot (fitted(glm_best_NDT3), 
            residuals(glm_best_NDT3), 
            nclass = NULL, 
            xlab = "Expected Values", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))


NDT3_t2$resids<-resid(glm_best_NDT3)

binnedplot (NDT3_t2$live_stand_volume_125, 
            NDT3_t2$resids, 
            nclass = NULL, 
            xlab = "live stand volume", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))

binnedplot (NDT3_t2$climate1, 
            NDT3_t2$resids, 
            nclass = NULL, 
            xlab = "", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))

# Diagnostic plots look good

# Looking at effect of forest height at the average amount of rainfall in September
plot(NDT3_t2$live_stand_volume_125,NDT3_t2$fire_pres)
curve(invlogit(coef(glm_best_NDT3)[1] +coef(glm_best_NDT3)[2]*mean(NDT3_t2$climate1) + coef(glm_best_NDT3)[3]*x), add=TRUE)

# looking at effect of climate1 at the average forest height.
plot(NDT3_t2$climate1,NDT3_t2$fire_pres)
curve(invlogit(coef(glm_best_NDT3)[1] +coef(glm_best_NDT3)[2]*x + coef(glm_best_NDT3)[3]*mean(NDT3_t2$live_stand_volume_125)), add=TRUE)


# create model table (only do this once) and add the relevant data
top_mod_table <- data.frame (matrix (ncol = 16, nrow = 0))
colnames (top_mod_table) <- c ("ZONE", "TREED", "Model_terms", "intercept", "coef_climate_1", "coef_climate_2", "coef_climate_interaction", "coef_stand_height", "coef_live_stand_volume_125", "coef_proj_age", "coef_vegtypeD", "coef_vegtypeOP", "coef_vegtypeS", "coef_vegtypeTB", "coef_vegtypeTC", "coef_vegtypeTM")



##STILL NEED TO ADD DATA FOR TABLE

##Add data for NDT3
top_mod_table[1,1]<-"NDT3"
top_mod_table[1,2]<-"Y"
top_mod_table[1,3]<-"fire_pres ~ ppt09 + proj_height_1" ######### UPDATE
top_mod_table[1,4]<- coef(glm_best_NDT3)[1] #Intercept
top_mod_table[1,5]<- coef(glm_best_NDT3)[2] #Climate variable 1
#top_mod_table[1,6]<- coef(glm_best_NDT3)[2] #Climate variable 2
#top_mod_table[1,7]<- coef(glm_best_NDT3)[3] #Interaction climate variables
#top_mod_table[1,8]<- coef(glm_best_NDT3)[3] #coef_stand_height
#top_mod_table[1,9]<- coef(glm_best_NDT3)[3] #live_stand_volume_125
#top_mod_table[1,10]<- coef(glm_best_NDT3)[4] #proj_age_1
#top_mod_table[1,11]<- coef(glm_best_NDT3)[4] #coefficient vegtypeD
#top_mod_table[1,12]<- coef(glm_best_NDT3)[4] #coefficient vegtypeOP
#top_mod_table[1,13]<- coef(glm_best_NDT3)[4] #coefficient vegtypeS
#top_mod_table[1,14]<- coef(glm_best_NDT3)[4] #coefficient vegtypeTB
#top_mod_table[1,15]<- coef(glm_best_NDT3)[4] #coefficient vegtypeTC
#top_mod_table[1,16]<- coef(glm_best_NDT3)[5] #coefficient vegtypeTM
top_mod_table ##Determine if better way to represent categories for vegtype, and if each climate variable should have its own column

########################## NDT3 Model Selection Complete ###################

```

############### Now choose the next NDT zone and repeat ########
Note: currently doing  those with one climate variable)
Models complete above: NDT4, NDT1, NDT2, NDT3
Models to still do henceforth: NDT5

Select next zone: NDT5

```{r}
zones1<-c("NDT5") #Do one zone at a time

filenames<-list()
prop<-0.75

########### 1. Climate and vegtype ############
for (g in 1:100){

for (h in 1:length(zones1)) {
  dat2<- dat_lightning_nt %>% dplyr::filter(ntrl_ds ==zones1[h])

for (i in 1: length(all.poss.mods.clim.vegtype2)){
  print(paste((all.poss.mods.clim.vegtype2[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, variables_all[i])
  model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, !!variables_all)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="fire_pres") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.aic, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.clim.vegtype2, big.mod, df.train=dat1, df.test=Valid)

}
}
}


```

Now extract elements from the output .

```{r}
#terms in each model
x1.5 <- unlist(sapply(mods.fit, '[', 1))
x1.5
#Aic for models
x3.5 <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3.5
#auc from validation data
x4.5 <- unlist(sapply(mods.fit, '[', 4))
x4.5
#combining all as df
tab.sum.climate.nt <- cbind.data.frame(model=x1.5, edf=x3.5[,1], aic=x3.5[,2], auc.valid=x4.5)
tab.sum.climate.nt$NDT<-c("NDT5 No trees")
tab.sum.climate.nt$delta.aic<- tab.sum.climate.nt$aic - (min(tab.sum.climate.nt$aic))
tab.sum.climate.nt 

```


#Now repeat for topography

```{r}

########### 2. Topography ############
for (g in 1:100){

for (h in 1:length(zones1)) {
 dat2<- dat_lightning_nt %>% dplyr::filter(ntrl_ds ==zones1[h])

for (i in 1: length(all.poss.mods.topo)){
  print(paste((all.poss.mods.topo[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, variables_all[i])
  model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, !!variables_all)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="fire_pres") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.aic, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.topo, big.mod, df.train=dat1, df.test=Valid)

}
}
}


```

Now extract elements from the output .

```{r}
#terms in each model
x1.5c <- unlist(sapply(mods.fit, '[', 1))
x1.5c
#Aic for models
x3.5c <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3.5c
#auc from validation data
x4.5c <- unlist(sapply(mods.fit, '[', 4))
x4.5c
#combining all as df
tab.sum.topo.nt <- cbind.data.frame(model=x1.5c, edf=x3.5c[,1], aic=x3.5c[,2], auc.valid=x4.5c)
tab.sum.topo.nt$NDT<-c("NDT5 No trees")
tab.sum.topo.nt$delta.aic<- tab.sum.topo.nt$aic - (min(tab.sum.topo.nt$aic))
tab.sum.topo.nt

```

#Now combine the datatables and save to computer

```{r}
NDT5_l_models_nt<-rbind(tab.sum.climate.nt, tab.sum.topo.nt)
NDT5_l_models_nt

write.csv(NDT5_l_models_nt, file="D:\\Fire\\fire_data\\raw_data\\NDT5_lightning_models_nt.csv")
```

Now choose the top variables and create final model. The below code will need to be updated manually, depending on what the results of the above analyses are.

######## UPDATE BELOW #########

```{r}
##### TOP MODEL####
NDT5_t<-dat_lightning_nt %>%
  filter(ntrl_ds=="NDT5")

NDT5_t2<-NDT5_t %>% drop_na(live_stand_volume_125, vegtype, climate1, climate2, proj_height_1)

glm_best_NDT5<- glm(fire_pres ~ scale(climate1)*scale(climate2) +
             scale(live_stand_volume_125) +
               scale(proj_height_1) +
               vegtype, 
           data= NDT5_t2,
           family = binomial,
           na.action=na.omit)

summary(glm_best_NDT5)

# model diagnostic plots
binnedplot (fitted(glm_best_NDT5), 
            residuals(glm_best_NDT5), 
            nclass = NULL, 
            xlab = "Expected Values", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))


NDT5_t2$resids<-resid(glm_best_NDT5)

binnedplot (NDT5_t2$live_stand_volume_125, 
            NDT5_t2$resids, 
            nclass = NULL, 
            xlab = "live stand volume", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))

binnedplot (NDT5_t2$climate1, 
            NDT5_t2$resids, 
            nclass = NULL, 
            xlab = "", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))

# Diagnostic plots look good

# Looking at effect of forest height at the average amount of rainfall in September
plot(NDT5_t2$live_stand_volume_125,NDT5_t2$fire_pres)
curve(invlogit(coef(glm_best_NDT5)[1] +coef(glm_best_NDT5)[2]*mean(NDT5_t2$climate1) + coef(glm_best_NDT5)[3]*x), add=TRUE)

# looking at effect of climate1 at the average forest height.
plot(NDT5_t2$climate1,NDT5_t2$fire_pres)
curve(invlogit(coef(glm_best_NDT5)[1] +coef(glm_best_NDT5)[2]*x + coef(glm_best_NDT5)[3]*mean(NDT5_t2$live_stand_volume_125)), add=TRUE)

# create model table (only do this once) and add the relevant data
top_mod_table <- data.frame (matrix (ncol = 16, nrow = 0))
colnames (top_mod_table) <- c ("ZONE", "TREED", "Model_terms", "intercept", "coef_climate_1", "coef_climate_2", "coef_climate_interaction", "coef_stand_height", "coef_live_stand_volume_125", "coef_proj_age", "coef_vegtypeD", "coef_vegtypeOP", "coef_vegtypeS", "coef_vegtypeTB", "coef_vegtypeTC", "coef_vegtypeTM")


##STILL NEED TO ADD DATA FOR TABLE

##Add data for NDT5
top_mod_table[1,1]<-"NDT5"
top_mod_table[1,2]<-"Y"
top_mod_table[1,3]<-"fire_pres ~ ppt09 + proj_height_1" ######### UPDATE
top_mod_table[1,4]<- coef(glm_best_NDT5)[1] #Intercept
top_mod_table[1,5]<- coef(glm_best_NDT5)[2] #Climate variable 1
#top_mod_table[1,6]<- coef(glm_best_NDT5)[2] #Climate variable 2
#top_mod_table[1,7]<- coef(glm_best_NDT5)[3] #Interaction climate variables
#top_mod_table[1,8]<- coef(glm_best_NDT5)[3] #coef_stand_height
#top_mod_table[1,9]<- coef(glm_best_NDT5)[3] #live_stand_volume_125
#top_mod_table[1,10]<- coef(glm_best_NDT5)[4] #proj_age_1
#top_mod_table[1,11]<- coef(glm_best_NDT5)[4] #coefficient vegtypeD
#top_mod_table[1,12]<- coef(glm_best_NDT5)[4] #coefficient vegtypeOP
#top_mod_table[1,13]<- coef(glm_best_NDT5)[4] #coefficient vegtypeS
#top_mod_table[1,14]<- coef(glm_best_NDT5)[4] #coefficient vegtypeTB
#top_mod_table[1,15]<- coef(glm_best_NDT5)[4] #coefficient vegtypeTC
#top_mod_table[1,16]<- coef(glm_best_NDT5)[5] #coefficient vegtypeTM
top_mod_table ##Determine if better way to represent categories for vegtype, and if each climate variable should have its own column

########################## NDT5 Model Selection Complete ###################

```




############# Now repeat for person-caused fires ###########

Now repeat for the entire model selection process for each NDT for person-caused fires. For person caused fires, the variables of interest include:

1. Climate variable(s)
2. vegtype
3. Projected Height (proj_height_1)
4. projected age (proj_age_1)  
5. live_stand_volume_125
6. slope
7. aspect
8. elevation
9. road density (roads_km)

We will include road density in our final model selection and compare AIC for top model with and without road density (while including the top climate and topography model).

First we will create the variable lists that contain all of our variables of interest. This variable list will differ from that for the lightning-caused model, but relevant interactions should remain the same.


```{r}
##Create variable lists to be used in the model loop.
variables_all_p<-c(climate1 = "climate1", climate2 = "climate2", proj_height_1 = "proj_height_1", proj_age_1 = "proj_age_1", live_stand_volume_125 = "live_stand_volume_125", slope = "slope", aspect = "aspect", elevation ="elevation", vegtype = "vegtype", roads_km = "roads_km") #this will apply to NDT1, NDT4 and NDT5

variables_all_p_c1<-c(climate1 = "climate1", proj_height_1 = "proj_height_1", proj_age_1 = "proj_age_1", live_stand_volume_125 = "live_stand_volume_125", slope = "slope", aspect = "aspect", elevation ="elevation", vegtype = "vegtype", roads_km = "roads_km") #This will apply to NDT2 and NDT3


vars.clim<-c("climate1")
vars.clim.vegtype<-c("climate1", "vegtype")
vars.oth<-c("proj_height_1", "proj_age_1", "live_stand_volume_125") 
vars.topo<-c("slope", "aspect", "elevation")


#Also for later with 2 climate variables
vars.clim.vegtype2<-c("climate1", "climate2","vegtype")

##Create interaction for climate and vegtype
inputs.me <- c(vars.clim.vegtype)
inputs.me2 <- c(vars.clim.vegtype2)
```

Now, we will generate two-way interactions for each of these lists. These interactions will be the same as they were for the lightning-caused fire models, so no need to repeat this chunk of code if you already have that loaded.

```{r}

#####1a. For those with one climate variable
#get the names of all possible two-way interactions for climate variable(s) and vegtype.
twoway.ints <- NULL
for (i in 1:(length(inputs.me)-1)) {
  for (j in (i+1):length(inputs.me)) {
     twoway.ints <- cbind(twoway.ints, paste(inputs.me[i], inputs.me[j], sep=":"))
  }
}
twoway.ints
length(twoway.ints)

#
#Create function to determine Powerset for any vector of variable names
## or use rje package
#powerSet <- function(x) {
#   z.list <- NULL
#   for(i in 1:length(x)) {
#      z.list <- append(z.list, combn(x, m=i, simplify=F))
#   }    
#   return(z.list)
#}


#Get variables on own
#complete list of models using non-climate vars
mods.me.tmp <- powerSet(vars.clim.vegtype) 
#add climate vars to all of the above
mods.me.climate <- list()
for (i in 1: length(mods.me.tmp)) {
   mods.me.climate[[i]] <- c(mods.me.tmp[[i]])
}

mods.me.climate


#####1b. For those with two climate variables
#get the names of all possible two-way interactions for climate variable(s) and vegtype.
twoway.ints2 <- NULL
for (i in 1:(length(inputs.me2)-1)) {
  for (j in (i+1):length(inputs.me2)) {
     twoway.ints2 <- cbind(twoway.ints2, paste(inputs.me2[i], inputs.me2[j], sep=":"))
  }
}
twoway.ints2
length(twoway.ints2)

#Get variables on own
#complete list of models using non-climate vars
mods.me.tmp <- powerSet(vars.clim.vegtype2) 
#add climate vars to all of the above
mods.me.climate2 <- list()
for (i in 1: length(mods.me.tmp)) {
   mods.me.climate2[[i]] <- c(mods.me.tmp[[i]])
}

mods.me.climate2

#complete list of two-way interactions
mods.twoway2 <- powerSet(twoway.ints2)
length(mods.twoway2) #7
mods.twoway2

#Finding models in mods.me that accommodate/allow interaction terms in each mods.twoway to be added
mods.inter2 <- list()
counter <- 0
for (i in 1: length(mods.twoway2)) {
   s1 <- unique(unlist( strsplit(mods.twoway2[[i]], split=':', fixed=TRUE) ) )
   for (j in 1: length(mods.me.climate2)) {
      if (all(s1 %in% mods.me.climate2[[j]])==TRUE) {
        counter <- counter + 1
        both <-  c(mods.me.climate2[[j]], mods.twoway2[[i]])
        mods.inter2[[counter]] <- both
      }
   }
}

length(mods.inter2)
mods.inter2



#########2. Now for topography data, get all possible two-way interactions

#get the names of all possible two-way interactions
twoway.intsT <- NULL
for (i in 1:(length(vars.topo)-1)) {
  for (j in (i+1):length(vars.topo)) {
     twoway.intsT <- cbind(twoway.intsT, paste(vars.topo[i], vars.topo[j], sep=":"))
  }
}
twoway.intsT
length(twoway.intsT)

#complete list of models using non-climate vars (topo)
mods.me.tmp <- powerSet(vars.topo) 
#add climate vars to all of the above
mods.meT <- list()
for (i in 1: length(mods.me.tmp)) {
   mods.meT[[i]] <- c(mods.me.tmp[[i]])
}

mods.meT

#complete list of two-way interactions
mods.twowayT <- powerSet(twoway.intsT)
length(mods.twowayT) #7
mods.twowayT

#Finding models in mods.me that accommodate/allow interaction terms in each mods.twoway to be added

mods.interT <- list()
counter <- 0
for (i in 1: length(mods.twowayT)) {
   s1 <- unique(unlist( strsplit(mods.twowayT[[i]], split=':', fixed=TRUE) ) )
   for (j in 1: length(mods.meT)) {
      if (all(s1 %in% mods.meT[[j]])==TRUE) {
        counter <- counter + 1
        both <-  c(mods.meT[[j]], mods.twowayT[[i]])
        mods.interT[[counter]] <- both
      }
   }
}

length(mods.interT)
mods.interT


####3.For other VRI data, get without interactions

#complete list of models using VRI - no interactions
mods.me.tmp <- powerSet(vars.oth) 
#add climate vars to all of the above
mods.me.oth <- list()
for (i in 1: length(mods.me.tmp)) {
   mods.me.oth[[i]] <- c(mods.me.tmp[[i]])
}

mods.me.oth

#Combine
all.poss.mods.clim.vegtype<-c(1, mods.me.climate, twoway.ints)
all.poss.mods.clim.vegtype 
#all.poss.mods.clim.vegtype<-all.poss.mods.clim.vegtype [-2] #Use this line only if there is an odd character(0) added to list
all.poss.mods.clim.vegtype2<-c(1, mods.me.climate2, mods.inter2)
all.poss.mods.clim.vegtype2
#all.poss.mods.clim.vegtype2<-all.poss.mods.clim.vegtype2[-2]
#all.poss.mods.clim.vegtype2<-all.poss.mods.clim.vegtype2[-9]
all.poss.mods.VRI<-c(1, mods.me.oth)
all.poss.mods.VRI
#all.poss.mods.VRI<-all.poss.mods.VRI[-2]
all.poss.mods.topo<-c(1, mods.meT, mods.interT)
all.poss.mods.topo
#all.poss.mods.topo<-all.poss.mods.topo[-10]
#all.poss.mods.topo<-all.poss.mods.topo[-2]

```

Let's work with one NDT at a time. 

Because of the large number of models with all variables included, we will test the climate and vegtype first, then the topography variables. Then we will combine the top models and road density.

```{r}
#View vegtype by NDT
table(dat_person_t$fire_veg, dat_person_t$ntrl_ds)
#We see that there are not enough OP type to be able to do anything with it, so we will remove.

dat_person_t<-subset(dat_person_t, dat_person_t$vegtype!="OP")

```



############### Part 3 of 4 Model Series: Person Caused Fires, Trees ##########

Select first NDT: NDT4 

```{r}
zones1<-c("NDT4") #Do one zone at a time

filenames<-list()
prop<-0.75

########### 1. Climate and vegtype ############
for (g in 1:100){

for (h in 1:length(zones1)) {
  dat2<- dat_person_t %>% dplyr::filter(ntrl_ds ==zones1[h])

for (i in 1: length(all.poss.mods.clim.vegtype2)){
  print(paste((all.poss.mods.clim.vegtype2[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, variables_all_p[i])
  model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, !!variables_all_p)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="fire_pres") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.aic, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.clim.vegtype2, big.mod, df.train=dat1, df.test=Valid)

}
}
}


```


Now extract elements from the output .

```{r}
#terms in each model
x1 <- unlist(sapply(mods.fit, '[', 1))
x1
#Aic for models
x3 <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3
#auc from validation data
x4 <- unlist(sapply(mods.fit, '[', 4))
x4
#combining all as df
tab.sum.climate <- cbind.data.frame(model=x1, edf=x3[,1], aic=x3[,2], auc.valid=x4)
tab.sum.climate$NDT<-c("NDT4")
tab.sum.climate$delta.aic<- tab.sum.climate$aic - (min(tab.sum.climate$aic))
tab.sum.climate 

```


#Now repeat for VRI data


```{r}

########### 2. VRI ############
for (g in 1:100){

for (h in 1:length(zones1)) {
  dat2<- dat_person_t %>% dplyr::filter(ntrl_ds ==zones1[h])

for (i in 1: length(all.poss.mods.VRI)){
  print(paste((all.poss.mods.VRI[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, variables_all_p[i])
  model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, !!variables_all_p)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="fire_pres") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.aic, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.VRI, big.mod, df.train=dat1, df.test=Valid)

}
}
}


```

Now extract elements from the output .

```{r}
#terms in each model
x1b <- unlist(sapply(mods.fit, '[', 1))
x1b
#Aic for models
x3b <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3b
#auc from validation data
x4b <- unlist(sapply(mods.fit, '[', 4))
x4b
#combining all as df
tab.sum.VRI <- cbind.data.frame(model=x1b, edf=x3b[,1], aic=x3b[,2], auc.valid=x4b)
tab.sum.VRI$NDT<-c("NDT4")
tab.sum.VRI$delta.aic<- tab.sum.VRI$aic - (min(tab.sum.VRI$aic))
tab.sum.VRI 

```


#Now repeat for topography

```{r}

########### 3. Topography ############
for (g in 1:100){

for (h in 1:length(zones1)) {
 dat2<- dat_person_t %>% dplyr::filter(ntrl_ds ==zones1[h])

for (i in 1: length(all.poss.mods.topo)){
  print(paste((all.poss.mods.topo[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, variables_all_p[i])
  model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, !!variables_all_p)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="fire_pres") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.aic, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.topo, big.mod, df.train=dat1, df.test=Valid)

}
}
}


```

Now extract elements from the output .

```{r}
#terms in each model
x1c <- unlist(sapply(mods.fit, '[', 1))
x1c
#Aic for models
x3c <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3c
#auc from validation data
x4c <- unlist(sapply(mods.fit, '[', 4))
x4c
#combining all as df
tab.sum.topo <- cbind.data.frame(model=x1c, edf=x3c[,1], aic=x3c[,2], auc.valid=x4c)
tab.sum.topo$NDT<-c("NDT4")
tab.sum.topo$delta.aic<- tab.sum.topo$aic - (min(tab.sum.topo$aic))
tab.sum.topo

```

#Now combine the datatables and save to computer

```{r}
NDT4_p_models<-rbind(tab.sum.climate, tab.sum.VRI, tab.sum.topo)
NDT4_p_models

write.csv(NDT4_p_models, file="D:\\Fire\\fire_data\\raw_data\\NDT4_person_models.csv")
```

Now choose the top variables and create final model. The below code will need to be updated manually, depending on what the results of the above analyses are.

######## UPDATE BELOW #########

```{r}
##### TOP MODEL####
NDT4_t<-dat_person_t %>%
  filter(ntrl_ds=="NDT4")

NDT4_t2<-NDT4_t %>% drop_na(live_stand_volume_125, vegtype, climate1, climate2, proj_height_1)

glm_best_NDT4<- glm(fire_pres ~ scale(climate1)*scale(climate2) +
             scale(live_stand_volume_125) +
               scale(proj_height_1) +
               vegtype, 
           data= NDT4_t2,
           family = binomial,
           na.action=na.omit)

summary(glm_best_NDT4)

# model diagnostic plots
binnedplot (fitted(glm_best_NDT4), 
            residuals(glm_best_NDT4), 
            nclass = NULL, 
            xlab = "Expected Values", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))


NDT4_t2$resids<-resid(glm_best_NDT4)

binnedplot (NDT4_t2$live_stand_volume_125, 
            NDT4_t2$resids, 
            nclass = NULL, 
            xlab = "live stand volume", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))

binnedplot (NDT4_t2$climate1, 
            NDT4_t2$resids, 
            nclass = NULL, 
            xlab = "", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))

# Diagnostic plots look good

# Looking at effect of forest height at the average amount of rainfall in September
plot(NDT4_t2$live_stand_volume_125,NDT4_t2$fire_pres)
curve(invlogit(coef(glm_best_NDT4)[1] +coef(glm_best_NDT4)[2]*mean(NDT4_t2$climate1) + coef(glm_best_NDT4)[3]*x), add=TRUE)

# looking at effect of climate1 at the average forest height.
plot(NDT4_t2$climate1,NDT4_t2$fire_pres)
curve(invlogit(coef(glm_best_NDT4)[1] +coef(glm_best_NDT4)[2]*x + coef(glm_best_NDT4)[3]*mean(NDT4_t2$live_stand_volume_125)), add=TRUE)


# create model table (only do this once) and add the relevant data
top_mod_table <- data.frame (matrix (ncol = 16, nrow = 0))
colnames (top_mod_table) <- c ("ZONE", "TREED", "Model_terms", "intercept", "coef_climate_1", "coef_climate_2", "coef_climate_interaction", "coef_stand_height", "coef_live_stand_volume_125", "coef_proj_age", "coef_vegtypeD", "coef_vegtypeOP", "coef_vegtypeS", "coef_vegtypeTB", "coef_vegtypeTC", "coef_vegtypeTM")



##STILL NEED TO ADD DATA FOR TABLE

##Add data for NDT4
top_mod_table[1,1]<-"NDT4"
top_mod_table[1,2]<-"Y"
top_mod_table[1,3]<-"fire_pres ~ ppt09 + proj_height_1" ######### UPDATE
top_mod_table[1,4]<- coef(glm_best_NDT4)[1] #Intercept
top_mod_table[1,5]<- coef(glm_best_NDT4)[2] #Climate variable 1
#top_mod_table[1,6]<- coef(glm_best_NDT4)[2] #Climate variable 2
#top_mod_table[1,7]<- coef(glm_best_NDT4)[3] #Interaction climate variables
#top_mod_table[1,8]<- coef(glm_best_NDT4)[3] #coef_stand_height
#top_mod_table[1,9]<- coef(glm_best_NDT4)[3] #live_stand_volume_125
#top_mod_table[1,10]<- coef(glm_best_NDT4)[4] #proj_age_1
#top_mod_table[1,11]<- coef(glm_best_NDT4)[4] #coefficient vegtypeD
#top_mod_table[1,12]<- coef(glm_best_NDT4)[4] #coefficient vegtypeOP
#top_mod_table[1,13]<- coef(glm_best_NDT4)[4] #coefficient vegtypeS
#top_mod_table[1,14]<- coef(glm_best_NDT4)[4] #coefficient vegtypeTB
#top_mod_table[1,15]<- coef(glm_best_NDT4)[4] #coefficient vegtypeTC
#top_mod_table[1,16]<- coef(glm_best_NDT4)[5] #coefficient vegtypeTM
top_mod_table ##Determine if better way to represent categories for vegtype, and if each climate variable should have its own column

########################## NDT4 Model Selection Complete ###################

```
 


############### Now choose the next NDT zone and repeat ########
Note: currently doing  those with one climate variable)
Models complete above: NDT4
Models to still do henceforth:NDT1, NDT2, NDT3, NDT5

Select next zone: NDT1

```{r}
zones1<-c("NDT1") #Do one zone at a time

filenames<-list()
prop<-0.75

########### 1. Climate and vegtype ############
for (g in 1:100){

for (h in 1:length(zones1)) {
  dat2<- dat_person_t %>% dplyr::filter(ntrl_ds ==zones1[h])

for (i in 1: length(all.poss.mods.clim.vegtype2)){
  print(paste((all.poss.mods.clim.vegtype2[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, variables_all_p[i])
  model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, !!variables_all_p)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="fire_pres") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.aic, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.clim.vegtype2, big.mod, df.train=dat1, df.test=Valid)

}
}
}


```

Now extract elements from the output .

```{r}
#terms in each model
x1.1 <- unlist(sapply(mods.fit, '[', 1))
x1.1
#Aic for models
x3.1 <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3.1
#auc from validation data
x4.1 <- unlist(sapply(mods.fit, '[', 4))
x4.1
#combining all as df
tab.sum.climate <- cbind.data.frame(model=x1.1, edf=x3.1[,1], aic=x3.1[,2], auc.valid=x4.1)
tab.sum.climate$NDT<-c("NDT1")
tab.sum.climate$delta.aic<- tab.sum.climate$aic - (min(tab.sum.climate$aic))
tab.sum.climate 

```

#Now repeat for VRI data

```{r}

########### 2. VRI ############
for (g in 1:100){

for (h in 1:length(zones1)) {
  dat2<- dat_person_t %>% dplyr::filter(ntrl_ds ==zones1[h])

for (i in 1: length(all.poss.mods.VRI)){
  print(paste((all.poss.mods.VRI[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, variables_all_p[i])
  model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, !!variables_all_p)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="fire_pres") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.aic, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.VRI, big.mod, df.train=dat1, df.test=Valid)

}
}
}


```

Now extract elements from the output .

```{r}
#terms in each model
x1.1b <- unlist(sapply(mods.fit, '[', 1))
x1.1b
#Aic for models
x3.1b <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3.1b
#auc from validation data
x4.1b <- unlist(sapply(mods.fit, '[', 4))
x4.1b
#combining all as df
tab.sum.VRI <- cbind.data.frame(model=x1.1b, edf=x3.1b[,1], aic=x3.1b[,2], auc.valid=x4.1b)
tab.sum.VRI$NDT<-c("NDT1")
tab.sum.VRI$delta.aic<- tab.sum.VRI$aic - (min(tab.sum.VRI$aic))
tab.sum.VRI 

```


#Now repeat for topography

```{r}

########### 3. Topography ############
for (g in 1:100){

for (h in 1:length(zones1)) {
 dat2<- dat_person_t %>% dplyr::filter(ntrl_ds ==zones1[h])

for (i in 1: length(all.poss.mods.topo)){
  print(paste((all.poss.mods.topo[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, variables_all_p[i])
  model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, !!variables_all_p)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="fire_pres") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.aic, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.topo, big.mod, df.train=dat1, df.test=Valid)

}
}
}


```

Now extract elements from the output.

```{r}
#terms in each model
x1.1c <- unlist(sapply(mods.fit, '[', 1))
x1.1c
#Aic for models
x3.1c <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3.1c
#auc from validation data
x4.1c <- unlist(sapply(mods.fit, '[', 4))
x4.1c
#combining all as df
tab.sum.topo <- cbind.data.frame(model=x1.1c, edf=x3.1c[,1], aic=x3.1c[,2], auc.valid=x4.1c)
tab.sum.topo$NDT<-c("NDT1")
tab.sum.topo$delta.aic<- tab.sum.topo$aic - (min(tab.sum.topo$aic))
tab.sum.topo

```

#Now combine the datatables and save to computer

```{r}
NDT1_p_models<-rbind(tab.sum.climate, tab.sum.VRI, tab.sum.topo)
NDT1_p_models

write.csv(NDT1_p_models, file="D:\\Fire\\fire_data\\raw_data\\NDT1_person_models.csv")
```

Now choose the top variables and create final model. The below code will need to be updated manually, depending on what the results of the above analyses are.

######## UPDATE BELOW #########

```{r}
##### TOP MODEL####
NDT1_t<-dat_person_t %>%
  filter(ntrl_ds=="NDT1")

NDT1_t2<-NDT1_t %>% drop_na(live_stand_volume_125, vegtype, climate1, climate2, proj_height_1)

glm_best_NDT1<- glm(fire_pres ~ scale(climate1)*scale(climate2) +
             scale(live_stand_volume_125) +
               scale(proj_height_1) +
               vegtype, 
           data= NDT1_t2,
           family = binomial,
           na.action=na.omit)

summary(glm_best_NDT1)

# model diagnostic plots
binnedplot (fitted(glm_best_NDT1), 
            residuals(glm_best_NDT1), 
            nclass = NULL, 
            xlab = "Expected Values", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))


NDT1_t2$resids<-resid(glm_best_NDT1)

binnedplot (NDT1_t2$live_stand_volume_125, 
            NDT1_t2$resids, 
            nclass = NULL, 
            xlab = "live stand volume", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))

binnedplot (NDT1_t2$climate1, 
            NDT1_t2$resids, 
            nclass = NULL, 
            xlab = "", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))

# Diagnostic plots look good

# Looking at effect of forest height at the average amount of rainfall in September
plot(NDT1_t2$live_stand_volume_125,NDT1_t2$fire_pres)
curve(invlogit(coef(glm_best_NDT1)[1] +coef(glm_best_NDT1)[2]*mean(NDT1_t2$climate1) + coef(glm_best_NDT1)[3]*x), add=TRUE)

# looking at effect of climate1 at the average forest height.
plot(NDT1_t2$climate1,NDT1_t2$fire_pres)
curve(invlogit(coef(glm_best_NDT1)[1] +coef(glm_best_NDT1)[2]*x + coef(glm_best_NDT1)[3]*mean(NDT1_t2$live_stand_volume_125)), add=TRUE)


# create model table (only do this once) and add the relevant data
top_mod_table <- data.frame (matrix (ncol = 16, nrow = 0))
colnames (top_mod_table) <- c ("ZONE", "TREED", "Model_terms", "intercept", "coef_climate_1", "coef_climate_2", "coef_climate_interaction", "coef_stand_height", "coef_live_stand_volume_125", "coef_proj_age", "coef_vegtypeD", "coef_vegtypeOP", "coef_vegtypeS", "coef_vegtypeTB", "coef_vegtypeTC", "coef_vegtypeTM")



##STILL NEED TO ADD DATA FOR TABLE

##Add data for NDT1
top_mod_table[1,1]<-"NDT1"
top_mod_table[1,2]<-"Y"
top_mod_table[1,3]<-"fire_pres ~ ppt09 + proj_height_1" ######### UPDATE
top_mod_table[1,4]<- coef(glm_best_NDT1)[1] #Intercept
top_mod_table[1,5]<- coef(glm_best_NDT1)[2] #Climate variable 1
#top_mod_table[1,6]<- coef(glm_best_NDT1)[2] #Climate variable 2
#top_mod_table[1,7]<- coef(glm_best_NDT1)[3] #Interaction climate variables
#top_mod_table[1,8]<- coef(glm_best_NDT1)[3] #coef_stand_height
#top_mod_table[1,9]<- coef(glm_best_NDT1)[3] #live_stand_volume_125
#top_mod_table[1,10]<- coef(glm_best_NDT1)[4] #proj_age_1
#top_mod_table[1,11]<- coef(glm_best_NDT1)[4] #coefficient vegtypeD
#top_mod_table[1,12]<- coef(glm_best_NDT1)[4] #coefficient vegtypeOP
#top_mod_table[1,13]<- coef(glm_best_NDT1)[4] #coefficient vegtypeS
#top_mod_table[1,14]<- coef(glm_best_NDT1)[4] #coefficient vegtypeTB
#top_mod_table[1,15]<- coef(glm_best_NDT1)[4] #coefficient vegtypeTC
#top_mod_table[1,16]<- coef(glm_best_NDT1)[5] #coefficient vegtypeTM
top_mod_table ##Determine if better way to represent categories for vegtype, and if each climate variable should have its own column

########################## NDT1 Model Selection Complete ###################



```



############### Now choose the next NDT zone and repeat ########
Note: currently doing  those with one climate variable)
Models complete above: NDT4, NDT1
Models to still do henceforth:NDT2, NDT3, NDT5


Select next zone: NDT2 (ONLY ONE CLIMATE VARIABLE)


```{r}
zones1<-c("NDT2") #Do one zone at a time

filenames<-list()
prop<-0.75

########### 1. Climate and vegtype ############
for (g in 1:100){

for (h in 1:length(zones1)) {
  dat2<- dat_person_t %>% dplyr::filter(ntrl_ds ==zones1[h])

for (i in 1: length(all.poss.mods.clim.vegtype)){
  print(paste((all.poss.mods.clim.vegtype[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, variables_all_p[i])
  model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, !!variables_all_p_c1)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="fire_pres") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.aic, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.clim.vegtype, big.mod, df.train=dat1, df.test=Valid)

}
}
}


```

Now extract elements from the output .

```{r}
#terms in each model
x1.2 <- unlist(sapply(mods.fit, '[', 1))
x1.2
#Aic for models
x3.2 <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3.2
#auc from validation data
x4.2 <- unlist(sapply(mods.fit, '[', 4))
x4.2
#combining all as df
tab.sum.climate <- cbind.data.frame(model=x1.2, edf=x3.2[,1], aic=x3.2[,2], auc.valid=x4.2)
tab.sum.climate$NDT<-c("NDT2")
tab.sum.climate$delta.aic<- tab.sum.climate$aic - (min(tab.sum.climate$aic))
tab.sum.climate 

```


#Now repeat for VRI data


```{r}

########### 2. VRI ############
for (g in 1:100){

for (h in 1:length(zones1)) {
  dat2<- dat_person_t %>% dplyr::filter(ntrl_ds ==zones1[h])

for (i in 1: length(all.poss.mods.VRI)){
  print(paste((all.poss.mods.VRI[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, variables_all_p[i])
  model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, !!variables_all_p_c1)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="fire_pres") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.aic, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.VRI, big.mod, df.train=dat1, df.test=Valid)

}
}
}


```

Now extract elements from the output .

```{r}
#terms in each model
x1.2b <- unlist(sapply(mods.fit, '[', 1))
x1.2b
#Aic for models
x3.2b <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3.2b
#auc from validation data
x4.2b <- unlist(sapply(mods.fit, '[', 4))
x4.2b
#combining all as df
tab.sum.VRI <- cbind.data.frame(model=x1.2b, edf=x3.2b[,1], aic=x3.2b[,2], auc.valid=x4.2b)
tab.sum.VRI$NDT<-c("NDT2")
tab.sum.VRI$delta.aic<- tab.sum.VRI$aic - (min(tab.sum.VRI$aic))
tab.sum.VRI 

```


#Now repeat for topography

```{r}

########### 3. Topography ############
for (g in 1:100){

for (h in 1:length(zones1)) {
 dat2<- dat_person_t %>% dplyr::filter(ntrl_ds ==zones1[h])

for (i in 1: length(all.poss.mods.topo)){
  print(paste((all.poss.mods.topo[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, variables_all_p[i])
  model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, !!variables_all_p_c1)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="fire_pres") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.aic, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.topo, big.mod, df.train=dat1, df.test=Valid)

}
}
}


```

Now extract elements from the output .

```{r}
#terms in each model
x1.2c <- unlist(sapply(mods.fit, '[', 1))
x1.2c
#Aic for models
x3.2c <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3.2c
#auc from validation data
x4.2c <- unlist(sapply(mods.fit, '[', 4))
x4.2c
#combining all as df
tab.sum.topo <- cbind.data.frame(model=x1.2c, edf=x3.2c[,1], aic=x3.2c[,2], auc.valid=x4.2c)
tab.sum.topo$NDT<-c("NDT2")
tab.sum.topo$delta.aic<- tab.sum.topo$aic - (min(tab.sum.topo$aic))
tab.sum.topo

```

#Now combine the datatables and save to computer

```{r}
NDT2_p_models<-rbind(tab.sum.climate, tab.sum.VRI, tab.sum.topo)
NDT2_p_models

write.csv(NDT2_p_models, file="D:\\Fire\\fire_data\\raw_data\\NDT2_person_models.csv")
```

Now choose the top variables and create final model. The below code will need to be updated manually, depending on what the results of the above analyses are.

######## UPDATE BELOW #########

```{r}
##### TOP MODEL####
NDT2_t<-dat_person_t %>%
  filter(ntrl_ds=="NDT2")

NDT2_t2<-NDT2_t %>% drop_na(live_stand_volume_125, vegtype, climate1, climate2, proj_height_1)

glm_best_NDT2<- glm(fire_pres ~ scale(climate1)*scale(climate2) +
             scale(live_stand_volume_125) +
               scale(proj_height_1) +
               vegtype, 
           data= NDT2_t2,
           family = binomial,
           na.action=na.omit)

summary(glm_best_NDT2)

# model diagnostic plots
binnedplot (fitted(glm_best_NDT2), 
            residuals(glm_best_NDT2), 
            nclass = NULL, 
            xlab = "Expected Values", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))


NDT2_t2$resids<-resid(glm_best_NDT2)

binnedplot (NDT2_t2$live_stand_volume_125, 
            NDT2_t2$resids, 
            nclass = NULL, 
            xlab = "live stand volume", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))

binnedplot (NDT2_t2$climate1, 
            NDT2_t2$resids, 
            nclass = NULL, 
            xlab = "", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))

# Diagnostic plots look good

# Looking at effect of forest height at the average amount of rainfall in September
plot(NDT2_t2$live_stand_volume_125,NDT2_t2$fire_pres)
curve(invlogit(coef(glm_best_NDT2)[1] +coef(glm_best_NDT2)[2]*mean(NDT2_t2$climate1) + coef(glm_best_NDT2)[3]*x), add=TRUE)

# looking at effect of climate1 at the average forest height.
plot(NDT2_t2$climate1,NDT2_t2$fire_pres)
curve(invlogit(coef(glm_best_NDT2)[1] +coef(glm_best_NDT2)[2]*x + coef(glm_best_NDT2)[3]*mean(NDT2_t2$live_stand_volume_125)), add=TRUE)


# create model table (only do this once) and add the relevant data
top_mod_table <- data.frame (matrix (ncol = 16, nrow = 0))
colnames (top_mod_table) <- c ("ZONE", "TREED", "Model_terms", "intercept", "coef_climate_1", "coef_climate_2", "coef_climate_interaction", "coef_stand_height", "coef_live_stand_volume_125", "coef_proj_age", "coef_vegtypeD", "coef_vegtypeOP", "coef_vegtypeS", "coef_vegtypeTB", "coef_vegtypeTC", "coef_vegtypeTM")



##STILL NEED TO ADD DATA FOR TABLE

##Add data for NDT2
top_mod_table[1,1]<-"NDT2"
top_mod_table[1,2]<-"Y"
top_mod_table[1,3]<-"fire_pres ~ ppt09 + proj_height_1" ######### UPDATE
top_mod_table[1,4]<- coef(glm_best_NDT2)[1] #Intercept
top_mod_table[1,5]<- coef(glm_best_NDT2)[2] #Climate variable 1
#top_mod_table[1,6]<- coef(glm_best_NDT2)[2] #Climate variable 2
#top_mod_table[1,7]<- coef(glm_best_NDT2)[3] #Interaction climate variables
#top_mod_table[1,8]<- coef(glm_best_NDT2)[3] #coef_stand_height
#top_mod_table[1,9]<- coef(glm_best_NDT2)[3] #live_stand_volume_125
#top_mod_table[1,10]<- coef(glm_best_NDT2)[4] #proj_age_1
#top_mod_table[1,11]<- coef(glm_best_NDT2)[4] #coefficient vegtypeD
#top_mod_table[1,12]<- coef(glm_best_NDT2)[4] #coefficient vegtypeOP
#top_mod_table[1,13]<- coef(glm_best_NDT2)[4] #coefficient vegtypeS
#top_mod_table[1,14]<- coef(glm_best_NDT2)[4] #coefficient vegtypeTB
#top_mod_table[1,15]<- coef(glm_best_NDT2)[4] #coefficient vegtypeTC
#top_mod_table[1,16]<- coef(glm_best_NDT2)[5] #coefficient vegtypeTM
top_mod_table ##Determine if better way to represent categories for vegtype, and if each climate variable should have its own column

########################## NDT2 Model Selection Complete ###################



```


############### Now choose the next NDT zone and repeat ########
Note: currently doing  those with one climate variable)
Models complete above: NDT4, NDT1, NDT2
Models to still do henceforth: NDT3, NDT5


Select next zone: NDT3 (only 1 climate variable!)


```{r}
zones1<-c("NDT3") #Do one zone at a time

filenames<-list()
prop<-0.75

########### 1. Climate and vegtype ############
for (g in 1:100){

for (h in 1:length(zones1)) {
  dat2<- dat_person_t %>% dplyr::filter(ntrl_ds ==zones1[h])

for (i in 1: length(all.poss.mods.clim.vegtype)){
  print(paste((all.poss.mods.clim.vegtype[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, variables_all_p[i])
  model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, !!variables_all_p_c1)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="fire_pres") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.aic, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.clim.vegtype, big.mod, df.train=dat1, df.test=Valid)

}
}
}


```

Now extract elements from the output .

```{r}
#terms in each model
x1.3 <- unlist(sapply(mods.fit, '[', 1))
x1.3
#Aic for models
x3.3 <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3.3
#auc from validation data
x4.3 <- unlist(sapply(mods.fit, '[', 4))
x4.3
#combining all as df
tab.sum.climate <- cbind.data.frame(model=x1.3, edf=x3.3[,1], aic=x3.3[,2], auc.valid=x4.3)
tab.sum.climate$NDT<-c("NDT3")
tab.sum.climate$delta.aic<- tab.sum.climate$aic - (min(tab.sum.climate$aic))
tab.sum.climate 

```


#Now repeat for VRI data


```{r}

########### 2. VRI ############
for (g in 1:100){

for (h in 1:length(zones1)) {
  dat2<- dat_person_t %>% dplyr::filter(ntrl_ds ==zones1[h])

for (i in 1: length(all.poss.mods.VRI)){
  print(paste((all.poss.mods.VRI[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, variables_all_p[i])
  model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, !!variables_all_p_c1)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="fire_pres") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.aic, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.VRI, big.mod, df.train=dat1, df.test=Valid)

}
}
}


```

Now extract elements from the output .

```{r}
#terms in each model
x1.3b <- unlist(sapply(mods.fit, '[', 1))
x1.3b
#Aic for models
x3.3b <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3.3b
#auc from validation data
x4.3b <- unlist(sapply(mods.fit, '[', 4))
x4.3b
#combining all as df
tab.sum.VRI <- cbind.data.frame(model=x1.3b, edf=x3.3b[,1], aic=x3.3b[,2], auc.valid=x4.3b)
tab.sum.VRI$NDT<-c("NDT3")
tab.sum.VRI$delta.aic<- tab.sum.VRI$aic - (min(tab.sum.VRI$aic))
tab.sum.VRI 

```


#Now repeat for topography

```{r}

########### 3. Topography ############
for (g in 1:100){

for (h in 1:length(zones1)) {
 dat2<- dat_person_t %>% dplyr::filter(ntrl_ds ==zones1[h])

for (i in 1: length(all.poss.mods.topo)){
  print(paste((all.poss.mods.topo[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, variables_all_p[i])
  model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, !!variables_all_p_c1)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="fire_pres") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.aic, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.topo, big.mod, df.train=dat1, df.test=Valid)

}
}
}


```

Now extract elements from the output .

```{r}
#terms in each model
x1.3c <- unlist(sapply(mods.fit, '[', 1))
x1.3c
#Aic for models
x3.3c <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3.3c
#auc from validation data
x4.3c <- unlist(sapply(mods.fit, '[', 4))
x4.3c
#combining all as df
tab.sum.topo <- cbind.data.frame(model=x1.3c, edf=x3.3c[,1], aic=x3.3c[,2], auc.valid=x4.3c)
tab.sum.topo$NDT<-c("NDT3")
tab.sum.topo$delta.aic<- tab.sum.topo$aic - (min(tab.sum.topo$aic))
tab.sum.topo

```

#Now combine the datatables and save to computer

```{r}
NDT3_p_models<-rbind(tab.sum.climate, tab.sum.VRI, tab.sum.topo)
NDT3_p_models

write.csv(NDT3_p_models, file="D:\\Fire\\fire_data\\raw_data\\NDT3_person_models.csv")
```

Now choose the top variables and create final model. The below code will need to be updated manually, depending on what the results of the above analyses are.

######## UPDATE BELOW #########

```{r}
##### TOP MODEL####
NDT3_t<-dat_person_t %>%
  filter(ntrl_ds=="NDT3")

NDT3_t2<-NDT3_t %>% drop_na(live_stand_volume_125, vegtype, climate1, climate2, proj_height_1)

glm_best_NDT3<- glm(fire_pres ~ scale(climate1)*scale(climate2) +
             scale(live_stand_volume_125) +
               scale(proj_height_1) +
               vegtype, 
           data= NDT3_t2,
           family = binomial,
           na.action=na.omit)

summary(glm_best_NDT3)

# model diagnostic plots
binnedplot (fitted(glm_best_NDT3), 
            residuals(glm_best_NDT3), 
            nclass = NULL, 
            xlab = "Expected Values", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))


NDT3_t2$resids<-resid(glm_best_NDT3)

binnedplot (NDT3_t2$live_stand_volume_125, 
            NDT3_t2$resids, 
            nclass = NULL, 
            xlab = "live stand volume", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))

binnedplot (NDT3_t2$climate1, 
            NDT3_t2$resids, 
            nclass = NULL, 
            xlab = "", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))

# Diagnostic plots look good

# Looking at effect of forest height at the average amount of rainfall in September
plot(NDT3_t2$live_stand_volume_125,NDT3_t2$fire_pres)
curve(invlogit(coef(glm_best_NDT3)[1] +coef(glm_best_NDT3)[2]*mean(NDT3_t2$climate1) + coef(glm_best_NDT3)[3]*x), add=TRUE)

# looking at effect of climate1 at the average forest height.
plot(NDT3_t2$climate1,NDT3_t2$fire_pres)
curve(invlogit(coef(glm_best_NDT3)[1] +coef(glm_best_NDT3)[2]*x + coef(glm_best_NDT3)[3]*mean(NDT3_t2$live_stand_volume_125)), add=TRUE)


# create model table (only do this once) and add the relevant data
top_mod_table <- data.frame (matrix (ncol = 16, nrow = 0))
colnames (top_mod_table) <- c ("ZONE", "TREED", "Model_terms", "intercept", "coef_climate_1", "coef_climate_2", "coef_climate_interaction", "coef_stand_height", "coef_live_stand_volume_125", "coef_proj_age", "coef_vegtypeD", "coef_vegtypeOP", "coef_vegtypeS", "coef_vegtypeTB", "coef_vegtypeTC", "coef_vegtypeTM")



##STILL NEED TO ADD DATA FOR TABLE

##Add data for NDT3
top_mod_table[1,1]<-"NDT3"
top_mod_table[1,2]<-"Y"
top_mod_table[1,3]<-"fire_pres ~ ppt09 + proj_height_1" ######### UPDATE
top_mod_table[1,4]<- coef(glm_best_NDT3)[1] #Intercept
top_mod_table[1,5]<- coef(glm_best_NDT3)[2] #Climate variable 1
#top_mod_table[1,6]<- coef(glm_best_NDT3)[2] #Climate variable 2
#top_mod_table[1,7]<- coef(glm_best_NDT3)[3] #Interaction climate variables
#top_mod_table[1,8]<- coef(glm_best_NDT3)[3] #coef_stand_height
#top_mod_table[1,9]<- coef(glm_best_NDT3)[3] #live_stand_volume_125
#top_mod_table[1,10]<- coef(glm_best_NDT3)[4] #proj_age_1
#top_mod_table[1,11]<- coef(glm_best_NDT3)[4] #coefficient vegtypeD
#top_mod_table[1,12]<- coef(glm_best_NDT3)[4] #coefficient vegtypeOP
#top_mod_table[1,13]<- coef(glm_best_NDT3)[4] #coefficient vegtypeS
#top_mod_table[1,14]<- coef(glm_best_NDT3)[4] #coefficient vegtypeTB
#top_mod_table[1,15]<- coef(glm_best_NDT3)[4] #coefficient vegtypeTC
#top_mod_table[1,16]<- coef(glm_best_NDT3)[5] #coefficient vegtypeTM
top_mod_table ##Determine if better way to represent categories for vegtype, and if each climate variable should have its own column

########################## NDT3 Model Selection Complete ###################



```



############### Now choose the next NDT zone and repeat ########
Note: currently doing  those with one climate variable)
Models complete above: NDT4, NDT1, NDT2, NDT3
Models to still do henceforth: NDT5


Select next zone: NDT5


```{r}
zones1<-c("NDT5") #Do one zone at a time

filenames<-list()
prop<-0.75

########### 1. Climate and vegtype ############
for (g in 1:100){

for (h in 1:length(zones1)) {
  dat2<- dat_person_t %>% dplyr::filter(ntrl_ds ==zones1[h])

for (i in 1: length(all.poss.mods.clim.vegtype2)){
  print(paste((all.poss.mods.clim.vegtype2[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, variables_all_p[i])
  model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, !!variables_all_p)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="fire_pres") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.aic, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.clim.vegtype2, big.mod, df.train=dat1, df.test=Valid)

}
}
}


```

Now extract elements from the output .

```{r}
#terms in each model
x1.5 <- unlist(sapply(mods.fit, '[', 1))
x1.5
#Aic for models
x3.5 <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3.5
#auc from validation data
x4.5 <- unlist(sapply(mods.fit, '[', 4))
x4.5
#combining all as df
tab.sum.climate <- cbind.data.frame(model=x1.5, edf=x3.5[,1], aic=x3.5[,2], auc.valid=x4.5)
tab.sum.climate$NDT<-c("NDT5")
tab.sum.climate$delta.aic<- tab.sum.climate$aic - (min(tab.sum.climate$aic))
tab.sum.climate 

```


#Now repeat for VRI data


```{r}

########### 2. VRI ############
for (g in 1:100){

for (h in 1:length(zones1)) {
  dat2<- dat_person_t %>% dplyr::filter(ntrl_ds ==zones1[h])

for (i in 1: length(all.poss.mods.VRI)){
  print(paste((all.poss.mods.VRI[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, variables_all_p[i])
  model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, !!variables_all_p)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="fire_pres") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.aic, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.VRI, big.mod, df.train=dat1, df.test=Valid)

}
}
}


```

Now extract elements from the output .

```{r}
#terms in each model
x1.5b <- unlist(sapply(mods.fit, '[', 1))
x1.5b
#Aic for models
x3.5b <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3.5b
#auc from validation data
x4.5b <- unlist(sapply(mods.fit, '[', 4))
x4.5b
#combining all as df
tab.sum.VRI <- cbind.data.frame(model=x1.5b, edf=x3.5b[,1], aic=x3.5b[,2], auc.valid=x4.5b)
tab.sum.VRI$NDT<-c("NDT5")
tab.sum.VRI$delta.aic<- tab.sum.VRI$aic - (min(tab.sum.VRI$aic))
tab.sum.VRI 

```


#Now repeat for topography

```{r}

########### 3. Topography ############
for (g in 1:100){

for (h in 1:length(zones1)) {
 dat2<- dat_person_t %>% dplyr::filter(ntrl_ds ==zones1[h])

for (i in 1: length(all.poss.mods.topo)){
  print(paste((all.poss.mods.topo[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, variables_all_p[i])
  model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, !!variables_all_p)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="fire_pres") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.aic, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.topo, big.mod, df.train=dat1, df.test=Valid)

}
}
}


```

Now extract elements from the output .

```{r}
#terms in each model
x1.5c <- unlist(sapply(mods.fit, '[', 1))
x1.5c
#Aic for models
x3.5c <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3.5c
#auc from validation data
x4.5c <- unlist(sapply(mods.fit, '[', 4))
x4.5c
#combining all as df
tab.sum.topo <- cbind.data.frame(model=x1.5c, edf=x3.5c[,1], aic=x3.5c[,2], auc.valid=x4.5c)
tab.sum.topo$NDT<-c("NDT5")
tab.sum.topo$delta.aic<- tab.sum.topo$aic - (min(tab.sum.topo$aic))
tab.sum.topo

```

#Now combine the datatables and save to computer

```{r}
NDT5_p_models<-rbind(tab.sum.climate, tab.sum.VRI, tab.sum.topo)
NDT5_p_models

write.csv(NDT5_p_models, file="D:\\Fire\\fire_data\\raw_data\\NDT5_person_models.csv")
```

Now choose the top variables and create final model. The below code will need to be updated manually, depending on what the results of the above analyses are.

######## UPDATE BELOW #########

```{r}
##### TOP MODEL####
NDT5_t<-dat_person_t %>%
  filter(ntrl_ds=="NDT5")

NDT5_t2<-NDT5_t %>% drop_na(live_stand_volume_125, vegtype, climate1, climate2, proj_height_1)

glm_best_NDT5<- glm(fire_pres ~ scale(climate1)*scale(climate2) +
             scale(live_stand_volume_125) +
               scale(proj_height_1) +
               vegtype, 
           data= NDT5_t2,
           family = binomial,
           na.action=na.omit)

summary(glm_best_NDT5)

# model diagnostic plots
binnedplot (fitted(glm_best_NDT5), 
            residuals(glm_best_NDT5), 
            nclass = NULL, 
            xlab = "Expected Values", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))


NDT5_t2$resids<-resid(glm_best_NDT5)

binnedplot (NDT5_t2$live_stand_volume_125, 
            NDT5_t2$resids, 
            nclass = NULL, 
            xlab = "live stand volume", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))

binnedplot (NDT5_t2$climate1, 
            NDT5_t2$resids, 
            nclass = NULL, 
            xlab = "", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))

# Diagnostic plots look good

# Looking at effect of forest height at the average amount of rainfall in September
plot(NDT5_t2$live_stand_volume_125,NDT5_t2$fire_pres)
curve(invlogit(coef(glm_best_NDT5)[1] +coef(glm_best_NDT5)[2]*mean(NDT5_t2$climate1) + coef(glm_best_NDT5)[3]*x), add=TRUE)

# looking at effect of climate1 at the average forest height.
plot(NDT5_t2$climate1,NDT5_t2$fire_pres)
curve(invlogit(coef(glm_best_NDT5)[1] +coef(glm_best_NDT5)[2]*x + coef(glm_best_NDT5)[3]*mean(NDT5_t2$live_stand_volume_125)), add=TRUE)


# create model table (only do this once) and add the relevant data
top_mod_table <- data.frame (matrix (ncol = 16, nrow = 0))
colnames (top_mod_table) <- c ("ZONE", "TREED", "Model_terms", "intercept", "coef_climate_1", "coef_climate_2", "coef_climate_interaction", "coef_stand_height", "coef_live_stand_volume_125", "coef_proj_age", "coef_vegtypeD", "coef_vegtypeOP", "coef_vegtypeS", "coef_vegtypeTB", "coef_vegtypeTC", "coef_vegtypeTM")



##STILL NEED TO ADD DATA FOR TABLE

##Add data for NDT5
top_mod_table[1,1]<-"NDT5"
top_mod_table[1,2]<-"Y"
top_mod_table[1,3]<-"fire_pres ~ ppt09 + proj_height_1" ######### UPDATE
top_mod_table[1,4]<- coef(glm_best_NDT5)[1] #Intercept
top_mod_table[1,5]<- coef(glm_best_NDT5)[2] #Climate variable 1
#top_mod_table[1,6]<- coef(glm_best_NDT5)[2] #Climate variable 2
#top_mod_table[1,7]<- coef(glm_best_NDT5)[3] #Interaction climate variables
#top_mod_table[1,8]<- coef(glm_best_NDT5)[3] #coef_stand_height
#top_mod_table[1,9]<- coef(glm_best_NDT5)[3] #live_stand_volume_125
#top_mod_table[1,10]<- coef(glm_best_NDT5)[4] #proj_age_1
#top_mod_table[1,11]<- coef(glm_best_NDT5)[4] #coefficient vegtypeD
#top_mod_table[1,12]<- coef(glm_best_NDT5)[4] #coefficient vegtypeOP
#top_mod_table[1,13]<- coef(glm_best_NDT5)[4] #coefficient vegtypeS
#top_mod_table[1,14]<- coef(glm_best_NDT5)[4] #coefficient vegtypeTB
#top_mod_table[1,15]<- coef(glm_best_NDT5)[4] #coefficient vegtypeTC
#top_mod_table[1,16]<- coef(glm_best_NDT5)[5] #coefficient vegtypeTM
top_mod_table ##Determine if better way to represent categories for vegtype, and if each climate variable should have its own column

########################## NDT5 Model Selection Complete ###################



```




############### Part 4 of 4 Model Series: Person Caused Fires, No Trees ##########

Because these areas are predominately not full of trees, we will ignore the VRI. Some locations will still have some VRI attributes because trees may exist on <50% of the plot, but many plots will have no VRI attributes. So we will ignore the VRI results for this section.

For person caused fires with no trees, the variables of interest include:

1. Climate variable(s)
2. vegtype
3. slope
4. aspect (cos)
5. elevation
6. road density (roads_km2)

Interactions of interest: two-way interactions between climate (1) and vegtype (2); two-way interactions between topography measures (3-5).

```{r}
table(dat_person_nt$vegtype, dat_person_nt$ntrl_ds)
table(dat_person_nt$ntrl_ds, dat_person_nt$fire_veg)

#Note, running below, we encounter problems because the Disturbed type gets unequally allocated between training and validation datasets, despite asking it to partition by fire_veg. Unsure how to fix.
```


===

Select first NDT: NDT4 

The loop for NDT4 kept coming up with an error in which "new level vegtype D not present", or something along those lines, so we are performing the below code to attempt to get this it work despite this error message. This does not happen for any other grouping since "fire_veg" was created to resolve this problem that had arisen prior to the creation of "fire-veg".

```{r}
dat_person_nt_NDT4<-subset(dat_person_nt, dat_person_nt$ntrl_ds=="NDT4")
head(dat_person_nt_NDT4)
table(dat_person_nt_NDT4$fire_veg, dat_person_nt_NDT4$ntrl_ds)

trainIndex <- createDataPartition(dat_person_nt_NDT4$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)

   dat1 <- dat_person_nt_NDT4[ trainIndex,]
   Valid <- dat_person_nt_NDT4[-trainIndex,]
   
   table(dat1$fire_veg, dat1$ntrl_ds)
   table(Valid$fire_veg, Valid$ntrl_ds)

```


```{r}
zones1<-c("NDT4") #Do one zone at a time

#filenames<-list()
#prop<-0.75

########### 1. Climate and vegtype ############
for (g in 1:100){


#  for (h in 1:length(zones1)) {
#  dat2<- dat_person_nt %>% dplyr::filter(ntrl_ds ==zones1[h])
  
for (h in 1:length(zones1)) {
  dat2<- dat_person_nt_NDT4 %>% dplyr::filter(ntrl_ds ==zones1[h])

for (i in 1: length(all.poss.mods.clim.vegtype2)){
  print(paste((all.poss.mods.clim.vegtype2[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, variables_all_p[i])
 # model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, !!variables_all_p)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
#  trainIndex <- createDataPartition(model_dat$fire_veg, p = prop,
 #                                   list = FALSE,
  #                                  times = 1)
  
   #dat1 <- model_dat[ trainIndex,]
   #Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="fire_pres") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.aic, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.clim.vegtype2, big.mod, df.train=dat1, df.test=Valid)

}
}
}


```

Now extract elements from the output .

```{r}
#terms in each model
x1 <- unlist(sapply(mods.fit, '[', 1))
x1
#Aic for models
x3 <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3
#auc from validation data
x4 <- unlist(sapply(mods.fit, '[', 4))
x4
#combining all as df
tab.sum.climate.nt <- cbind.data.frame(model=x1, edf=x3[,1], aic=x3[,2], auc.valid=x4)
tab.sum.climate.nt$NDT<-c("NDT4 No trees")
tab.sum.climate.nt$delta.aic<- tab.sum.climate.nt$aic - (min(tab.sum.climate.nt$aic))
tab.sum.climate.nt 

```


#Now repeat for topography

```{r}

########### 2. Topography ############
for (g in 1:100){

for (h in 1:length(zones1)) {
 dat2<- dat_person_nt %>% dplyr::filter(ntrl_ds ==zones1[h])

for (i in 1: length(all.poss.mods.topo)){
  print(paste((all.poss.mods.topo[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, variables_all_p[i])
  model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, !!variables_all_p)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="fire_pres") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.aic, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.topo, big.mod, df.train=dat1, df.test=Valid)

}
}
}


```

Now extract elements from the output .

```{r}
#terms in each model
x1c <- unlist(sapply(mods.fit, '[', 1))
x1c
#Aic for models
x3c <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3c
#auc from validation data
x4c <- unlist(sapply(mods.fit, '[', 4))
x4c
#combining all as df
tab.sum.topo.nt <- cbind.data.frame(model=x1c, edf=x3c[,1], aic=x3c[,2], auc.valid=x4c)
tab.sum.topo.nt$NDT<-c("NDT4 No trees")
tab.sum.topo.nt$delta.aic<- tab.sum.topo.nt$aic - (min(tab.sum.topo.nt$aic))
tab.sum.topo.nt

```

#Now combine the datatables and save to computer

```{r}
NDT4_p_models_nt<-rbind(tab.sum.climate.nt, tab.sum.topo.nt)
NDT4_p_models_nt

write.csv(NDT4_p_models_nt, file="D:\\Fire\\fire_data\\raw_data\\NDT4_person_models_nt.csv")
```

Now choose the top variables and create final model. The below code will need to be updated manually, depending on what the results of the above analyses are.

######## UPDATE BELOW #########

```{r}
##### TOP MODEL####
NDT4_t<-dat_person_nt %>%
  filter(ntrl_ds=="NDT4")

NDT4_t2<-NDT4_t %>% drop_na(live_stand_volume_125, vegtype, climate1, climate2, proj_height_1)

glm_best_NDT4<- glm(fire_pres ~ scale(climate1)*scale(climate2) +
             scale(live_stand_volume_125) +
               scale(proj_height_1) +
               vegtype, 
           data= NDT4_t2,
           family = binomial,
           na.action=na.omit)

summary(glm_best_NDT4)

# model diagnostic plots
binnedplot (fitted(glm_best_NDT4), 
            residuals(glm_best_NDT4), 
            nclass = NULL, 
            xlab = "Expected Values", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))


NDT4_t2$resids<-resid(glm_best_NDT4)

binnedplot (NDT4_t2$live_stand_volume_125, 
            NDT4_t2$resids, 
            nclass = NULL, 
            xlab = "live stand volume", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))

binnedplot (NDT4_t2$climate1, 
            NDT4_t2$resids, 
            nclass = NULL, 
            xlab = "", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))

# Diagnostic plots look good

# Looking at effect of forest height at the average amount of rainfall in September
plot(NDT4_t2$live_stand_volume_125,NDT4_t2$fire_pres)
curve(invlogit(coef(glm_best_NDT4)[1] +coef(glm_best_NDT4)[2]*mean(NDT4_t2$climate1) + coef(glm_best_NDT4)[3]*x), add=TRUE)

# looking at effect of climate1 at the average forest height.
plot(NDT4_t2$climate1,NDT4_t2$fire_pres)
curve(invlogit(coef(glm_best_NDT4)[1] +coef(glm_best_NDT4)[2]*x + coef(glm_best_NDT4)[3]*mean(NDT4_t2$live_stand_volume_125)), add=TRUE)


# create model table (only do this once) and add the relevant data
top_mod_table <- data.frame (matrix (ncol = 16, nrow = 0))
colnames (top_mod_table) <- c ("ZONE", "TREED", "Model_terms", "intercept", "coef_climate_1", "coef_climate_2", "coef_climate_interaction", "coef_stand_height", "coef_live_stand_volume_125", "coef_proj_age", "coef_vegtypeD", "coef_vegtypeOP", "coef_vegtypeS", "coef_vegtypeTB", "coef_vegtypeTC", "coef_vegtypeTM")



##STILL NEED TO ADD DATA FOR TABLE

##Add data for NDT4
top_mod_table[1,1]<-"NDT4"
top_mod_table[1,2]<-"Y"
top_mod_table[1,3]<-"fire_pres ~ ppt09 + proj_height_1" ######### UPDATE
top_mod_table[1,4]<- coef(glm_best_NDT4)[1] #Intercept
top_mod_table[1,5]<- coef(glm_best_NDT4)[2] #Climate variable 1
#top_mod_table[1,6]<- coef(glm_best_NDT4)[2] #Climate variable 2
#top_mod_table[1,7]<- coef(glm_best_NDT4)[3] #Interaction climate variables
#top_mod_table[1,8]<- coef(glm_best_NDT4)[3] #coef_stand_height
#top_mod_table[1,9]<- coef(glm_best_NDT4)[3] #live_stand_volume_125
#top_mod_table[1,10]<- coef(glm_best_NDT4)[4] #proj_age_1
#top_mod_table[1,11]<- coef(glm_best_NDT4)[4] #coefficient vegtypeD
#top_mod_table[1,12]<- coef(glm_best_NDT4)[4] #coefficient vegtypeOP
#top_mod_table[1,13]<- coef(glm_best_NDT4)[4] #coefficient vegtypeS
#top_mod_table[1,14]<- coef(glm_best_NDT4)[4] #coefficient vegtypeTB
#top_mod_table[1,15]<- coef(glm_best_NDT4)[4] #coefficient vegtypeTC
#top_mod_table[1,16]<- coef(glm_best_NDT4)[5] #coefficient vegtypeTM
top_mod_table ##Determine if better way to represent categories for vegtype, and if each climate variable should have its own column

########################## NDT4 Model Selection Complete ###################

```
 
############### Now choose the next NDT zone and repeat ########
Note: currently doing  those with one climate variable)
Models complete above: NDT4
Models to still do henceforth:NDT1, NDT2, NDT3, NDT5


Select next zone: NDT1


```{r}
zones1<-c("NDT1") #Do one zone at a time

filenames<-list()
prop<-0.75

########### 1. Climate and vegtype ############
for (g in 1:100){

for (h in 1:length(zones1)) {
  dat2<- dat_person_nt %>% dplyr::filter(ntrl_ds ==zones1[h])

for (i in 1: length(all.poss.mods.clim.vegtype2)){
  print(paste((all.poss.mods.clim.vegtype2[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, variables_all_p[i])
  model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, !!variables_all_p)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="fire_pres") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.aic, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.clim.vegtype2, big.mod, df.train=dat1, df.test=Valid)

}
}
}


```

Now extract elements from the output .

```{r}
#terms in each model
x1.1 <- unlist(sapply(mods.fit, '[', 1))
x1.1
#Aic for models
x3.1 <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3.1
#auc from validation data
x4.1 <- unlist(sapply(mods.fit, '[', 4))
x4.1
#combining all as df
tab.sum.climate.nt <- cbind.data.frame(model=x1.1, edf=x3.1[,1], aic=x3.1[,2], auc.valid=x4.1)
tab.sum.climate.nt$NDT<-c("NDT1 No trees")
tab.sum.climate.nt$delta.aic<- tab.sum.climate.nt$aic - (min(tab.sum.climate.nt$aic))
tab.sum.climate.nt 

```


#Now repeat for topography

```{r}

########### 2. Topography ############
for (g in 1:100){

for (h in 1:length(zones1)) {
 dat2<- dat_person_nt %>% dplyr::filter(ntrl_ds ==zones1[h])

for (i in 1: length(all.poss.mods.topo)){
  print(paste((all.poss.mods.topo[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, variables_all_p[i])
  model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, !!variables_all_p)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="fire_pres") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.aic, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.topo, big.mod, df.train=dat1, df.test=Valid)

}
}
}


```

Now extract elements from the output.

```{r}
#terms in each model
x1.1c <- unlist(sapply(mods.fit, '[', 1))
x1.1c
#Aic for models
x3.1c <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3.1c
#auc from validation data
x4.1c <- unlist(sapply(mods.fit, '[', 4))
x4.1c
#combining all as df
tab.sum.topo.nt <- cbind.data.frame(model=x1.1c, edf=x3.1c[,1], aic=x3.1c[,2], auc.valid=x4.1c)
tab.sum.topo.nt$NDT<-c("NDT1 No trees")
tab.sum.topo.nt$delta.aic<- tab.sum.topo.nt$aic - (min(tab.sum.topo.nt$aic))
tab.sum.topo.nt

```

#Now combine the datatables and save to computer

```{r}
NDT1_p_models_nt<-rbind(tab.sum.climate.nt, tab.sum.topo.nt)
NDT1_p_models_nt

write.csv(NDT1_p_models_nt, file="D:\\Fire\\fire_data\\raw_data\\NDT1_person_models_nt.csv")
```

Now choose the top variables and create final model. The below code will need to be updated manually, depending on what the results of the above analyses are.

######## UPDATE BELOW #########

```{r}
##### TOP MODEL####
NDT1_t<-dat_person_nt %>%
  filter(ntrl_ds=="NDT1")

NDT1_t2<-NDT1_t %>% drop_na(live_stand_volume_125, vegtype, climate1, climate2, proj_height_1)

glm_best_NDT1<- glm(fire_pres ~ scale(climate1)*scale(climate2) +
             scale(live_stand_volume_125) +
               scale(proj_height_1) +
               vegtype, 
           data= NDT1_t2,
           family = binomial,
           na.action=na.omit)

summary(glm_best_NDT1)

# model diagnostic plots
binnedplot (fitted(glm_best_NDT1), 
            residuals(glm_best_NDT1), 
            nclass = NULL, 
            xlab = "Expected Values", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))


NDT1_t2$resids<-resid(glm_best_NDT1)

binnedplot (NDT1_t2$live_stand_volume_125, 
            NDT1_t2$resids, 
            nclass = NULL, 
            xlab = "live stand volume", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))

binnedplot (NDT1_t2$climate1, 
            NDT1_t2$resids, 
            nclass = NULL, 
            xlab = "", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))

# Diagnostic plots look good

# Looking at effect of forest height at the average amount of rainfall in September
plot(NDT1_t2$live_stand_volume_125,NDT1_t2$fire_pres)
curve(invlogit(coef(glm_best_NDT1)[1] +coef(glm_best_NDT1)[2]*mean(NDT1_t2$climate1) + coef(glm_best_NDT1)[3]*x), add=TRUE)

# looking at effect of climate1 at the average forest height.
plot(NDT1_t2$climate1,NDT1_t2$fire_pres)
curve(invlogit(coef(glm_best_NDT1)[1] +coef(glm_best_NDT1)[2]*x + coef(glm_best_NDT1)[3]*mean(NDT1_t2$live_stand_volume_125)), add=TRUE)


# create model table (only do this once) and add the relevant data
top_mod_table <- data.frame (matrix (ncol = 16, nrow = 0))
colnames (top_mod_table) <- c ("ZONE", "TREED", "Model_terms", "intercept", "coef_climate_1", "coef_climate_2", "coef_climate_interaction", "coef_stand_height", "coef_live_stand_volume_125", "coef_proj_age", "coef_vegtypeD", "coef_vegtypeOP", "coef_vegtypeS", "coef_vegtypeTB", "coef_vegtypeTC", "coef_vegtypeTM")



##STILL NEED TO ADD DATA FOR TABLE

##Add data for NDT1
top_mod_table[1,1]<-"NDT1"
top_mod_table[1,2]<-"Y"
top_mod_table[1,3]<-"fire_pres ~ ppt09 + proj_height_1" ######### UPDATE
top_mod_table[1,4]<- coef(glm_best_NDT1)[1] #Intercept
top_mod_table[1,5]<- coef(glm_best_NDT1)[2] #Climate variable 1
#top_mod_table[1,6]<- coef(glm_best_NDT1)[2] #Climate variable 2
#top_mod_table[1,7]<- coef(glm_best_NDT1)[3] #Interaction climate variables
#top_mod_table[1,8]<- coef(glm_best_NDT1)[3] #coef_stand_height
#top_mod_table[1,9]<- coef(glm_best_NDT1)[3] #live_stand_volume_125
#top_mod_table[1,10]<- coef(glm_best_NDT1)[4] #proj_age_1
#top_mod_table[1,11]<- coef(glm_best_NDT1)[4] #coefficient vegtypeD
#top_mod_table[1,12]<- coef(glm_best_NDT1)[4] #coefficient vegtypeOP
#top_mod_table[1,13]<- coef(glm_best_NDT1)[4] #coefficient vegtypeS
#top_mod_table[1,14]<- coef(glm_best_NDT1)[4] #coefficient vegtypeTB
#top_mod_table[1,15]<- coef(glm_best_NDT1)[4] #coefficient vegtypeTC
#top_mod_table[1,16]<- coef(glm_best_NDT1)[5] #coefficient vegtypeTM
top_mod_table ##Determine if better way to represent categories for vegtype, and if each climate variable should have its own column

########################## NDT1 Model Selection Complete ###################



```



############### Now choose the next NDT zone and repeat ########
Note: currently doing  those with one climate variable)
Models complete above: NDT4, NDT1
Models to still do henceforth:NDT2, NDT3, NDT5


Select next zone: NDT2

```{r}
zones1<-c("NDT2") #Do one zone at a time

filenames<-list()
prop<-0.75

########### 1. Climate and vegtype ############
for (g in 1:100){

for (h in 1:length(zones1)) {
  dat2<- dat_person_nt %>% dplyr::filter(ntrl_ds ==zones1[h])

for (i in 1: length(all.poss.mods.clim.vegtype)){
  print(paste((all.poss.mods.clim.vegtype[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, variables_all_p[i])
  model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, !!variables_all_p_c1)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="fire_pres") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.aic, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.clim.vegtype, big.mod, df.train=dat1, df.test=Valid)

}
}
}


```

Now extract elements from the output .

```{r}
#terms in each model
x1.2 <- unlist(sapply(mods.fit, '[', 1))
x1.2
#Aic for models
x3.2 <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3.2
#auc from validation data
x4.2 <- unlist(sapply(mods.fit, '[', 4))
x4.2
#combining all as df
tab.sum.climate.nt <- cbind.data.frame(model=x1.2, edf=x3.2[,1], aic=x3.2[,2], auc.valid=x4.2)
tab.sum.climate.nt$NDT<-c("NDT2 No trees")
tab.sum.climate.nt$delta.aic<- tab.sum.climate.nt$aic - (min(tab.sum.climate.nt$aic))
tab.sum.climate.nt 

```


#Now repeat for topography

```{r}

########### 2. Topography ############
for (g in 1:100){

for (h in 1:length(zones1)) {
 dat2<- dat_person_nt %>% dplyr::filter(ntrl_ds ==zones1[h])

for (i in 1: length(all.poss.mods.topo)){
  print(paste((all.poss.mods.topo[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, variables_all_p[i])
  model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, !!variables_all_p)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="fire_pres") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.aic, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.topo, big.mod, df.train=dat1, df.test=Valid)

}
}
}


```

Now extract elements from the output .

```{r}
#terms in each model
x1.2c <- unlist(sapply(mods.fit, '[', 1))
x1.2c
#Aic for models
x3.2c <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3.2c
#auc from validation data
x4.2c <- unlist(sapply(mods.fit, '[', 4))
x4.2c
#combining all as df
tab.sum.topo.nt <- cbind.data.frame(model=x1.2c, edf=x3.2c[,1], aic=x3.2c[,2], auc.valid=x4.2c)
tab.sum.topo.nt$NDT<-c("NDT2 No trees")
tab.sum.topo.nt$delta.aic<- tab.sum.topo.nt$aic - (min(tab.sum.topo.nt$aic))
tab.sum.topo.nt

```

#Now combine the datatables and save to computer

```{r}
NDT2_p_models_nt<-rbind(tab.sum.climate.nt, tab.sum.topo.nt)
NDT2_p_models_nt

write.csv(NDT2_p_models_nt, file="D:\\Fire\\fire_data\\raw_data\\NDT2_person_models_nt.csv")
```

Now choose the top variables and create final model. The below code will need to be updated manually, depending on what the results of the above analyses are.

######## UPDATE BELOW #########

```{r}
##### TOP MODEL####
NDT2_t<-dat_person_nt %>%
  filter(ntrl_ds=="NDT2")

NDT2_t2<-NDT2_t %>% drop_na(live_stand_volume_125, vegtype, climate1, climate2, proj_height_1)

glm_best_NDT2<- glm(fire_pres ~ scale(climate1)*scale(climate2) +
             scale(live_stand_volume_125) +
               scale(proj_height_1) +
               vegtype, 
           data= NDT2_t2,
           family = binomial,
           na.action=na.omit)

summary(glm_best_NDT2)

# model diagnostic plots
binnedplot (fitted(glm_best_NDT2), 
            residuals(glm_best_NDT2), 
            nclass = NULL, 
            xlab = "Expected Values", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))


NDT2_t2$resids<-resid(glm_best_NDT2)

binnedplot (NDT2_t2$live_stand_volume_125, 
            NDT2_t2$resids, 
            nclass = NULL, 
            xlab = "live stand volume", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))

binnedplot (NDT2_t2$climate1, 
            NDT2_t2$resids, 
            nclass = NULL, 
            xlab = "", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))

# Diagnostic plots look good

# Looking at effect of forest height at the average amount of rainfall in September
plot(NDT2_t2$live_stand_volume_125,NDT2_t2$fire_pres)
curve(invlogit(coef(glm_best_NDT2)[1] +coef(glm_best_NDT2)[2]*mean(NDT2_t2$climate1) + coef(glm_best_NDT2)[3]*x), add=TRUE)

# looking at effect of climate1 at the average forest height.
plot(NDT2_t2$climate1,NDT2_t2$fire_pres)
curve(invlogit(coef(glm_best_NDT2)[1] +coef(glm_best_NDT2)[2]*x + coef(glm_best_NDT2)[3]*mean(NDT2_t2$live_stand_volume_125)), add=TRUE)


# create model table (only do this once) and add the relevant data
top_mod_table <- data.frame (matrix (ncol = 16, nrow = 0))
colnames (top_mod_table) <- c ("ZONE", "TREED", "Model_terms", "intercept", "coef_climate_1", "coef_climate_2", "coef_climate_interaction", "coef_stand_height", "coef_live_stand_volume_125", "coef_proj_age", "coef_vegtypeD", "coef_vegtypeOP", "coef_vegtypeS", "coef_vegtypeTB", "coef_vegtypeTC", "coef_vegtypeTM")



##STILL NEED TO ADD DATA FOR TABLE

##Add data for NDT2
top_mod_table[1,1]<-"NDT2"
top_mod_table[1,2]<-"Y"
top_mod_table[1,3]<-"fire_pres ~ ppt09 + proj_height_1" ######### UPDATE
top_mod_table[1,4]<- coef(glm_best_NDT2)[1] #Intercept
top_mod_table[1,5]<- coef(glm_best_NDT2)[2] #Climate variable 1
#top_mod_table[1,6]<- coef(glm_best_NDT2)[2] #Climate variable 2
#top_mod_table[1,7]<- coef(glm_best_NDT2)[3] #Interaction climate variables
#top_mod_table[1,8]<- coef(glm_best_NDT2)[3] #coef_stand_height
#top_mod_table[1,9]<- coef(glm_best_NDT2)[3] #live_stand_volume_125
#top_mod_table[1,10]<- coef(glm_best_NDT2)[4] #proj_age_1
#top_mod_table[1,11]<- coef(glm_best_NDT2)[4] #coefficient vegtypeD
#top_mod_table[1,12]<- coef(glm_best_NDT2)[4] #coefficient vegtypeOP
#top_mod_table[1,13]<- coef(glm_best_NDT2)[4] #coefficient vegtypeS
#top_mod_table[1,14]<- coef(glm_best_NDT2)[4] #coefficient vegtypeTB
#top_mod_table[1,15]<- coef(glm_best_NDT2)[4] #coefficient vegtypeTC
#top_mod_table[1,16]<- coef(glm_best_NDT2)[5] #coefficient vegtypeTM
top_mod_table ##Determine if better way to represent categories for vegtype, and if each climate variable should have its own column

########################## NDT2 Model Selection Complete ###################



```


############### Now choose the next NDT zone and repeat ########
Note: currently doing  those with one climate variable)
Models complete above: NDT4, NDT1, NDT2
Models to still do henceforth: NDT3, NDT5


Select next zone: NDT3


```{r}
zones1<-c("NDT3") #Do one zone at a time

filenames<-list()
prop<-0.75

########### 1. Climate and vegtype ############
for (g in 1:100){

for (h in 1:length(zones1)) {
  dat2<- dat_person_nt %>% dplyr::filter(ntrl_ds ==zones1[h])

for (i in 1: length(all.poss.mods.clim.vegtype)){
  print(paste((all.poss.mods.clim.vegtype[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, variables_all_p[i])
  model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, !!variables_all_p_c1)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="fire_pres") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.aic, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.clim.vegtype, big.mod, df.train=dat1, df.test=Valid)

}
}
}


```

Now extract elements from the output .

```{r}
#terms in each model
x1.3 <- unlist(sapply(mods.fit, '[', 1))
x1.3
#Aic for models
x3.3 <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3.3
#auc from validation data
x4.3 <- unlist(sapply(mods.fit, '[', 4))
x4.3
#combining all as df
tab.sum.climate.nt <- cbind.data.frame(model=x1.3, edf=x3.3[,1], aic=x3.3[,2], auc.valid=x4.3)
tab.sum.climate.nt$NDT<-c("NDT3 No trees")
tab.sum.climate.nt$delta.aic<- tab.sum.climate.nt$aic - (min(tab.sum.climate.nt$aic))
tab.sum.climate.nt 

```

#Now repeat for topography

```{r}

########### 2. Topography ############
for (g in 1:100){

for (h in 1:length(zones1)) {
 dat2<- dat_person_nt %>% dplyr::filter(ntrl_ds ==zones1[h])

for (i in 1: length(all.poss.mods.topo)){
  print(paste((all.poss.mods.topo[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, variables_all_p[i])
  model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, !!variables_all_p)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="fire_pres") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.aic, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.topo, big.mod, df.train=dat1, df.test=Valid)

}
}
}


```

Now extract elements from the output .

```{r}
#terms in each model
x1.3c <- unlist(sapply(mods.fit, '[', 1))
x1.3c
#Aic for models
x3.3c <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3.3c
#auc from validation data
x4.3c <- unlist(sapply(mods.fit, '[', 4))
x4.3c
#combining all as df
tab.sum.topo.nt <- cbind.data.frame(model=x1.3c, edf=x3.3c[,1], aic=x3.3c[,2], auc.valid=x4.3c)
tab.sum.topo.nt$NDT<-c("NDT3 No trees")
tab.sum.topo.nt$delta.aic<- tab.sum.topo.nt$aic - (min(tab.sum.topo.nt$aic))
tab.sum.topo.nt

```

#Now combine the datatables and save to computer

```{r}
NDT3_p_models_nt<-rbind(tab.sum.climate.nt, tab.sum.topo.nt)
NDT3_p_models_nt

write.csv(NDT3_p_models_nt, file="D:\\Fire\\fire_data\\raw_data\\NDT3_person_models_nt.csv")
```

Now choose the top variables and create final model. The below code will need to be updated manually, depending on what the results of the above analyses are.

######## UPDATE BELOW #########

```{r}
##### TOP MODEL####
NDT3_t<-dat_person_nt %>%
  filter(ntrl_ds=="NDT3")

NDT3_t2<-NDT3_t %>% drop_na(live_stand_volume_125, vegtype, climate1, climate2, proj_height_1)

glm_best_NDT3<- glm(fire_pres ~ scale(climate1)*scale(climate2) +
             scale(live_stand_volume_125) +
               scale(proj_height_1) +
               vegtype, 
           data= NDT3_t2,
           family = binomial,
           na.action=na.omit)

summary(glm_best_NDT3)

# model diagnostic plots
binnedplot (fitted(glm_best_NDT3), 
            residuals(glm_best_NDT3), 
            nclass = NULL, 
            xlab = "Expected Values", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))


NDT3_t2$resids<-resid(glm_best_NDT3)

binnedplot (NDT3_t2$live_stand_volume_125, 
            NDT3_t2$resids, 
            nclass = NULL, 
            xlab = "live stand volume", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))

binnedplot (NDT3_t2$climate1, 
            NDT3_t2$resids, 
            nclass = NULL, 
            xlab = "", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))

# Diagnostic plots look good

# Looking at effect of forest height at the average amount of rainfall in September
plot(NDT3_t2$live_stand_volume_125,NDT3_t2$fire_pres)
curve(invlogit(coef(glm_best_NDT3)[1] +coef(glm_best_NDT3)[2]*mean(NDT3_t2$climate1) + coef(glm_best_NDT3)[3]*x), add=TRUE)

# looking at effect of climate1 at the average forest height.
plot(NDT3_t2$climate1,NDT3_t2$fire_pres)
curve(invlogit(coef(glm_best_NDT3)[1] +coef(glm_best_NDT3)[2]*x + coef(glm_best_NDT3)[3]*mean(NDT3_t2$live_stand_volume_125)), add=TRUE)


# create model table (only do this once) and add the relevant data
top_mod_table <- data.frame (matrix (ncol = 16, nrow = 0))
colnames (top_mod_table) <- c ("ZONE", "TREED", "Model_terms", "intercept", "coef_climate_1", "coef_climate_2", "coef_climate_interaction", "coef_stand_height", "coef_live_stand_volume_125", "coef_proj_age", "coef_vegtypeD", "coef_vegtypeOP", "coef_vegtypeS", "coef_vegtypeTB", "coef_vegtypeTC", "coef_vegtypeTM")



##STILL NEED TO ADD DATA FOR TABLE

##Add data for NDT3
top_mod_table[1,1]<-"NDT3"
top_mod_table[1,2]<-"Y"
top_mod_table[1,3]<-"fire_pres ~ ppt09 + proj_height_1" ######### UPDATE
top_mod_table[1,4]<- coef(glm_best_NDT3)[1] #Intercept
top_mod_table[1,5]<- coef(glm_best_NDT3)[2] #Climate variable 1
#top_mod_table[1,6]<- coef(glm_best_NDT3)[2] #Climate variable 2
#top_mod_table[1,7]<- coef(glm_best_NDT3)[3] #Interaction climate variables
#top_mod_table[1,8]<- coef(glm_best_NDT3)[3] #coef_stand_height
#top_mod_table[1,9]<- coef(glm_best_NDT3)[3] #live_stand_volume_125
#top_mod_table[1,10]<- coef(glm_best_NDT3)[4] #proj_age_1
#top_mod_table[1,11]<- coef(glm_best_NDT3)[4] #coefficient vegtypeD
#top_mod_table[1,12]<- coef(glm_best_NDT3)[4] #coefficient vegtypeOP
#top_mod_table[1,13]<- coef(glm_best_NDT3)[4] #coefficient vegtypeS
#top_mod_table[1,14]<- coef(glm_best_NDT3)[4] #coefficient vegtypeTB
#top_mod_table[1,15]<- coef(glm_best_NDT3)[4] #coefficient vegtypeTC
#top_mod_table[1,16]<- coef(glm_best_NDT3)[5] #coefficient vegtypeTM
top_mod_table ##Determine if better way to represent categories for vegtype, and if each climate variable should have its own column

########################## NDT3 Model Selection Complete ###################

```

############### Now choose the next NDT zone and repeat ########
Note: currently doing  those with one climate variable)
Models complete above: NDT4, NDT1, NDT2, NDT3
Models to still do henceforth: NDT5

Select next zone: NDT5

```{r}
zones1<-c("NDT5") #Do one zone at a time

filenames<-list()
prop<-0.75

########### 1. Climate and vegtype ############
for (g in 1:100){

for (h in 1:length(zones1)) {
  dat2<- dat_person_nt %>% dplyr::filter(ntrl_ds ==zones1[h])

for (i in 1: length(all.poss.mods.clim.vegtype2)){
  print(paste((all.poss.mods.clim.vegtype2[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, variables_all_p[i])
  model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, !!variables_all_p)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="fire_pres") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.aic, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.clim.vegtype2, big.mod, df.train=dat1, df.test=Valid)

}
}
}


```

Now extract elements from the output .

```{r}
#terms in each model
x1.5 <- unlist(sapply(mods.fit, '[', 1))
x1.5
#Aic for models
x3.5 <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3.5
#auc from validation data
x4.5 <- unlist(sapply(mods.fit, '[', 4))
x4.5
#combining all as df
tab.sum.climate.nt <- cbind.data.frame(model=x1.5, edf=x3.5[,1], aic=x3.5[,2], auc.valid=x4.5)
tab.sum.climate.nt$NDT<-c("NDT5 No trees")
tab.sum.climate.nt$delta.aic<- tab.sum.climate.nt$aic - (min(tab.sum.climate.nt$aic))
tab.sum.climate.nt 

```


#Now repeat for topography

```{r}

########### 2. Topography ############
for (g in 1:100){

for (h in 1:length(zones1)) {
 dat2<- dat_person_nt %>% dplyr::filter(ntrl_ds ==zones1[h])

for (i in 1: length(all.poss.mods.topo)){
  print(paste((all.poss.mods.topo[i]), (zones1[h]), sep=" "))
  
 # model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, variables_all_p[i])
  model_dat<- dat2 %>% dplyr::select(fire_pres, fire_veg, !!variables_all_p)
  # Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(model_dat$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- model_dat[ trainIndex,]
   Valid <- model_dat[-trainIndex,]

big.mod <- function(mods.in, df.train, df.test, dep.var="fire_pres") {
   rhs <- paste(mods.in, collapse=" + ")
   form <- as.formula(paste(noquote(dep.var), " ~", rhs))
   mods.fit <- glm(form, family=binomial, data=df.train)
   mod.stuff <- summary(mods.fit)
   mod.aic <- extractAIC(mods.fit)
   mod.valid <- predict.glm(mods.fit, newdata=df.test, type="response")
   roc_obj <- roc(df.test[,dep.var], mod.valid)
   mod.auc <- auc(roc_obj)
   return(list(rhs, mod.stuff, mod.aic, mod.auc))
   
}

mods.fit <- lapply(all.poss.mods.topo, big.mod, df.train=dat1, df.test=Valid)

}
}
}


```

Now extract elements from the output .

```{r}
#terms in each model
x1.5c <- unlist(sapply(mods.fit, '[', 1))
x1.5c
#Aic for models
x3.5c <- matrix(unlist(sapply(mods.fit, '[', 3)), ncol=2, byrow=TRUE)
x3.5c
#auc from validation data
x4.5c <- unlist(sapply(mods.fit, '[', 4))
x4.5c
#combining all as df
tab.sum.topo.nt <- cbind.data.frame(model=x1.5c, edf=x3.5c[,1], aic=x3.5c[,2], auc.valid=x4.5c)
tab.sum.topo.nt$NDT<-c("NDT5 No trees")
tab.sum.topo.nt$delta.aic<- tab.sum.topo.nt$aic - (min(tab.sum.topo.nt$aic))
tab.sum.topo.nt

```

#Now combine the datatables and save to computer

```{r}
NDT5_p_models_nt<-rbind(tab.sum.climate.nt, tab.sum.topo.nt)
NDT5_p_models_nt

write.csv(NDT5_p_models_nt, file="D:\\Fire\\fire_data\\raw_data\\NDT5_person_models_nt.csv")
```

Now choose the top variables and create final model. The below code will need to be updated manually, depending on what the results of the above analyses are.

######## UPDATE BELOW #########

```{r}
##### TOP MODEL####
NDT5_t<-dat_person_nt %>%
  filter(ntrl_ds=="NDT5")

NDT5_t2<-NDT5_t %>% drop_na(live_stand_volume_125, vegtype, climate1, climate2, proj_height_1)

glm_best_NDT5<- glm(fire_pres ~ scale(climate1)*scale(climate2) +
             scale(live_stand_volume_125) +
               scale(proj_height_1) +
               vegtype, 
           data= NDT5_t2,
           family = binomial,
           na.action=na.omit)

summary(glm_best_NDT5)

# model diagnostic plots
binnedplot (fitted(glm_best_NDT5), 
            residuals(glm_best_NDT5), 
            nclass = NULL, 
            xlab = "Expected Values", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))


NDT5_t2$resids<-resid(glm_best_NDT5)

binnedplot (NDT5_t2$live_stand_volume_125, 
            NDT5_t2$resids, 
            nclass = NULL, 
            xlab = "live stand volume", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))

binnedplot (NDT5_t2$climate1, 
            NDT5_t2$resids, 
            nclass = NULL, 
            xlab = "", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm", i))

# Diagnostic plots look good

# Looking at effect of forest height at the average amount of rainfall in September
plot(NDT5_t2$live_stand_volume_125,NDT5_t2$fire_pres)
curve(invlogit(coef(glm_best_NDT5)[1] +coef(glm_best_NDT5)[2]*mean(NDT5_t2$climate1) + coef(glm_best_NDT5)[3]*x), add=TRUE)

# looking at effect of climate1 at the average forest height.
plot(NDT5_t2$climate1,NDT5_t2$fire_pres)
curve(invlogit(coef(glm_best_NDT5)[1] +coef(glm_best_NDT5)[2]*x + coef(glm_best_NDT5)[3]*mean(NDT5_t2$live_stand_volume_125)), add=TRUE)

# create model table (only do this once) and add the relevant data
top_mod_table <- data.frame (matrix (ncol = 16, nrow = 0))
colnames (top_mod_table) <- c ("ZONE", "TREED", "Model_terms", "intercept", "coef_climate_1", "coef_climate_2", "coef_climate_interaction", "coef_stand_height", "coef_live_stand_volume_125", "coef_proj_age", "coef_vegtypeD", "coef_vegtypeOP", "coef_vegtypeS", "coef_vegtypeTB", "coef_vegtypeTC", "coef_vegtypeTM")


##STILL NEED TO ADD DATA FOR TABLE

##Add data for NDT5
top_mod_table[1,1]<-"NDT5"
top_mod_table[1,2]<-"Y"
top_mod_table[1,3]<-"fire_pres ~ ppt09 + proj_height_1" ######### UPDATE
top_mod_table[1,4]<- coef(glm_best_NDT5)[1] #Intercept
top_mod_table[1,5]<- coef(glm_best_NDT5)[2] #Climate variable 1
#top_mod_table[1,6]<- coef(glm_best_NDT5)[2] #Climate variable 2
#top_mod_table[1,7]<- coef(glm_best_NDT5)[3] #Interaction climate variables
#top_mod_table[1,8]<- coef(glm_best_NDT5)[3] #coef_stand_height
#top_mod_table[1,9]<- coef(glm_best_NDT5)[3] #live_stand_volume_125
#top_mod_table[1,10]<- coef(glm_best_NDT5)[4] #proj_age_1
#top_mod_table[1,11]<- coef(glm_best_NDT5)[4] #coefficient vegtypeD
#top_mod_table[1,12]<- coef(glm_best_NDT5)[4] #coefficient vegtypeOP
#top_mod_table[1,13]<- coef(glm_best_NDT5)[4] #coefficient vegtypeS
#top_mod_table[1,14]<- coef(glm_best_NDT5)[4] #coefficient vegtypeTB
#top_mod_table[1,15]<- coef(glm_best_NDT5)[4] #coefficient vegtypeTC
#top_mod_table[1,16]<- coef(glm_best_NDT5)[5] #coefficient vegtypeTM
top_mod_table ##Determine if better way to represent categories for vegtype, and if each climate variable should have its own column

########################## NDT5 Model Selection Complete ###################

```
















Write as a table to save data for top models for all BEC zones, for those with trees. Will need to repeat for areas without trees.

```{r}
write.csv(top_mod_table, file="D:\\Fire\\fire_data\\raw_data\\Top_Models_Treed.csv")

```
