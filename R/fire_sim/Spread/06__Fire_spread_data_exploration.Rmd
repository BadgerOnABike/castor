---
title: "06_Fire_spread_model_fits_by_FRT_data_prep"
author: "Elizabeth Kleynhans and Cora Skaien"
contributor: "Peter Ott"
date: "20/04/2021"
output: html_document
editor_options: 
  chunk_output_type: console
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library (kableExtra)
library (data.table)
library (DBI)
library (RPostgreSQL)
library (dplyr)
library (ggplot2)
library (here)
library(ggpubr)
library(arm)
library(tidyr)
library(AICcmodavg)
library(keyring)
library(caret)
library(pROC)
library(rje)
library(sf)
library(car)

source(here::here("R/functions/R_Postgres.R"))
```

<!--
Copyright 2021 Province of British Columbia

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and limitations under the License.
-->


# Introduction

Here, we are running a glm for each separate fire regime type to develop a predictive equation so that we can extrapolate which cells are likely to burn and which are not into the future. The data that we include in these glms is vegetation, climate date, and human impact. The top climate variable for each fire regime type was determined in the script "05_spread_climate_variable_selection.R". 

Before running these glms I will plot the relationship between the climate variable and probability of spread. I should probably do partial plots because I also included lat and long in these models to try to account for autocorrelation. 




```{r eval=, message=FALSE, AIC table, echo=F}

climate_variable<-read.csv("C:/Work/caribou/castor_data/Fire/Fire_sim_data/data/climate_AIC_results_spread_summary.csv")

kable (climate_variable,
       caption = "<b>Table 1. Top candidate climate variables for lightning caused fires as selected through an AIC analysis for each Fire Regime Type.<b>",
       digits = 2) %>%
  kable_styling (position = "left",
                 bootstrap_options = c("striped", "hover"),
                 fixed_thead = T,
                 full_width = F,
                 font_size = 11)
```

# Import the data

```{r}
fire_spread<-st_read("C:\\Work\\caribou\\castor_data\\Fire\\Fire_sim_data\\data\\spread\\Fire_data_all_veg.gpkg")
head(fire_spread)

fire_spread$tot_spring_PPT<-fire_spread$PPT04+ fire_spread$PPT05 + fire_spread$PPT06
fire_spread$spring_Tave<-(fire_spread$Tave04+ fire_spread$Tave05 + fire_spread$Tave06)/3

fire_spread$mean_Tmax05_Tmax06_Tmax07<- (fire_spread$Tmax05+ fire_spread$Tmax06 + fire_spread$Tmax07)/3

fire_spread$mean_Tmax05_Tmax06_Tmax07_Tmax08<- (fire_spread$Tmax05 + fire_spread$Tmax06+ fire_spread$Tmax07 + fire_spread$Tmax08)/4

fire_spread$mean_PPT05_PPT06_PPT07_PPT08<- (fire_spread$PPT05 + fire_spread$PPT06+ fire_spread$PPT07 + fire_spread$PPT08)/4

fire_spread$mean_PPT05_PPT06_PPT07<- (fire_spread$PPT05+ fire_spread$PPT06 + fire_spread$PPT07)/3

fire_spread$mean_Tave05_Tave06_Tave07_Tave08<- (fire_spread$Tave05 + fire_spread$Tave06+ fire_spread$Tave07 + fire_spread$Tave08)/4

```


#Create climate1 and climate2 columns

```{r}
#View top variable
names(fire_spread)
unique(fire_spread$frt) # FRT 3 should not be in this list
table(is.na(fire_spread$frt))
fire_spread$frt[fire_spread$frt==3]<-5

fire_spread2<-st_drop_geometry(fire_spread)
fire_spread2<-fire_spread %>% drop_na(frt)
fire_spread2$frt<-as.numeric(fire_spread2$frt)

table(fire_spread2$frt)

## Create empty vector
fire_spread2$climate1<-"NA"
head(fire_spread2)

fire_spread2<-fire_spread2 %>%
    mutate(climate1 = case_when(
                            frt == "5" ~ Tmax08 ,
                            frt == "7" ~ as.numeric(RH07),
                            frt == "9" ~ spring_Tave,
                            frt == "10" ~ mean_Tmax05_Tmax06_Tmax07_Tmax08 ,
                            frt == "11" ~ as.numeric(RH08),
                            frt == "12" ~ mean_Tmax05_Tmax06_Tmax07_Tmax08,
                            frt == "13" ~ mean_Tave05_Tave06_Tave07_Tave08,
                            frt == "14" ~ mean_Tmax05_Tmax06_Tmax07,
                            frt == "15" ~ Tave05 ,
                            TRUE ~ NA_real_))

#Repeat for climate 2
fire_spread2$climate2<-"NA"

fire_spread2<-fire_spread2 %>%
    mutate(climate2 = case_when(
                            frt == "5" ~ as.numeric(PPT08),
                            frt == "7" ~ as.numeric(PPT07),
                            frt == "9" ~ as.numeric(tot_spring_PPT),
                            frt == "10" ~ as.numeric(mean_PPT05_PPT06_PPT07_PPT08) ,
                            frt == "11" ~ as.numeric(PPT08),
                            frt == "12" ~ as.numeric(mean_PPT05_PPT06_PPT07_PPT08),
                            frt == "13" ~ as.numeric(mean_PPT05_PPT06_PPT07_PPT08),
                            frt == "14" ~ as.numeric(mean_PPT05_PPT06_PPT07),
                            frt == "15" ~ as.numeric(PPT05),
                            TRUE ~ NA_real_))

head(fire_spread2)

##Change vegtype to factor
fire_spread2$FWI_veg<-as.factor(fire_spread2$FWI_veg)

#create new column
fire_spread2$fire_veg<-paste(fire_spread2$fire, fire_spread2$FWI_veg)

```

#Change Aspect to N,S,E,W
```{r}
library(rvest)
library(tidyverse)

url <- 'http://snowfence.umn.edu/Components/winddirectionanddegreeswithouttable3.htm'
page <- read_html(url)
directions_raw <- page %>% html_node('td table') %>% html_table(header = TRUE)

directions <- directions_raw %>% 
    set_names(~tolower(sub(' Direction', '', .x))) %>% 
    slice(-1) %>% 
    separate(degree, c('degree_min', 'degree_max'), sep = '\\s+-\\s+', convert = TRUE)

directions

fire_spread2 <- fire_spread2 %>% 
    mutate(aspect_cardinal = cut(
        aspect_ha_bc, 
        breaks = c(0, directions$degree_max, 360), 
        labels = c(directions$cardinal, 'N')
    ))

fire_spread2$aspect_cardinal2<-0
fire_spread2$aspect_cardinal2[fire_spread2$aspect_cardinal=="N"]<-"N"
fire_spread2$aspect_cardinal2[fire_spread2$aspect_cardinal=="E"]<-"E"
fire_spread2$aspect_cardinal2[fire_spread2$aspect_cardinal=="S"]<-"S"
fire_spread2$aspect_cardinal2[fire_spread2$aspect_cardinal=="W"]<-"W"

fire_spread2$aspect_cardinal2[fire_spread2$aspect_cardinal=="NNE"]<-"N"
fire_spread2$aspect_cardinal2[fire_spread2$aspect_cardinal=="NNW"]<-"N"
fire_spread2$aspect_cardinal2[fire_spread2$aspect_cardinal=="NE" & fire_spread2$aspect_ha_bc<=45]<-"N"

fire_spread2$aspect_cardinal2[fire_spread2$aspect_cardinal=="NE" & fire_spread2$aspect_ha_bc>45]<-"E"
fire_spread2$aspect_cardinal2[fire_spread2$aspect_cardinal=="ENE"]<-"E"
fire_spread2$aspect_cardinal2[fire_spread2$aspect_cardinal=="ESE"]<-"E"
fire_spread2$aspect_cardinal2[fire_spread2$aspect_cardinal=="SE" & fire_spread2$aspect_ha_bc<=135]<-"E"

fire_spread2$aspect_cardinal2[fire_spread2$aspect_cardinal=="SE" & fire_spread2$aspect_ha_bc>135]<-"S"
fire_spread2$aspect_cardinal2[fire_spread2$aspect_cardinal=="SSE"]<-"S"
fire_spread2$aspect_cardinal2[fire_spread2$aspect_cardinal=="SSW"]<-"S"
fire_spread2$aspect_cardinal2[fire_spread2$aspect_cardinal=="SW" & fire_spread2$aspect_ha_bc<=225]<-"S"

fire_spread2$aspect_cardinal2[fire_spread2$aspect_cardinal=="SW" & fire_spread2$aspect_ha_bc>225]<-"W"
fire_spread2$aspect_cardinal2[fire_spread2$aspect_cardinal=="WSW"]<-"W"
fire_spread2$aspect_cardinal2[fire_spread2$aspect_cardinal=="WNW"]<-"W"
fire_spread2$aspect_cardinal2[fire_spread2$aspect_cardinal=="NW" & fire_spread2$aspect_ha_bc<=315]<-"W"
fire_spread2$aspect_cardinal2[fire_spread2$aspect_cardinal=="NW" & fire_spread2$aspect_ha_bc>315]<-"N"

fire_spread2

table(fire_spread2$aspect_cardinal2, fire_spread2$pttype)
 fire_spread2[fire_spread2$aspect_cardinal2=="0",]
 fire_spread2<-fire_spread2 %>% drop_na(aspect_cardinal)



x<-fire_spread2 %>% filter(pttype==1)

hist(x$aspect_ha_bc)
```

#View plots.

```{r}
p <- ggplot(fire_spread2, aes(aspect_ha_bc, as.numeric(pttype))) +
  geom_smooth(method="glm", formula=y~x,
              method.args=list(family="binomial"),
              alpha=0.3, size=1) +
  geom_point(position=position_jitter(height=0.03, width=0)) +
  xlab("aspect") + ylab("Pr (ignition)")
p

#  positive association with slope

ggplot(fire_spread2, aes(x = slope_ha_bc)) +
  geom_histogram(fill = "white", colour = "black") +
  facet_grid(pttype ~ .)

##Seeing distribution of ignitions by slope makes me believe that slope is not a big factor for ignitions despite seemingly positive trend prior.
p <- ggplot(fire_spread2, aes(dem_ha_bc, as.numeric(pttype))) +
  geom_smooth(method="glm", formula=y~x,
              method.args=list(family="binomial"),
              alpha=0.3, size=1) +
  geom_point(position=position_jitter(height=0.03, width=0)) +
  xlab("elevation") + ylab("Pr (ignition)")
p # seems like there is probably no relationship with elevation

ggplot(fire_spread2, aes(x = dem_ha_bc)) +
  geom_histogram(fill = "white", colour = "black") +
  facet_grid(pttype ~ .)
```

# Fit models


# FRT 5 ####

```{r}
# Plot climate data results

frt5<-fire_spread2 %>% filter(frt==5)
model1 <- glm (pttype ~ Latitude + Longitude + Tave07 + PPT07 ,
               data=frt5,
               family = binomial (link = "logit"))
summary(model1)

library(visreg)
visreg(model1, scale="response", "Tave07")
visreg(model1, scale="response", "PPT07")
visreg(model1, "Tave07")



library(GGally)

table(is.na(frt5$win_spg))

frt5_2<-frt5 %>% drop_na(win_spg)
frt5_2<-frt5_2 %>% drop_na(dem_ha_bc)
frt5_2 <-frt5_2 %>% st_drop_geometry()
table(is.na(frt5_2$dist_ignit))

# note Dem and tave07 are 0.733 correlated and dist_roads_m and Dist_infr_m are also somewhat correlated 0.658.

# Using AIC Ill pick the model that is better with leaving some of these combinations out

table(frt5_2$FWI_veg, frt5_2$pttype)
frt5_2$FWI_veg[frt5_2$FWI_veg=="S-1"]<-"M-1/2"
frt5_2$FWI_veg[frt5_2$FWI_veg=="C-4"]<-"C-2"

frt5_2<-frt5_2 %>% 
  filter(FWI_veg !="W") # remove water from the model

frt5_2<-frt5_2 %>% 
  filter(!bclcs_level_5 %in% c("GL", "LA")) # remove glaciers or lakes. Sometimes these get put into the N veg category so I want to make sure there are not present
table(frt5_2$FWI_veg, frt5_2$pttype)


model1 <- glm (pttype ~ Latitude + Longitude + Tave07 + PPT07 + dem_ha_bc + as.factor(FWI_veg) + dist_roads_m + dist_infr_m + win_spg + dist_ignit,
               data=frt5_2,
               family = binomial (link = "logit"))
summary(model1)

model2 <- glm (pttype ~ Latitude + Longitude + PPT07 + dem_ha_bc + as.factor(aspect_cardinal2) + as.factor(FWI_veg) + dist_roads_m + dist_infr_m + win_spg + dist_ignit,
               data=frt5_2,
               family = binomial (link = "logit"))
summary(model2)

model3 <- glm (pttype ~ Latitude + Longitude + Tave07 + PPT07 + as.factor(FWI_veg) + dist_roads_m + dist_infr_m + win_spg + dist_ignit,
               data=frt5_2,
               family = binomial (link = "logit"))

summary(model3)

# will use model 2. Note I tried logging roads and infrastructure but it does not improve the model. It actually makes it worse

model2 <- glm (pttype ~ Latitude + Longitude + PPT07 + dem_ha_bc + as.factor(aspect_cardinal2) + as.factor(FWI_veg) + dist_roads_m + dist_infr_m + win_spg,
               data=frt5_2,
               family = binomial (link = "logit"))
summary(model2)
Anova(model2, type=3)
visreg(model2)

ggpairs(frt5_2[, c("Latitude", "Longitude", "PPT07", "dem_ha_bc", "dist_roads_m", "dist_infr_m", "win_spg")])


# model diagnostic plots
# below model looks way better with log road dist. It had some structure with just road dist
binnedplot (fitted(model2), 
            residuals(model2), 
            nclass = NULL, 
            xlab = "Expected Values", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm"))


frt5_2$resids<-resid(model2)

binnedplot (frt5_2$PPT07, 
            frt5_2$resids, 
            nclass = NULL)

binnedplot (frt5_2$Latitude                     , 
            frt5_2$resids, 
            nclass = NULL)

binnedplot (frt5_2$Longitude  , 
            frt5_2$resids, 
            nclass = NULL)

binnedplot (frt5_2$dem_ha_bc, 
            frt5_2$resids)

binnedplot (frt5_2$dist_roads_m, 
            frt5_2$resids, 
            nclass = NULL)

binnedplot (frt5_2$dist_infr_m, 
            frt5_2$resids, 
            nclass = NULL)
binnedplot (frt5_2$win_spg, 
            frt5_2$resids, 
            nclass = NULL)

```
# FRT 5 check model fit
```{r}
#Here, we’ll check the linear relationship between continuous predictor variables and the logit of the outcome. This can be done by visually inspecting the scatter plot between each predictor and the logit values.

#Remove qualitative variables from the original data frame and bind the logit values to the data:

# Select only numeric predictors
str(frt5_2)

dat2_b<-frt5_2 %>% dplyr::select(pttype, PPT07, dem_ha_bc,Latitude, Longitude, dist_roads_m, dist_infr_m, win_spg )
probabilities <- predict(model2, type = "response")
predicted.classes <- ifelse(probabilities > 0.5, "pos", "neg")

mydata <- dat2_b %>%
  dplyr::select_if(is.numeric) 
predictors <- colnames(mydata)

# Bind the logit and tidying the data for plot
mydata <- mydata %>%
  mutate(logit = log(probabilities/(1-probabilities))) %>%
  gather(key = "predictors", value = "predictor.value", -logit)

ggplot(mydata, aes(logit, predictor.value))+
  geom_point(size = 0.5, alpha = 0.5) +
  geom_smooth(method = "loess") + 
  theme_bw() + 
  facet_wrap(~predictors, scales = "free_y")

# all variables should be approximatly linear which is mostly true
```

#Checking assumption of influential values

see: (http://www.sthda.com/english/articles/36-classification-methods-essentials/148-logistic-regression-assumptions-and-diagnostics-in-r/)
```{r}
#Influential values are extreme individual data points that can alter the quality of the logistic regression model.
#The most extreme values in the data can be examined by visualizing the Cook’s distance values. Here we label the top 3 largest values:

plot(model2, which = 4, id.n = 3)

#Note that, not all outliers are influential observations. To check whether the data contains potential influential observations, the standardized residual error can be inspected. Data points with an absolute standardized residuals above 3 represent possible outliers and may deserve closer attention.

#The following R code computes the standardized residuals (.std.resid) and the Cook’s distance (.cooksd) using the R function augment() [broom package].

# Extract model results
library(broom)

model.data <- augment(model2) %>% 
  mutate(index = 1:n()) 

#The data for the top 3 largest values, according to the Cook’s distance, can be displayed as follow:
model.data %>% 
  dplyr::select(PPT07, dem_ha_bc,dist_roads_m ,.std.resid, .cooksd) %>%
  top_n(5, .cooksd) 

ggplot(model.data, aes(index, .std.resid)) + 
  geom_point(aes(color = pttype), alpha = .5) +
  theme_bw()

```

# checking assumption of no multicollinearity

```{r}
#Multicollinearity corresponds to a situation where the data contain highly correlated predictor variables. Read more in Chapter @ref(multicollinearity).

#Multicollinearity is an important issue in regression analysis and should be fixed by removing the concerned variables. It can be assessed using the R function vif() [car package], which computes the variance inflation factors:

car::vif(model2)

#As a rule of thumb, a VIF value that exceeds 5 or 10 indicates a problematic amount of collinearity. 
```


```{r}
frt5_2$aspect_cardinal2<-as.factor(frt5_2$aspect_cardinal2)
frt5_2$FWI_veg<-as.factor(frt5_2$FWI_veg)

model2 <- glm (pttype ~ Latitude + Longitude + PPT07 + dem_ha_bc + aspect_cardinal2 + FWI_veg + dist_roads_m + dist_infr_m + win_spg,
               data=frt5_2,
               family = binomial (link = "logit"))

summary(model2)
table(frt5_2$FWI_veg)

#Create a new blank table and get AUC too
top_mod_table_FRT5_All <- data.frame (matrix (ncol = 25, nrow = 0))
colnames (top_mod_table_FRT5_All ) <- c ("CAUSE", 
                                    "FRT",  
                                    "Model_terms", 
                                    "intercept", 
                                    "coef_Latitude",
                                    "coef_Longitude",
                                    "coef_PPT07", 
                                    "coef_elevation", 
                                    "coef_aspect_N",
                                    "coef_aspect_S",
                                    "coef_aspect_W",
                                    "coef_FWI_veg_C-2", 
                                    "coef_FWI_veg_C-3", 
                                    "coef_FWI_veg_C-5",
                                    "coef_FWI_veg_C-7",
                                    "coef_FWI_veg_D-1/2",
                                    "coef_FWI_veg_M-1/2",
                                    "coef_FWI_veg_M-3",
                                    "coef_FWI_veg_N",
                                    "coef_FWI_veg_O-1a/b",
                                    "coef_FWI_veg_S-2",
                                    "coef_dist_roads",
                                    "coef_dist_infr",
                                    "coef_win_spg",
                                    "AUC")

frt5_2$fire_veg<-paste(frt5_2$pttype, frt5_2$FWI_veg)
```

Let's run it 100 times to get good mean values.

```{r}

for (g in 1:100){

prop<-0.75
# Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(frt5_2$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- frt5_2[ trainIndex,]
   Valid <- frt5_2[-trainIndex,]
   
#Model   
mod<-glm (pttype ~ Latitude + Longitude + PPT07 + dem_ha_bc + aspect_cardinal2 + FWI_veg + dist_roads_m + dist_infr_m + win_spg, data=dat1, family=binomial(link="logit"))

mod.valid <- predict.glm(mod, newdata=Valid, type="response")
   roc_obj <- roc(Valid[,"pttype"], mod.valid, quiet=TRUE)
   mod.auc <- auc(roc_obj)

# create model table (only do this once) and add the relevant data
top_mod_table_FRT5_person <- data.frame (matrix (ncol = 25, nrow = 0))
colnames (top_mod_table_FRT5_person ) <- c ("CAUSE", 
                                    "FRT",  
                                    "Model_terms", 
                                    "intercept", 
                                    "coef_Latitude",
                                    "coef_Longitude",
                                    "coef_PPT07", 
                                    "coef_elevation", 
                                    "coef_aspect_N",
                                    "coef_aspect_S",
                                    "coef_aspect_W",
                                    "coef_FWI_veg_C-2", 
                                    "coef_FWI_veg_C-3", 
                                    "coef_FWI_veg_C-5",
                                    "coef_FWI_veg_C-7",
                                    "coef_FWI_veg_D-1/2",
                                    "coef_FWI_veg_M-1/2",
                                    "coef_FWI_veg_M-3",
                                    "coef_FWI_veg_N",
                                    "coef_FWI_veg_O-1a/b",
                                    "coef_FWI_veg_S-2",
                                    "coef_dist_roads",
                                    "coef_dist_infr",
                                    "coef_win_spg",
                                    "AUC")

##Add data for NDT1
top_mod_table_FRT5_person[1,1]<-"spread"
top_mod_table_FRT5_person[1,2]<-"frt5"
top_mod_table_FRT5_person[1,3]<-"pttype ~ Lat + Long + PPT07 + elev + aspect + FWI_veg + dist_road + dist_infa + win_spg"
top_mod_table_FRT5_person[1,4]<- coef(mod)[1] #Intercept
top_mod_table_FRT5_person[1,5]<- coef(mod)[2] 
top_mod_table_FRT5_person[1,6]<- coef(mod)[3] 
top_mod_table_FRT5_person[1,7]<- coef(mod)[4] 
top_mod_table_FRT5_person[1,8]<- coef(mod)[5] 
top_mod_table_FRT5_person[1,9]<- coef(mod)[6] 
top_mod_table_FRT5_person[1,10]<- coef(mod)[7] 
top_mod_table_FRT5_person[1,11]<- coef(mod)[8] 
top_mod_table_FRT5_person[1,12]<- coef(mod)[9] 
top_mod_table_FRT5_person[1,13]<- coef(mod)[10] 
top_mod_table_FRT5_person[1,14]<- coef(mod)[11] 
top_mod_table_FRT5_person[1,15]<- coef(mod)[12] 
top_mod_table_FRT5_person[1,16]<- coef(mod)[13] 
top_mod_table_FRT5_person[1,17]<- coef(mod)[14] 
top_mod_table_FRT5_person[1,18]<- coef(mod)[16] 
top_mod_table_FRT5_person[1,19]<- coef(mod)[16] 
top_mod_table_FRT5_person[1,20]<- coef(mod)[17] 
top_mod_table_FRT5_person[1,21]<- coef(mod)[18] 
top_mod_table_FRT5_person[1,22]<- coef(mod)[19] 
top_mod_table_FRT5_person[1,23]<- coef(mod)[20] 
top_mod_table_FRT5_person[1,24]<- coef(mod)[21] 
top_mod_table_FRT5_person[1,25]<- mod.auc

top_mod_table_FRT5_All<-rbind(top_mod_table_FRT5_All, top_mod_table_FRT5_person)

}

```

Check.
```{r}
head(top_mod_table_FRT5_All)

```


Get mean values.

```{r}
names(top_mod_table_FRT5_All)
str(top_mod_table_FRT5_All)
stderror <- function(x) sd(x)/sqrt(length(x))

FRT5_summary_table_mean<- top_mod_table_FRT5_All %>% summarize_if(is.numeric,mean)


```

#Save table.

```{r}
write.csv(FRT5_summary_table_mean, file="C:\\Work\\caribou\\castor_data\\Fire\\Fire_sim_data\\data\\BC\\top_mod_table_frt5_spread.csv")
```


# FRT 7

```{r}
# Plot climate data results

frt7<-fire_spread2 %>% filter(frt==7)
model1 <- glm (pttype ~ Latitude + Longitude + climate1 + climate2 ,
               data=frt7,
               family = binomial (link = "logit"))
summary(model1)

library(visreg)
visreg(model1, scale="response", "climate1")
visreg(model1, scale="response", "climate2")
visreg(model1, "climate1")


table(is.na(frt7$win_spg))

frt7_2<-frt7 %>% drop_na(win_spg)
frt7_2<-frt7_2 %>% drop_na(dem_ha_bc)
frt7_2 <-frt7_2 %>% st_drop_geometry()
library(GGally)
ggpairs(frt7_2[, c("spring_Tave", "tot_spring_PPT", "dem_ha_bc", "Latitude", "Longitude", "slope_ha_bc", "win_spg", "dist_infr_m", "dist_roads_m")])


table(frt7_2$FWI_veg, frt7_2$pttype)
frt7_2$FWI_veg[frt7_2$FWI_veg=="C-5"]<-"C-7"
frt7_2$FWI_veg[frt7_2$FWI_veg=="M-3"]<-"O-1a/b"

frt7_2<-frt7_2 %>% 
  filter(FWI_veg !="W") # remove water from the model

frt7_2<-frt7_2 %>% 
  filter(!bclcs_level_5 %in% c("GL", "LA")) # remove glaciers or lakes. Sometimes these get put into the N veg category so I want to make sure there are not present
table(frt7_2$FWI_veg, frt7_2$pttype)


model1 <- glm (pttype ~ Latitude + Longitude + spring_Tave + tot_spring_PPT + dem_ha_bc + aspect_cardinal2 + as.factor(FWI_veg) + dist_roads_m + dist_infr_m + win_spg,
               data=frt7_2,
               family = binomial (link = "logit"))
summary(model1)
Anova(model1, type=3)

model1a <- glm (pttype ~ Latitude + Longitude + spring_Tave + tot_spring_PPT + dem_ha_bc + aspect_cardinal2 + as.factor(FWI_veg) + log(dist_roads_m+1) + dist_infr_m + win_spg,
               data=frt7_2,
               family = binomial (link = "logit"))


model1b <- glm (pttype ~ Latitude + Longitude + spring_Tave + tot_spring_PPT + dem_ha_bc + aspect_cardinal2 + as.factor(FWI_veg) + log(dist_roads_m+1) + dist_infr_m + win_spg,
               data=frt7_2,
               family = binomial (link = "logit"))
summary(model1b)
Anova(model1b, type=3)

# including dist to roads with log helps but does not seem tohelp for dist to infra


# model diagnostic plots
# below model looks way better with log road dist. It had some structure with just road dist
binnedplot (fitted(model1a), 
            residuals(model1a), 
            nclass = NULL, 
            xlab = "Expected Values", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm"))


frt7_2$resids<-resid(model1a)

binnedplot (as.numeric(frt7_2$spring_Tave), 
            frt7_2$resids, 
            nclass = NULL)

binnedplot (frt7_2$Latitude                     , 
            frt7_2$resids, 
            nclass = NULL)

binnedplot (frt7_2$Longitude  , 
            frt7_2$resids, 
            nclass = NULL)

binnedplot (frt7_2$dem_ha_bc, 
            frt7_2$resids)

binnedplot (frt7_2$dist_roads_m, 
            frt7_2$resids, 
            nclass = NULL)

binnedplot (frt7_2$dist_infr_m, 
            frt7_2$resids, 
            nclass = NULL)
binnedplot (frt7_2$win_spg, 
            frt7_2$resids, 
            nclass = NULL)

```

```{r}
#Here, we’ll check the linear relationship between continuous predictor variables and the logit of the outcome. This can be done by visually inspecting the scatter plot between each predictor and the logit values.

#Remove qualitative variables from the original data frame and bind the logit values to the data:

# Select only numeric predictors
str(frt7_2)

dat2_b<-frt7_2 %>% dplyr::select(pttype, spring_Tave, tot_spring_PPT, dem_ha_bc,Latitude, Longitude, dist_roads_m, dist_infr_m, win_spg )
probabilities <- predict(model1a, type = "response")
predicted.classes <- ifelse(probabilities > 0.5, "pos", "neg")

mydata <- dat2_b %>%
  dplyr::select_if(is.numeric) 
predictors <- colnames(mydata)

# Bind the logit and tidying the data for plot
mydata <- mydata %>%
  mutate(logit = log(probabilities/(1-probabilities))) %>%
  gather(key = "predictors", value = "predictor.value", -logit)

ggplot(mydata, aes(logit, predictor.value))+
  geom_point(size = 0.5, alpha = 0.5) +
  geom_smooth(method = "loess") + 
  theme_bw() + 
  facet_wrap(~predictors, scales = "free_y")

# all variables should be approximatly linear which is mostly true
```

Checking assumption of influential values
see: (http://www.sthda.com/english/articles/36-classification-methods-essentials/148-logistic-regression-assumptions-and-diagnostics-in-r/)
```{r}
#Influential values are extreme individual data points that can alter the quality of the logistic regression model.
#The most extreme values in the data can be examined by visualizing the Cook’s distance values. Here we label the top 3 largest values:

plot(model1a, which = 4, id.n = 3)

#Note that, not all outliers are influential observations. To check whether the data contains potential influential observations, the standardized residual error can be inspected. Data points with an absolute standardized residuals above 3 represent possible outliers and may deserve closer attention.

#The following R code computes the standardized residuals (.std.resid) and the Cook’s distance (.cooksd) using the R function augment() [broom package].

# Extract model results
library(broom)

model.data <- augment(model1a) %>% 
  mutate(index = 1:n()) 

#The data for the top 3 largest values, according to the Cook’s distance, can be displayed as follow:
model.data %>% 
  dplyr::select(spring_Tave, tot_spring_PPT, dem_ha_bc, Longitude, dist_infr_m,.std.resid, .cooksd) %>%
  top_n(5, .cooksd) 

ggplot(model.data, aes(index, .std.resid)) + 
  geom_point(aes(color = pttype), alpha = .5) +
  theme_bw()

```

# checking assumption of no multicollinearity

```{r}
#Multicollinearity corresponds to a situation where the data contain highly correlated predictor variables. Read more in Chapter @ref(multicollinearity).

#Multicollinearity is an important issue in regression analysis and should be fixed by removing the concerned variables. It can be assessed using the R function vif() [car package], which computes the variance inflation factors:

car::vif(model1a)

#As a rule of thumb, a VIF value that exceeds 5 or 10 indicates a problematic amount of collinearity. 
```


```{r}
frt7_2$aspect_cardinal2<-as.factor(frt7_2$aspect_cardinal2)
frt7_2$FWI_veg<-as.factor(frt7_2$FWI_veg)
frt7_2$dist_roads_m_log<-log(frt7_2$dist_roads_m+1)

model1 <- glm (pttype ~ Latitude + Longitude + spring_Tave + tot_spring_PPT + dem_ha_bc + aspect_cardinal2 + FWI_veg + dist_roads_m_log + dist_infr_m + win_spg,
               data=frt7_2,
               family = binomial (link = "logit"))

summary(model1)
table(frt7_2$FWI_veg)

#Create a new blank table and get AUC too
top_mod_table_frt7_All <- data.frame (matrix (ncol = 26, nrow = 0))
colnames (top_mod_table_frt7_All ) <- c ("CAUSE", 
                                    "FRT",  
                                    "Model_terms", 
                                    "intercept", 
                                    "coef_Latitude",
                                    "coef_Longitude",
                                    "coef_spring_Tave", 
                                    "coef_tot_spring_PPT",
                                    "coef_elevation", 
                                    "coef_aspect_N",
                                    "coef_aspect_S",
                                    "coef_aspect_W",
                                    "coef_FWI_veg_C-2", 
                                    "coef_FWI_veg_C-3",
                                    "coef_FWI_veg_C-4",
                                    "coef_FWI_veg_C-7",
                                    "coef_FWI_veg_D-1/2",
                                    "coef_FWI_veg_M-1/2",
                                    "coef_FWI_veg_N",
                                    "coef_FWI_veg_O-1a/b",
                                    "coef_FWI_veg_S-1",
                                    "coef_FWI_veg_S-2",
                                    "coef_log_dist_roads",
                                    "coef_dist_infr",
                                    "coef_win_spg",
                                    "AUC")

frt7_2$fire_veg<-paste(frt7_2$pttype, frt7_2$FWI_veg)
```

Let's run it 100 times to get good mean values.

```{r}

for (g in 1:100){

prop<-0.75
# Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(frt7_2$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- frt7_2[ trainIndex,]
   Valid <- frt7_2[-trainIndex,]
   
#Model   
mod<-glm (pttype ~ Latitude + Longitude + spring_Tave + tot_spring_PPT + dem_ha_bc + aspect_cardinal2 + FWI_veg + dist_roads_m_log + dist_infr_m + win_spg, data=dat1, family=binomial(link="logit"))

mod.valid <- predict.glm(mod, newdata=Valid, type="response")
   roc_obj <- roc(Valid[,"pttype"], mod.valid, quiet=TRUE)
   mod.auc <- auc(roc_obj)

# create model table (only do this once) and add the relevant data
top_mod_table_frt7_person <- data.frame (matrix (ncol = 26, nrow = 0))
colnames (top_mod_table_frt7_person ) <- c ("CAUSE", 
                                    "FRT",  
                                    "Model_terms", 
                                    "intercept", 
                                    "coef_Latitude",
                                    "coef_Longitude",
                                    "coef_spring_Tave", 
                                    "coef_tot_spring_PPT",
                                    "coef_elevation", 
                                    "coef_aspect_N",
                                    "coef_aspect_S",
                                    "coef_aspect_W",
                                    "coef_FWI_veg_C-2", 
                                    "coef_FWI_veg_C-3",
                                    "coef_FWI_veg_C-4",
                                    "coef_FWI_veg_C-7",
                                    "coef_FWI_veg_D-1/2",
                                    "coef_FWI_veg_M-1/2",
                                    "coef_FWI_veg_N",
                                    "coef_FWI_veg_O-1a/b",
                                    "coef_FWI_veg_S-1",
                                    "coef_FWI_veg_S-2",
                                    "coef_log_dist_roads",
                                    "coef_dist_infr",
                                    "coef_win_spg",
                                    "AUC")

##Add data for NDT1
top_mod_table_frt7_person[1,1]<-"spread"
top_mod_table_frt7_person[1,2]<-"frt7"
top_mod_table_frt7_person[1,3]<-"pttype ~ Lat + Long + PPT07 + elev + aspect + FWI_veg + dist_road + dist_infa + win_spg"
top_mod_table_frt7_person[1,4]<- coef(mod)[1] #Intercept
top_mod_table_frt7_person[1,5]<- coef(mod)[2] 
top_mod_table_frt7_person[1,6]<- coef(mod)[3] 
top_mod_table_frt7_person[1,7]<- coef(mod)[4] 
top_mod_table_frt7_person[1,8]<- coef(mod)[5] 
top_mod_table_frt7_person[1,9]<- coef(mod)[6] 
top_mod_table_frt7_person[1,10]<- coef(mod)[7] 
top_mod_table_frt7_person[1,11]<- coef(mod)[8] 
top_mod_table_frt7_person[1,12]<- coef(mod)[9] 
top_mod_table_frt7_person[1,13]<- coef(mod)[10] 
top_mod_table_frt7_person[1,14]<- coef(mod)[11] 
top_mod_table_frt7_person[1,15]<- coef(mod)[12] 
top_mod_table_frt7_person[1,16]<- coef(mod)[13] 
top_mod_table_frt7_person[1,17]<- coef(mod)[14] 
top_mod_table_frt7_person[1,18]<- coef(mod)[16] 
top_mod_table_frt7_person[1,19]<- coef(mod)[16] 
top_mod_table_frt7_person[1,20]<- coef(mod)[17] 
top_mod_table_frt7_person[1,21]<- coef(mod)[18] 
top_mod_table_frt7_person[1,22]<- coef(mod)[19] 
top_mod_table_frt7_person[1,23]<- coef(mod)[20] 
top_mod_table_frt7_person[1,24]<- coef(mod)[21]
top_mod_table_frt7_person[1,25]<- coef(mod)[22]
top_mod_table_frt7_person[1,26]<- mod.auc

top_mod_table_frt7_All<-rbind(top_mod_table_frt7_All, top_mod_table_frt7_person)

}

```

Check.
```{r}
head(top_mod_table_frt7_All)

```


Get mean values.

```{r}
names(top_mod_table_frt7_All)
str(top_mod_table_frt7_All)
stderror <- function(x) sd(x)/sqrt(length(x))

frt7_summary_table_mean<- top_mod_table_frt7_All %>% summarize_if(is.numeric,mean)


```

Save table.

```{r}
write.csv(frt7_summary_table_mean, file="C:\\Work\\caribou\\castor_data\\Fire\\Fire_sim_data\\data\\BC\\top_mod_table_frt7_spread.csv")
```

################################
#FRT 9
################################

```{r}
# Plot climate data results

frt9<-fire_spread2 %>% filter(frt==9)
model1 <- glm (pttype ~ Latitude + Longitude + climate1 + climate2 ,
               data=frt9,
               family = binomial (link = "logit"))
summary(model1)

library(visreg)
visreg(model1, scale="response", "climate1")
visreg(model1, scale="response", "climate2")
visreg(model1, "climate1")


table(is.na(frt9$win_spg))

frt9_2<-frt9 %>% drop_na(win_spg)
frt9_2<-frt9_2 %>% drop_na(dem_ha_bc)
frt9_2 <-frt9_2 %>% st_drop_geometry()

table(frt9_2$FWI_veg, frt9_2$pttype)

frt9_2<-frt9_2 %>% 
  filter(FWI_veg !="W") # remove water from the model

frt9_2<-frt9_2 %>% 
  filter(!bclcs_level_5 %in% c("GL", "LA")) # remove glaciers or lakes. Sometimes these get put into the N veg category so I want to make sure there are not present
table(frt9_2$FWI_veg, frt9_2$pttype)


library(GGally)
ggpairs(frt9_2[, c("spring_Tave", "tot_spring_PPT", "dem_ha_bc", "Latitude", "Longitude", "slope_ha_bc", "win_spg", "dist_infr_m", "dist_roads_m")])

# note tave_spring and elevation; and dist_road and dist_infra are > 0.7 correlated so must remove one of each of these.

model1 <- glm (pttype ~ Latitude + Longitude + spring_Tave + tot_spring_PPT + dem_ha_bc + aspect_cardinal2 + as.factor(FWI_veg) + dist_roads_m + dist_infr_m + win_spg,
               data=frt9_2,
               family = binomial (link = "logit"))
summary(model1)

model1a <- glm (pttype ~ Latitude + Longitude + tot_spring_PPT + dem_ha_bc + aspect_cardinal2 + as.factor(FWI_veg) + dist_roads_m + dist_infr_m + win_spg,
               data=frt9_2,
               family = binomial (link = "logit"))
model1b <- glm (pttype ~ Latitude + Longitude + spring_Tave + tot_spring_PPT + aspect_cardinal2 + as.factor(FWI_veg) + dist_roads_m + dist_infr_m + win_spg,
               data=frt9_2,
               family = binomial (link = "logit"))

# removing elevation is better

model1c <- glm (pttype ~ Latitude + Longitude + spring_Tave + tot_spring_PPT + aspect_cardinal2 + as.factor(FWI_veg) + dist_infr_m + win_spg,
               data=frt9_2,
               family = binomial (link = "logit"))

model1d <- glm (pttype ~ Latitude + Longitude + spring_Tave + tot_spring_PPT + aspect_cardinal2 + as.factor(FWI_veg) + dist_roads_m + win_spg,
               data=frt9_2,
               family = binomial (link = "logit"))

### Best model is this one!
model1d <- glm (pttype ~ Latitude + Longitude + spring_Tave + tot_spring_PPT + aspect_cardinal2 + as.factor(FWI_veg) + dist_roads_m + win_spg,
               data=frt9_2,
               family = binomial (link = "logit"))

# and log roads helps!
model1d <- glm (pttype ~ Latitude + Longitude + spring_Tave + tot_spring_PPT + aspect_cardinal2 + as.factor(FWI_veg) + log(dist_roads_m+1) + win_spg,
               data=frt9_2,
               family = binomial (link = "logit"))

summary(model1d)
Anova(model1d, type=3)

# remove spring wind since its not significant
model1e <- glm (pttype ~ Latitude + Longitude + spring_Tave + tot_spring_PPT + aspect_cardinal2 + as.factor(FWI_veg) + log(dist_roads_m+1),
               data=frt9_2,
               family = binomial (link = "logit"))

summary(model1e)
Anova(model1e, type=3)



# model diagnostic plots
# below model looks way better with log road dist. It had some structure with just road dist
binnedplot (fitted(model1e), 
            residuals(model1e), 
            nclass = NULL, 
            xlab = "Expected Values", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm"))


frt9_2$resids<-resid(model1e)

binnedplot (frt9_2$spring_Tave, 
            frt9_2$resids)

binnedplot (frt9_2$Latitude                     , 
            frt9_2$resids, 
            nclass = NULL)

binnedplot (frt9_2$Longitude  , 
            frt9_2$resids, 
            nclass = NULL)

binnedplot (log(frt9_2$dist_roads_m+1), 
            frt9_2$resids, 
            nclass = NULL)

binnedplot (frt9_2$tot_spring_PPT, 
            frt9_2$resids, 
            nclass = NULL)


```

```{r}
#Here, we’ll check the linear relationship between continuous predictor variables and the logit of the outcome. This can be done by visually inspecting the scatter plot between each predictor and the logit values.

#Remove qualitative variables from the original data frame and bind the logit values to the data:

# Select only numeric predictors
str(frt9_2)

dat2_b<-frt9_2 %>% dplyr::select(pttype, spring_Tave, tot_spring_PPT,Latitude, Longitude, dist_roads_m, dist_infr_m )
probabilities <- predict(model1e, type = "response")
predicted.classes <- ifelse(probabilities > 0.5, "pos", "neg")

mydata <- dat2_b %>%
  dplyr::select_if(is.numeric) 
predictors <- colnames(mydata)

# Bind the logit and tidying the data for plot
mydata <- mydata %>%
  mutate(logit = log(probabilities/(1-probabilities))) %>%
  gather(key = "predictors", value = "predictor.value", -logit)

ggplot(mydata, aes(logit, predictor.value))+
  geom_point(size = 0.5, alpha = 0.5) +
  geom_smooth(method = "loess") + 
  theme_bw() + 
  facet_wrap(~predictors, scales = "free_y")

# all variables should be approximatly linear which is mostly true
```

Checking assumption of influential values
see: (http://www.sthda.com/english/articles/36-classification-methods-essentials/148-logistic-regression-assumptions-and-diagnostics-in-r/)
```{r}
#Influential values are extreme individual data points that can alter the quality of the logistic regression model.
#The most extreme values in the data can be examined by visualizing the Cook’s distance values. Here we label the top 3 largest values:

plot(model1e, which = 4, id.n = 3)

#Note that, not all outliers are influential observations. To check whether the data contains potential influential observations, the standardized residual error can be inspected. Data points with an absolute standardized residuals above 3 represent possible outliers and may deserve closer attention.

#The following R code computes the standardized residuals (.std.resid) and the Cook’s distance (.cooksd) using the R function augment() [broom package].

# Extract model results
library(broom)

model.data <- augment(model1e) %>% 
  mutate(index = 1:n()) 

#The data for the top 3 largest values, according to the Cook’s distance, can be displayed as follow:
model.data %>% 
  dplyr::select(spring_Tave, tot_spring_PPT, Longitude,.std.resid, .cooksd) %>%
  top_n(5, .cooksd) 

ggplot(model.data, aes(index, .std.resid)) + 
  geom_point(aes(color = pttype), alpha = .5) +
  theme_bw()

```

# checking assumption of no multicollinearity

```{r}
#Multicollinearity corresponds to a situation where the data contain highly correlated predictor variables. Read more in Chapter @ref(multicollinearity).

#Multicollinearity is an important issue in regression analysis and should be fixed by removing the concerned variables. It can be assessed using the R function vif() [car package], which computes the variance inflation factors:

car::vif(model1e)

#As a rule of thumb, a VIF value that exceeds 5 or 10 indicates a problematic amount of collinearity. 
```


```{r}
frt9_2$aspect_cardinal2<-as.factor(frt9_2$aspect_cardinal2)
frt9_2$FWI_veg<-as.factor(frt9_2$FWI_veg)
frt9_2$dist_roads_m_log<-log(frt9_2$dist_roads_m+1)

model1 <- glm (pttype ~ Latitude + Longitude + spring_Tave + tot_spring_PPT + aspect_cardinal2 + FWI_veg + dist_roads_m_log,
               data=frt9_2,
               family = binomial (link = "logit"))

summary(model1)
table(frt9_2$FWI_veg)

#Create a new blank table and get AUC too
top_mod_table_frt9_All <- data.frame (matrix (ncol = 20, nrow = 0))
colnames (top_mod_table_frt9_All ) <- c ("CAUSE", 
                                    "FRT",  
                                    "Model_terms", 
                                    "intercept", 
                                    "coef_Latitude",
                                    "coef_Longitude",
                                    "coef_spring_Tave", 
                                    "coef_tot_spring_PPT", 
                                    "coef_aspect_N",
                                    "coef_aspect_S",
                                    "coef_aspect_W",
                                    "coef_FWI_veg_C-2", 
                                    "coef_FWI_veg_C-3",
                                    "coef_FWI_veg_C-7",
                                    "coef_FWI_veg_D-1/2",
                                    "coef_FWI_veg_M-1/2",
                                    "coef_FWI_veg_N",
                                    "coef_FWI_veg_O-1a/b",
                                    "coef_log_dist_roads",
                                    "AUC")

frt9_2$fire_veg<-paste(frt9_2$pttype, frt9_2$FWI_veg)
```

Let's run it 100 times to get good mean values.

```{r}

for (g in 1:100){

prop<-0.75
# Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(frt9_2$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- frt9_2[ trainIndex,]
   Valid <- frt9_2[-trainIndex,]
   
#Model   
mod<-glm (pttype ~ Latitude + Longitude + spring_Tave + tot_spring_PPT + aspect_cardinal2 + FWI_veg + dist_roads_m_log, data=dat1, family=binomial(link="logit"))

mod.valid <- predict.glm(mod, newdata=Valid, type="response")
   roc_obj <- roc(Valid[,"pttype"], mod.valid, quiet=TRUE)
   mod.auc <- auc(roc_obj)

# create model table (only do this once) and add the relevant data
top_mod_table_frt9_person <- data.frame (matrix (ncol = 20, nrow = 0))
colnames (top_mod_table_frt9_person ) <- c ("CAUSE", 
                                    "FRT",  
                                    "Model_terms", 
                                    "intercept", 
                                    "coef_Latitude",
                                    "coef_Longitude",
                                    "coef_spring_Tave", 
                                    "coef_tot_spring_PPT", 
                                    "coef_aspect_N",
                                    "coef_aspect_S",
                                    "coef_aspect_W",
                                    "coef_FWI_veg_C-2", 
                                    "coef_FWI_veg_C-3",
                                    "coef_FWI_veg_C-7",
                                    "coef_FWI_veg_D-1/2",
                                    "coef_FWI_veg_M-1/2",
                                    "coef_FWI_veg_N",
                                    "coef_FWI_veg_O-1a/b",
                                    "coef_log_dist_roads",
                                    "AUC")

##Add data for NDT1
top_mod_table_frt9_person[1,1]<-"spread"
top_mod_table_frt9_person[1,2]<-"frt9"
top_mod_table_frt9_person[1,3]<-"pttype ~ Latitude + Longitude + spring_Tave + tot_spring_PPT + aspect_cardinal2 + FWI_veg + dist_roads_m_log"
top_mod_table_frt9_person[1,4]<- coef(mod)[1] #Intercept
top_mod_table_frt9_person[1,5]<- coef(mod)[2] 
top_mod_table_frt9_person[1,6]<- coef(mod)[3] 
top_mod_table_frt9_person[1,7]<- coef(mod)[4] 
top_mod_table_frt9_person[1,8]<- coef(mod)[5] 
top_mod_table_frt9_person[1,9]<- coef(mod)[6] 
top_mod_table_frt9_person[1,10]<- coef(mod)[7] 
top_mod_table_frt9_person[1,11]<- coef(mod)[8] 
top_mod_table_frt9_person[1,12]<- coef(mod)[9] 
top_mod_table_frt9_person[1,13]<- coef(mod)[10] 
top_mod_table_frt9_person[1,14]<- coef(mod)[11] 
top_mod_table_frt9_person[1,15]<- coef(mod)[12] 
top_mod_table_frt9_person[1,16]<- coef(mod)[13] 
top_mod_table_frt9_person[1,17]<- coef(mod)[14] 
top_mod_table_frt9_person[1,18]<- coef(mod)[16] 
top_mod_table_frt9_person[1,19]<- coef(mod)[16] 
top_mod_table_frt9_person[1,20]<- mod.auc

top_mod_table_frt9_All<-rbind(top_mod_table_frt9_All, top_mod_table_frt9_person)

}

```

Check.
```{r}
head(top_mod_table_frt9_All)

```


Get mean values.

```{r}
names(top_mod_table_frt9_All)
str(top_mod_table_frt9_All)
stderror <- function(x) sd(x)/sqrt(length(x))

frt9_summary_table_mean<- top_mod_table_frt9_All %>% summarize_if(is.numeric,mean)


```

Save table.

```{r}
write.csv(frt9_summary_table_mean, file="C:\\Work\\caribou\\castor_data\\Fire\\Fire_sim_data\\data\\BC\\top_mod_table_frt9_spread.csv")
```

################################
#FRT 10
################################

```{r}
# Plot climate data results

frt10<-fire_spread2 %>% filter(frt==10)
model1 <- glm (pttype ~ Latitude + Longitude + climate1 + climate2 ,
               data=frt10,
               family = binomial (link = "logit"))
summary(model1)

library(visreg)
visreg(model1, scale="response", "climate1")
visreg(model1, scale="response", "climate2")
visreg(model1, "climate1")

table(is.na(frt10$win_spg))

frt10_2<-frt10 %>% drop_na(win_spg)
frt10_2<-frt10_2 %>% drop_na(dem_ha_bc)
frt10_2 <-frt10_2 %>% st_drop_geometry()

table(frt10_2$FWI_veg, frt10_2$pttype)
frt10_2$FWI_veg[frt10_2$FWI_veg=="S-2"]<-"C-7"
frt10_2$FWI_veg[frt10_2$FWI_veg=="M-3"]<-"O-1a/b"

frt10_2<-frt10_2 %>% 
  filter(FWI_veg !="W") # remove water from the model

frt10_2<-frt10_2 %>% 
  filter(!bclcs_level_5 %in% c("GL", "LA")) # remove glaciers or lakes. Sometimes these get put into the N veg category so I want to make sure there are not present
table(frt10_2$FWI_veg, frt10_2$pttype)


library(GGally)
ggpairs(frt10_2[, c("climate1", "climate2", "dem_ha_bc", "Latitude", "Longitude", "slope_ha_bc", "win_spg", "dist_infr_m", "dist_roads_m")])

cor.test(frt10_2$dem_ha_bc, frt10_2$Longitude)
cor.test(frt10_2$dem_ha_bc, frt10_2$climate1)

# note climate1 and elevation; and longitude and elevation are > 0.7 correlated so must remove one of each of these... probably elevation since its causing issues

model1 <- glm (pttype ~ Latitude + Longitude + climate1 + climate2 + dem_ha_bc + aspect_cardinal2 + as.factor(FWI_veg) + dist_roads_m + dist_infr_m + win_spg,
               data=frt10_2,
               family = binomial (link = "logit"))
summary(model1)

model1a <- glm (pttype ~ Latitude + Longitude + climate1 + climate2 + aspect_cardinal2 + as.factor(FWI_veg) + dist_roads_m + dist_infr_m + win_spg,
               data=frt10_2,
               family = binomial (link = "logit"))

model1b <- glm (pttype ~ Latitude + climate2 + dem_ha_bc + aspect_cardinal2 + as.factor(FWI_veg) + dist_roads_m + dist_infr_m + win_spg,
               data=frt10_2,
               family = binomial (link = "logit"))

# Does taking the logorithm of roads and infrastructure help?

model1c <- glm (pttype ~ Latitude + Longitude + climate1 + climate2 + aspect_cardinal2 + as.factor(FWI_veg) + log(dist_roads_m +1) + dist_infr_m + win_spg,
               data=frt10_2,
               family = binomial (link = "logit"))

model1d <- glm (pttype ~ Latitude + Longitude + climate1 + climate2 + aspect_cardinal2 + as.factor(FWI_veg) + dist_roads_m + log(dist_infr_m+1) + win_spg,
               data=frt10_2,
               family = binomial (link = "logit"))

#  taking the log of roads and infrastructure distance does not seem to help!

model1a <- glm (pttype ~ Latitude + Longitude + climate1 + climate2 + aspect_cardinal2 + as.factor(FWI_veg) + dist_roads_m + dist_infr_m + win_spg,
               data=frt10_2,
               family = binomial (link = "logit"))

summary(model1a)
Anova(model1a, type=3)

# model diagnostic plots
# below model looks way better with log road dist. It had some structure with just road dist
binnedplot (fitted(model1a), 
            residuals(model1a), 
            nclass = NULL, 
            xlab = "Expected Values", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm"))


frt10_2$resids<-resid(model1a)

plot (as.numeric(frt10_2$climate1), 
            frt10_2$resids)

binnedplot (frt10_2$Latitude                     , 
            frt10_2$resids, 
            nclass = NULL)

binnedplot (frt10_2$Longitude  , 
            frt10_2$resids, 
            nclass = NULL)

binnedplot (frt10_2$dist_roads_m, 
            frt10_2$resids, 
            nclass = NULL)

binnedplot (frt10_2$climate2, 
            frt10_2$resids, 
            nclass = NULL)


```

# check some model assumptions
```{r}
#Here, we’ll check the linear relationship between continuous predictor variables and the logit of the outcome. This can be done by visually inspecting the scatter plot between each predictor and the logit values.

#Remove qualitative variables from the original data frame and bind the logit values to the data:

# Select only numeric predictors
str(frt10_2)

dat2_b<-frt10_2 %>% dplyr::select(pttype, climate1, climate2,Latitude, Longitude, dist_roads_m, dist_infr_m )
probabilities <- predict(model1a, type = "response")
predicted.classes <- ifelse(probabilities > 0.5, "pos", "neg")

mydata <- dat2_b %>%
  dplyr::select_if(is.numeric) 
predictors <- colnames(mydata)

# Bind the logit and tidying the data for plot
mydata <- mydata %>%
  mutate(logit = log(probabilities/(1-probabilities))) %>%
  gather(key = "predictors", value = "predictor.value", -logit)

ggplot(mydata, aes(logit, predictor.value))+
  geom_point(size = 0.5, alpha = 0.5) +
  geom_smooth(method = "loess") + 
  theme_bw() + 
  facet_wrap(~predictors, scales = "free_y")

# all variables should be approximatly linear
```

#Checking assumption of influential values

see: (http://www.sthda.com/english/articles/36-classification-methods-essentials/148-logistic-regression-assumptions-and-diagnostics-in-r/)
```{r}
#Influential values are extreme individual data points that can alter the quality of the logistic regression model.
#The most extreme values in the data can be examined by visualizing the Cook’s distance values. Here we label the top 3 largest values:

plot(model1a, which = 4, id.n = 3)

#Note that, not all outliers are influential observations. To check whether the data contains potential influential observations, the standardized residual error can be inspected. Data points with an absolute standardized residuals above 3 represent possible outliers and may deserve closer attention.

#The following R code computes the standardized residuals (.std.resid) and the Cook’s distance (.cooksd) using the R function augment() [broom package].

# Extract model results
library(broom)

model.data <- augment(model1a) %>% 
  mutate(index = 1:n()) 

#The data for the top 3 largest values, according to the Cook’s distance, can be displayed as follow:
model.data %>% 
  dplyr::select(climate1, climate2, Longitude,.std.resid, .cooksd) %>%
  top_n(5, .cooksd) 

ggplot(model.data, aes(index, .std.resid)) + 
  geom_point(aes(color = pttype), alpha = .5) +
  theme_bw()

```

# checking assumption of no multicollinearity

```{r}
#Multicollinearity corresponds to a situation where the data contain highly correlated predictor variables. Read more in Chapter @ref(multicollinearity).

#Multicollinearity is an important issue in regression analysis and should be fixed by removing the concerned variables. It can be assessed using the R function vif() [car package], which computes the variance inflation factors:

car::vif(model1a)

#As a rule of thumb, a VIF value that exceeds 5 or 10 indicates a problematic amount of collinearity. 
```


```{r}
frt10_2$aspect_cardinal2<-as.factor(frt10_2$aspect_cardinal2)
frt10_2$FWI_veg<-as.factor(frt10_2$FWI_veg)

model1 <- glm (pttype ~ Latitude + Longitude + climate1 + climate2 + aspect_cardinal2 + as.factor(FWI_veg) + dist_roads_m + dist_infr_m + win_spg,
               data=frt10_2,
               family = binomial (link = "logit"))

summary(model1)
table(frt10_2$FWI_veg)

#Create a new blank table and get AUC too
top_mod_table_frt10_All <- data.frame (matrix (ncol = 24, nrow = 0))
colnames (top_mod_table_frt10_All ) <- c ("CAUSE", 
                                    "FRT",  
                                    "Model_terms", 
                                    "intercept", 
                                    "coef_Latitude",
                                    "coef_Longitude",
                                    "coef_climate1", 
                                    "coef_climate2", 
                                    "coef_aspect_N",
                                    "coef_aspect_S",
                                    "coef_aspect_W",
                                    "coef_FWI_veg_C-2", 
                                    "coef_FWI_veg_C-3",
                                    "coef_FWI_veg_C-5",
                                    "coef_FWI_veg_C-7",
                                    "coef_FWI_veg_D-1/2",
                                    "coef_FWI_veg_M-1/2",
                                    "coef_FWI_veg_N",
                                    "coef_FWI_veg_O-1a/b",
                                    "coef_FWI_veg_S-1",
                                    "coef_dist_roads",
                                    "coef_dist_infr",
                                    "coef_wind_spring",
                                    "AUC")

frt10_2$fire_veg<-paste(frt10_2$pttype, frt10_2$FWI_veg)
```

Let's run it 100 times to get good mean values.

```{r}

for (g in 1:100){

prop<-0.75
# Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(frt10_2$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- frt10_2[ trainIndex,]
   Valid <- frt10_2[-trainIndex,]
   
#Model   
mod<-glm (pttype ~ Latitude + Longitude + climate1 + climate2 + aspect_cardinal2 + FWI_veg + dist_roads_m + dist_infr_m + win_spg, data=dat1, family=binomial(link="logit"))

mod.valid <- predict.glm(mod, newdata=Valid, type="response")
   roc_obj <- roc(Valid[,"pttype"], mod.valid, quiet=TRUE)
   mod.auc <- auc(roc_obj)

# create model table (only do this once) and add the relevant data
top_mod_table_frt10_person <- data.frame (matrix (ncol = 24, nrow = 0))
colnames (top_mod_table_frt10_person ) <- c ("CAUSE", 
                                    "FRT",  
                                    "Model_terms", 
                                    "intercept", 
                                    "coef_Latitude",
                                    "coef_Longitude",
                                    "coef_climate1", 
                                    "coef_climate2", 
                                    "coef_aspect_N",
                                    "coef_aspect_S",
                                    "coef_aspect_W",
                                    "coef_FWI_veg_C-2", 
                                    "coef_FWI_veg_C-3",
                                    "coef_FWI_veg_C-5",
                                    "coef_FWI_veg_C-7",
                                    "coef_FWI_veg_D-1/2",
                                    "coef_FWI_veg_M-1/2",
                                    "coef_FWI_veg_N",
                                    "coef_FWI_veg_O-1a/b",
                                    "coef_FWI_veg_S-1",
                                    "coef_dist_roads",
                                    "coef_dist_infr",
                                    "coef_wind_spring",
                                    "AUC")

##Add data for NDT1
top_mod_table_frt10_person[1,1]<-"spread"
top_mod_table_frt10_person[1,2]<-"frt10"
top_mod_table_frt10_person[1,3]<-"pttype ~ Latitude + Longitude + climate1 + climate2 + aspect_cardinal2 + as.factor(FWI_veg) + dist_roads_m + dist_infr_m + win_spg"
top_mod_table_frt10_person[1,4]<- coef(mod)[1] #Intercept
top_mod_table_frt10_person[1,5]<- coef(mod)[2] 
top_mod_table_frt10_person[1,6]<- coef(mod)[3] 
top_mod_table_frt10_person[1,7]<- coef(mod)[4] 
top_mod_table_frt10_person[1,8]<- coef(mod)[5] 
top_mod_table_frt10_person[1,9]<- coef(mod)[6] 
top_mod_table_frt10_person[1,10]<- coef(mod)[7] 
top_mod_table_frt10_person[1,11]<- coef(mod)[8] 
top_mod_table_frt10_person[1,12]<- coef(mod)[9] 
top_mod_table_frt10_person[1,13]<- coef(mod)[10] 
top_mod_table_frt10_person[1,14]<- coef(mod)[11] 
top_mod_table_frt10_person[1,15]<- coef(mod)[12] 
top_mod_table_frt10_person[1,16]<- coef(mod)[13] 
top_mod_table_frt10_person[1,17]<- coef(mod)[14] 
top_mod_table_frt10_person[1,18]<- coef(mod)[15] 
top_mod_table_frt10_person[1,19]<- coef(mod)[16] 
top_mod_table_frt10_person[1,20]<- coef(mod)[17] 
top_mod_table_frt10_person[1,21]<- coef(mod)[18] 
top_mod_table_frt10_person[1,22]<- coef(mod)[19] 
top_mod_table_frt10_person[1,23]<- coef(mod)[20] 
top_mod_table_frt10_person[1,24]<- mod.auc

top_mod_table_frt10_All<-rbind(top_mod_table_frt10_All, top_mod_table_frt10_person)

}

```

Check.
```{r}
head(top_mod_table_frt10_All)

```


Get mean values.

```{r}
names(top_mod_table_frt10_All)
str(top_mod_table_frt10_All)
stderror <- function(x) sd(x)/sqrt(length(x))

frt10_summary_table_mean<- top_mod_table_frt10_All %>% summarize_if(is.numeric,mean)


```

Save table.

```{r}
write.csv(frt10_summary_table_mean, file="C:\\Work\\caribou\\castor_data\\Fire\\Fire_sim_data\\data\\BC\\top_mod_table_frt10_spread.csv")
```


################################
#FRT 11
################################

```{r}
# Plot climate data results

frt11<-fire_spread2 %>% filter(frt==11)
model1 <- glm (pttype ~ Latitude + Longitude + climate1 + climate2 ,
               data=frt11,
               family = binomial (link = "logit"))
summary(model1)

library(visreg)
visreg(model1, scale="response", "climate1")
visreg(model1, scale="response", "climate2")
visreg(model1, "climate1")

table(is.na(frt11$win_spg))

frt11_2<-frt11 %>% drop_na(win_spg)
frt11_2<-frt11_2 %>% drop_na(dem_ha_bc)
frt11_2 <-frt11_2 %>% st_drop_geometry()

table(frt11_2$FWI_veg, frt11_2$pttype)

frt11_2<-frt11_2 %>% 
  filter(FWI_veg !="W") # remove water from the model

frt11_2<-frt11_2 %>% 
  filter(!bclcs_level_5 %in% c("GL", "LA")) # remove glaciers or lakes. Sometimes these get put into the N veg category so I want to make sure there are not present
table(frt11_2$FWI_veg, frt11_2$pttype)


library(GGally)
ggpairs(frt11_2[, c("climate1", "climate2", "dem_ha_bc", "Latitude", "Longitude", "slope_ha_bc", "win_spg", "dist_infr_m", "dist_roads_m")])

# Nothing is very correlated 

model1 <- glm (pttype ~ Latitude + Longitude + climate1 + climate2 + dem_ha_bc + aspect_cardinal2 + as.factor(FWI_veg) + dist_roads_m + dist_infr_m + win_spg,
               data=frt11_2,
               family = binomial (link = "logit"))
summary(model1)
Anova(model1, type=3)

model2 <- glm (pttype ~ Longitude + climate1 + climate2 + dem_ha_bc + aspect_cardinal2 + as.factor(FWI_veg) + dist_roads_m + dist_infr_m + win_spg,
               data=frt11_2,
               family = binomial (link = "logit"))
summary(model2)
Anova(model2, type=3)

model3 <- glm (pttype ~ Longitude + climate1 + climate2 + dem_ha_bc + aspect_cardinal2 + as.factor(FWI_veg) + dist_roads_m + win_spg,
               data=frt11_2,
               family = binomial (link = "logit"))
summary(model3)
Anova(model3, type=3)

# Does taking the logorithm of roads and infrastructure help?

model3 <- glm (pttype ~ Longitude + climate1 + climate2 + dem_ha_bc + aspect_cardinal2 + as.factor(FWI_veg) + dist_roads_m + win_spg,
               data=frt11_2,
               family = binomial (link = "logit"))

summary(model3)
Anova(model3, type=3)

# model diagnostic plots
# below model looks way better with log road dist. It had some structure with just road dist
binnedplot (fitted(model3), 
            residuals(model3), 
            nclass = NULL, 
            xlab = "Expected Values", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm"))


frt11_2$resids<-resid(model3)

binnedplot (as.numeric(frt11_2$climate1), 
            frt11_2$resids)

binnedplot (frt11_2$Latitude                     , 
            frt11_2$resids, 
            nclass = NULL)

binnedplot (frt11_2$Longitude  , 
            frt11_2$resids, 
            nclass = NULL)

binnedplot (frt11_2$dist_roads_m, 
            frt11_2$resids, 
            nclass = NULL)

binnedplot (frt11_2$climate2, 
            frt11_2$resids, 
            nclass = NULL)


```

# check some model assumptions
```{r}
#Here, we’ll check the linear relationship between continuous predictor variables and the logit of the outcome. This can be done by visually inspecting the scatter plot between each predictor and the logit values.

#Remove qualitative variables from the original data frame and bind the logit values to the data:

# Select only numeric predictors
str(frt11_2)

dat2_b<-frt11_2 %>% dplyr::select(pttype, climate1, climate2,Latitude, Longitude, dist_roads_m )
probabilities <- predict(model3, type = "response")
predicted.classes <- ifelse(probabilities > 0.5, "pos", "neg")

mydata <- dat2_b %>%
  dplyr::select_if(is.numeric) 
predictors <- colnames(mydata)

# Bind the logit and tidying the data for plot
mydata <- mydata %>%
  mutate(logit = log(probabilities/(1-probabilities))) %>%
  gather(key = "predictors", value = "predictor.value", -logit)

ggplot(mydata, aes(logit, predictor.value))+
  geom_point(size = 0.5, alpha = 0.5) +
  geom_smooth(method = "loess") + 
  theme_bw() + 
  facet_wrap(~predictors, scales = "free_y")

# all variables should be approximatly linear
```

#Checking assumption of influential values

see: (http://www.sthda.com/english/articles/36-classification-methods-essentials/148-logistic-regression-assumptions-and-diagnostics-in-r/)
```{r}
#Influential values are extreme individual data points that can alter the quality of the logistic regression model.
#The most extreme values in the data can be examined by visualizing the Cook’s distance values. Here we label the top 3 largest values:

plot(model3, which = 4, id.n = 3)

#Note that, not all outliers are influential observations. To check whether the data contains potential influential observations, the standardized residual error can be inspected. Data points with an absolute standardized residuals above 3 represent possible outliers and may deserve closer attention.

#The following R code computes the standardized residuals (.std.resid) and the Cook’s distance (.cooksd) using the R function augment() [broom package].

# Extract model results
library(broom)

model.data <- augment(model3) %>% 
  mutate(index = 1:n()) 

#The data for the top 3 largest values, according to the Cook’s distance, can be displayed as follow:
model.data %>% 
  dplyr::select(climate1, climate2, Longitude,.std.resid, .cooksd) %>%
  top_n(5, .cooksd) 

ggplot(model.data, aes(index, .std.resid)) + 
  geom_point(aes(color = pttype), alpha = .5) +
  theme_bw()

```

# checking assumption of no multicollinearity

```{r}
#Multicollinearity corresponds to a situation where the data contain highly correlated predictor variables. Read more in Chapter @ref(multicollinearity).

#Multicollinearity is an important issue in regression analysis and should be fixed by removing the concerned variables. It can be assessed using the R function vif() [car package], which computes the variance inflation factors:

car::vif(model3)

#As a rule of thumb, a VIF value that exceeds 5 or 10 indicates a problematic amount of collinearity. 
```


```{r}
frt11_2$aspect_cardinal2<-as.factor(frt11_2$aspect_cardinal2)
frt11_2$FWI_veg<-as.factor(frt11_2$FWI_veg)

model1 <- glm (pttype ~ Longitude + climate1 + climate2 + dem_ha_bc + aspect_cardinal2 + FWI_veg + dist_roads_m + win_spg,
               data=frt11_2,
               family = binomial (link = "logit"))

summary(model1)
table(frt11_2$FWI_veg)

#Create a new blank table and get AUC too
top_mod_table_frt11_All <- data.frame (matrix (ncol = 22, nrow = 0))
colnames (top_mod_table_frt11_All ) <- c ("CAUSE", 
                                    "FRT",  
                                    "Model_terms", 
                                    "intercept",
                                    "coef_Longitude",
                                    "coef_climate1", 
                                    "coef_climate2",
                                    "coef_elevation",
                                    "coef_aspect_N",
                                    "coef_aspect_S",
                                    "coef_aspect_W",
                                    "coef_FWI_veg_C-2", 
                                    "coef_FWI_veg_C-3",
                                    "coef_FWI_veg_C-5",
                                    "coef_FWI_veg_C-7",
                                    "coef_FWI_veg_D-1/2",
                                    "coef_FWI_veg_M-1/2",
                                    "coef_FWI_veg_N",
                                    "coef_FWI_veg_O-1a/b",
                                    "coef_dist_roads",
                                    "coef_wind_spring",
                                    "AUC")

frt11_2$fire_veg<-paste(frt11_2$pttype, frt11_2$FWI_veg)
```

Let's run it 100 times to get good mean values.

```{r}

for (g in 1:100){

prop<-0.75
# Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(frt11_2$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- frt11_2[ trainIndex,]
   Valid <- frt11_2[-trainIndex,]
   
#Model   
mod<-glm (pttype ~ Longitude + climate1 + climate2 + dem_ha_bc + aspect_cardinal2 + FWI_veg + dist_roads_m + win_spg, data=dat1, family=binomial(link="logit"))

mod.valid <- predict.glm(mod, newdata=Valid, type="response")
   roc_obj <- roc(Valid[,"pttype"], mod.valid, quiet=TRUE)
   mod.auc <- auc(roc_obj)

# create model table (only do this once) and add the relevant data
top_mod_table_frt11_person <- data.frame (matrix (ncol = 22, nrow = 0))
colnames (top_mod_table_frt11_person ) <- c ("CAUSE", 
                                    "FRT",  
                                    "Model_terms", 
                                    "intercept",
                                    "coef_Longitude",
                                    "coef_climate1", 
                                    "coef_climate2",
                                    "coef_elevation",
                                    "coef_aspect_N",
                                    "coef_aspect_S",
                                    "coef_aspect_W",
                                    "coef_FWI_veg_C-2", 
                                    "coef_FWI_veg_C-3",
                                    "coef_FWI_veg_C-5",
                                    "coef_FWI_veg_C-7",
                                    "coef_FWI_veg_D-1/2",
                                    "coef_FWI_veg_M-1/2",
                                    "coef_FWI_veg_N",
                                    "coef_FWI_veg_O-1a/b",
                                    "coef_dist_roads",
                                    "coef_wind_spring",
                                    "AUC")

##Add data for NDT1
top_mod_table_frt11_person[1,1]<-"spread"
top_mod_table_frt11_person[1,2]<-"frt11"
top_mod_table_frt11_person[1,3]<-"pttype ~ Longitude + climate1 + climate2 + dem_ha_bc + aspect_cardinal2 + FWI_veg + dist_roads_m + win_spg"
top_mod_table_frt11_person[1,4]<- coef(mod)[1] #Intercept
top_mod_table_frt11_person[1,5]<- coef(mod)[2] 
top_mod_table_frt11_person[1,6]<- coef(mod)[3] 
top_mod_table_frt11_person[1,7]<- coef(mod)[4] 
top_mod_table_frt11_person[1,8]<- coef(mod)[5] 
top_mod_table_frt11_person[1,9]<- coef(mod)[6] 
top_mod_table_frt11_person[1,10]<- coef(mod)[7] 
top_mod_table_frt11_person[1,11]<- coef(mod)[8] 
top_mod_table_frt11_person[1,12]<- coef(mod)[9] 
top_mod_table_frt11_person[1,13]<- coef(mod)[10] 
top_mod_table_frt11_person[1,14]<- coef(mod)[11] 
top_mod_table_frt11_person[1,15]<- coef(mod)[12] 
top_mod_table_frt11_person[1,16]<- coef(mod)[13] 
top_mod_table_frt11_person[1,17]<- coef(mod)[14] 
top_mod_table_frt11_person[1,18]<- coef(mod)[15] 
top_mod_table_frt11_person[1,19]<- coef(mod)[16] 
top_mod_table_frt11_person[1,20]<- coef(mod)[17] 
top_mod_table_frt11_person[1,21]<- coef(mod)[18] 
top_mod_table_frt11_person[1,22]<- mod.auc

top_mod_table_frt11_All<-rbind(top_mod_table_frt11_All, top_mod_table_frt11_person)

}

```

Check.
```{r}
head(top_mod_table_frt11_All)

```


Get mean values.

```{r}
names(top_mod_table_frt11_All)
str(top_mod_table_frt11_All)
stderror <- function(x) sd(x)/sqrt(length(x))

frt11_summary_table_mean<- top_mod_table_frt11_All %>% summarize_if(is.numeric,mean)


```

Save table.

```{r}
write.csv(frt11_summary_table_mean, file="C:\\Work\\caribou\\castor_data\\Fire\\Fire_sim_data\\data\\BC\\top_mod_table_frt11_spread.csv")
```


################################
#FRT 12
################################

```{r}
# Plot climate data results

frt12<-fire_spread2 %>% filter(frt==12)
model1 <- glm (pttype ~ Latitude + Longitude + climate1 + climate2 ,
               data=frt12,
               family = binomial (link = "logit"))
summary(model1)

library(visreg)
visreg(model1, scale="response", "climate1")
visreg(model1, scale="response", "climate2")
visreg(model1, "climate1")

table(is.na(frt12$win_spg))

frt12_2<-frt12 %>% drop_na(win_spg)
frt12_2<-frt12_2 %>% drop_na(dem_ha_bc)
frt12_2 <-frt12_2 %>% st_drop_geometry()

table(frt12_2$FWI_veg, frt12_2$pttype)
frt12_2$FWI_veg[frt12_2$FWI_veg=="S-3"]<-"C-7"


frt12_2<-frt12_2 %>% 
  filter(FWI_veg !="W") # remove water from the model

frt12_2<-frt12_2 %>% 
  filter(!bclcs_level_5 %in% c("GL", "LA")) # remove glaciers or lakes. Sometimes these get put into the N veg category so I want to make sure there are not present
table(frt12_2$FWI_veg, frt12_2$pttype)


library(GGally)
ggpairs(frt12_2[, c("climate1", "climate2", "dem_ha_bc", "Latitude", "Longitude", "slope_ha_bc", "win_spg", "dist_infr_m", "dist_roads_m")])

# Nothing is very correlated 

model1 <- glm (pttype ~ Latitude + Longitude + climate1 + climate2 + dem_ha_bc + aspect_cardinal2 + as.factor(FWI_veg) + dist_roads_m + dist_infr_m + win_sum,
               data=frt12_2,
               family = binomial (link = "logit"))
summary(model1)
Anova(model1, type=3)

model2 <- glm (pttype ~ Latitude + Longitude + climate1 + climate2 + dem_ha_bc + aspect_cardinal2 + as.factor(FWI_veg) + log(dist_roads_m+1) + dist_infr_m + win_sum,
               data=frt12_2,
               family = binomial (link = "logit"))
summary(model2)
Anova(model2, type=3)

model3 <- glm (pttype ~ Latitude + Longitude + climate1 + climate2 + dem_ha_bc + aspect_cardinal2 + as.factor(FWI_veg) + log(dist_roads_m+1) + log(dist_infr_m+1) + win_sum,
               data=frt12_2,
               family = binomial (link = "logit"))
summary(model3)
Anova(model3, type=3)

# Tking the logorithm of roads and infrastructure really helps


# model diagnostic plots
# below model looks way better with log road dist. It had some structure with just road dist
binnedplot (fitted(model3), 
            residuals(model3), 
            nclass = NULL, 
            xlab = "Expected Values", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm"))


frt12_2$resids<-resid(model3)

binnedplot (as.numeric(frt12_2$climate1), 
            frt12_2$resids)

binnedplot (frt12_2$Latitude                     , 
            frt12_2$resids, 
            nclass = NULL)

binnedplot (frt12_2$Longitude  , 
            frt12_2$resids, 
            nclass = NULL)

binnedplot (frt12_2$dist_roads_m, 
            frt12_2$resids, 
            nclass = NULL)

binnedplot (frt12_2$climate2, 
            frt12_2$resids, 
            nclass = NULL)


```

# check some model assumptions
```{r}
#Here, we’ll check the linear relationship between continuous predictor variables and the logit of the outcome. This can be done by visually inspecting the scatter plot between each predictor and the logit values.

#Remove qualitative variables from the original data frame and bind the logit values to the data:

# Select only numeric predictors
str(frt12_2)

dat2_b<-frt12_2 %>% dplyr::select(pttype, climate1, climate2,Latitude, Longitude, dist_roads_m )
probabilities <- predict(model3, type = "response")
predicted.classes <- ifelse(probabilities > 0.5, "pos", "neg")

mydata <- dat2_b %>%
  dplyr::select_if(is.numeric) 
predictors <- colnames(mydata)

# Bind the logit and tidying the data for plot
mydata <- mydata %>%
  mutate(logit = log(probabilities/(1-probabilities))) %>%
  gather(key = "predictors", value = "predictor.value", -logit)

ggplot(mydata, aes(logit, predictor.value))+
  geom_point(size = 0.5, alpha = 0.5) +
  geom_smooth(method = "loess") + 
  theme_bw() + 
  facet_wrap(~predictors, scales = "free_y")

# all variables should be approximatly linear
```

#Checking assumption of influential values

see: (http://www.sthda.com/english/articles/36-classification-methods-essentials/148-logistic-regression-assumptions-and-diagnostics-in-r/)
```{r}
#Influential values are extreme individual data points that can alter the quality of the logistic regression model.
#The most extreme values in the data can be examined by visualizing the Cook’s distance values. Here we label the top 3 largest values:

plot(model3, which = 4, id.n = 3)

#Note that, not all outliers are influential observations. To check whether the data contains potential influential observations, the standardized residual error can be inspected. Data points with an absolute standardized residuals above 3 represent possible outliers and may deserve closer attention.

#The following R code computes the standardized residuals (.std.resid) and the Cook’s distance (.cooksd) using the R function augment() [broom package].

# Extract model results
library(broom)

model.data <- augment(model3) %>% 
  mutate(index = 1:n()) 

#The data for the top 3 largest values, according to the Cook’s distance, can be displayed as follow:
model.data %>% 
  dplyr::select(climate1, climate2, Longitude,.std.resid, .cooksd) %>%
  top_n(5, .cooksd) 

ggplot(model.data, aes(index, .std.resid)) + 
  geom_point(aes(color = pttype), alpha = .5) +
  theme_bw()

```

# checking assumption of no multicollinearity

```{r}
#Multicollinearity corresponds to a situation where the data contain highly correlated predictor variables. Read more in Chapter @ref(multicollinearity).

#Multicollinearity is an important issue in regression analysis and should be fixed by removing the concerned variables. It can be assessed using the R function vif() [car package], which computes the variance inflation factors:

car::vif(model3)

cor.test(frt12_2$climate1, frt12_2$Latitude)
cor.test(frt12_2$climate1, frt12_2$dem_ha_bc)
cor.test(frt12_2$Latitude, frt12_2$dem_ha_bc)

#As a rule of thumb, a VIF value that exceeds 5 or 10 indicates a problematic amount of collinearity. 
```


## RUN BELOW

```{r}
frt12_2$aspect_cardinal2<-as.factor(frt12_2$aspect_cardinal2)
frt12_2$FWI_veg<-as.factor(frt12_2$FWI_veg)

model1 <- glm (pttype ~ Latitude + Longitude + climate1 + climate2 + dem_ha_bc + aspect_cardinal2 + as.factor(FWI_veg) + log(dist_roads_m+1) + log(dist_infr_m+1) + win_sum,
               data=frt12_2,
               family = binomial (link = "logit"))

summary(model1)
table(frt12_2$FWI_veg)

#Create a new blank table and get AUC too
top_mod_table_frt12_All <- data.frame (matrix (ncol = 28, nrow = 0))
colnames (top_mod_table_frt12_All ) <- c ("CAUSE", 
                                    "FRT",  
                                    "Model_terms", 
                                    "intercept",
                                    "coef_Latitude",
                                    "coef_Longitude",
                                    "coef_climate1", 
                                    "coef_climate2",
                                    "coef_elevation",
                                    "coef_aspect_N",
                                    "coef_aspect_S",
                                    "coef_aspect_W",
                                    "coef_FWI_veg_C-2", 
                                    "coef_FWI_veg_C-3",
                                    "coef_FWI_veg_C-4",
                                    "coef_FWI_veg_C-5",
                                    "coef_FWI_veg_C-7",
                                    "coef_FWI_veg_D-1/2",
                                    "coef_FWI_veg_M-1/2",
                                    "coef_FWI_veg_M-3",
                                    "coef_FWI_veg_N",
                                    "coef_FWI_veg_O-1a/b",
                                    "coef_FWI_veg_S-1",
                                    "coef_FWI_veg_S-2",
                                    "coef_log_dist_roads",
                                    "coef_log_dist_infra",
                                    "coef_wind_summer",
                                    "AUC")

frt12_2$fire_veg<-paste(frt12_2$pttype, frt12_2$FWI_veg)
```

Let's run it 100 times to get good mean values.

```{r}

for (g in 1:100){

prop<-0.75
# Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(frt12_2$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- frt12_2[ trainIndex,]
   Valid <- frt12_2[-trainIndex,]
   
#Model   
mod<-glm (pttype ~ Latitude + Longitude + climate1 + climate2 + dem_ha_bc + aspect_cardinal2 + FWI_veg + log(dist_roads_m+1) + log(dist_infr_m+1) + win_sum, data=dat1, family=binomial(link="logit"))

mod.valid <- predict.glm(mod, newdata=Valid, type="response")
   roc_obj <- roc(Valid[,"pttype"], mod.valid, quiet=TRUE)
   mod.auc <- auc(roc_obj)

# create model table (only do this once) and add the relevant data
top_mod_table_frt12_person <- data.frame (matrix (ncol = 28, nrow = 0))
colnames (top_mod_table_frt12_person ) <- c ("CAUSE", 
                                    "FRT",  
                                    "Model_terms", 
                                    "intercept",
                                    "coef_Latitude",
                                    "coef_Longitude",
                                    "coef_climate1", 
                                    "coef_climate2",
                                    "coef_elevation",
                                    "coef_aspect_N",
                                    "coef_aspect_S",
                                    "coef_aspect_W",
                                    "coef_FWI_veg_C-2", 
                                    "coef_FWI_veg_C-3",
                                    "coef_FWI_veg_C-4",
                                    "coef_FWI_veg_C-5",
                                    "coef_FWI_veg_C-7",
                                    "coef_FWI_veg_D-1/2",
                                    "coef_FWI_veg_M-1/2",
                                    "coef_FWI_veg_M-3",
                                    "coef_FWI_veg_N",
                                    "coef_FWI_veg_O-1a/b",
                                    "coef_FWI_veg_S-1",
                                    "coef_FWI_veg_S-2",
                                    "coef_log_dist_roads",
                                    "coef_log_dist_infra",
                                    "coef_wind_summer",
                                    "AUC")

##Add data for NDT1
top_mod_table_frt12_person[1,1]<-"spread"
top_mod_table_frt12_person[1,2]<-"frt12"
top_mod_table_frt12_person[1,3]<-"pttype ~ Latitude + Longitude + climate1 + climate2 + dem_ha_bc + aspect_cardinal2 + FWI_veg + log_dist_roads_m + log_dist_infr_m + win_sum"
top_mod_table_frt12_person[1,4]<- coef(mod)[1] #Intercept
top_mod_table_frt12_person[1,5]<- coef(mod)[2] 
top_mod_table_frt12_person[1,6]<- coef(mod)[3] 
top_mod_table_frt12_person[1,7]<- coef(mod)[4] 
top_mod_table_frt12_person[1,8]<- coef(mod)[5] 
top_mod_table_frt12_person[1,9]<- coef(mod)[6] 
top_mod_table_frt12_person[1,10]<- coef(mod)[7] 
top_mod_table_frt12_person[1,11]<- coef(mod)[8] 
top_mod_table_frt12_person[1,12]<- coef(mod)[9] 
top_mod_table_frt12_person[1,13]<- coef(mod)[10] 
top_mod_table_frt12_person[1,14]<- coef(mod)[11] 
top_mod_table_frt12_person[1,15]<- coef(mod)[12] 
top_mod_table_frt12_person[1,16]<- coef(mod)[13] 
top_mod_table_frt12_person[1,17]<- coef(mod)[14] 
top_mod_table_frt12_person[1,18]<- coef(mod)[15] 
top_mod_table_frt12_person[1,19]<- coef(mod)[16] 
top_mod_table_frt12_person[1,20]<- coef(mod)[17] 
top_mod_table_frt12_person[1,21]<- coef(mod)[18] 
top_mod_table_frt12_person[1,22]<- coef(mod)[19] 
top_mod_table_frt12_person[1,23]<- coef(mod)[20] 
top_mod_table_frt12_person[1,24]<- coef(mod)[21] 
top_mod_table_frt12_person[1,25]<- coef(mod)[22] 
top_mod_table_frt12_person[1,26]<- coef(mod)[23] 
top_mod_table_frt12_person[1,27]<- coef(mod)[24] 
top_mod_table_frt12_person[1,28]<- mod.auc

top_mod_table_frt12_All<-rbind(top_mod_table_frt12_All, top_mod_table_frt12_person)

}

```

Check.
```{r}
head(top_mod_table_frt12_All)

```


Get mean values.

```{r}
names(top_mod_table_frt12_All)
str(top_mod_table_frt12_All)
stderror <- function(x) sd(x)/sqrt(length(x))

frt12_summary_table_mean<- top_mod_table_frt12_All %>% summarize_if(is.numeric,mean)


```

Save table.

```{r}
write.csv(frt12_summary_table_mean, file="C:\\Work\\caribou\\castor_data\\Fire\\Fire_sim_data\\data\\BC\\top_mod_table_frt12_spread.csv")
```

################################
#FRT 13
################################

```{r}
# Plot climate data results

frt13<-fire_spread2 %>% filter(frt==13)
model1 <- glm (pttype ~ Latitude + Longitude + climate1 + climate2 ,
               data=frt13,
               family = binomial (link = "logit"))
summary(model1)

library(visreg)
visreg(model1, scale="response", "climate1")
visreg(model1, scale="response", "climate2")
visreg(model1, "climate1")

ggplot(frt13, aes(x = climate1)) +
  geom_histogram(fill = "white", colour = "black") +
  facet_grid(pttype ~ .)

ggplot(frt13, aes(x = climate2)) +
  geom_histogram(fill = "white", colour = "black") +
  facet_grid(pttype ~ .)

table(is.na(frt13$win_spg))

frt13_2<-frt13 %>% drop_na(win_spg)
frt13_2<-frt13_2 %>% drop_na(dem_ha_bc)
frt13_2 <-frt13_2 %>% st_drop_geometry()

table(frt13_2$FWI_veg, frt13_2$pttype)
frt13_2$FWI_veg[frt13_2$FWI_veg=="C-1"]<-"C-7"


frt13_2<-frt13_2 %>% 
  filter(FWI_veg !="W") # remove water from the model

frt13_2<-frt13_2 %>% 
  filter(!bclcs_level_5 %in% c("GL", "LA")) # remove glaciers or lakes. Sometimes these get put into the N veg category so I want to make sure there are not present
table(frt13_2$FWI_veg, frt13_2$pttype)

require (ggcorrplot)
dist.cut.corr <- (frt13_2 [, c("climate1", "climate2", "dem_ha_bc", "Latitude", "Longitude", "slope_ha_bc", "win_sum", "dist_infr_m", "dist_roads_m")])
corr <- round (cor (dist.cut.corr), 3)
p.mat <- round (cor_pmat (dist.cut.corr), 2)
ggcorrplot (corr, type = "lower", lab = TRUE, tl.cex = 10,  lab_size = 3)
# Note climate 1 and dem are correlated

model1 <- glm (pttype ~ Latitude + Longitude + climate1 + climate2 + dem_ha_bc + aspect_cardinal2 + as.factor(FWI_veg) + dist_roads_m + dist_infr_m + win_sum,
               data=frt13_2,
               family = binomial (link = "logit"))
summary(model1)
Anova(model1, type=3)

model2 <- glm (pttype ~ Latitude + Longitude + climate1 + climate2 + aspect_cardinal2 + as.factor(FWI_veg) + dist_roads_m + dist_infr_m + win_sum,
               data=frt13_2,
               family = binomial (link = "logit"))
summary(model2)
Anova(model2, type=3)

model3<-glm (pttype ~ Latitude + Longitude + climate2 + dem_ha_bc + aspect_cardinal2 + as.factor(FWI_veg) + dist_roads_m + dist_infr_m + win_sum,
               data=frt13_2,
               family = binomial (link = "logit"))
summary(model3)
Anova(model3, type=3)

# Best model is the one that leaves out climate1
model4 <- glm (pttype ~ Latitude + Longitude + climate2 + dem_ha_bc + aspect_cardinal2 + as.factor(FWI_veg) + dist_roads_m + dist_infr_m + win_sum,
               data=frt13_2,
               family = binomial (link = "logit"))
summary(model4)
Anova(model1, type=3)

model5 <- glm (pttype ~ Latitude + Longitude + climate2 + dem_ha_bc + aspect_cardinal2 + as.factor(FWI_veg) + log(dist_roads_m +1)+ dist_infr_m + win_sum,
               data=frt13_2,
               family = binomial (link = "logit"))
summary(model5)

# taking log of roads helps
model6 <- glm (pttype ~ Latitude + Longitude + climate2 + dem_ha_bc + aspect_cardinal2 + as.factor(FWI_veg) + log(dist_roads_m +1)+ log(dist_infr_m+1) + win_sum,
               data=frt13_2,
               family = binomial (link = "logit"))
summary(model6)

# tahking log of both roads and distance to infrastructure helps


# model diagnostic plots
# below model looks way better with log road dist. It had some structure with just road dist
binnedplot (fitted(model6), 
            residuals(model6), 
            nclass = NULL, 
            xlab = "Expected Values", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm"))


frt13_2$resids<-resid(model6)

binnedplot (frt13_2$dem_ha_bc, 
            frt13_2$resids)

binnedplot (as.numeric(frt13_2$climate2), 
            frt13_2$resids)


binnedplot (frt13_2$Latitude                     , 
            frt13_2$resids, 
            nclass = NULL)

binnedplot (frt13_2$Longitude  , 
            frt13_2$resids, 
            nclass = NULL)


binnedplot (frt13_2$dist_roads_m, 
            frt13_2$resids, 
            nclass = NULL)

binnedplot (log(frt13_2$dist_roads_m+1), 
            frt13_2$resids, 
            nclass = NULL)

binnedplot (log(frt13_2$dist_infr_m+1), 
            frt13_2$resids, 
            nclass = NULL)


```

# check some model assumptions
```{r}
#Here, we’ll check the linear relationship between continuous predictor variables and the logit of the outcome. This can be done by visually inspecting the scatter plot between each predictor and the logit values.

#Remove qualitative variables from the original data frame and bind the logit values to the data:

# Select only numeric predictors
str(frt13_2)

dat2_b<-frt13_2 %>% dplyr::select(pttype, climate1, climate2,Latitude, Longitude, dist_roads_m, dist_infr_m )
probabilities <- predict(model3, type = "response")
predicted.classes <- ifelse(probabilities > 0.5, "pos", "neg")

mydata <- dat2_b %>%
  dplyr::select_if(is.numeric) 
predictors <- colnames(mydata)

# Bind the logit and tidying the data for plot
mydata <- mydata %>%
  mutate(logit = log(probabilities/(1-probabilities))) %>%
  gather(key = "predictors", value = "predictor.value", -logit)

ggplot(mydata, aes(logit, predictor.value))+
  geom_point(size = 0.5, alpha = 0.5) +
  geom_smooth(method = "loess") + 
  theme_bw() + 
  facet_wrap(~predictors, scales = "free_y")

# all variables should be approximatly linear
```

#Checking assumption of influential values

see: (http://www.sthda.com/english/articles/36-classification-methods-essentials/148-logistic-regression-assumptions-and-diagnostics-in-r/)
```{r}
#Influential values are extreme individual data points that can alter the quality of the logistic regression model.
#The most extreme values in the data can be examined by visualizing the Cook’s distance values. Here we label the top 3 largest values:

plot(model6, which = 4, id.n = 3)

#Note that, not all outliers are influential observations. To check whether the data contains potential influential observations, the standardized residual error can be inspected. Data points with an absolute standardized residuals above 3 represent possible outliers and may deserve closer attention.

#The following R code computes the standardized residuals (.std.resid) and the Cook’s distance (.cooksd) using the R function augment() [broom package].

# Extract model results
library(broom)

model.data <- augment(model6) %>% 
  mutate(index = 1:n()) 

#The data for the top 3 largest values, according to the Cook’s distance, can be displayed as follow:
model.data %>% 
  dplyr::select(dem_ha_bc, climate2, Longitude,.std.resid, .cooksd) %>%
  top_n(5, .cooksd) 

ggplot(model.data, aes(index, .std.resid)) + 
  geom_point(aes(color = pttype), alpha = .5) +
  theme_bw()

```

# checking assumption of no multicollinearity

```{r}
#Multicollinearity corresponds to a situation where the data contain highly correlated predictor variables. Read more in Chapter @ref(multicollinearity).

#Multicollinearity is an important issue in regression analysis and should be fixed by removing the concerned variables. It can be assessed using the R function vif() [car package], which computes the variance inflation factors:

car::vif(model6)

#As a rule of thumb, a VIF value that exceeds 5 or 10 indicates a problematic amount of collinearity. 
```


```{r}
frt13_2$aspect_cardinal2<-as.factor(frt13_2$aspect_cardinal2)
frt13_2$FWI_veg<-as.factor(frt13_2$FWI_veg)

model1 <- glm (pttype ~ Latitude + Longitude + climate2 + dem_ha_bc + aspect_cardinal2 + as.factor(FWI_veg) + log(dist_roads_m +1)+ log(dist_infr_m+1) + win_sum,
               data=frt13_2,
               family = binomial (link = "logit"))

summary(model1)
table(frt13_2$FWI_veg)

#Create a new blank table and get AUC too
top_mod_table_frt13_All <- data.frame (matrix (ncol = 27, nrow = 0))
colnames (top_mod_table_frt13_All ) <- c ("CAUSE", 
                                    "FRT",  
                                    "Model_terms", 
                                    "intercept",
                                    "coef_Latitude",
                                    "coef_Longitude",
                                    "coef_climate2",
                                    "coef_elevation",
                                    "coef_aspect_N",
                                    "coef_aspect_S",
                                    "coef_aspect_W", 
                                    "coef_FWI_veg_C-3",
                                    "coef_FWI_veg_C-4",
                                    "coef_FWI_veg_C-5",
                                    "coef_FWI_veg_C-7",
                                    "coef_FWI_veg_D-1/2",
                                    "coef_FWI_veg_M-1/2",
                                    "coef_FWI_veg_M-3",
                                    "coef_FWI_veg_N",
                                    "coef_FWI_veg_O-1a/b",
                                    "coef_FWI_veg_S-1",
                                    "coef_FWI_veg_S-2",
                                    "coef_FWI_veg_S-3",
                                    "coef_log_dist_roads",
                                    "coef_log_dist_infra",
                                    "coef_wind_summer",
                                    "AUC")

frt13_2$fire_veg<-paste(frt13_2$pttype, frt13_2$FWI_veg)
```

Let's run it 100 times to get good mean values.

```{r}

for (g in 1:100){

prop<-0.75
# Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(frt13_2$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- frt13_2[ trainIndex,]
   Valid <- frt13_2[-trainIndex,]
   
#Model   
mod<-glm (pttype ~ Latitude + Longitude + climate2 + dem_ha_bc + aspect_cardinal2 + as.factor(FWI_veg) + log(dist_roads_m +1)+ log(dist_infr_m+1) + win_sum, data=dat1, family=binomial(link="logit"))

mod.valid <- predict.glm(mod, newdata=Valid, type="response")
   roc_obj <- roc(Valid[,"pttype"], mod.valid, quiet=TRUE)
   mod.auc <- auc(roc_obj)

# create model table (only do this once) and add the relevant data
top_mod_table_frt13_person <- data.frame (matrix (ncol = 27, nrow = 0))
colnames (top_mod_table_frt13_person ) <- c ("CAUSE", 
                                    "FRT",  
                                    "Model_terms", 
                                    "intercept",
                                    "coef_Latitude",
                                    "coef_Longitude",
                                    "coef_climate2",
                                    "coef_elevation",
                                    "coef_aspect_N",
                                    "coef_aspect_S",
                                    "coef_aspect_W", 
                                    "coef_FWI_veg_C-3",
                                    "coef_FWI_veg_C-4",
                                    "coef_FWI_veg_C-5",
                                    "coef_FWI_veg_C-7",
                                    "coef_FWI_veg_D-1/2",
                                    "coef_FWI_veg_M-1/2",
                                    "coef_FWI_veg_M-3",
                                    "coef_FWI_veg_N",
                                    "coef_FWI_veg_O-1a/b",
                                    "coef_FWI_veg_S-1",
                                    "coef_FWI_veg_S-2",
                                    "coef_FWI_veg_S-3",
                                    "coef_log_dist_roads",
                                    "coef_log_dist_infra",
                                    "coef_wind_summer",
                                    "AUC")

##Add data for NDT1
top_mod_table_frt13_person[1,1]<-"spread"
top_mod_table_frt13_person[1,2]<-"frt13"
top_mod_table_frt13_person[1,3]<-"pttype ~ Latitude + Longitude + climate2 + dem_ha_bc + aspect_cardinal2 + FWI_veg + log_dist_roads_m + log_dist_infr_m + win_sum"
top_mod_table_frt13_person[1,4]<- coef(mod)[1] #Intercept
top_mod_table_frt13_person[1,5]<- coef(mod)[2] 
top_mod_table_frt13_person[1,6]<- coef(mod)[3] 
top_mod_table_frt13_person[1,7]<- coef(mod)[4] 
top_mod_table_frt13_person[1,8]<- coef(mod)[5] 
top_mod_table_frt13_person[1,9]<- coef(mod)[6] 
top_mod_table_frt13_person[1,10]<- coef(mod)[7] 
top_mod_table_frt13_person[1,11]<- coef(mod)[8] 
top_mod_table_frt13_person[1,12]<- coef(mod)[9] 
top_mod_table_frt13_person[1,13]<- coef(mod)[10] 
top_mod_table_frt13_person[1,14]<- coef(mod)[11] 
top_mod_table_frt13_person[1,15]<- coef(mod)[12] 
top_mod_table_frt13_person[1,16]<- coef(mod)[13] 
top_mod_table_frt13_person[1,17]<- coef(mod)[14] 
top_mod_table_frt13_person[1,18]<- coef(mod)[15] 
top_mod_table_frt13_person[1,19]<- coef(mod)[16] 
top_mod_table_frt13_person[1,20]<- coef(mod)[17] 
top_mod_table_frt13_person[1,21]<- coef(mod)[18] 
top_mod_table_frt13_person[1,22]<- coef(mod)[19] 
top_mod_table_frt13_person[1,23]<- coef(mod)[20] 
top_mod_table_frt13_person[1,24]<- coef(mod)[21] 
top_mod_table_frt13_person[1,25]<- coef(mod)[22] 
top_mod_table_frt13_person[1,26]<- coef(mod)[23] 
top_mod_table_frt13_person[1,27]<- mod.auc

top_mod_table_frt13_All<-rbind(top_mod_table_frt13_All, top_mod_table_frt13_person)

}

```

Check.
```{r}
head(top_mod_table_frt13_All)

```


Get mean values.

```{r}
names(top_mod_table_frt13_All)
str(top_mod_table_frt13_All)
stderror <- function(x) sd(x)/sqrt(length(x))

frt13_summary_table_mean<- top_mod_table_frt13_All %>% summarize_if(is.numeric,mean)


```

Save table.

```{r}
write.csv(frt13_summary_table_mean, file="C:\\Work\\caribou\\castor_data\\Fire\\Fire_sim_data\\data\\BC\\top_mod_table_frt13_spread.csv")
```


################################
#FRT 14
################################

```{r}
# Plot climate data results

frt14<-fire_spread2 %>% filter(frt==14)
model1 <- glm (pttype ~ Latitude + Longitude + climate1 + climate2 ,
               data=frt14,
               family = binomial (link = "logit"))
summary(model1)

library(visreg)
visreg(model1, scale="response", "climate1")
visreg(model1, scale="response", "climate2")
visreg(model1, "climate1")

ggplot(frt14, aes(x = climate1)) +
  geom_histogram(fill = "white", colour = "black") +
  facet_grid(pttype ~ .)

ggplot(frt14, aes(x = climate2)) +
  geom_histogram(fill = "white", colour = "black") +
  facet_grid(pttype ~ .)

table(is.na(frt14$win_spg))

frt14_2<-frt14 %>% drop_na(win_spg)
frt14_2<-frt14_2 %>% drop_na(dem_ha_bc)
frt14_2 <-frt14_2 %>% st_drop_geometry()

table(frt14_2$FWI_veg, frt14_2$pttype)
frt14_2$FWI_veg[frt14_2$FWI_veg=="C-4"]<-"C-2"
frt14_2$FWI_veg[frt14_2$FWI_veg=="S-2"]<-"C-7"
frt14_2$FWI_veg[frt14_2$FWI_veg=="S-3"]<-"M-1/2"


frt14_2<-frt14_2 %>% 
  filter(FWI_veg !="W") # remove water from the model

frt14_2<-frt14_2 %>% 
  filter(!bclcs_level_5 %in% c("GL", "LA")) # remove glaciers or lakes. Sometimes these get put into the N veg category so I want to make sure there are not present
table(frt14_2$FWI_veg, frt14_2$pttype)

require (ggcorrplot)
dist.cut.corr <- (frt14_2 [, c("climate1", "climate2", "dem_ha_bc", "Latitude", "Longitude", "slope_ha_bc", "win_sum","win_spg", "dist_infr_m", "dist_roads_m")])
corr <- round (cor (dist.cut.corr), 3)
p.mat <- round (cor_pmat (dist.cut.corr), 2)
ggcorrplot (corr, type = "lower", lab = TRUE, tl.cex = 10,  lab_size = 3)
# Note climate 1 and dem, lat and long and win_spg and win_sum are correlated

model1 <- glm (pttype ~ Latitude + Longitude + climate1 + climate2 + dem_ha_bc + aspect_cardinal2 + as.factor(FWI_veg) + dist_roads_m + dist_infr_m + win_sum,
               data=frt14_2,
               family = binomial (link = "logit"))
summary(model1)
Anova(model1, type=3)

model2 <- glm (pttype ~ Latitude + climate1 + climate2 + dem_ha_bc + aspect_cardinal2 + as.factor(FWI_veg) + dist_roads_m + dist_infr_m + win_sum,
               data=frt14_2,
               family = binomial (link = "logit"))
AIC(model2)

model3 <- glm (pttype ~ Longitude + climate1 + climate2 + dem_ha_bc + aspect_cardinal2 + as.factor(FWI_veg) + dist_roads_m + dist_infr_m + win_sum,
               data=frt14_2,
               family = binomial (link = "logit"))
AIC(model3)
# remove long is better than lat

model4 <- glm (pttype ~ Latitude + climate2 + dem_ha_bc + aspect_cardinal2 + as.factor(FWI_veg) + dist_roads_m + dist_infr_m + win_sum,
               data=frt14_2,
               family = binomial (link = "logit"))
AIC(model4)

model5 <- glm (pttype ~ Latitude + climate1 + climate2 + aspect_cardinal2 + as.factor(FWI_veg) + dist_roads_m + dist_infr_m + win_sum,
               data=frt14_2,
               family = binomial (link = "logit"))
AIC(model5)

# tanking about climate1 is better than dem

model6 <- glm (pttype ~ Latitude + climate2 + dem_ha_bc + aspect_cardinal2 + as.factor(FWI_veg) + dist_roads_m + dist_infr_m + win_sum,
               data=frt14_2,
               family = binomial (link = "logit"))
summary(model6)
Anova(model6, type=3)
AIC(model6)

model7 <- glm (pttype ~ Latitude + climate2 + dem_ha_bc + aspect_cardinal2 + as.factor(FWI_veg) + log(dist_roads_m +1) + dist_infr_m + win_sum,
               data=frt14_2,
               family = binomial (link = "logit"))
AIC(model7)

model8 <- glm (pttype ~ Latitude + climate2 + dem_ha_bc + aspect_cardinal2 + as.factor(FWI_veg) + log(dist_roads_m +1) + log(dist_infr_m+1) + win_sum,
               data=frt14_2,
               family = binomial (link = "logit"))
AIC(model8)

# tahking log of both roads and distance to infrastructure helps


# model diagnostic plots
# below model looks way better with log road dist. It had some structure with just road dist
binnedplot (fitted(model8), 
            residuals(model8), 
            nclass = NULL, 
            xlab = "Expected Values", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm"))


frt14_2$resids<-resid(model8)

binnedplot (frt14_2$dem_ha_bc, 
            frt14_2$resids)

binnedplot (as.numeric(frt14_2$climate2), 
            frt14_2$resids)


binnedplot (frt14_2$Latitude                     , 
            frt14_2$resids, 
            nclass = NULL)

binnedplot (log(frt14_2$dist_roads_m+1), 
            frt14_2$resids, 
            nclass = NULL)


binnedplot (log(frt14_2$dist_infr_m+1), 
            frt14_2$resids, 
            nclass = NULL)


```

# check some model assumptions
```{r}
#Here, we’ll check the linear relationship between continuous predictor variables and the logit of the outcome. This can be done by visually inspecting the scatter plot between each predictor and the logit values.

#Remove qualitative variables from the original data frame and bind the logit values to the data:

# Select only numeric predictors
str(frt14_2)

dat2_b<-frt14_2 %>% dplyr::select(pttype, climate1, climate2,Latitude, Longitude, dist_roads_m, dist_infr_m )
probabilities <- predict(model3, type = "response")
predicted.classes <- ifelse(probabilities > 0.5, "pos", "neg")

mydata <- dat2_b %>%
  dplyr::select_if(is.numeric) 
predictors <- colnames(mydata)

# Bind the logit and tidying the data for plot
mydata <- mydata %>%
  mutate(logit = log(probabilities/(1-probabilities))) %>%
  gather(key = "predictors", value = "predictor.value", -logit)

ggplot(mydata, aes(logit, predictor.value))+
  geom_point(size = 0.5, alpha = 0.5) +
  geom_smooth(method = "loess") + 
  theme_bw() + 
  facet_wrap(~predictors, scales = "free_y")

# all variables should be approximatly linear
```

#Checking assumption of influential values

see: (http://www.sthda.com/english/articles/36-classification-methods-essentials/148-logistic-regression-assumptions-and-diagnostics-in-r/)
```{r}
#Influential values are extreme individual data points that can alter the quality of the logistic regression model.
#The most extreme values in the data can be examined by visualizing the Cook’s distance values. Here we label the top 3 largest values:

plot(model8, which = 4, id.n = 3)

#Note that, not all outliers are influential observations. To check whether the data contains potential influential observations, the standardized residual error can be inspected. Data points with an absolute standardized residuals above 3 represent possible outliers and may deserve closer attention.

#The following R code computes the standardized residuals (.std.resid) and the Cook’s distance (.cooksd) using the R function augment() [broom package].

# Extract model results
library(broom)

model.data <- augment(model8) %>% 
  mutate(index = 1:n()) 

#The data for the top 3 largest values, according to the Cook’s distance, can be displayed as follow:
model.data %>% 
  dplyr::select(dem_ha_bc, climate2, Latitude,.std.resid, .cooksd) %>%
  top_n(5, .cooksd) 

ggplot(model.data, aes(index, .std.resid)) + 
  geom_point(aes(color = pttype), alpha = .5) +
  theme_bw()

```

# checking assumption of no multicollinearity

```{r}
#Multicollinearity corresponds to a situation where the data contain highly correlated predictor variables. Read more in Chapter @ref(multicollinearity).

#Multicollinearity is an important issue in regression analysis and should be fixed by removing the concerned variables. It can be assessed using the R function vif() [car package], which computes the variance inflation factors:

car::vif(model8)

#As a rule of thumb, a VIF value that exceeds 5 or 10 indicates a problematic amount of collinearity. 
```


```{r}
frt14_2$aspect_cardinal2<-as.factor(frt14_2$aspect_cardinal2)
frt14_2$FWI_veg<-as.factor(frt14_2$FWI_veg)

model1 <- glm (pttype ~ Latitude + climate2 + dem_ha_bc + aspect_cardinal2 + FWI_veg + log(dist_roads_m +1) + log(dist_infr_m+1) + win_sum,
               data=frt14_2,
               family = binomial (link = "logit"))

summary(model1)
table(frt14_2$FWI_veg)

#Create a new blank table and get AUC too
top_mod_table_frt14_All <- data.frame (matrix (ncol = 23, nrow = 0))
colnames (top_mod_table_frt14_All ) <- c ("CAUSE", 
                                    "FRT",  
                                    "Model_terms", 
                                    "intercept",
                                    "coef_Latitude",
                                    "coef_climate2",
                                    "coef_elevation",
                                    "coef_aspect_N",
                                    "coef_aspect_S",
                                    "coef_aspect_W", 
                                    "coef_FWI_veg_C-3",
                                    "coef_FWI_veg_C-5",
                                    "coef_FWI_veg_C-7",
                                    "coef_FWI_veg_D-1/2",
                                    "coef_FWI_veg_M-1/2",
                                    "coef_FWI_veg_M-3",
                                    "coef_FWI_veg_N",
                                    "coef_FWI_veg_O-1a/b",
                                    "coef_FWI_veg_S-1",
                                    "coef_log_dist_roads",
                                    "coef_log_dist_infra",
                                    "coef_wind_summer",
                                    "AUC")

frt14_2$fire_veg<-paste(frt14_2$pttype, frt14_2$FWI_veg)
```

Let's run it 100 times to get good mean values.

```{r}

for (g in 1:100){

prop<-0.75
# Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(frt14_2$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- frt14_2[ trainIndex,]
   Valid <- frt14_2[-trainIndex,]
   
#Model   
mod<-glm (pttype ~ Latitude + climate2 + dem_ha_bc + aspect_cardinal2 + FWI_veg + log(dist_roads_m +1) + log(dist_infr_m+1) + win_sum, data=dat1, family=binomial(link="logit"))

mod.valid <- predict.glm(mod, newdata=Valid, type="response")
   roc_obj <- roc(Valid[,"pttype"], mod.valid, quiet=TRUE)
   mod.auc <- auc(roc_obj)

# create model table (only do this once) and add the relevant data
top_mod_table_frt14_person <- data.frame (matrix (ncol = 23, nrow = 0))
colnames (top_mod_table_frt14_person ) <- c ("CAUSE", 
                                    "FRT",  
                                    "Model_terms", 
                                    "intercept",
                                    "coef_Latitude",
                                    "coef_climate2",
                                    "coef_elevation",
                                    "coef_aspect_N",
                                    "coef_aspect_S",
                                    "coef_aspect_W", 
                                    "coef_FWI_veg_C-3",
                                    "coef_FWI_veg_C-5",
                                    "coef_FWI_veg_C-7",
                                    "coef_FWI_veg_D-1/2",
                                    "coef_FWI_veg_M-1/2",
                                    "coef_FWI_veg_M-3",
                                    "coef_FWI_veg_N",
                                    "coef_FWI_veg_O-1a/b",
                                    "coef_FWI_veg_S-1",
                                    "coef_log_dist_roads",
                                    "coef_log_dist_infra",
                                    "coef_wind_summer",
                                    "AUC")

##Add data for NDT1
top_mod_table_frt14_person[1,1]<-"spread"
top_mod_table_frt14_person[1,2]<-"frt14"
top_mod_table_frt14_person[1,3]<-"pttype ~ Latitude + climate2 + dem_ha_bc + aspect_cardinal2 + FWI_veg + log(dist_roads_m +1) + log(dist_infr_m+1) + win_sum"
top_mod_table_frt14_person[1,4]<- coef(mod)[1] #Intercept
top_mod_table_frt14_person[1,5]<- coef(mod)[2] 
top_mod_table_frt14_person[1,6]<- coef(mod)[3] 
top_mod_table_frt14_person[1,7]<- coef(mod)[4] 
top_mod_table_frt14_person[1,8]<- coef(mod)[5] 
top_mod_table_frt14_person[1,9]<- coef(mod)[6] 
top_mod_table_frt14_person[1,10]<- coef(mod)[7] 
top_mod_table_frt14_person[1,11]<- coef(mod)[8] 
top_mod_table_frt14_person[1,12]<- coef(mod)[9] 
top_mod_table_frt14_person[1,13]<- coef(mod)[10] 
top_mod_table_frt14_person[1,14]<- coef(mod)[11] 
top_mod_table_frt14_person[1,15]<- coef(mod)[12] 
top_mod_table_frt14_person[1,16]<- coef(mod)[13] 
top_mod_table_frt14_person[1,17]<- coef(mod)[14] 
top_mod_table_frt14_person[1,18]<- coef(mod)[15] 
top_mod_table_frt14_person[1,19]<- coef(mod)[16] 
top_mod_table_frt14_person[1,20]<- coef(mod)[17] 
top_mod_table_frt14_person[1,21]<- coef(mod)[18] 
top_mod_table_frt14_person[1,22]<- coef(mod)[19] 
top_mod_table_frt14_person[1,23]<- mod.auc

top_mod_table_frt14_All<-rbind(top_mod_table_frt14_All, top_mod_table_frt14_person)

}

```

Check.
```{r}
head(top_mod_table_frt14_All)

```


Get mean values.

```{r}
names(top_mod_table_frt14_All)
str(top_mod_table_frt14_All)
stderror <- function(x) sd(x)/sqrt(length(x))

frt14_summary_table_mean<- top_mod_table_frt14_All %>% summarize_if(is.numeric,mean)


```

Save table.

```{r}
write.csv(frt14_summary_table_mean, file="C:\\Work\\caribou\\castor_data\\Fire\\Fire_sim_data\\data\\BC\\top_mod_table_frt14_spread.csv")
```


################################
#FRT 15
################################

```{r}
# Plot climate data results

frt15<-fire_spread2 %>% filter(frt==15)
model1 <- glm (pttype ~ Latitude + Longitude + climate1 + climate2 ,
               data=frt15,
               family = binomial (link = "logit"))
summary(model1)

library(visreg)
visreg(model1, scale="response", "climate1")
visreg(model1, scale="response", "climate2")
visreg(model1, "climate1")

ggplot(frt15, aes(x = climate1)) +
  geom_histogram(fill = "white", colour = "black") +
  facet_grid(pttype ~ .)

ggplot(frt15, aes(x = climate2)) +
  geom_histogram(fill = "white", colour = "black") +
  facet_grid(pttype ~ .)

table(is.na(frt15$win_spg))

frt15_2<-frt15 %>% drop_na(win_spg)
frt15_2<-frt15_2 %>% drop_na(dem_ha_bc)
frt15_2 <-frt15_2 %>% st_drop_geometry()

table(frt15_2$FWI_veg, frt15_2$pttype)
frt15_2$FWI_veg[frt15_2$FWI_veg=="M-3"]<-"O-1a/b"


frt15_2<-frt15_2 %>% 
  filter(FWI_veg !="W") # remove water from the model

frt15_2<-frt15_2 %>% 
  filter(!bclcs_level_5 %in% c("GL", "LA")) # remove glaciers or lakes. Sometimes these get put into the N veg category so I want to make sure there are not present
table(frt15_2$FWI_veg, frt15_2$pttype)

require (ggcorrplot)
dist.cut.corr <- (frt15_2 [, c("climate1", "climate2", "dem_ha_bc", "Latitude", "Longitude", "slope_ha_bc", "win_sum","win_spg", "dist_infr_m", "dist_roads_m")])
corr <- round (cor (dist.cut.corr), 3)
p.mat <- round (cor_pmat (dist.cut.corr), 2)
ggcorrplot (corr, type = "lower", lab = TRUE, tl.cex = 10,  lab_size = 3)
# Note climate 1 and dem, and win_spg and win_sum are correlated

model1 <- glm (pttype ~ Latitude + Longitude + climate1 + climate2 + dem_ha_bc + aspect_cardinal2 + as.factor(FWI_veg) + dist_roads_m + dist_infr_m + win_sum,
               data=frt15_2,
               family = binomial (link = "logit"))
summary(model1)
Anova(model1, type=3)

model2 <- glm (pttype ~ Latitude + Longitude + climate2 + dem_ha_bc + aspect_cardinal2 + as.factor(FWI_veg) + dist_roads_m + dist_infr_m + win_sum,
               data=frt15_2,
               family = binomial (link = "logit"))
AIC(model2)

model3 <- glm (pttype ~ Latitude + Longitude + climate1 + climate2 + aspect_cardinal2 + as.factor(FWI_veg) + dist_roads_m + dist_infr_m + win_sum,
               data=frt15_2,
               family = binomial (link = "logit"))
AIC(model3)
# remove climate1 is better than dem

model4 <- glm (pttype ~ Latitude + Longitude + climate2 + dem_ha_bc + aspect_cardinal2 + as.factor(FWI_veg) + dist_roads_m + dist_infr_m + win_sum,
               data=frt15_2,
               family = binomial (link = "logit"))
summary(model4)
Anova(model4, type=3)

# remove Longitude

model5 <- glm (pttype ~ Latitude + climate2 + dem_ha_bc + aspect_cardinal2 + as.factor(FWI_veg) + dist_roads_m + dist_infr_m + win_sum,
               data=frt15_2,
               family = binomial (link = "logit"))
summary(model5)
Anova(model5, type=3)

model6 <- glm (pttype ~ Latitude + climate2 + dem_ha_bc + aspect_cardinal2 + as.factor(FWI_veg) + dist_infr_m + win_sum,
               data=frt15_2,
               family = binomial (link = "logit"))
summary(model6)
Anova(model6, type=3)

model7 <- glm (pttype ~ Latitude + climate2 + dem_ha_bc + aspect_cardinal2 + as.factor(FWI_veg) + log(dist_infr_m+1) + win_sum,
               data=frt15_2,
               family = binomial (link = "logit"))
summary(model7)
Anova(model7, type=3)
# interesting, taking the log of dist_infr does not help at all!

model8 <- glm (pttype ~ climate2 + dem_ha_bc + aspect_cardinal2 + as.factor(FWI_veg) + dist_infr_m + win_sum,
               data=frt15_2,
               family = binomial (link = "logit"))
summary(model8)
Anova(model8, type=3)

AIC(model4)
AIC(model5)
AIC(model6)
AIC(model7)
AIC(model8)

# model diagnostic plots
# below model looks way better with log road dist. It had some structure with just road dist
binnedplot (fitted(model8), 
            residuals(model8), 
            nclass = NULL, 
            xlab = "Expected Values", 
            ylab = "Average residual", 
            main = paste("Binned Residual Plot - glm"))


frt15_2$resids<-resid(model8)

binnedplot (frt15_2$dem_ha_bc, 
            frt15_2$resids)

binnedplot (as.numeric(frt15_2$climate2), 
            frt15_2$resids)


binnedplot (frt15_2$Latitude                     , 
            frt15_2$resids, 
            nclass = NULL)



binnedplot (frt15_2$dist_infr_m, 
            frt15_2$resids, 
            nclass = NULL)


```

# check some model assumptions
```{r}
#Here, we’ll check the linear relationship between continuous predictor variables and the logit of the outcome. This can be done by visually inspecting the scatter plot between each predictor and the logit values.

#Remove qualitative variables from the original data frame and bind the logit values to the data:

# Select only numeric predictors
str(frt15_2)

dat2_b<-frt15_2 %>% dplyr::select(pttype, climate2, dist_infr_m )
probabilities <- predict(model8, type = "response")
predicted.classes <- ifelse(probabilities > 0.5, "pos", "neg")

mydata <- dat2_b %>%
  dplyr::select_if(is.numeric) 
predictors <- colnames(mydata)

# Bind the logit and tidying the data for plot
mydata <- mydata %>%
  mutate(logit = log(probabilities/(1-probabilities))) %>%
  gather(key = "predictors", value = "predictor.value", -logit)

ggplot(mydata, aes(logit, predictor.value))+
  geom_point(size = 0.5, alpha = 0.5) +
  geom_smooth(method = "loess") + 
  theme_bw() + 
  facet_wrap(~predictors, scales = "free_y")

# all variables should be approximatly linear
```

#Checking assumption of influential values

see: (http://www.sthda.com/english/articles/36-classification-methods-essentials/148-logistic-regression-assumptions-and-diagnostics-in-r/)
```{r}
#Influential values are extreme individual data points that can alter the quality of the logistic regression model.
#The most extreme values in the data can be examined by visualizing the Cook’s distance values. Here we label the top 3 largest values:

plot(model8, which = 4, id.n = 3)

#Note that, not all outliers are influential observations. To check whether the data contains potential influential observations, the standardized residual error can be inspected. Data points with an absolute standardized residuals above 3 represent possible outliers and may deserve closer attention.

#The following R code computes the standardized residuals (.std.resid) and the Cook’s distance (.cooksd) using the R function augment() [broom package].

# Extract model results
library(broom)

model.data <- augment(model8) %>% 
  mutate(index = 1:n()) 

#The data for the top 3 largest values, according to the Cook’s distance, can be displayed as follow:
model.data %>% 
  dplyr::select(dem_ha_bc, climate2,.std.resid, .cooksd) %>%
  top_n(5, .cooksd) 

ggplot(model.data, aes(index, .std.resid)) + 
  geom_point(aes(color = pttype), alpha = .5) +
  theme_bw()

```

# checking assumption of no multicollinearity

```{r}
#Multicollinearity corresponds to a situation where the data contain highly correlated predictor variables. Read more in Chapter @ref(multicollinearity).

#Multicollinearity is an important issue in regression analysis and should be fixed by removing the concerned variables. It can be assessed using the R function vif() [car package], which computes the variance inflation factors:

car::vif(model8)

#As a rule of thumb, a VIF value that exceeds 5 or 10 indicates a problematic amount of collinearity. 
```


```{r}
frt15_2$aspect_cardinal2<-as.factor(frt15_2$aspect_cardinal2)
frt15_2$FWI_veg<-as.factor(frt15_2$FWI_veg)

model1 <- glm (pttype ~ climate2 + dem_ha_bc + aspect_cardinal2 + FWI_veg + dist_infr_m + win_sum,
               data=frt15_2,
               family = binomial (link = "logit"))

summary(model1)
table(frt15_2$FWI_veg)

#Create a new blank table and get AUC too
top_mod_table_frt15_All <- data.frame (matrix (ncol = 20, nrow = 0))
colnames (top_mod_table_frt15_All ) <- c ("CAUSE", 
                                    "FRT",  
                                    "Model_terms",
                                    "intercept",
                                    "coef_climate2",
                                    "coef_elevation",
                                    "coef_aspect_N",
                                    "coef_aspect_S",
                                    "coef_aspect_W",
                                    "coef_FWI_veg_C-5",
                                    "coef_FWI_veg_C-7",
                                    "coef_FWI_veg_D-1/2",
                                    "coef_FWI_veg_M-1/2",
                                    "coef_FWI_veg_N",
                                    "coef_FWI_veg_O-1a/b",
                                    "coef_FWI_veg_S-1",
                                    "coef_FWI_veg_S-3",
                                    "coef_log_dist_infra",
                                    "coef_wind_summer",
                                    "AUC")

frt15_2$fire_veg<-paste(frt15_2$pttype, frt15_2$FWI_veg)
```

Let's run it 100 times to get good mean values.

```{r}

for (g in 1:100){

prop<-0.75
# Creating training and testing datasets so that I can get a measure of how well the model actually predicts the data e.g. AUG
  trainIndex <- createDataPartition(frt15_2$fire_veg, p = prop,
                                    list = FALSE,
                                    times = 1)
  
   dat1 <- frt15_2[ trainIndex,]
   Valid <- frt15_2[-trainIndex,]
   
#Model   
mod<-glm (pttype ~ climate2 + dem_ha_bc + aspect_cardinal2 + FWI_veg + dist_infr_m + win_sum, data=dat1, family=binomial(link="logit"))

mod.valid <- predict.glm(mod, newdata=Valid, type="response")
   roc_obj <- roc(Valid[,"pttype"], mod.valid, quiet=TRUE)
   mod.auc <- auc(roc_obj)

# create model table (only do this once) and add the relevant data
top_mod_table_frt15_person <- data.frame (matrix (ncol = 20, nrow = 0))
colnames (top_mod_table_frt15_person ) <- c ("CAUSE", 
                                    "FRT",  
                                    "Model_terms", 
                                    "intercept",
                                    "coef_climate2",
                                    "coef_elevation",
                                    "coef_aspect_N",
                                    "coef_aspect_S",
                                    "coef_aspect_W",
                                    "coef_FWI_veg_C-5",
                                    "coef_FWI_veg_C-7",
                                    "coef_FWI_veg_D-1/2",
                                    "coef_FWI_veg_M-1/2",
                                    "coef_FWI_veg_N",
                                    "coef_FWI_veg_O-1a/b",
                                    "coef_FWI_veg_S-1",
                                    "coef_FWI_veg_S-3",
                                    "coef_log_dist_infra",
                                    "coef_wind_summer",
                                    "AUC")

##Add data for NDT1
top_mod_table_frt15_person[1,1]<-"spread"
top_mod_table_frt15_person[1,2]<-"frt15"
top_mod_table_frt15_person[1,3]<-"pttype ~ climate2 + dem_ha_bc + aspect_cardinal2 + FWI_veg + dist_infr_m + win_sum"
top_mod_table_frt15_person[1,4]<- coef(mod)[1] #Intercept
top_mod_table_frt15_person[1,5]<- coef(mod)[2] 
top_mod_table_frt15_person[1,6]<- coef(mod)[3] 
top_mod_table_frt15_person[1,7]<- coef(mod)[4] 
top_mod_table_frt15_person[1,8]<- coef(mod)[5] 
top_mod_table_frt15_person[1,9]<- coef(mod)[6] 
top_mod_table_frt15_person[1,10]<- coef(mod)[7] 
top_mod_table_frt15_person[1,11]<- coef(mod)[8] 
top_mod_table_frt15_person[1,12]<- coef(mod)[9] 
top_mod_table_frt15_person[1,13]<- coef(mod)[10] 
top_mod_table_frt15_person[1,14]<- coef(mod)[11] 
top_mod_table_frt15_person[1,15]<- coef(mod)[12] 
top_mod_table_frt15_person[1,16]<- coef(mod)[13] 
top_mod_table_frt15_person[1,17]<- coef(mod)[14] 
top_mod_table_frt15_person[1,18]<- coef(mod)[15] 
top_mod_table_frt15_person[1,19]<- coef(mod)[15] 
top_mod_table_frt15_person[1,20]<- mod.auc

top_mod_table_frt15_All<-rbind(top_mod_table_frt15_All, top_mod_table_frt15_person)

}

```

Check.
```{r}
head(top_mod_table_frt15_All)

```


Get mean values.

```{r}
names(top_mod_table_frt15_All)
str(top_mod_table_frt15_All)
stderror <- function(x) sd(x)/sqrt(length(x))

frt15_summary_table_mean<- top_mod_table_frt15_All %>% summarize_if(is.numeric,mean)


```

Save table.

```{r}
write.csv(frt15_summary_table_mean, file="C:\\Work\\caribou\\castor_data\\Fire\\Fire_sim_data\\data\\BC\\top_mod_table_frt15_spread.csv")
```


###############DATA PREP COMPLETE###################
