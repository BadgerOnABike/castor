---
title: "Distance_from_ignition"
author: "Elizabeth Kleynhans"
date: '2022-11-04'
output: html_document
---


#Overview
In this file, we will be creating a 1km buffer around each fire burn polygon, subtract the polygon area from the buffer, and then divide both the buffers and polygons into squares . With this, we can attempt to create logistic regressions where the 1 ha squares from the buffers are 0 for spread and the 1 ha squares from the fire polygons receive a 1. The data will not be entirely related to environmental variables, however, as it will be confounded by fire-fighting efforts and fire weather change - but we will see if we can find any patterns using this approach. I suspect climate will not be able to come out from this, resulting in fire size being important for characterizing how climate impacts fires. Here, we can assess how topography, VRI and land-use impact the probability of spread into neighbouring cells. 


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
require (sf)
require (RPostgreSQL)
require (rpostgis)
require (fasterize)
require (raster)
require (dplyr)
library(bcdata)
source(here::here("R/functions/R_Postgres.R"))


```

First Ill create a raster for each year that has the distance from the ignition points on it.

# import my ignition locations
```{r}
# get latest data off BCGW
ignit<-try(
  bcdc_query_geodata("WHSE_LAND_AND_NATURAL_RESOURCE.PROT_HISTORICAL_INCIDENTS_SP") %>%
    filter(FIRE_YEAR > 2002) %>%
    filter(FIRE_TYPE == "Fire") %>%
    collect()
)

ignit<-ignit %>% filter(FIRE_YEAR>2002, CURRENT_SIZE>=10)
ignit

# join fire ignition to fire_polygons
fire_bounds_hist<-try(
  bcdc_query_geodata("WHSE_LAND_AND_NATURAL_RESOURCE.PROT_HISTORICAL_FIRE_POLYS_SP") %>%
    filter(FIRE_YEAR > 2002) %>%
    collect()
)

polys<-fire_bounds_hist %>% select(FIRE_LABEL, FIRE_SIZE_HECTARES, FIRE_YEAR) %>% st_drop_geometry()

fire_ignits<-inner_join(ignit, polys)

# create raster of ignition points
# ha BC standard raster
prov.rast <- raster::raster ( # standardized provincial raster with no data in it
                              nrows = 15744, ncols = 17216, 
                              xmn = 159587.5, xmx = 1881187.5, 
                              ymn = 173787.5, ymx = 1748187.5, 
                              crs = "+proj=aea +lat_0=45 +lon_0=-126 +lat_1=50 +lat_2=58.5 +x_0=1000000 +y_0=0 +datum=NAD83 +units=m +no_defs", 
                              resolution = c(100, 100),                               
                              vals = 0)
years<-unique(fire_ignits$FIRE_YEAR)

for (i in 1:length(years)) {
ignit_all<- fire_ignits %>% filter(FIRE_YEAR==years[i])
xy<-st_coordinates(ignit_all)

d1 <- distanceFromPoints(prov.rast, xy)
#plot(d1)
terra::writeRaster (d1, 
                     filename = paste0( "C:\\Work\\caribou\\castor_data\\Fire\\Fire_sim_data\\tmp\\spread\\dist_rasts\\","rast_ignit_dist_", years[i], ".tiff", sep=""), overwrite=TRUE)
}


```

get data and join ignition data with fire polygon data
```{r}
# OR get latest data off BCGW

table(fire_bounds_hist$FIRE_YEAR)

fire_bounds_hist<-fire_bounds_hist %>% filter(FIRE_SIZE_HECTARES >= 10 & FIRE_YEAR>2002)

ggplot() +
  geom_sf(data = (fire_bounds_hist %>% filter(FIRE_YEAR==2018)), colour="red", fill="red")

#FROM HERE

ignition<-st_drop_geometry(ignit)
ignition$ignition_point<-"yes"
ignition2 <- ignition %>% dplyr::select(FIRE_NUMBER, FIRE_LABEL, FIRE_YEAR,LATITUDE, LONGITUDE, ignition_point)

ignition2 <- ignition2 %>% rename (Lat_ignition=LATITUDE,
                                Long_ignition=LONGITUDE)

fire_bounds_with_igitions<-inner_join(fire_bounds_hist, ignition2)

st_crs(fire_bounds_hist)
table(fire_bounds_hist$FIRE_YEAR)
table(fire_bounds_with_igitions$FIRE_YEAR)

#Inspect
head(fire_bounds_with_igitions)
```

Create buffers around the fire polygons taht is approximately the same size as the area burned by the fire.
1.) assume the the fire is approximately round. in that case the area can be estimated using 
A = pi *r^2

Then the area of the fire plus the buffer will be

B = pi*(r+x)^2

if the buffered area is the same as A then

A = B - A so substitute the values in and I get

pi * r^2 = pi * (r+x)^2 - pi*r^2
simplify this equation to get
0 = 2rx + x^2 - r^2

Since we know the area burned we can get r using A = pi r^2 then substitute r into the above equation and solve for x

```{r}
years<-unique(fire_bounds_with_igitions$FIRE_YEAR)
f<-function (x, r) 2*r*x + x^2 - r^2


filenames<-list()

  for (i in 14:14){#length(years)) {
    datalist = list()
# first clip out the fire perimeteres from the buffered area and sample within the buffered area.
    foo<-fire_bounds_with_igitions %>%
      filter(FIRE_YEAR==years[i])
    
    print(years[i])
    
    fire_num<-unique(foo$FIRE_LABEL)
    
    for (j in 1:length(fire_num)) {
      print(fire_num[j])
    bar<-foo %>% filter(FIRE_LABEL == fire_num[j])
    
    #########
      #sample points within fire
    if(bar$FIRE_SIZE_HECTARES<30){ptsize=200} else{ptsize=400}
    
      foo4_sp<-as(bar, "Spatial")
      samp_points2 <- spsample (foo4_sp, cellsize = c (ptsize, ptsize), type = "regular")
      samp_points_new2 <- data.frame (matrix (ncol = 3, nrow = nrow (samp_points2@coords))) # add 'data' to the points
      colnames (samp_points_new2) <- c ("pttype","year", "fire_label")
      samp_points_new2$pttype <- 1
      samp_points_new2$year<-years[i]
      samp_points_new2$fire_label<-fire_num[j]
      sampled_points2 <- SpatialPointsDataFrame (samp_points2, data = samp_points_new2)
      sampled_points_sf2<-st_as_sf(sampled_points2)
      
      
    #get size of buffer
      if(bar$FIRE_SIZE_HECTARES<50){r_val = 400} else {
    r_val<-as.numeric(sqrt((sum(st_area(bar)))/pi))}
    x<-uniroot(f, c(0,1000000),r=r_val)
    bar_buff<-st_buffer(bar,dist=x$root)
    #check
    st_area(bar)
    st_area(bar_buff)
    st_area(bar_buff) - st_area(bar)
    
    # clip buffered area out of fire perimeter  
    foo3<-sf::st_difference(bar_buff, st_buffer(bar,0),)
      # check it worked
      #ggplot() + geom_sf(data = foo3, colour="red", fill="red")
      
      #Third sample points in each year for each herd
      # change sf feature to a SpatialPolygonDataFrame
      foo3_sp<-as(foo3, "Spatial")
      
      samp_points <- spsample (foo3_sp, n=length(sampled_points_sf2$pttype), type = "regular")
      samp_points_new <- data.frame (matrix (ncol = 3, nrow = nrow (samp_points@coords))) # add 'data' to the points
      colnames (samp_points_new) <- c ("pttype","year", "fire_label")
      samp_points_new$pttype <- 0
      samp_points_new$year<-years[i]
      samp_points_new$fire_label<-fire_num[j]
      sampled_points <- SpatialPointsDataFrame (samp_points, data = samp_points_new)
      sampled_points_sf<-st_as_sf(sampled_points)
      
      pts<-rbind(sampled_points_sf, sampled_points_sf2)
      datalist[[j]] <- pts
      
      rm(pts, sampled_points_sf, sampled_points_sf2)
      
    }
    #assign file names to the work
    big_data = do.call(rbind, datalist)
    table(big_data$fire_label, big_data$pttype)
      
    nam1<-paste("sampled_points",years[i],sep=".") #defining the name
      
      assign(nam1,big_data)
      filenames<-append(filenames,nam1)
    }
      
mkFrameList <- function(nfiles) {
  d <- lapply(seq_len(nfiles),function(i) {
    eval(parse(text=filenames[i]))
  })
  do.call(rbind,d)
}

n<-length(filenames)
samp_spread<-mkFrameList(n) 
dim(samp_spread)

table(samp_spread$pttype, samp_spread$year)

# or save it as a shape file
st_write(samp_spread, dsn="C:\\Work\\caribou\\castor_data\\Fire\\Fire_sim_data\\data\\spread\\all_sample_points_400m_Dec23.gpkg")



```


```{r}
# import elevation data
#Elevation
DEM <- raster("C:\\Users\\ekleynha\\OneDrive - Government of BC\\Dem_bc_ha\\BCelevComplete.tif")
plot(DEM)

crs(DEM)
```

#import FRT and change it to a raster for faster extraction

```{r}
# import FRT from the D drive or Kyle CASTOR (below)
frt<-getSpatialQuery("SELECT * FROM frt_canada")

layeraoi<-getSpatialQuery("SELECT * FROM study_area_compart limit 1")
#Create a provincial raster
prov.rast <- raster::raster ( # standardized provincial raster with no data in it
                              nrows = 15744, ncols = 17216, 
                              xmn = 159587.5, xmx = 1881187.5, 
                              ymn = 173787.5, ymx = 1748187.5, 
                              crs = "+proj=aea +lat_0=45 +lon_0=-126 +lat_1=50 +lat_2=58.5 +x_0=1000000 +y_0=0 +datum=NAD83 +units=m +no_defs", 
                              resolution = c(100, 100),                               
                              vals = 0)

ras.frt <- fasterize::fasterize (frt, prov.rast, field = "Cluster")

ras.frt<-setExtent(ras.frt,DEM)

```

```{r}
#if need to import points
#all_points<-st_read("C:\\Work\\caribou\\castor_data\\Fire\\Fire_sim_data\\data\\spread\\all_sample_points.gpkg")

# extract DEM and FRT at each point
x3a<- st_as_sf(samp_spread)
x3a$idno<-1:dim(x3a)[1]

test<-cbind(x3a, st_coordinates(x3a))
head(test)

pointCoordinates<-data.frame(test$X, test$Y)
head(pointCoordinates)
#crs(pointCoordinates) #No CRS when a dataframe
```



```{r}
##Extract DEM values from stacked layer

rasStack = stack(DEM, ras.frt)
rasValue2=raster::extract(DEM, pointCoordinates)
rasValue3=raster::extract(ras.frt, pointCoordinates)

rasValue2

x3_dem<-cbind(x3a, rasValue2)
x3<-cbind(x3_dem,rasValue3)

head(x3)
crs(x3)

# now extract lat long data and feed it into climate BC to get the climate data. 
x3b<- st_transform(x3, crs = "+proj=longlat +datum=NAD83 / BC Albers +no_defs")
x3b<- x3b %>% rename (dem = rasValue2,
                      frt = rasValue3)

head(x3b)

#getting long lat info
#geo.prj <- "+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0" 
st_crs(x3b) #Retrieve coordinate reference system to check

x4a<-as.data.frame(x3b)
#x4a$idno<- 1:dim(x4a[1])
x4<- x4a %>%
  tidyr::separate(geom, into = c("longitude", "latitude")," ")
x4$longitude<- gsub(",", "", as.character(x4$longitude) )
x4$longitude<- substring(x4$longitude, 3)
x4$longitude<- as.numeric(x4$longitude)
x4$longitude<- round(x4$longitude, digits=4)
x4$latitude<- gsub(")", "", as.character(x4$latitude) )
x4$latitude<- as.numeric(x4$latitude)
x4$latitude<- round(x4$latitude, digits=4)

#x4$ID2<-x4$frt
export_dat<- x4 %>% rename(ID1 = idno,
                           ID2 = year,
                           lat = latitude,
                           lon = longitude,
                           el = dem) %>%
  select(ID1, ID2, lat, lon, el)

```


```{r}
years<-c("2002", "2003", "2004", "2005", "2006", "2007","2008","2009","2010","2011","2012","2013","2014","2015","2016","2017","2018", "2019", "2020", "2021", "2022")

for (i in 1: length(years)) {
  
  dat<- export_dat %>% filter(ID2==years[i])
  
  nam1<-paste("sampled.points.spread",years[i], "csv",sep=".")
  the_dir <- "D:\\Fire\\fire_data\\raw_data\\ClimateBC_Data\\climate_BC_input\\Fire_Spread"
  write.csv(dat, file = paste0(the_dir, "\\", basename(nam1)), row.names=FALSE)
}

```

Next, see http://climatebc.ca/Help for how to use ClimateBC to get the climate data. 
You will need to download ClimateBC (http://climatebc.ca/downloads/download.html) and use the files you generate as input to the first code chunk below.

# Here we have a choice you can either manually extract the points or use the R code below to extract them. I find it faster and easier to us the R code although I originally manually extracted the points because I did not know how to connect to the program through R. I think they built this functionality more recently.

## manual extraction
##To acquire ClimateBC Data for your sampled Locations##
1. Open ClimateBC on your computer.
2. In the Multi-Location section, select "Annual Data" and select the appropriate year for each individual file. 
3. In the bottom drop down menu, select "monthly primary variables". 
4. Upload each year, one at a time, and specify an output file location. Name the output files as the default suggested, but create a folder specifically for your outputs for each run.
5. Once all things are set up, click the "Start" button
6. Repeat for each year

Once the above has been completed for the random points and known fire locations you have created in code earlier in this R Markdown file, proceed to the next code chunk.


```{r}

# should really update this so that the year number is not repeated so many time. Maybe in the future

setwd("D:/Climatebc_v742"); # set the ClimateBC root directory as the working directory
exe <- "ClimateBC_v7.42.exe"

## 2002
inputFile = '/D:\\Fire\\fire_data\\raw_data\\ClimateBC_Data\\climate_BC_input\\Fire_Spread\\sampled.points.spread.2002.csv' 
outputFile = '/D:\\Fire\\fire_data\\raw_data\\ClimateBC_Data\\climate_BC_input\\Fire_Spread\\output\\samp_points_2002.csv'
yearPeriod = '/Year_2002.ann'
system2(exe,args= c('/M', yearPeriod, inputFile, outputFile))

##2003
inputFile = '/D:\\Fire\\fire_data\\raw_data\\ClimateBC_Data\\climate_BC_input\\Fire_Spread\\sampled.points.spread.2003.csv' 
outputFile = '/D:\\Fire\\fire_data\\raw_data\\ClimateBC_Data\\climate_BC_input\\Fire_Spread\\output\\samp_points_2003.csv'
yearPeriod = '/Year_2003.ann'
system2(exe,args= c('/M', yearPeriod, inputFile, outputFile))

##2004
inputFile = '/D:\\Fire\\fire_data\\raw_data\\ClimateBC_Data\\climate_BC_input\\Fire_Spread\\sampled.points.spread.2004.csv' 
outputFile = '/D:\\Fire\\fire_data\\raw_data\\ClimateBC_Data\\climate_BC_input\\Fire_Spread\\output\\samp_points_2004.csv'
yearPeriod = '/Year_2004.ann'
system2(exe,args= c('/M', yearPeriod, inputFile, outputFile))

##2005
inputFile = '/D:\\Fire\\fire_data\\raw_data\\ClimateBC_Data\\climate_BC_input\\Fire_Spread\\sampled.points.spread.2005.csv' 
outputFile = '/D:\\Fire\\fire_data\\raw_data\\ClimateBC_Data\\climate_BC_input\\Fire_Spread\\output\\samp_points_2005.csv'
yearPeriod = '/Year_2005.ann'
system2(exe,args= c('/M', yearPeriod, inputFile, outputFile))

##2006
inputFile = '/D:\\Fire\\fire_data\\raw_data\\ClimateBC_Data\\climate_BC_input\\Fire_Spread\\sampled.points.spread.2006.csv' 
outputFile = '/D:\\Fire\\fire_data\\raw_data\\ClimateBC_Data\\climate_BC_input\\Fire_Spread\\output\\samp_points_2006.csv'
yearPeriod = '/Year_2006.ann'
system2(exe,args= c('/M', yearPeriod, inputFile, outputFile))

##2007
inputFile = '/D:\\Fire\\fire_data\\raw_data\\ClimateBC_Data\\climate_BC_input\\Fire_Spread\\sampled.points.spread.2007.csv' 
outputFile = '/D:\\Fire\\fire_data\\raw_data\\ClimateBC_Data\\climate_BC_input\\Fire_Spread\\output\\samp_points_2007.csv'
yearPeriod = '/Year_2007.ann'
system2(exe,args= c('/M', yearPeriod, inputFile, outputFile))

##2008
inputFile = '/D:\\Fire\\fire_data\\raw_data\\ClimateBC_Data\\climate_BC_input\\Fire_Spread\\sampled.points.spread.2008.csv' 
outputFile = '/D:\\Fire\\fire_data\\raw_data\\ClimateBC_Data\\climate_BC_input\\Fire_Spread\\output\\samp_points_2008.csv'
yearPeriod = '/Year_2008.ann'
system2(exe,args= c('/M', yearPeriod, inputFile, outputFile))

##2009
inputFile = '/D:\\Fire\\fire_data\\raw_data\\ClimateBC_Data\\climate_BC_input\\Fire_Spread\\sampled.points.spread.2009.csv' 
outputFile = '/D:\\Fire\\fire_data\\raw_data\\ClimateBC_Data\\climate_BC_input\\Fire_Spread\\output\\samp_points_2009.csv'
yearPeriod = '/Year_2009.ann'
system2(exe,args= c('/M', yearPeriod, inputFile, outputFile))

##2010
inputFile = '/D:\\Fire\\fire_data\\raw_data\\ClimateBC_Data\\climate_BC_input\\Fire_Spread\\sampled.points.spread.2010.csv' 
outputFile = '/D:\\Fire\\fire_data\\raw_data\\ClimateBC_Data\\climate_BC_input\\Fire_Spread\\output\\samp_points_2010.csv'
yearPeriod = '/Year_2010.ann'
system2(exe,args= c('/M', yearPeriod, inputFile, outputFile))

##2011
inputFile = '/D:\\Fire\\fire_data\\raw_data\\ClimateBC_Data\\climate_BC_input\\Fire_Spread\\sampled.points.spread.2011.csv' 
outputFile = '/D:\\Fire\\fire_data\\raw_data\\ClimateBC_Data\\climate_BC_input\\Fire_Spread\\output\\samp_points_2011.csv'
yearPeriod = '/Year_2011.ann'
system2(exe,args= c('/M', yearPeriod, inputFile, outputFile))

##2012
inputFile = '/D:\\Fire\\fire_data\\raw_data\\ClimateBC_Data\\climate_BC_input\\Fire_Spread\\sampled.points.spread.2012.csv' 
outputFile = '/D:\\Fire\\fire_data\\raw_data\\ClimateBC_Data\\climate_BC_input\\Fire_Spread\\output\\samp_points_2012.csv'
yearPeriod = '/Year_2012.ann'
system2(exe,args= c('/M', yearPeriod, inputFile, outputFile))

##2013
inputFile = '/D:\\Fire\\fire_data\\raw_data\\ClimateBC_Data\\climate_BC_input\\Fire_Spread\\sampled.points.spread.2013.csv' 
outputFile = '/D:\\Fire\\fire_data\\raw_data\\ClimateBC_Data\\climate_BC_input\\Fire_Spread\\output\\samp_points_2013.csv'
yearPeriod = '/Year_2013.ann'
system2(exe,args= c('/M', yearPeriod, inputFile, outputFile))

##2014
inputFile = '/D:\\Fire\\fire_data\\raw_data\\ClimateBC_Data\\climate_BC_input\\Fire_Spread\\sampled.points.spread.2014.csv' 
outputFile = '/D:\\Fire\\fire_data\\raw_data\\ClimateBC_Data\\climate_BC_input\\Fire_Spread\\output\\samp_points_2014.csv'
yearPeriod = '/Year_2014.ann'
system2(exe,args= c('/M', yearPeriod, inputFile, outputFile))

##2015
inputFile = '/D:\\Fire\\fire_data\\raw_data\\ClimateBC_Data\\climate_BC_input\\Fire_Spread\\sampled.points.spread.2015.csv' 
outputFile = '/D:\\Fire\\fire_data\\raw_data\\ClimateBC_Data\\climate_BC_input\\Fire_Spread\\output\\samp_points_2015.csv'

yearPeriod = '/Year_2015.ann'
system2(exe,args= c('/M', yearPeriod, inputFile, outputFile))

##2016
inputFile = '/D:\\Fire\\fire_data\\raw_data\\ClimateBC_Data\\climate_BC_input\\Fire_Spread\\sampled.points.spread.2016.csv' 
outputFile = '/D:\\Fire\\fire_data\\raw_data\\ClimateBC_Data\\climate_BC_input\\Fire_Spread\\output\\samp_points_2016.csv'

yearPeriod = '/Year_2016.ann'
system2(exe,args= c('/M', yearPeriod, inputFile, outputFile))

##2017
inputFile = '/D:\\Fire\\fire_data\\raw_data\\ClimateBC_Data\\climate_BC_input\\Fire_Spread\\sampled.points.spread.2017.csv' 
outputFile = '/D:\\Fire\\fire_data\\raw_data\\ClimateBC_Data\\climate_BC_input\\Fire_Spread\\output\\samp_points_2017.csv'
yearPeriod = '/Year_2017.ann'
system2(exe,args= c('/M', yearPeriod, inputFile, outputFile))

##2018
inputFile = '/D:\\Fire\\fire_data\\raw_data\\ClimateBC_Data\\climate_BC_input\\Fire_Spread\\sampled.points.spread.2018.csv' 
outputFile = '/D:\\Fire\\fire_data\\raw_data\\ClimateBC_Data\\climate_BC_input\\Fire_Spread\\output\\samp_points_2018.csv'
yearPeriod = '/Year_2018.ann'
system2(exe,args= c('/M', yearPeriod, inputFile, outputFile))

##2019
inputFile = '/D:\\Fire\\fire_data\\raw_data\\ClimateBC_Data\\climate_BC_input\\Fire_Spread\\sampled.points.spread.2019.csv' 
outputFile = '/D:\\Fire\\fire_data\\raw_data\\ClimateBC_Data\\climate_BC_input\\Fire_Spread\\output\\samp_points_2019.csv'
yearPeriod = '/Year_2019.ann'
system2(exe,args= c('/M', yearPeriod, inputFile, outputFile))

##2020
inputFile = '/D:\\Fire\\fire_data\\raw_data\\ClimateBC_Data\\climate_BC_input\\Fire_Spread\\sampled.points.spread.2020.csv' 
outputFile = '/D:\\Fire\\fire_data\\raw_data\\ClimateBC_Data\\climate_BC_input\\Fire_Spread\\output\\samp_points_2020.csv'
yearPeriod = '/Year_2020.ann'
system2(exe,args= c('/M', yearPeriod, inputFile, outputFile))

##2021
inputFile = '/D:\\Fire\\fire_data\\raw_data\\ClimateBC_Data\\climate_BC_input\\Fire_Spread\\sampled.points.spread.2021.csv' 
outputFile = '/D:\\Fire\\fire_data\\raw_data\\ClimateBC_Data\\climate_BC_input\\Fire_Spread\\output\\samp_points_2021.csv'
yearPeriod = '/Year_2021.ann'
system2(exe,args= c('/M', yearPeriod, inputFile, outputFile))

##2022
inputFile = '/D:\\Fire\\fire_data\\raw_data\\ClimateBC_Data\\climate_BC_input\\Fire_Spread\\sampled.points.spread.2022.csv' 
outputFile = '/D:\\Fire\\fire_data\\raw_data\\ClimateBC_Data\\climate_BC_input\\Fire_Spread\\output\\samp_points_2022.csv'
yearPeriod = '/Year_2022.ann'
system2(exe,args= c('/M', yearPeriod, inputFile, outputFile))

```

#Import climate data and calculate Drought Code

```{r}

###############################
#Import climate data per ignition and sample location
###############################

#Depending on where you saved your output, you may need to update the directory below
file.list1<-list.files("D:\\Fire\\fire_data\\raw_data\\ClimateBC_Data\\climate_BC_input\\Fire_Spread\\output", pattern="samp.points", all.files=FALSE, full.names=FALSE)
y1<-gsub(".csv","",file.list1)
the_dir <- "D:\\Fire\\fire_data\\raw_data\\ClimateBC_Data\\climate_BC_input\\Fire_Spread\\output"

for (i in 1:length(file.list1)){
  assign(paste0(y1[i]),read.csv (file=paste0(the_dir, "\\", file.list1[i])))
}

```

Because much literature suggests that the monthly drought code (MDC) is an important factor, we will use information acquired from ClimateBC to get MDC values.

```{r}
# FOR EACH DATASET CALCULATE THE MONTHLY DROUGHT CODE

#############################################
#### Equations to calculate drought code ####
#############################################
   
months<- c("02", "03", "04", "05", "06", "07", "08", "09", "10", "11", "12")
  
days_month<- c(31, 30, 31, 30, 31, 31, 30, 31, 30) # number of days in each month starting in Jan
#### Daylength adjustment factor (Lf) [Development and Structure of the Canadian Forest Fire Weather Index System pg 15, https://d1ied5g1xfgpx8.cloudfront.net/pdfs/19927.pdf] ####
# Month <- Lf value
# LF[1] is the value for Jan
Lf<-c( -1.6, 0.9, 3.8, 5.8, 6.4, 5.0, 2.4, 0.4, -1.6)
####

### Calculate drought code for Fire ignition data
filenames<-list()
for (i in 1: length(y1)){
  
  x<-eval(as.name(y1[i])) %>% 
    rename(YEAR=ID2) %>%
    dplyr::select(ID1, YEAR,Latitude, Longitude, Tmax02:Tmax11, Tmin02:Tmin11, Tave02:Tave11, PPT02:PPT11, RH02:RH11, CMI02:CMI11, CMD02:CMD11)
  
  x2<- x %>% filter(Tmax05 != -9999) # there are some locations that did not have climate data, probably because they were over the ocean, so Im removing these here.
  
  for (j in 1 : length(Lf)) {

    
    x2$MDC_02<-15 # the MDC value for Feb This assumes that the ground is saturated at the start of the season. Maybe not true for all locations... may need to think about this a little more.
    
    Em<- days_month[j]*((0.36*x2[[paste0("Tmax",months[j+1])]])+Lf[j])
    Em2 <- ifelse(Em<0, 0, Em)
    DC_half<- x2[[paste0("MDC_",months[j])]] + (0.25 * Em2)
    precip<-x2[[paste0("PPT",months[j+1])]]
    RMeff<-(0.83 * (x2[[paste0("PPT",months[j+1])]]))
    Qmr<- (800 * exp((-(DC_half))/400)) + (3.937 * RMeff)
    Qmr2 <- ifelse(Qmr>800, 800, Qmr)
    MDC_m <- (400 * log(800/Qmr2)) + 0.25*Em2
    x2[[paste0("MDC_",months[j+1])]] <- (x2[[paste0("MDC_",months[j])]] + MDC_m)/2
    x2[[paste0("MDC_",months[j+1])]] <- ifelse(x2[[paste0("MDC_",months[j+1])]] <15, 15, x2[[paste0("MDC_",months[j+1])]])
  }
  nam1<-paste("DC.",y1[i],sep="") #defining the name
  assign(nam1,x2)
  filenames<-append(filenames,nam1)
}


# combined all the DC.ignition files together
mkFrameList <- function(nfiles) {
  d <- lapply(seq_len(nfiles),function(i) {
    eval(parse(text=y1[i]))
  })
  do.call(rbind,d)
}

n<-length(y1)
DC.ignitions<-mkFrameList(n) 
#DC.ignitions$ID1<- as.factor(DC.ignitions$ID1)

dim(DC.ignitions) 
names(DC.ignitions)
names(x3b)
dim(x3b)

DC.ignitions<- DC.ignitions %>% rename(idno=ID1,
                                        year=ID2,
                                       dem=Elevation) %>% 
  select(idno:PPT11, CMD01:CMI12)

str(DC.ignitions)
DC.ignitions$year<-as.numeric(as.character(DC.ignitions$year))
DC.ignitions$idno<-as.numeric(as.character(DC.ignitions$idno))


x3b$idno <- as.numeric(as.character(x3b$idno))
x3b$year <- as.numeric(as.character(x3b$year))
str(x3)

# Now join DC.ignitions back with the original fire ignition dataset
spread_weather<-left_join(x3b, DC.ignitions)
head(spread_weather)
tail(spread_weather) #Lat -Longs match
dim(spread_weather) 
st_crs(spread_weather) #Answer NA
head(spread_weather) #Note, there are 2 Lat/Long columns: ensure that they are the same; otherwise, you may be using the incorrect climate csvs that were manually created.
spread_weather_crs <- st_as_sf(spread_weather)
crs(spread_weather_crs)
spread_weather_crs<- st_transform(spread_weather, 3005)
crs(spread_weather_crs)
```


```{r}
st_write(spread_weather_crs, dsn="C:\\Work\\caribou\\castor_data\\Fire\\Fire_sim_data\\data\\spread\\all_sample_points_400m_Dec23.gpkg")

# remove everything from memory except spread_weather_crs
rm(list=setdiff(ls(), "spread_weather_crs"))
source(here::here("R/functions/R_Postgres.R"))
```

# Now create a raster stack of roads and development and extract that data. 

# extract distance to road and distance to infrastructure.
```{r}
# import roads distance raster
roads_dist <- raster("C:\\Work\\caribou\\castor_data\\Fire\\Fire_sim_data\\data\\dist_roads.tif")
crs(roads_dist)

# import infrastructure data
dist_rail<- raster("C:\\Work\\caribou\\castor_data\\Fire\\Fire_sim_data\\data\\dist_rail.tif")
dist_power<- raster("C:\\Work\\caribou\\castor_data\\Fire\\Fire_sim_data\\data\\dist_power.tif")
dist_oil<- raster("C:\\Work\\caribou\\castor_data\\Fire\\Fire_sim_data\\data\\dist_oil.tif")
dist_mines<- raster("C:\\Work\\caribou\\castor_data\\Fire\\Fire_sim_data\\data\\dist_mines.tif")
dist_urban<- raster("C:\\Work\\caribou\\castor_data\\Fire\\Fire_sim_data\\data\\dist_urban.tif")

rasStackinfrastructure = stack(roads_dist,dist_rail, dist_power, dist_oil, dist_mines, dist_urban)


crs(rasStackinfrastructure) # EPSG 9001. Hmm should probably change to 3005
res(rasStackinfrastructure) # at ha scale ... perfect

```

Bring back points from the 05_Distance_to_Road_Data_Prep.rmd file, jion the infrastructure data and create a new column that is the shortest distance to any infrastructure type.

```{r}
test<-cbind(spread_weather_crs, st_coordinates(spread_weather_crs))
head(test)

pointCoordinates<-data.frame(test$X, test$Y)
head(pointCoordinates)

rasValue3=raster::extract(rasStackinfrastructure, pointCoordinates)
#Append new information
 dat2<-cbind(spread_weather_crs, rasValue3)

head(dat2)
crs(dat2)

dat2$dist_infr<-0

dat2$dist_infr<-
  ifelse(dat2$dist_rail < dat2$dist_power, dat2$dist_rail, dat2$dist_power)

dat2$dist_infr<-
  ifelse(dat2$dist_oil < dat2$dist_infr, dat2$dist_oil, dat2$dist_infr)

dat2$dist_infr<-
  ifelse(dat2$dist_mines < dat2$dist_infr, dat2$dist_mines, dat2$dist_infr)

dat2$dist_infr<-
  ifelse(dat2$dist_urban < dat2$dist_infr, dat2$dist_urban, dat2$dist_infr)

dat2$dist_infr_m<-dat2$dist_infr*100
dat2$dist_roads_m<-dat2$dist_roads*100

```


```{r}
sf::st_write(dat2, dsn = "C:\\Work\\caribou\\castor_data\\Fire\\Fire_sim_data\\data\\spread\\Spread_dem_clim_rds_infr_400m_Nov23.gpkg", delete_layer=TRUE)

##Save to personal drive
#ogr2ogr -f "PostgreSQL" PG:"host=localhost user=postgres dbname=postgres password=postgres port=5432" C:\\Work\\caribou\\castor\\R\\fire_sim\\tmp\\Data_clim_DEM_roads_wind_infra.shp -overwrite -a_srs EPSG:3005 -progress --config PG_USE_COPY YES -nlt PROMOTE_TO_MULTI

#dat<-st_read("C:\\Work\\caribou\\castor_data\\Fire\\Fire_sim_data\\data\\Quesnel_WilliamsL_100Mile_points_with_rds_infrastructure.gpkg")
```

```{r}
##Slope
DEM_slope <- raster("T:\\FOR\\VIC\\HTS\\ANA\\PROJECTS\\CASTOR\\Data\\dem\\all_bc\\slope_ha_bc.tif")

##Aspect
DEM_aspect <- raster("T:\\FOR\\VIC\\HTS\\ANA\\PROJECTS\\CASTOR\\Data\\dem\\all_bc\\aspect_ha_bc.tif")

rasStack = stack(DEM_slope, DEM_aspect)

##Try this first
test<-cbind(dat2, st_coordinates(dat2))
head(test)

pointCoordinates<-data.frame(test$X, test$Y)
head(pointCoordinates)
#crs(pointCoordinates) #No CRS when a dataframe

##Extract DEM values from stacked layer
rasValue2=raster::extract(rasStack, pointCoordinates)
head(rasValue2)
str(rasValue2) #200298 values
str(dat2)#200298 values

#Append new information
dat3<-cbind(dat2, rasValue2)
head(dat3)
crs(dat3)
```

```{r}
summer_wind_raster<- raster("D:\\Fire\\fire_data\\raw_data\\GovCanadaWindFiles\\wind_summer_clipped_224.tif")
res(summer_wind_raster)#res seems out of wack

spring_wind_raster<- raster("D:\\Fire\\fire_data\\raw_data\\GovCanadaWindFiles\\wind_spring_raster_224.tif")
res(spring_wind_raster) #resolution seems a bit out of wack...

rasStackWind = stack(summer_wind_raster, spring_wind_raster)

##Extract Wind values from stacked layer
rasValue3=raster::extract(rasStackWind, pointCoordinates)
head(rasValue3)

dat4<-cbind(dat3, rasValue3)
dat4<- dat4 %>% rename(
  win_sum=wind_summer_clipped_224,
  win_spg=wind_spring_raster_224)

head(dat4)

sf::st_write(dat4, dsn = "C:\\Work\\caribou\\castor_data\\Fire\\Fire_sim_data\\data\\spread\\Spread_dem_clim_rds_infr_wind_400m_Dec23.gpkg", delete_layer=TRUE)
```

Extract distance to the ignition point of the fire

```{r}
#dat4<-sf::st_read("C:\\Work\\caribou\\castor_data\\Fire\\Fire_sim_data\\data\\spread\\Spread_dem_clim_rds_infr_wind.gpkg")

filenames<-list()
years<-c("2003", "2004", "2005", "2006", "2007", "2008", "2009", "2010", "2011", "2012", "2013", "2014", "2015", "2016","2017","2018", "2019", "2020", "2021", "2022")

for(i in 1:length(years)) {
  print(years[i])

  dat_dist<-dat4 %>% filter(year==years[i])
  coords<-st_coordinates(dat_dist)

  x<-rast(paste0( "C:\\Work\\caribou\\castor_data\\Fire\\Fire_sim_data\\tmp\\spread\\dist_rasts\\","rast_ignit_dist_", years[i], ".tiff", sep=""))

  rasVal=extract(x, coords)
  colnames(rasVal)<-c("rast_ignit_dist")
  dat_with_dist<-cbind(dat_dist, rasVal)

  #assign file names to the work
  nam1<-paste("dist_points",years[i],sep="_") #defining the name
      
      
  assign(nam1,dat_with_dist)
  filenames<-append(filenames,nam1)
}

mkFrameList <- function(nfiles) {
  d <- lapply(seq_len(nfiles),function(i) {
    eval(parse(text=filenames[i]))
  })
  do.call(rbind,d)
}


n<-length(filenames)
dat_with_dist_to_ignit<-mkFrameList(n) 
dim(dat_with_dist_to_ignit)
names(dat_with_dist_to_ignit)
```

Now save each file separately so that i can extract the VRI data using QGIS

```{r}

#dat_with_dist_to_ignit<-dat4
# Save each fire year separately
# ignit_all_2002<- dat_with_dist_to_ignit %>% filter(year==2002)
# dim(ignit_all_2002)
# sf::st_write(ignit_all_2002, dsn = "C:\\Work\\caribou\\castor_data\\Fire\\Fire_sim_data\\tmp\\spread\\for_veg_extraction\\spread_2002.gpkg", delete_layer=TRUE)

ignit_all_2003<- dat_with_dist_to_ignit %>% filter(year==2003)
dim(ignit_all_2003)
sf::st_write(ignit_all_2003, "C:\\Work\\caribou\\castor_data\\Fire\\Fire_sim_data\\tmp\\spread\\for_veg_extraction\\spread_2003.gpkg", delete_layer=TRUE)

ignit_all_2004<- dat_with_dist_to_ignit %>% filter(year==2004)
dim(ignit_all_2004)
sf::st_write(ignit_all_2004, dsn = "C:\\Work\\caribou\\castor_data\\Fire\\Fire_sim_data\\tmp\\spread\\for_veg_extraction\\spread_2004.gpkg", delete_layer=TRUE)

ignit_all_2005<- dat_with_dist_to_ignit %>% filter(year==2005)
dim(ignit_all_2005)
sf::st_write(ignit_all_2005, dsn = "C:\\Work\\caribou\\castor_data\\Fire\\Fire_sim_data\\tmp\\spread\\for_veg_extraction\\spread_2005.gpkg", delete_layer=TRUE)

ignit_all_2006<- dat_with_dist_to_ignit %>% filter(year==2006)
dim(ignit_all_2006)
sf::st_write(ignit_all_2006, dsn = "C:\\Work\\caribou\\castor_data\\Fire\\Fire_sim_data\\tmp\\spread\\for_veg_extraction\\spread_2006.gpkg", delete_layer=TRUE)

ignit_all_2007<- dat_with_dist_to_ignit %>% filter(year==2007)
dim(ignit_all_2007)
sf::st_write(ignit_all_2007, dsn = "C:\\Work\\caribou\\castor_data\\Fire\\Fire_sim_data\\tmp\\spread\\for_veg_extraction\\spread_2007.gpkg", delete_layer=TRUE)

ignit_all_2008<- dat_with_dist_to_ignit %>% filter(year==2008)
dim(ignit_all_2008)
sf::st_write(ignit_all_2008, dsn = "C:\\Work\\caribou\\castor_data\\Fire\\Fire_sim_data\\tmp\\spread\\for_veg_extraction\\spread_2008.gpkg", delete_layer=TRUE)

ignit_all_2009<- dat_with_dist_to_ignit %>% filter(year==2009)
dim(ignit_all_2009)
sf::st_write(ignit_all_2009, dsn = "C:\\Work\\caribou\\castor_data\\Fire\\Fire_sim_data\\tmp\\spread\\for_veg_extraction\\spread_2009.gpkg", delete_layer=TRUE)

ignit_all_2010<- dat_with_dist_to_ignit %>% filter(year==2010)
dim(ignit_all_2010)
sf::st_write(ignit_all_2010, dsn = "C:\\Work\\caribou\\castor_data\\Fire\\Fire_sim_data\\tmp\\spread\\for_veg_extraction\\spread_2010.gpkg", delete_layer=TRUE)

ignit_all_2011<- dat_with_dist_to_ignit %>% filter(year==2011)
dim(ignit_all_2011)
sf::st_write(ignit_all_2011, dsn = "C:\\Work\\caribou\\castor_data\\Fire\\Fire_sim_data\\tmp\\spread\\for_veg_extraction\\spread_2011.gpkg", delete_layer=TRUE)

ignit_all_2012<- dat_with_dist_to_ignit %>% filter(year==2012)
dim(ignit_all_2012)
sf::st_write(ignit_all_2012, dsn = "C:\\Work\\caribou\\castor_data\\Fire\\Fire_sim_data\\tmp\\spread\\for_veg_extraction\\spread_2012.gpkg", delete_layer=TRUE)

ignit_all_2013<- dat_with_dist_to_ignit %>% filter(year==2013)
dim(ignit_all_2013)
sf::st_write(ignit_all_2013, dsn = "C:\\Work\\caribou\\castor_data\\Fire\\Fire_sim_data\\tmp\\spread\\for_veg_extraction\\spread_2013.gpkg", delete_layer=TRUE)

ignit_all_2014<- dat_with_dist_to_ignit %>% filter(year==2014)
dim(ignit_all_2014)
sf::st_write(ignit_all_2014, dsn = "C:\\Work\\caribou\\castor_data\\Fire\\Fire_sim_data\\tmp\\spread\\for_veg_extraction\\spread_2014.gpkg", delete_layer=TRUE)

ignit_all_2015<- dat_with_dist_to_ignit %>% filter(year==2015)
dim(ignit_all_2015)
sf::st_write(ignit_all_2015, dsn = "C:\\Work\\caribou\\castor_data\\Fire\\Fire_sim_data\\tmp\\spread\\for_veg_extraction\\spread_2015.gpkg", delete_layer=TRUE)

ignit_all_2016<- dat_with_dist_to_ignit %>% filter(year==2016)
dim(ignit_all_2016)
sf::st_write(ignit_all_2016, dsn = "C:\\Work\\caribou\\castor_data\\Fire\\Fire_sim_data\\tmp\\spread\\for_veg_extraction\\spread_2016.gpkg", delete_layer=TRUE)

ignit_all_2017<- dat_with_dist_to_ignit %>% filter(year==2017)
dim(ignit_all_2017)
sf::st_write(ignit_all_2017, dsn = "C:\\Work\\caribou\\castor_data\\Fire\\Fire_sim_data\\tmp\\spread\\for_veg_extraction\\spread_2017.gpkg", delete_layer=TRUE)

ignit_all_2018<- dat_with_dist_to_ignit %>% filter(year==2018)
dim(ignit_all_2018)
sf::st_write(ignit_all_2018, dsn = "C:\\Work\\caribou\\castor_data\\Fire\\Fire_sim_data\\tmp\\spread\\for_veg_extraction\\spread_2018.gpkg", delete_layer=TRUE)

ignit_all_2019<- dat_with_dist_to_ignit %>% filter(year==2019)
dim(ignit_all_2019)
sf::st_write(ignit_all_2019, dsn = "C:\\Work\\caribou\\castor_data\\Fire\\Fire_sim_data\\tmp\\spread\\for_veg_extraction\\spread_2019.gpkg", delete_layer=TRUE)

ignit_all_2020<- dat_with_dist_to_ignit %>% filter(year==2020)
dim(ignit_all_2020)
sf::st_write(ignit_all_2020, dsn = "C:\\Work\\caribou\\castor_data\\Fire\\Fire_sim_data\\tmp\\spread\\for_veg_extraction\\spread_2020.gpkg", delete_layer=TRUE)

ignit_all_2021<- dat_with_dist_to_ignit %>% filter(year==2021)
dim(ignit_all_2021)
sf::st_write(ignit_all_2021, dsn = "C:\\Work\\caribou\\castor_data\\Fire\\Fire_sim_data\\tmp\\spread\\for_veg_extraction\\spread_2021.gpkg", delete_layer=TRUE)

ignit_all_2022<- dat_with_dist_to_ignit %>% filter(year==2022)
dim(ignit_all_2022)
sf::st_write(ignit_all_2022, dsn = "C:\\Work\\caribou\\castor_data\\Fire\\Fire_sim_data\\tmp\\spread\\for_veg_extraction\\spread_2022.gpkg", delete_layer=TRUE)


```

### Now that the ignition points have been joined to the VRI data in QGIS. I need to reimport the data so that i can join it all together and use it.

```{r}
file.list1<-list.files("C:\\Work\\caribou\\castor_data\\Fire\\Fire_sim_data\\tmp\\spread\\Extracted", pattern="veg_spread_", all.files=FALSE, full.names=FALSE)
y1<-gsub(".gpkg","",file.list1)
the_dir <- "C:\\Work\\caribou\\castor_data\\Fire\\Fire_sim_data\\tmp\\spread\\Extracted"

for (i in 1:length(file.list1)){
  assign(paste0(y1[i]),st_read (dsn=paste0(the_dir, "\\", file.list1[i])))
}

# combined all the DC.ignition files together
mkFrameList <- function(nfiles) {
  d <- lapply(seq_len(nfiles),function(i) {
    eval(parse(text=y1[i]))
  })
  do.call(rbind,d)
}

n<-length(y1)
fire_spread_02_21<-mkFrameList(n) 
fire_spread_02_21[duplicated(fire_spread_02_21$idno),]$fire_yr # there should be no DUPLICATES

sf::st_write(fire_spread_02_21, dsn = "C:\\Work\\caribou\\castor_data\\Fire\\Fire_sim_data\\data\\spread\\Spread_dem_clim_rds_infr_wind_veg.gpkg", delete_layer=TRUE)

table(fire_spread_02_21$bclcs_level_4, fire_spread_02_21$pttype)

```


