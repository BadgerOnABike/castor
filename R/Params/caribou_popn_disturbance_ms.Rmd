---
title: "BC Caribou Population Estimates"
author: "Tyler Muhly"
date: "22/08/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(rpostgis)
library(data.table)
library(ggplot2)
library(plotly)
library(nlme)
library(ggspatial)
library(tidyr)
library(cowplot)
library(ggrepel)
source(paste0(here::here(), "/R/functions/R_Postgres.R"))
```

# Background
In this analysis, we fit models of caribou abundance using measures of forestry disturbance. Various disturbance measures are tested and compared to find applicability to caribou recovery efforts.

### Caribou Coritical Habitat
Criticalhabitat has been defined. However this contains non-habitat areas such as glaciers and steep cliffs. This section nets these non-habitat areas needed to get at population density.

Using VRI, non-habitat is conservative using glaciers and steep rock screes along with lakes and rivers. The area of the core minus this non-habitat area will be used.

```{r, core_matrix}
#for.area<-data.table(getTableQuery("create table caribou_sm_forest_area as (select a.herd_name, a.bc_habitat, sum(ST_Area(ST_Intersection(a.geom, b.geom))) FROM (select herd_name, bc_habitat, wkb_geometry as geom from public.bc_caribou_linework_v20200507_shp_core_matrix where herd_name in ('Barkerville', 'Wells_Gray_South','Wells_Gray_North','Central_Selkirks','Columbia_North','Columbia_South', 'Groundhog', 'Hart_Ranges', 'Narrow_Lake', 'North_Cariboo', 'Purcell_Central', 'Purcells_South', 'South_Selkirks')) as a, (select shape as geom from veg_comp_lyr_r1_poly2019 where bclcs_level_2 = 'T') as b WHERE ST_Intersects(a.geom, b.geom) GROUP BY a.herd_name, a.bc_habitat);"))
for.area<-data.table(getTableQuery(paste0("SELECT herd as herd_name, hab as critical_hab, area_for/10000 as area_for from caribou_sm_forest_area where herd <> 'Hart_Ranges'")))
if(FALSE){
  
hr.for.area<-getSpatialQuery("SELECT feature_id, shape, bclcs_level_2
FROM veg_comp_lyr_r1_poly2019 
WHERE bclcs_level_2 = 'T' and 
ST_Intersects(shape, 'SRID=3005;POLYGON((1237665.5001 943506.823450048,1237665.5001 1073059.65781366,1399606.37521117 1073059.65781366,1399606.37521117 943506.823450048,1237665.5001 943506.823450048))'::geometry);")
hr.poly<-getSpatialQuery("SELECt * from hart_ranges_south_bnds;")
hr.for.area.dissolve<-hr.for.area %>%
   group_by(bclcs_level_2) %>%
   summarise()
test<-st_intersection(hr.for.area.dissolve, hr.poly) 
test$area<-st_area(test)
test[c("bc_habitat", "area")]
}
for.area<-rbindlist(list(for.area, data.table( herd_name= 'Hart_Ranges_South', critical_hab = c('Core', 'Matrix'), area_for = c(1865470516/10000, 3921853454/10000))))
areas<-for.area
```

### Caribou population data
Caribou surveys have been completed for a number of southern-mountain caribou herds.Some of these surveys include expert opionon, minimum counts or total counts. Here we use model corrected survey estimates which correct for sightability in some way. The official population estimates were delievered by KMB through templates which were mannually searched. The search criterion included best parameter = 'Y', method = 'MC', "individual". 

```{r, pop}
if(FALSE){
#caribou_pop<-read.csv("T:/FOR/VIC/HTS/ANA/PROJECTS/CLUS/Data/caribou/population/herd_estimates_simple_20200106.csv")
caribou_pop<-data.table(read.csv("T:/FOR/VIC/HTS/ANA/PROJECTS/CLUS/Data/caribou/population/TylerMuhly_CaribouPopData_1Mar2021/pop_agg_summary20210318.csv"))
setnames(caribou_pop, c("Herd", "Year", "Pop_est"), c("herd_name", "year", "pop_estimate"))
caribou_pop<-caribou_pop[,year := as.integer(year)][,herd_name:= trimws(herd_name)]

#Export to postgres
conn<-DBI::dbConnect(dbDriver("PostgreSQL"), host=keyring::key_get('dbhost', keyring = 'postgreSQL'), dbname = keyring::key_get('dbname', keyring = 'postgreSQL'), port='5432' ,user=keyring::key_get('dbuser', keyring = 'postgreSQL') ,password= keyring::key_get('dbpass', keyring = 'postgreSQL'))
DBI::dbWriteTable(conn, c("public", "caribou_pop_20210318"), value= caribou_pop, row.names = FALSE, overwrite = TRUE) 
dbDisconnect(conn)
}
#Get the population estimates from the database
caribou_pop<-data.table(getTableQuery("SELECT * FROM caribou_pop_20210318;"))
```


### Predator management data

Predator management may confound the habitat-population density response. Tyler pulled this dataset together -- to determine in which years population control activities take place.

```{r, pop_control}
if(FALSE){
wolf_actions<-read.csv("T:/FOR/VIC/HTS/ANA/PROJECTS/CLUS/Data/caribou/population/table_wolf_control_20200302.csv")
colnames(wolf_actions)<-c("herd_name", "year", "type")
wolf_actions<-data.table(wolf_actions)
wolf_actions<-wolf_actions[,herd_name:= trimws(herd_name)][herd_name == 'Wells Gray', herd_name:= 'Wells Gray North'] #Determined this was WGN
conn<-DBI::dbConnect(dbDriver("PostgreSQL"), host=keyring::key_get('dbhost', keyring = 'postgreSQL'), dbname = keyring::key_get('dbname', keyring = 'postgreSQL'), port='5432' ,user=keyring::key_get('dbuser', keyring = 'postgreSQL') ,password= keyring::key_get('dbpass', keyring = 'postgreSQL'))
#data.table(wolf_actions)[,herd_name:= gsub(" ", "_", herd_name)]
DBI::dbWriteTable(conn, c("public", "wolf_control"), value= wolf_actions, row.names = FALSE, overwrite = TRUE) 
dbDisconnect(conn)
}
wolf_actions<-data.table(getTableQuery("SELECT * FROM wolf_control;"))
```

### Merge predator management and caribou population survey data
Determine the population surveys that are not confounded by predator management strategies.

```{r, final, echo=FALSE}
if(TRUE){
data_new<-data.table(merge(caribou_pop, wolf_actions, by.x = c("herd_name", "year"), by.y =c("herd_name", "year"), all.x = TRUE))
#remove dates confounded by population control responses
data_new<-data_new[is.na(type),]
#sort by herd_name and year
data_new[order(herd_name, year)]
#remove 'old' estimaste so this agrees with disturbance data
data_new<-data_new[year > 1975,]
#remove functionally extirpated populations
data_new<-data_new[pop_estimate > 0,]

#remove barkerville population after 2007 see QUESNEL HIGHLAND WOLF STERILIZATION PILOT ASSESSMENT 2012 An Independent Evaluation of the Response of Mountain Caribou. While the wolf reduction may not be efficable, the combination of the moose might be.
data_new<-data_new[!(herd_name == 'Barkerville' & year > 2007),]
data_new<-data_new[!(herd_name == 'Wells Gray North' & year > 2007),]

#remove herds with only two data point
herds_counts <- data_new[, .(rowCount = .N), by = herd_name][rowCount >= 2,]
data_new<-data_new[herd_name %in% herds_counts$herd_name,]
#calc the averaged census lambda
data_new[, pop_lag:= lapply(.SD, function(x) c(NA,x[-.N])), by = herd_name, .SDcols = "pop_estimate"]
data_new[, year_lag:= lapply(.SD, function(x) c(NA,x[-.N])), by = herd_name, .SDcols = "year"]
data_new[, lambda:= (pop_estimate/pop_lag)**(1/(year-year_lag))]
data_new[, pop.change:= (pop_estimate/pop_lag)-1]
#data_new[,c("pop_lag", "year_lag"):= list(NULL, NULL)]  
#calc the averaged census lambda
data_new[, year.0 := min(year), by=herd_name]
data_new[, pop.max := max(pop_estimate), by=herd_name]
data_new[, per.pop := pop_estimate/pop.max]
pop.0<-data_new[year==year.0, c("herd_name","pop_estimate", "year.0")]
setnames(pop.0, "pop_estimate", "pop.0")
pop0<-data_new[year==year.0, c("herd_name","pop_estimate")]
setnames(pop0, "pop_estimate", "pop.0")
data_new<-merge(data_new, pop0, by.x = "herd_name", by.y = "herd_name")
data_new[, lambda.ratio:= (pop_estimate/pop.0)]
data_new[year==year.0, lambda.ratio:= NA]
data_new[, lambda.finite:= (pop_estimate/pop.0)**(1/(year-year.0))]
data_new[year==year.0, lambda.finite:= NA]
# From https://www.nature.com/scitable/knowledge/library/how-populations-grow-the-exponential-and-logistic-13240157/
data_new[, log.pop:= log(pop_estimate)]
data_new[, lambda.dif:= log(pop_estimate)-log(pop.0)]
data_new[, lambda.dift:= lambda.dif/(year-year.0)]
data_new[, lambda.dif.n0:= log(pop_estimate)-log(pop_lag)]
data_new[, lambda.dift.n0:= lambda.dif.n0/(year-year_lag)]
#rename the herds so that they link with CLUS
data_new[, herd_name:= lapply(.SD, function(x) { gsub("-", "_", x)}), .SDcols = "herd_name"]
data_new[, herd_name:= lapply(.SD, function(x) { gsub(" ", "_", x)}), .SDcols = "herd_name"]
conn<-DBI::dbConnect(dbDriver("PostgreSQL"), host=keyring::key_get('dbhost', keyring = 'postgreSQL'), dbname = keyring::key_get('dbname', keyring = 'postgreSQL'), port='5432' ,user=keyring::key_get('dbuser', keyring = 'postgreSQL') ,password= keyring::key_get('dbpass', keyring = 'postgreSQL'))
DBI::dbWriteTable(conn, c("public", "caribou_trend"), value= data_new, row.names = FALSE, overwrite = TRUE) 
dbDisconnect(conn)
}
```

#### Map of herds
Most of the DU9 herds have core and matrix habitat delinated. The exception is Hart Ranges South. This section will create a map of the herd boundaries and their corresponding critical habtiat types.

##### Hart Ranges South critical habitat
```{r, hr_crithab}
if(FALSE){
hart.south.noRR.poly<-st_read("T:/FOR/VIC/HTS/ANA/PROJECTS/CLUS/Data/caribou/caribou_herd/HartRanges_WC_Area_without_kennedy_withoutRR.shp")
hart.south.noRR.poly<-hart.south.noRR.poly[hart.south.noRR.poly$OBJECTID_1 == 1,]
herd.spat<-getSpatialQuery( "Select * from public.bc_caribou_linework_v20200507_shp_core_matrix")
herd.spat.hr<-herd.spat[herd.spat$herd_name == 'Hart_Ranges',]
hr.south.poly<-st_intersection(herd.spat.hr,hart.south.noRR.poly)
hr.south.poly <- st_zm(hr.south.poly, drop=T, what='ZM')
poly2 <-st_union(hr.south.poly, by_feature = TRUE)
poly2$OBJECTID<-NULL
poly2$objectid<-NULL
poly2$OBJECTID_1<-NULL
poly2$Shape_Leng<-NULL
poly2$study_area<-NULL
poly2$Shape_Le_1<-NULL
poly2$Shape_Area<-NULL
poly2$shape_area<-NULL
poly2$shape_leng<-NULL
st_write(poly2,"T:/FOR/VIC/HTS/ANA/PROJECTS/CLUS/Data/caribou/caribou_herd/hart_ranges_south_bnds.shp" ,append=FALSE)
#ogr2ogr -f PostgreSQL PG:"dbname=clus port = 5432 user=postgres" T:\FOR\VIC\HTS\ANA\PROJECTS\CLUS\Data\caribou\caribou_herd\hart_ranges_south_bnds.shp -overwrite -a_srs EPSG:3005 -progress --config PG_USE_COPY YES -nlt PROMOTE_TO_MULTI
}
```

#### Map critical habitat
Map of critical habitat to be used as a map of the study area.
```{r, map_figure}
herd.spat<-getSpatialQuery( "Select herd_name, bc_habitat, wkb_geometry from public.bc_caribou_linework_v20200507_shp_core_matrix where herd_name in ('Barkerville', 'Central_Selkirks', 'Columbia_North', 'Columbia_South',  
 'Frisby_Boulder', 'Monashee',  'Narrow_Lake', 'North_Cariboo', 'Purcells_South', 'Wells_Gray_North')")
hr.south<-getSpatialQuery( "Select herd_name, bc_habitat, wkb_geometry from public.hart_ranges_south_bnds")
herd.spat<-rbind(herd.spat,hr.south)
herd.spat<-st_zm(herd.spat, drop=TRUE, what = 'ZM')
#Make a grouping variable
herd.spat$herd_hab<-paste(herd.spat$herd_name, herd.spat$bc_habitat)
herd.spat$herd_name2<-gsub("_", " ", herd.spat$herd_name)
#Dissolve
#herd.bounds<-herd.spat %>%group_by(herd_name2) %>% summarise()
herd.bounds<-getSpatialQuery( "Select herd_name, shape from public.bc_caribou_herd_boundary_v20200507 where herd_name in ('Barkerville', 'Central_Selkirks', 'Columbia_North', 'Columbia_South',  
 'Frisby_Boulder', 'Hart_Ranges', 'Monashee',  'Narrow_Lake', 'North_Cariboo', 'Purcells_South',   'Wells_Gray_North')")
herd.bounds.all<-getSpatialQuery( "Select herd_name, shape from public.bc_caribou_herd_boundary_v20200507 where eco_group = 'Southern Mountain - Southern Group' and herd_name <> 'George_Mountain'")
#Add XY for labels
xys<-st_coordinates(st_centroid(st_transform(herd.bounds, 4326)))
herd.bounds<-cbind(herd.bounds, xys)
herd.bounds[herd.bounds$herd_name == 'Hart_Ranges',]$herd_name <- 'Hart Ranges South'
herd.bounds$herd_name<-gsub("_", " ", herd.bounds$herd_name)
#Get the map of canada
if (!file.exists("./src/ref/ne_50m_admin_1_states_provinces_lakes/ne_50m_admin_1_states_provinces_lakes.dbf")){
  download.file(file.path('http://www.naturalearthdata.com/http/',
                          'www.naturalearthdata.com/download/50m/cultural',
                          'ne_50m_admin_1_states_provinces_lakes.zip'), 
                f <- tempfile())
  unzip(f, exdir = "./src/ref/ne_50m_admin_1_states_provinces_lakes")
  rm(f)
}
region <- readOGR("./src/ref/ne_50m_admin_1_states_provinces_lakes", 'ne_50m_admin_1_states_provinces_lakes', encoding='UTF-8')
canada = subset(region, name %in% c("British Columbia", "Alberta", "Saskatchewan", "Manitoba", "Ontario", "QuÃ©bec", "New Brunswick", "Prince Edward Island", "Nova Scotia", "Newfoundland and Labrador", "Yukon", "Northwest Territories", "Nunavut")) #notice Quebec has a problem
canada<-st_as_sf(canada)
canada$groups<-1
canada[canada$name == 'British Columbia',]$groups<-0
canada1<-canada %>%
   group_by(groups) %>%
   summarise()
canada1$prov<-''
canada1[canada1$groups == 0,]$prov<-"BC" 
#Get the bounding box of the study area
southern.mountain.bb = st_as_sfc(st_bbox(herd.spat))
inset<-ggplot() + 
  geom_sf(data = canada1,  fill = "white") + 
  geom_sf(data = southern.mountain.bb, fill = NA, color = "red", size = 1) +
  geom_label( aes(x=-100,y=70, label = "Canada"), size = 3)+
  geom_text( aes(x=-112,y=58.5, label = "BC"), size = 2) +
  theme_void()
main<-ggplot() +
    geom_sf(data = canada1, aes(alpha = 0.4), show.legend=FALSE)+
  geom_sf(data = herd.bounds.all, aes(),fill = "grey50", show.legend=FALSE ) +
    geom_sf(data = herd.spat[herd.spat$bc_habitat=='Core',], aes(fill = "blue"), color = NA, show.legend=FALSE )+
   geom_sf(data = herd.spat[herd.spat$bc_habitat=='Matrix',], aes(fill = "red"), color = NA, show.legend=FALSE )+
   
    geom_sf(data = herd.bounds, aes(alpha = 0.2), show.legend=FALSE ) +
    geom_text_repel(data = herd.bounds, aes(x=X, y=Y, label = herd_name), 
        fontface = "bold", size = 3,nudge_x = c(-4,-2.25,-4,-4,-3,-2,-3,-4,-3.15,-2.25,-3,-4), nudge_y = c(-0.2,0,-0.1,-0.5,-0.35,0,0.5,0,0.15,0.05,0,0))+
    coord_sf(xlim = c(-126.5,-115.2), ylim = c(48.9, 54.8), expand = FALSE) + 
    theme_bw()+
    xlab("Longitude") + ylab("Latitude") +
    annotation_scale(location = "bl", width_hint = 0.4) +
    annotation_north_arrow(location = "bl", which_north = "true", 
        style = north_arrow_fancy_orienteering, pad_y = unit(0.3, "in")) 
ggdraw() +
  draw_plot(main) +
  draw_plot(inset, x = 0.63, y = 0.688, width = 0.29, height = 0.28)
```
#### Graph of population data
```{r, graph_pop}
data_new<-data.table(getTableQuery( "Select * from caribou_trend where herd_name in ('Barkerville', 'Wells_Gray_South','Wells_Gray_North','Central_Selkirks','Columbia_North','Columbia_South', 'Groundhog', 'Hart_South', 'Narrow_Lake', 'North_Cariboo', 'Purcells_South', 'South_Selkirks');"))
ggplotly(ggplot(data = data_new, aes(x=year, y = pop_estimate, color = herd_name))+
  geom_point() + geom_line())
```

#### Get the disturbance information

```{r, disturbance}
conn<-DBI::dbConnect(dbDriver("PostgreSQL"), host=keyring::key_get('vmdbhost', keyring = 'postgreSQL'), dbname = keyring::key_get('vmdbname', keyring = 'postgreSQL'), port='5432' ,user=keyring::key_get('vmdbuser', keyring = 'postgreSQL') ,password= keyring::key_get('vmdbpass', keyring = 'postgreSQL'))
disturb<-data.table(dbGetQuery(conn, paste0("SELECT * from disturbance_measures2.disturbance where compartment in ('", paste(unique(data_new$herd_name), collapse = "', '"),"');")))
disturb<-disturb[,road50:=as.numeric(road50)]
dbDisconnect(conn)
 
disturb<-disturb[,year:=as.integer(timeperiod+1980)]
setnames(disturb, "scenario", "herd_name")
data.1<-disturb
#rename critical_hab to either matrix or core
data.1[critical_hab %like% "Matrix",critical_hab:= 'Matrix' ]
data.1[critical_hab %like% "Core",critical_hab:= 'Core' ]

data.2<-merge(data.1, areas, by.x =c("herd_name", "critical_hab"), by.y = c("herd_name", "critical_hab") )
```
### Create the linkage
```{r, linkage}
data.3<-merge(data.2, data_new, by.x = c("herd_name", "year"), by.y = c("herd_name", "year"), all.x=TRUE)
#subset by habitat type
data.core<-data.3[critical_hab== 'Core', c("herd_name", "year", "pop_estimate", "lambda", "year.0","pop.0", "lambda.ratio", "lambda.finite", "per.pop", "total_area", "pop_lag", "log.pop", "year_lag", "lambda.dift","lambda.dif", "pop.change","lambda.dift.n0","lambda.dif.n0", "area_for", "cut20", "cut40", "cut80", "cut10_40", "road50", "road250", "road500", "road750", "c20r50", "c20r250", "c20r500", "c20r750","c40r50", "c40r250", "c40r500", "c40r750","c80r50", "c80r250", "c80r500", "c80r750","c10_40r50","c10_40r500")]
setnames(data.core, c("total_area", "area_for","cut20", "cut40", "cut80", "cut10_40", "road50", "road250", "road500", "road750", "c20r50", "c20r250", "c20r500", "c20r750","c40r50", "c40r250", "c40r500", "c40r750","c80r50", "c80r250", "c80r500", "c80r750","c10_40r50","c10_40r500"), 
         c("core.area", "core.area.for","core.cut20", "core.cut40", "core.cut80", "core.cut10_40","core.road50", "core.road250", "core.road500", "core.road750", "core.c20r50", "core.c20r250", "core.c20r500", "core.c20r750","core.c40r50", "core.c40r250", "core.c40r500", "core.c40r750","core.c80r50", "core.c80r250", "core.c80r500", "core.c80r750","core.c10_40r50","core.c10_40r500"))
data.matrix<-data.3[critical_hab == 'Matrix',c("herd_name", "year","total_area","area_for", "cut20", "cut40", "cut80", "cut10_40", "road50", "road250", "road500", "road750", "c20r50", "c20r250", "c20r500", "c20r750","c40r50", "c40r250", "c40r500", "c40r750","c80r50", "c80r250", "c80r500", "c80r750","c10_40r50","c10_40r500" )]
setnames(data.matrix, c("total_area", "area_for", "cut20", "cut40", "cut80", "cut10_40", "road50", "road250", "road500", "road750", "c20r50", "c20r250", "c20r500", "c20r750","c40r50", "c40r250", "c40r500", "c40r750","c80r50", "c80r250", "c80r500", "c80r750","c10_40r50","c10_40r500"), c("matrix.area","matrix.area.for","matrix.cut20", "matrix.cut40", "matrix.cut80", "matrix.cut10_40", "matrix.road50", "matrix.road250", "matrix.road500", "matrix.road750", "matrix.c20r50", "matrix.c20r250", "matrix.c20r500", "matrix.c20r750","matrix.c40r50", "matrix.c40r250", "matrix.c40r500", "matrix.c40r750","matrix.c80r50", "matrix.c80r250", "matrix.c80r500", "matrix.c80r750","matrix.c10_40r50","matrix.c10_40r500"))

data.set<-merge(data.core, data.matrix, by.x = c("herd_name", "year"), by.y = c("herd_name", "year"))
data.set[, time:=year-year.0]
data.set[, pop.den:= pop_estimate/((core.area)*0.01)]
#Calc diturbance indicators
data.set[, core.cut20.per:= (core.cut20/core.area.for)*100]
data.set[, core.cut40.per:= (core.cut40/core.area.for)*100]
data.set[, core.cut80.per:= (core.cut80/core.area.for)*100]
data.set[, core.cut10_40.per:= (core.cut10_40/core.area.for)*100]
data.set[, core.road50.per:= (core.road50/core.area.for)*100]
data.set[, core.road250.per:= (core.road250/core.area.for)*100]
data.set[, core.road500.per:= (core.road500/core.area.for)*100]
data.set[, core.road750.per:= (core.road750/core.area.for)*100]
data.set[, core.cut20r50.per:= (core.c20r50/core.area.for)*100]
data.set[, core.cut20r250.per:= (core.c20r250/core.area.for)*100]
data.set[, core.cut20r500.per:= (core.c20r500/core.area.for)*100]
data.set[, core.cut20r750.per:= (core.c20r750/core.area.for)*100]
data.set[, core.cut40r50.per:= (core.c40r50/core.area.for)*100]
data.set[, core.cut40r250.per:= (core.c40r250/core.area.for)*100]
data.set[, core.cut40r500.per:= (core.c40r500/core.area.for)*100]
data.set[, core.cut40r750.per:= (core.c40r750/core.area.for)*100]
data.set[, core.cut80r50.per:= (core.c80r50/core.area.for)*100]
data.set[, core.cut80r250.per:= (core.c80r250/core.area.for)*100]
data.set[, core.cut80r500.per:= (core.c80r500/core.area.for)*100]
data.set[, core.cut80r750.per:= (core.c80r750/core.area.for)*100]
data.set[, core.c10_40r50.per:= (core.c10_40r50/core.area.for)*100]
data.set[, core.c10_40r500.per:= (core.c10_40r500/core.area.for)*100]
data.set[, core.af.cut20:= core.area.for-core.cut20]
data.set[, core.af.cut20.per:= (core.af.cut20/core.area.for)*100]
data.set[, core.af.cut40:= core.area.for-core.cut40]
data.set[, core.af.cut40.per:= (core.af.cut40/core.area.for)*100]
data.set[, core.af.cut80:= core.area.for-core.cut80]
data.set[, core.af.cut80.per:= (core.af.cut80/core.area.for)*100]
data.set[, core.af.road50:= core.area.for-core.road50]
data.set[, core.af.road50.per:= (core.af.road50/core.area.for)*100]
data.set[, core.af.road500:= core.area.for-core.road500]
data.set[, core.af.road500.per:= (core.af.road500/core.area.for)*100]
data.set[, core.af.road750:= core.area.for-core.road750]
data.set[, core.af.road750.per:= (core.af.road750/core.area.for)*100]
data.set[, core.af.cut20r50:= core.area.for-core.c20r50]
data.set[, core.af.cut20r50.per:= (core.af.cut20r50/core.area.for)*100]
data.set[, core.af.cut20r500:= core.area.for-core.c20r500]
data.set[, core.af.cut20r500.per:= (core.af.cut20r500/core.area.for)*100]
data.set[, core.af.cut40r50:= core.area.for-core.c40r50]
data.set[, core.af.cut40r50.per:= (core.af.cut40r50/core.area.for)*100]
data.set[, core.af.cut40r500:= core.area.for-core.c40r500]
data.set[, core.af.cut40r500.per:= (core.af.cut40r500/core.area.for)*100]
#MAtrix
data.set[, matrix.cut20.per:= (matrix.cut20/matrix.area.for)*100]
data.set[, matrix.cut40.per:= (matrix.cut40/matrix.area.for)*100]
data.set[, matrix.cut80.per:= (matrix.cut80/matrix.area.for)*100]
data.set[, matrix.cut10_40.per:= (matrix.cut10_40/matrix.area.for)*100]
data.set[, matrix.road50.per:= (matrix.road50/matrix.area.for)*100]
data.set[, matrix.road250.per:= (matrix.road250/matrix.area.for)*100]
data.set[, matrix.road500.per:= (matrix.road500/matrix.area.for)*100]
data.set[, matrix.road750.per:= (matrix.road750/matrix.area.for)*100]
data.set[, matrix.cut20r50.per:= (matrix.c20r50/matrix.area.for)*100]
data.set[, matrix.cut20r250.per:= (matrix.c20r250/matrix.area.for)*100]
data.set[, matrix.cut20r500.per:= (matrix.c20r500/matrix.area.for)*100]
data.set[, matrix.cut20r750.per:= (matrix.c20r750/matrix.area.for)*100]
data.set[, matrix.cut40r50.per:= (matrix.c40r50/matrix.area.for)*100]
data.set[, matrix.cut40r250.per:= (matrix.c40r250/matrix.area.for)*100]
data.set[, matrix.cut40r500.per:= (matrix.c40r500/matrix.area.for)*100]
data.set[, matrix.cut40r750.per:= (matrix.c40r750/matrix.area.for)*100]
data.set[, matrix.cut80r50.per:= (matrix.c80r50/matrix.area.for)*100]
data.set[, matrix.cut80r250.per:= (matrix.c80r250/matrix.area.for)*100]
data.set[, matrix.cut80r500.per:= (matrix.c80r500/matrix.area.for)*100]
data.set[, matrix.cut80r750.per:= (matrix.c80r750/matrix.area.for)*100]
data.set[, matrix.c10_40r50.per:= (matrix.c10_40r50/matrix.area.for)*100]
data.set[, matrix.c10_40r500.per:= (matrix.c10_40r500/matrix.area.for)*100]
data.set[, matrix.af.cut20:= matrix.area.for-matrix.cut20]
data.set[, matrix.af.cut20.per:= (matrix.af.cut20/matrix.area.for)*100]
data.set[, matrix.af.cut40:= matrix.area.for-matrix.cut40]
data.set[, matrix.af.cut40.per:= (matrix.af.cut40/matrix.area.for)*100]
data.set[, matrix.af.cut80:= matrix.area.for-matrix.cut80]
data.set[, matrix.af.cut80.per:= (matrix.af.cut80/matrix.area.for)*100]
data.set[, matrix.af.road50:= matrix.area.for-matrix.road50]
data.set[, matrix.af.road50.per:= (matrix.af.road50/matrix.area.for)*100]
data.set[, matrix.af.road500:= matrix.area.for-matrix.road500]
data.set[, matrix.af.road500.per:= (matrix.af.road500/matrix.area.for)*100]
data.set[, matrix.af.road750:= matrix.area.for-matrix.road750]
data.set[, matrix.af.road750.per:= (matrix.af.road750/matrix.area.for)*100]
data.set[, matrix.af.cut20r50:= matrix.area.for-matrix.c20r50]
data.set[, matrix.af.cut20r50.per:= (matrix.af.cut20r50/matrix.area.for)*100]
data.set[, matrix.af.cut40r50:= matrix.area.for-matrix.c40r50]
data.set[, matrix.af.cut40r50.per:= (matrix.af.cut40r50/matrix.area.for)*100]
data.set[, matrix.af.cut40r500:= matrix.area.for-matrix.c40r500]
data.set[, matrix.af.cut40r500.per:= (matrix.af.cut40r50/matrix.area.for)*100]
data.set[, matrix.af.cut40r500:= matrix.area.for-matrix.c40r500]
data.set[, matrix.af.cut40r500.per:= (matrix.af.cut40r500/matrix.area.for)*100]
##TOTAL
data.set[, total.cut20.per:= (matrix.cut20 + core.cut20)/(matrix.area.for+core.area.for)*100]
data.set[, total.cut40.per:= (matrix.cut40 + core.cut40)/(matrix.area.for+core.area.for)*100]
data.set[, total.cut80.per:= (matrix.cut80 + core.cut80)/(matrix.area.for+core.area.for)*100]
data.set[, total.cut10_40.per:= (matrix.cut10_40 + core.cut10_40)/(matrix.area.for+core.area.for)*100]
data.set[, total.road50.per:= (matrix.road50 + core.road50)/(matrix.area.for+core.area.for)*100]
data.set[, total.road250.per:= (matrix.road250 + core.road250)/(matrix.area.for+core.area.for)*100]
data.set[, total.road500.per:= (matrix.road500 + core.road500)/(matrix.area.for+core.area.for)*100]
data.set[, total.road750.per:= (matrix.road750 + core.road750)/(matrix.area.for+core.area.for)*100]
data.set[, total.cut40r50.per:= (matrix.c40r50 + core.c40r50)/(matrix.area+core.area)*100]
data.set[, total.cut40r500.per:= (matrix.c40r500 + core.c40r500)/(matrix.area+core.area)*100]
data.set[, total.cut80r50.per:= (matrix.c80r50 + core.c80r50)/(matrix.area+core.area)*100]
data.set[, total.cut80r500.per:= (matrix.c80r500 + core.c80r500)/(matrix.area+core.area)*100]
data.set[, total.cut10_40r50.per:= (matrix.c10_40r50 + core.c10_40r50)/(matrix.area+core.area)*100]
data.set[, total.cut10_40r500.per:= (matrix.c10_40r500 + core.c10_40r500)/(matrix.area+core.area)*100]
#RATES
##Core
if(FALSE){
data.set[, core.early.seral.lag:= lapply(.SD, function(x) c(NA,x[-.N])), by = herd_name, .SDcols = "core.early.seral"]
data.set[, core.dist.lag:= lapply(.SD, function(x) c(NA,x[-.N])), by = herd_name, .SDcols = "core.dist"]
data.set[, core.dist500.lag:= lapply(.SD, function(x) c(NA,x[-.N])), by = herd_name, .SDcols = "core.dist500"]
#Matrix
data.set[, matrix.early.seral.lag:= lapply(.SD, function(x) c(NA,x[-.N])), by = herd_name, .SDcols = "matrix.early.seral"]
data.set[, matrix.dist.lag:= lapply(.SD, function(x) c(NA,x[-.N])), by = herd_name, .SDcols = "matrix.dist"]
data.set[, matrix.dist500.lag:= lapply(.SD, function(x) c(NA,x[-.N])), by = herd_name, .SDcols = "matrix.dist500"]
#Metrics
data.set[, core.early.seral.rate:=( (core.early.seral-core.early.seral.lag)/core.area.for)*100]
data.set[, core.dist.rate:= ((core.dist-core.dist.lag)/core.area.for)*100]
data.set[, core.dist500.rate:= ((core.dist500-core.dist500.lag)/core.area.for)*100]
##Matrix
data.set[, matrix.early.seral.rate:=( (matrix.early.seral-matrix.early.seral.lag)/matrix.area.for)*100]
data.set[, matrix.dist.rate:= ((matrix.dist-matrix.dist.lag)/matrix.area.for)*100]
data.set[, matrix.dist500.rate:=( (matrix.dist500-matrix.dist500.lag)/matrix.area.for)*100]
}
#Final
data.all<-data.set[, c("herd_name", "year", "core.cut80r50.per","matrix.cut80r50.per", "core.area", "matrix.road50.per","core.road50.per")]
data.set<-data.set[!is.na(pop.den),]
data.set<-data.set[!herd_name == 'Purcell_Central',]
#table1<- data.set[year == year.0, c("herd_name", 'core.cut40r500')]
```

# Figure of disturbance profile
```{r, dist_graph}
c80<-data.set[, c("herd_name", "year","core.cut80.per")]
setnames(c80, "core.cut80.per" , "value")
c80[, dm:='C80']
r50<-data.set[, c("herd_name", "year","core.road50.per")]
setnames(r50, "core.road50.per" , "value")
r50[, dm:='R50']
c80r50<-data.set[, c("herd_name", "year","core.cut80r50.per")]
setnames(c80r50, "core.cut80r50.per" , "value")
c80r50[, dm:='C80R50']
core.graph.dist<-rbind(c80,r50,c80r50)
core.graph.dist[, hab:='Core']
c80.m<-data.set[, c("herd_name", "year","matrix.cut80.per")]
setnames(c80.m, "matrix.cut80.per" , "value")
c80.m[, dm:='C80']
r50.m<-data.set[, c("herd_name", "year","matrix.road50.per")]
setnames(r50.m, "matrix.road50.per" , "value")
r50.m[, dm:='R50']
c80r50.m<-data.set[, c("herd_name", "year","matrix.cut80r50.per")]
setnames(c80r50.m, "matrix.cut80r50.per" , "value")
c80r50.m[, dm:='C80R50']
matrix.graph.dist<-rbind(c80.m, r50.m, c80r50.m)
matrix.graph.dist[, hab:='Matrix']
graph.dist<-rbind(core.graph.dist,matrix.graph.dist)
graph.dist<-graph.dist[, herd_name:=lapply(.SD, function(x) { gsub("_", " ", x)}), .SDcols = "herd_name"]
graph.dist$dm<- factor(graph.dist$dm, levels = c( 'C80','R50','C80R50'))
out.graph.dist<- ggplot(data = graph.dist, aes(x = year, y =value,color = herd_name) ) +
  facet_wrap(.~hab+dm , scales="free_y") +
  labs(y = "Disturbance Measure (%)", x = "Year")+
  geom_point() +
  stat_smooth(method = "loess", formula = y ~ x, se = FALSE)+
  #geom_smooth(method = 'lm', se=FALSE) +
  #stat_summary(fun.data=mean_cl_boot, geom="ribbon", alpha=0.25)+
  guides(color=guide_legend(title = "Herd")) +
  theme_bw() 
out.graph.dist
```
## Population threshold
```{r, threshold_pop}
library(minpack.lm)
logistic.model <- function( a, b, c, x) {
  f <-a/(1+exp(b*(x-log(c))))
  return(f)
}
data.set[,log.core.area := log(core.area)]
data.set[,total.area:= core.area+matrix.area ]
plot(data.set[,c("total.area", "pop_estimate")])
pop.size <- nlsLM(pop_estimate~ logistic.model( a, b, c, log.core.area), start=list( a=201, b=-9, c=224000), data= data.set, control=c(maxiter =500))
summary(pop.size)
data.set[,herd.size:=0]
data.set[core.area >= coef(pop.size)[3],herd.size:=1]
ggplot(data = data.set, aes(x = log.core.area, y = pop_estimate)) + 
  geom_point(color='blue') +
  geom_line(color='red',data = data.table(pred=predict(pop.size), core.area = data.set$log.core.area), aes(y=pred, x= core.area))+
              geom_vline(xintercept = log(coef(pop.size)[3]))
```

## Plot between core disturbance and ratio between population estimates
```{r, pop_graph_core}
core.p0<-ggplot(data = data.set, aes(x =core.cut80.per, y =pop_estimate, color = herd_name )) +  geom_point() + geom_smooth(method = 'lm',se= FALSE) + theme(legend.position = "none")
core.p1<-ggplot(data = data.set, aes(x =core.road50.per, y =pop_estimate, color = herd_name ,  linetype = as.factor(herd.size))) +  geom_point() + geom_smooth(method = 'lm',se= FALSE) + theme(legend.position = "none")
core.p2<-ggplot(data = data.set, aes(x =core.cut10_40.per, y =pop_estimate, color = herd_name,  linetype = as.factor(herd.size)  )) +  geom_point() + geom_smooth(method = 'lm', se= FALSE) + theme(legend.position = "none")
ggplotly(core.p0)
ggplotly(core.p1)
ggplotly(core.p2)
```

## Plot between matrix disturbance and ratio between population estimates
```{r, pop_graph_core}
matrix.p0<-ggplot(data = data.set, aes(x =matrix.road50.per, y =pop_estimate, color = herd_name,  linetype = as.factor(herd.size)  )) +  geom_point() + geom_smooth(method = 'lm', se= FALSE) + theme(legend.position = "none")
matrix.p1<-ggplot(data = data.set, aes(x =matrix.cut80.per, y =pop_estimate, color = herd_name,  linetype = as.factor(herd.size)  )) +  geom_point() + geom_smooth(method = 'lm', se= FALSE) + theme(legend.position = "none")
matrix.p2<-ggplot(data = data.set, aes(x =matrix.cut40r500.per, y =pop_estimate, color = herd_name )) +  geom_point() + geom_smooth(method = 'lm', se= FALSE) + theme(legend.position = "none")
ggplotly(matrix.p0)
ggplotly(matrix.p1)
ggplotly(matrix.p2)
```
.(count = .N, var = sum(VAR))
# Table of disturbance and population
```{r, table1}
table1<-data.set[,.(Core = mean(core.area),Core_For = mean(core.area.for), Matrix = mean(matrix.area),Matrix_For = mean(matrix.area.for),YearMin= min(year), YearMax= max(year),n = .N, popavg = round(mean(pop.den),3), popmax = max(pop.den), popmin = min(pop.den) ), by = "herd_name"]
table1
```
#DISTRUBITIONAL ASSUMPTIONS

I start with a normal distribution- since the change in population is likely symetrical distribution. This assumption does not seem valid.
```{r, assump}
library(gamlss)
data.set[, log.pop.den:=log(pop.den)]
histDist(log.pop.den,family="NO", data=data.set, nbins = 12)
histDist(pop_estimate,family="LOGNO", data=data.set, nbins = 12)
histDist(pop_estimate,family="GA", data=data.set, nbins = 12)
histDist(pop_estimate,family="NBI", data=data.set, nbins = 4)
hist(data.set$pop_estimate,freq = F)
curve(dpois(x, 65), add=T)
```
#CORRELATION BETWEEN X
```{r, cor_x}
library(usdm)
vif(data.set[,c("core.cut80.per","matrix.cut80.per")])
vif(data.set[,c("core.cut80r50.per","matrix.cut80r50.per")])
vif(data.set[,c("core.cut40r500.per","matrix.cut40r500.per")])
vif(data.set[,c("core.road50.per","matrix.road50.per")])
#Correlations between core and matrix
cor(data.set[,"matrix.cut80.per"],data.set[,"core.cut80.per"])
cor(data.set[,"matrix.cut40.per"],data.set[,"core.cut40.per"])
cor(data.set[,"matrix.cut10_40.per"],data.set[,"core.cut10_40.per"])
cor.test(data.set$matrix.road50.per,data.set$core.road50.per)
cor(data.set[,"matrix.road500.per"],data.set[,"core.road500.per"])
cor(data.set[,"matrix.cut80r50.per"],data.set[,"core.cut80r50.per"])
cor(data.set[,"matrix.cut80r500.per"],data.set[,"core.cut80r500.per"])
cor(data.set[,"matrix.cut40r50.per"],data.set[,"core.cut40r50.per"])
cor(data.set[,"matrix.cut40r500.per"],data.set[,"core.cut40r500.per"])
cor(data.set[,"matrix.c10_40r500.per"],data.set[,"core.c10_40r500.per"])
cor(data.set[,"matrix.c10_40r50.per"],data.set[,"core.c10_40r50.per"])
cor(data.set[,"core.road50.per"],data.set[,"core.cut40.per"])
cor(data.set[,"core.cut80.per"],data.set[,"core.road50.per"])
cor(data.set[,"matrix.cut80.per"],data.set[,"matrix.road50.per"])
cor(data.set[,"matrix.cut40.per"],data.set[,"matrix.road50.per"])
summary(data.set[,c("core.road50.per","core.cut80.per","core.cut80r50.per")])
summary(data.set[,c("matrix.road50.per","matrix.cut80.per","matrix.cut80r50.per")])
t.test(data.set$matrix.road50.per,data.set$core.road50.per,paired=TRUE,conf.level=0.95)
t.test(data.set$matrix.cut80.per,data.set$core.cut80.per,paired=TRUE,conf.level=0.95)
t.test(data.set$matrix.cut80r50.per,data.set$core.cut80r50.per,paired=TRUE,conf.level=0.95)
```


#MODEL SETTINGS

Here the data set is cleaned up to only include those variables that are important to the modelling process. Further, the control parameters are set for the model fitting algorithums
```{r, setting}
library(gamlss)
library(nlme)
library(MuMIn)
model.data<-data.set[,c("herd_name","herd.size","core.area", "pop_estimate", "pop.0",  "time", "year","core.road50.per","core.road500.per","core.road250.per","core.road750.per","core.cut40.per", "core.cut20.per", "core.cut80.per","core.cut10_40.per", "core.cut40r50.per", "core.cut40r500.per","core.cut80r500.per","core.cut80r50.per","core.cut20r500.per","core.af.cut40.per","core.af.cut20r500.per","core.c10_40r500.per","core.c10_40r50.per", "matrix.road50.per","matrix.road250.per", "matrix.road500.per","matrix.road750.per","matrix.cut40.per","matrix.cut80.per","matrix.cut20.per","matrix.cut10_40.per", "matrix.cut40r50.per", "matrix.cut40r500.per","matrix.cut80r500.per","matrix.cut80r50.per","matrix.cut20r500.per","matrix.c10_40r500.per","matrix.c10_40r50.per","total.cut40r50.per","total.cut40.per", "total.cut80.per","total.road50.per","total.road500.per","total.cut10_40.per","total.cut10_40r50.per","total.cut10_40r500.per","total.cut40r50.per", "total.cut40r500.per","total.cut80r500.per","total.cut80r50.per", "total.area")]
con1 <- gamlss::gamlss.control(c.crit=0.001, n.cyc=5000,msMaxIter=1000000)
#xys2<-herd.bounds[,c("herd_name2", "X", "Y")]
#xys2$shape<-NULL
#xys2<-data.table(xys2)
#Add in the X and Y from the xys object
#model.data<-merge(model.data, xys2, by.x= "herd_name", by.y = "herd_name2", all.x=TRUE)
# Add the null group
model.data[,group:=1]
#model.data<-model.data[!herd_name %in% c("Purcell_Central", "Narrow_Lake"),]
#Reporting function
report<-function(x){
par(mfrow=c(2,2))
acf(residuals(x,type="normalized"), ci=0.975,lag.max = 10) 
pacf(residuals(x,type="normalized"), lag.max = 10)
plot(predict(x), residuals(x,type="normalized"))
abline(0,0, col = 'red')
plot(predict(x, level=1), model.data$pop_estimate)
abline(0,1, col = 'red')
}
```

#Exponential models
```{r, nonliner}
#NULL
start.null<-nlsLM(pop_estimate~exp(N0), start=list(N0=4.5), data=model.data)
expo.null.1 <- nlme(pop_estimate~exp(N0), fixed =list(N0~1), random= N0~1|herd_name,   correlation = corARMA(p=0,q=1,form=~time), weights = varExp(form=~herd.size), start =list(fixed=c(N0=4.5)), data = model.data, method = 'ML', control = c(maxIter = 100000))
summary(expo.null.1) 
report(expo.null.1)
model.data$res<-abs(residuals(expo.null.1, type= 'normalized'))**2
lev<- lm(res ~ as.factor(herd_name), data=model.data) 
anova(lev) #displays the results
AICc(expo.null.1)
```

#Road Models
```{r}
#Total Road 50
start.total.road50<-nls(pop_estimate~exp(a+b*total.road50.per), start=list(a=5, b=-0.004), data=model.data, nls.control(maxiter=1000))
expo.total.road50.1 <- nlme(pop_estimate~ exp(a+b*total.road50.per), fixed =list(a~1, b~1), random= a+b~1|herd_name,weights = varExp(form=~herd.size),start =list(fixed=c(a=6, b=-0.4)), data = model.data, method = 'ML', control = c(maxIter = 100000))
summary(expo.total.road50.1) 
report(expo.total.road50.1)

#Core and Matrix road 50
expo.road50.1 <- nlme(pop_estimate  ~ exp(a+b*core.road50.per+c*matrix.road50.per), fixed =list(a~1,b~1, c~1),  random= a+c~1|herd_name, weights = varExp(form=~herd.size), start =list(fixed=c(a=4.42, b=-0.01, c=-0.01)), data = model.data, method = 'ML', control = c(maxIter = 100000))
summary(expo.road50.1) 
report(expo.road50.1)
model.data$res<-abs(residuals(expo.road50.1, type= 'normalized'))**2
lev<- lm(res ~ as.factor(herd_name), data=model.data) 
anova(lev) #f-stat for levenes
model.data[, s.core.road50.per:=scale(core.road50.per, center=TRUE, scale=TRUE)]
model.data[, s.matrix.road50.per:=scale(matrix.road50.per, center=TRUE, scale=TRUE)]
#Core and Matrix road 50
expo.road50.s <- nlme(pop_estimate  ~ exp(a+b*s.core.road50.per+c*s.matrix.road50.per), fixed =list(a~1,b~1, c~1),  random= a+c~1|herd_name, weights = varExp(form=~herd.size), start =list(fixed=c(a=3.42, b=-0.01, c=-0.01)), data = model.data, method = 'REML', control = c(maxIter = 100000))
summary(expo.road50.s) 
report(expo.road50.s)
model.data$res<-abs(residuals(expo.road50.s, type= 'normalized'))**2
lev<- lm(res ~ as.factor(herd_name), data=model.data) 
anova(lev) #f-stat for levenes
AICc(expo.null.1, expo.road50.1, expo.total.road50.1)

#Total Road 500
start.total.road500<-nls(pop_estimate  ~ exp(a+b*total.road500.per), start=list(a=1.5, b=-.041), data=model.data, nls.control(maxiter = 1000))
expo.total.road500.1 <- nlme(pop_estimate  ~ exp(a+b*total.road500.per),fixed =list(a~1,b~1), weights= varExp(form=~pop.0), random= a+b~1|herd_name, start =list(fixed=coef(start.total.road500)), data = model.data, method = 'ML', control = c(maxIter = 100000))
summary(expo.total.road500.1) 
report(expo.total.road500.1)
model.data$res<-abs(residuals(expo.total.road500.1, type= 'normalized'))**2
lev<- lm(res ~ as.factor(herd_name), data=model.data) 
anova(lev) #f-stat for levenes
anova(expo.null.1,expo.total.road500.1 )
#Core and Matrix road 500
start.road500<-nlsLM(pop_estimate~exp(a+b*core.road500.per+c*matrix.road500.per) ,start=list(a=-3.5, b=-0.001, c= -0.009), data=model.data)
expo.road500.1 <- nlme(pop_estimate  ~ exp(a+b*core.road500.per+c*matrix.road500.per), fixed =list(a~1,b~1,c~1), weights= varExp(form=~pop.0), random= a+c~1|herd_name, start =list(fixed=c(a=-2.4, b=-0.002, c=-0.002)), data = model.data, method = 'ML', control = c(maxIter = 100000))
summary(expo.road500.1) 
report(expo.road500.1)
model.data$res<-abs(residuals(expo.road500.1, type= 'normalized'))**2
lev<- lm(res ~ as.factor(herd_name), data=model.data) 
anova(lev) #f-stat for levenes
AICc(expo.null.1, expo.road500.1, expo.total.road500.1,expo.road50.1, expo.total.road50.1)
anova(expo.null.1,expo.road500.1, expo.total.road500.1)

```

#Cutblock models
```{r}
#Total cut10-40
start.total.cut10_40<-nlsLM(pop_estimate~exp(a+b*total.cut10_40.per) ,start=list(a=0, b=-0.002), data=model.data, control = nls.lm.control(maxiter=100))
expo.total.cut10_40.1 <- nlme(pop_estimate~exp(a+b*total.cut10_40.per), fixed =list(a~1, b~1),  random= a+b~1|herd_name, weights=varExp(form=~herd.size), start =list(fixed=coef(start.total.cut10_40)), data = model.data, method = 'ML', control = c(maxIter = 100000))
summary(expo.total.cut10_40.1) 
report(expo.total.cut10_40.1)
model.data$res<-abs(residuals(expo.total.cut10_40.1, type= 'normalized'))**2
lev<- lm(res ~ as.factor(herd_name), data=model.data) 
anova(lev) #f-stat for levenes
#Core and Matrix cut10_40
start.cut10_40<-nlsLM(pop_estimate  ~ exp(a+b*core.cut10_40.per+c*matrix.cut10_40.per) ,start=list(a=-4, b=-0.001, c =-0.001), data=model.data)
expo.cut10_40.1 <- nlme(pop_estimate  ~ exp(a+b*core.cut10_40.per+c*matrix.cut10_40.per), fixed =list(a~1, b~1,c~1),  random= a+c~1|herd_name,weights=varExp(form=~herd.size), start =list(fixed=coef(start.cut10_40)), data = model.data, method = 'ML', control = c(maxIter = 100000))
summary(expo.cut10_40.1) 
report(expo.cut10_40.1)
model.data$res<-abs(residuals(expo.cut10_40.1, type= 'normalized'))**2
lev<- lm(res ~ as.factor(herd_name), data=model.data) 
anova(lev) #f-stat for levenes
#Cut40
start.total.cut40<-nlsLM(pop_estimate  ~ exp(a+b*total.cut40.per) ,start=list(a=1, b=-0.001), data=model.data)
expo.total.cut40.1 <- nlme(pop_estimate  ~ exp(a+b*total.cut40.per), fixed =list(a~1,b~1), weights=varExp(form=~herd.size), random= a+b~1|herd_name, start =list(fixed=coef(start.total.cut40)), data = model.data, method = 'ML', control = c(maxIter = 100000))
summary(expo.total.cut40.1) 
report(expo.total.cut40.1)
model.data$res<-abs(residuals(expo.total.cut40.1, type= 'normalized'))**2
lev<- lm(res ~ as.factor(herd_name), data=model.data) 
anova(lev) #f-stat for levenes
#Core and Matrix cut40
start.cut40<-nls(pop_estimate~exp(a+b*core.cut40.per+c*matrix.cut40.per) ,start=list(a=.001, b=-0.001, c=-0.0001), data=model.data)
expo.cut40.1 <- nlme(pop_estimate  ~ exp(a+b*core.cut40.per+c*matrix.cut40.per), fixed =list(a~1,b~1,c~1), weights=varExp(form=~herd.size), random=a+c~1|herd_name, start =list(fixed=coef(start.cut40)), data = model.data, method = 'ML', control = c(maxIter = 100000))
summary(expo.cut40.1) 
report(expo.cut40.1)
model.data$res<-abs(residuals(expo.cut40.1, type= 'normalized'))**2
lev<- lm(res ~ as.factor(herd_name), data=model.data) 
anova(lev) #f-stat for levenes
#Cut80
start.total.cut80<-nls(pop_estimate~exp(a+b*total.cut80.per) ,start=list(a=2, b=-0.001), data=model.data)
expo.total.cut80.novar <- nlme(pop_estimate~exp(a+b*total.cut80.per), fixed =list(a~1,b~1), random= a+b~1|herd_name, start =list(fixed=coef(start.total.cut80)), data = model.data, method = 'REML', control = c(maxIter = 100000))
summary(expo.total.cut80.novar)
expo.total.cut80.1 <- nlme(pop_estimate~exp(a+b*total.cut80.per), fixed =list(a~1,b~1),  weights=varExp(form=~herd.size), random= a+b~1|herd_name, start =list(fixed=coef(start.total.cut80)), data = model.data, method = 'REML', control = c(maxIter = 100000))
anova(expo.total.cut80.1,expo.total.cut80.novar)
update(expo.total.cut80.1, method = 'ML')
summary(expo.total.cut80.1)
report(expo.total.cut80.1)
model.data$res<-abs(residuals(expo.total.cut80.1, type= 'normalized'))**2
lev<- lm(res ~ as.factor(herd_name), data=model.data) 
anova(lev) #f-stat for levenes
#Core and Matrix cut80
start.cut80<-nls(pop_estimate~exp(a+b*core.cut80.per+c*matrix.cut80.per) ,start=list( a=0.01, b=-0.01, c=-0.009), data=model.data)
expo.cut80.1 <- nlme(pop_estimate~exp(a+b*core.cut80.per+c*matrix.cut80.per), fixed =list(a~1,b~1,c~1), weights=varExp(form=~herd.size), random= a+c~1|herd_name, start =list(fixed=coef(start.cut80)), data = model.data, method = 'ML', control = c(maxIter = 100000))
summary(expo.cut80.1) 
report(expo.cut80.1)
model.data$res<-abs(residuals(expo.cut80.1, type= 'normalized'))**2
lev<- lm(res ~ as.factor(herd_name), data=model.data) 
anova(lev) #f-stat for levenes
#Scaled coefficients
model.data[, s.core.cut80.per:=scale(core.cut80.per, center=TRUE,scale=TRUE)]
model.data[, s.matrix.cut80.per:=scale(matrix.cut80.per,center=TRUE,scale=TRUE)]
expo.cut80.s <- nlme(pop_estimate~exp(a+b*s.core.cut80.per+c*s.matrix.cut80.per), fixed =list(a~1,b~1,c~1), weights=varExp(form=~herd.size), random= a+c~1|herd_name, start =list(fixed=coef(start.cut80)), data = model.data, method = 'REML', control = c(maxIter = 100000))
summary(expo.cut80.s) 
report(expo.cut80.s)
model.data$res<-abs(residuals(expo.cut80.s, type= 'normalized'))**2
lev<- lm(res ~ as.factor(herd_name), data=model.data) 
anova(lev) #f-stat for levenes
AICc(expo.null.1,expo.cut10_40.1, expo.total.cut10_40.1, expo.cut40.1, expo.total.cut40.1,expo.cut80.1, expo.total.cut80.1)
```

#Combined models
```{r}
#Cut10_40r50
start.total.cut10_40r50<-nls(pop_estimate ~ exp(a+b*total.cut10_40r50.per)  ,start=list(a=1, b=-0.004), data=model.data)
expo.total.cut10_40r50.1 <- nlme(pop_estimate  ~ exp(a+b*total.cut10_40r50.per), fixed =list(a~1,b~1), weights= varExp(form=~herd.size), random= a+b~1|herd_name, start =list(fixed=coef(start.total.cut10_40r50)), data = model.data, method = 'ML', control = c(maxIter = 100000))
summary(expo.total.cut10_40r50.1) 
report(expo.total.cut10_40r50.1)
model.data$res<-abs(residuals(expo.cut80.1, type= 'normalized'))**2
lev<- lm(res ~ as.factor(herd_name), data=model.data) 
anova(lev) #f-stat for levenes
#Core and Matrix cut10_40r50
start.cut10_40r50<-nls(pop_estimate~exp(a+b*core.c10_40r50.per+c*matrix.c10_40r50.per) ,start=list(a=0.01, b=-0.001,c=-0.001), data=model.data)
expo.cut10_40r50.1 <- nlme(pop_estimate  ~ exp(a+b*core.c10_40r50.per+c*matrix.c10_40r50.per), fixed =list(a~1,b~1,c~1), weights= varExp(form=~pop.0), random= a+b~1|herd_name, start =list(fixed=coef(start.cut10_40r50)), data = model.data, method = 'ML', control = c(maxIter = 100000))
summary(expo.cut10_40r50.1) 
report(expo.cut10_40r50.1)
model.data$res<-abs(residuals(expo.cut10_40r50.1, type= 'normalized'))**2
lev<- lm(res ~ as.factor(herd_name), data=model.data) 
anova(lev) #f-stat for levenes
anova(expo.null.1, expo.total.cut10_40r50.1, expo.cut10_40r50.1)
#Total Cut10_40r500
start.total.cut10_40r500<-nls(pop_estimate~exp(a+b*total.cut10_40r500.per),start=list(a=0.1, b=-0.0002), data=model.data)
expo.total.cut10_40r500.1 <- nlme(pop_estimate~exp(a+b*total.cut10_40r500.per), fixed =list(a~1,b~1), weights= varExp(form=~pop.0), random= a+b~1|herd_name, start =list(fixed=coef(start.total.cut10_40r500)), data = model.data, method = 'ML', control = c(maxIter = 100000))
summary(expo.total.cut10_40r500.1) 
report(expo.total.cut10_40r500.1)
model.data$res<-abs(residuals(expo.total.cut10_40r500.1, type= 'normalized'))**2
lev<- lm(res ~ as.factor(herd_name), data=model.data) 
anova(lev) #f-stat for levenes
#Core and Matrix cut10_40r500
start.cut10_40r500<-nls(pop_estimate~exp(a+b*core.c10_40r500.per+c*matrix.c10_40r500.per), start=list(a=0.1, b=-0.001, c=-0.0097), data=model.data)
expo.cut10_40r500.1 <- nlme(pop_estimate~exp(a+b*core.c10_40r500.per+c*matrix.c10_40r500.per), fixed =list(a~1,b~1, c~1),  weights= varExp(form=~herd.size), random= a+c~1|herd_name, start =list(fixed=coef(start.cut10_40r500)), data = model.data, method = 'ML', control = c(maxIter = 100000))
summary(expo.cut10_40r500.1) 
report(expo.cut10_40r500.1)
model.data$res<-abs(residuals(expo.cut10_40r500.1, type= 'normalized'))**2
lev<- lm(res ~ as.factor(herd_name), data=model.data) 
anova(lev) #f-stat for levenes
#Total Cut40r50
start.total.cut40r50<-nls(pop_estimate~exp(a+b*total.cut40r50.per) ,start=list(a=0.01,b=-0.002), data=model.data)
expo.total.cut40r50.1 <- nlme(pop_estimate~exp(a+b*total.cut40r50.per), fixed =list(a~1,b~1), weights= varExp(form=~herd.size),random= a+b~1|herd_name, start =list(fixed=coef(start.total.cut40r50)), data = model.data, method = 'ML', control = c(maxIter = 100000))
summary(expo.total.cut40r50.1) 
report(expo.total.cut40r50.1)
#Core and Matrix cut40r50
start.cut40r50<-nls(pop_estimate  ~exp(a+b*core.cut40r50.per+c*matrix.cut40r50.per) ,start=list( a=0.01, b=-0.001, c=-0.001), data=model.data)
expo.cut40r50.1 <- nlme(pop_estimate~exp(a+b*core.cut40r50.per+c*matrix.cut40r50.per), fixed =list(a~1,b~1,c~1), weights=varExp(form=~herd.size), random= a+c~1|herd_name, start =list(fixed=coef(start.cut40r50)), data = model.data, method = 'ML', control = c(maxIter = 100000))
summary(expo.cut40r50.1) 
report(expo.cut40r50.1)
#Total Cut40r500
start.total.cut40r500<-nls(pop_estimate~exp(a+b*total.cut40r500.per) ,start=list( a=0.01, b=-0.002), data=model.data)
expo.total.cut40r500.1 <- nlme(pop_estimate~exp(a+b*total.cut40r500.per), fixed =list(a~1,b~1), weights=varExp(form=~pop.0), random= a+b~1|herd_name, start =list(fixed=coef(start.total.cut40r500)), data = model.data, method = 'ML', control = c(maxIter = 100000))
summary(expo.total.cut40r500.1) 
report(expo.total.cut40r500.1)
#Core and Matrix cut40r500
start.cut40r500<-nls(pop_estimate~exp(a+b*core.cut40r500.per+c*matrix.cut40r500.per), start=list(a=0.01, b=-0.001, c=-0.002), data=model.data)
expo.cut40r500.1 <- nlme(pop_estimate~exp(a+b*core.cut40r500.per+c*matrix.cut40r500.per), fixed =list(a~1,b~1,c~1),weights=varExp(form=~pop.0), random= a+c~1|herd_name, start =list(fixed=coef(start.cut40r500)), data = model.data, method = 'ML', control = c(maxIter = 100000))
summary(expo.cut40r500.1) 
report(expo.cut40r500.1)
#Cut80r50
start.total.cut80r50<-nls(pop_estimate~exp(a+b*total.cut80r50.per) ,start=list(a=0.01, b=-0.002), data=model.data)
expo.total.cut80r50.1 <- nlme(pop_estimate~exp(a+b*total.cut80r50.per), fixed =list(a~1, b~1), weights=varExp(form=~herd.size), random= a+b~1|herd_name, start =list(fixed=coef(start.total.cut80r50)), data = model.data, method = 'ML', control = c(maxIter = 100000))
summary(expo.total.cut80r50.1) 
report(expo.total.cut80r50.1)
model.data$res<-abs(residuals(expo.total.cut80r50.1, type= 'normalized'))**2
lev<- lm(res ~ as.factor(herd_name), data=model.data) 
anova(lev) #f-stat for levenes

#Core and Matrix cut80r50
start.cut80r50<-nls(pop_estimate~exp(a+b*core.cut80r50.per+c*matrix.cut80r50.per),start=list(a=0.01, b=-0.001, c=-0.002), data=model.data)
expo.cut80r50.1 <- nlme(pop_estimate~exp(a+b*core.cut80r50.per+c*matrix.cut80r50.per), fixed =list(a~1,b~1,c~1), weights=varExp(form=~pop.0), random= a+b~1|herd_name, start =list(fixed=coef(start.cut80r50)), data = model.data, method = 'ML', control = c(maxIter = 100000))
summary(expo.cut80r50.1) 
report(expo.cut80r50.1)
model.data$res<-abs(residuals(expo.cut80r50.1, type= 'normalized'))**2
lev<- lm(res ~ as.factor(herd_name), data=model.data) 
anova(lev) #f-stat for levenes
#Scaled
model.data[, s.core.cut80r50.per:=scale(core.cut80r50.per, center=TRUE,scale=TRUE)]
model.data[, s.matrix.cut80r50.per:=scale(matrix.cut80r50.per,center=TRUE,scale=TRUE)]
expo.cut80r50.s <- nlme(pop_estimate~exp(a+b*s.core.cut80r50.per+c*s.matrix.cut80r50.per), fixed =list(a~1,b~1,c~1), weights=varExp(form=~herd.size), random= a+c~1|herd_name, start =list(fixed=coef(start.cut80r50)), data = model.data, method = 'REML', control = c(maxIter = 100000))
summary(expo.cut80r50.s) 
report(expo.cut80r50.s)
model.data$res<-abs(residuals(expo.cut80r50.s, type= 'normalized'))**2
lev<- lm(res ~ as.factor(herd_name), data=model.data) 
anova(lev) #f-stat for levenes
#Cut80r500
start.total.cut80r500<-nls(pop_estimate~exp(a+b*total.cut80r500.per) ,start=list(a=0.01,b=-0.002), data=model.data)
expo.total.cut80r500.1 <- nlme(pop_estimate~exp(a+b*total.cut80r500.per), fixed =list(a~1,b~1), weights=varExp(form=~herd.size),random= a+b~1|herd_name, start =list(fixed=coef(start.total.cut80r500)), data = model.data, method = 'ML', control = c(maxIter = 100000))
summary(expo.total.cut80r500.1) 
report(expo.total.cut80r500.1)
model.data$res<-abs(residuals(expo.total.cut80r500.1, type= 'normalized'))**2
lev<- lm(res ~ as.factor(herd_name), data=model.data) 
anova(lev) #f-stat for levenes
#Core and Matrix cut80r500
start.cut80r500<-nls(pop_estimate~exp(a+b*core.cut80r500.per+c*matrix.cut80r500.per), start=list(a=5, b=-0.001, c=-0.0002), data=model.data)
expo.cut80r500.1 <- nlme(pop_estimate~exp(a+b*core.cut80r500.per+c*matrix.cut80r500.per), fixed =list(a~1,b~1,c~1),  weights= varExp(form=~herd.size), random= a+b~1|herd_name, start =list(fixed=coef(start.cut80r500)), data = model.data, method = 'ML', control = c(maxIter = 100000))
summary(expo.cut80r500.1) 
report(expo.cut80r500.1)

AICc(expo.null.1,expo.total.cut10_40r50.1,expo.cut10_40r50.1,expo.total.cut10_40r500.1,expo.cut10_40r500.1,expo.total.cut40r50.1,expo.cut40r50.1,
     expo.total.cut40r500.1,expo.cut40r500.1,expo.total.cut80r50.1,expo.cut80r50.1,expo.total.cut80r500.1,expo.cut80r500.1)
```

#Summary
```{r}
AICc(expo.null.1, expo.road50.1, expo.total.road50.1,expo.road500.1, expo.total.road500.1,expo.cut10_40.1, expo.total.cut10_40.1, expo.cut40.1, expo.total.cut40.1,expo.cut80.1, expo.total.cut80.1, expo.total.cut10_40r50.1,expo.cut10_40r50.1,expo.total.cut10_40r500.1,expo.cut10_40r500.1,expo.total.cut40r50.1,expo.cut40r50.1,
     expo.total.cut40r500.1,expo.cut40r500.1,expo.total.cut80r50.1,expo.cut80r50.1,expo.total.cut80r500.1,expo.cut80r500.1)

aic.values<-AICc(expo.null.1,expo.total.cut80.1,expo.cut80.1,expo.total.road50.1,expo.road50.1,expo.total.cut80r50.1, expo.cut80r50.1)
aic.values$delta<-round(qpcR::akaike.weights(aic.values$AIC)$deltaAIC, 3)
aic.values$weights<-round(qpcR::akaike.weights(aic.values$AIC)$weights, 3)
aic.values
plot(model.data$time,residuals(expo.road50.1, type='normalized'))
summary(update(expo.null.1, method = 'ML'))
summary(update(expo.total.cut80.1, method = 'ML'))
summary(update(expo.cut80.1, method = 'ML'))
summary(update(expo.total.road500.1, method = 'ML'))
summary(update(expo.road500.1, method = 'ML'))
summary(update(expo.total.cut80r500.1, method = 'ML'))
summary(update(expo.cut80r500.1, method = 'ML'))
summary(update(expo.null.1, method = 'REML'))
summary(update(expo.total.cut80.1, method = 'REML'))
summary(update(expo.cut80.1, method = 'REML'))
summary(update(expo.total.road50.1, method = 'REML'))
summary(update(expo.road50.1, method = 'REML'))
summary(update(expo.total.cut80r50.1, method = 'REML'))
summary(update(expo.cut80r50.1, method = 'REML'))
```

#FIGURE 3: observed vs predicted
```{r, obs_pred}
par(mfrow=c(2,2))
plot(predict(expo.road50.1, level =1), model.data$pop_estimate, title= '', ylab = 'Observed', xlab = 'Predicted')
abline(0,1, col = 'red')
plot(predict(expo.road50.1, level =1), residuals(expo.road50.1, type= 'normalized'), title= '', ylab = 'Normalized Residuals', xlab = 'Predicted')
abline(0,0, col = 'red')
acf(residuals(expo.road50.1,  type= 'normalized'), c1 =0.975, main = '')
hist(residuals(expo.road50.1,  type= 'normalized') , freq = FALSE,main = '', xlab = 'Normalized Residuals')
curve(dnorm(x,0, sd(residuals(expo.road50.1,  type= 'normalized'))), add=T)
mean.matrix<-with(model.data,
       expand.grid(core.road50.per =
                   seq(from = min(core.road50.per),
                       to = max(core.road50.per), by = 0.1),
                       matrix.road50.per = mean(matrix.road50.per)
                   ))
mean.matrix$pop.pred<- predict(expo.road50.1, newdata = mean.matrix, level =0) 
mean.matrix$herd_name<-"All"
mean.matrix$type<-'Core'
mean.matrix$matrix.road50.per<-NULL
setnames(mean.matrix, "core.road50.per", "R50")
mean.core<-with(model.data,
       expand.grid(matrix.road50.per =
                   seq(from = min(matrix.road50.per),
                       to = max(matrix.road50.per), by = 0.1),
                       core.road50.per = mean(core.road50.per)
                   ))
mean.core$pop.pred<- predict(expo.road50.1, newdata = mean.core, level =0) 
mean.core$herd_name<-"All"
mean.core$type<-'Matrix'
mean.core$core.road50.per<-NULL
setnames(mean.core, "matrix.road50.per", "R50")
fig.data<-rbind(mean.core,mean.matrix)
fig.data$pop_estimate<-NA
raw.data<-model.data[, c("core.road50.per","matrix.road50.per", "pop_estimate", "herd_name")]
raw.data$pop.pred<-predict(expo.road50.1)
raw.data1<-raw.data[, c("core.road50.per", "pop_estimate", "herd_name", "pop.pred")]
raw.data1$type = 'Core'
setnames(raw.data1, "core.road50.per", "R50")
raw.data2<-raw.data[, c("matrix.road50.per", "pop_estimate", "herd_name","pop.pred")]
raw.data2$type = 'Matrix'
setnames(raw.data2, "matrix.road50.per", "R50")
fig.data2<-rbind(fig.data, raw.data1,raw.data2 )
ggplot(data = fig.data2, aes(x = R50, y = pop_estimate, colour = factor(herd_name))) +
  facet_wrap(~type, nrow =2, ncol=1)+
  geom_point() +
  geom_line(aes(y = pop.pred ))+
  labs(x = 'R50 (%)', y ='Caribou Abundance', colour = "Herd")+
  theme_bw() 
                
```

#FIGURE 4. Behaviour of the model

## Thresholds
```{r, thresholds}
data.threshold<-data.all
data.threshold$pred<-predict(expo.cut80r50.1, data.threshold,level=1)
data.threshold<-data.threshold[!is.na(pred),]
ggplot(data=data.threshold[,c("herd_name", "pred", "year")], aes(x=year, y= pred, group = herd_name, color = herd_name)) + geom_line() 
sum(data.threshold[year==2000 & !herd_name == 'Barkerville', ]$pred)
```


