---
title: "BC Caribou Population Estimates"
author: "Tyler Muhly"
date: "22/08/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(rpostgis)
library(data.table)
library(ggplot2)
library(plotly)
library(nlme)
library(ggspatial)
library(tidyr)
library(cowplot)
library(ggrepel)
source(paste0(here::here(), "/R/functions/R_Postgres.R"))
```

# Background
In this analysis, we fit models of caribou abundance using measures of disturbance. Various disturbance measures are tested and compared to find applicability to caribou recovery efforts.

### Caribou Coritical Habitat
Criticalhabitat has been defined. However this contains non-habitat areas such as glaciers and steep cliffs. This section nets these non-habitat areas needed to get at population density.

Using VRI, non-habitat is conservative using glaciers and steep rock screes along with lakes and rivers. The area of the core minus this non-habitat area will be used.

```{r, core_matrix}

#area.ice<-getTableQuery("with core as (SELECT herd_name, wkb_geometry from bc_caribou_linework_v20200507_shp_core_matrix where bc_habitat = 'Core' and herd_name in ('Barkerville', 'Wells_Gray_South','Wells_Gray_North','Central_Selkirks','Columbia_North','Columbia_South', 'Groundhog', 'Hart_Ranges', 'Narrow_Lake', 'North_Cariboo', 'Purcell_Central', 'Purcells_South', 'South_Selkirks' )), nohab as (SELECT shape from veg_comp_lyr_r1_poly2019 WHERE bclcs_level_5 in ('GL', 'TA') or non_productive_descriptor_cd in ('ICE', 'L', 'RIV'))  select sum(st_area(st_intersection(core.wkb_geometry, nohab.shape))/10000) as area, core.herd_name from core, nohab where st_intersects(core.wkb_geometry, nohab.shape) group by core.herd_name ;")

#area.ice.hr.south<-getTableQuery("with core as (SELECT herd_name, wkb_geometry from hart_ranges_south_bnds where bc_habitat = 'Core'), nohab as (SELECT shape from veg_comp_lyr_r1_poly2019 WHERE bclcs_level_5 in ('GL', 'TA') or non_productive_descriptor_cd in ('ICE', 'L', 'RIV'))  select sum(st_area(st_intersection(core.wkb_geometry, nohab.shape))/10000) as area, core.herd_name from core, nohab where st_intersects(core.wkb_geometry, nohab.shape) group by core.herd_name ;")

area.ice<-data.table(herd_name = c('Barkerville', 'Central_Selkirks','Columbia_North','Columbia_South', 'Groundhog', 'Narrow_Lake', 'North_Cariboo', 'Purcell_Central', 'Purcells_South', 'South_Selkirks', 'Wells_Gray_South','Wells_Gray_North','Hart_Ranges_South'), ice=c(117.109072842166, 17892.4221042202,
12945.2994439308,7014.79151159945,6763.99471008934,2.8945917329086,
906.392742195574,17256.9050646071,4384.33746236994,
2180.62003260568,3711.54252050654,22712.172978544,11776.5414584458), critical_hab = 'Core')


#for.area<-data.table(getTableQuery("create table caribou_sm_forest_area as (select a.herd_name, a.bc_habitat, sum(ST_Area(ST_Intersection(a.geom, b.geom))) FROM (select herd_name, bc_habitat, wkb_geometry as geom from public.bc_caribou_linework_v20200507_shp_core_matrix where herd_name in ('Barkerville', 'Wells_Gray_South','Wells_Gray_North','Central_Selkirks','Columbia_North','Columbia_South', 'Groundhog', 'Hart_Ranges', 'Narrow_Lake', 'North_Cariboo', 'Purcell_Central', 'Purcells_South', 'South_Selkirks')) as a, (select shape as geom from veg_comp_lyr_r1_poly2019 where bclcs_level_2 = 'T') as b WHERE ST_Intersects(a.geom, b.geom) GROUP BY a.herd_name, a.bc_habitat);"))

for.area<-data.table(getTableQuery(paste0("SELECT herd as herd_name, hab as critical_hab, area_for/10000 as area_for from caribou_sm_forest_area where herd <> 'Hart_Ranges'")))

if(FALSE){
  
hr.for.area<-getSpatialQuery("SELECT feature_id, shape, bclcs_level_2
FROM veg_comp_lyr_r1_poly2019 
WHERE bclcs_level_2 = 'T' and 
ST_Intersects(shape, 'SRID=3005;POLYGON((1237665.5001 943506.823450048,1237665.5001 1073059.65781366,1399606.37521117 1073059.65781366,1399606.37521117 943506.823450048,1237665.5001 943506.823450048))'::geometry);")
hr.poly<-getSpatialQuery("SELECt * from hart_ranges_south_bnds;")

hr.for.area.dissolve<-hr.for.area %>%
   group_by(bclcs_level_2) %>%
   summarise()
test<-st_intersection(hr.for.area.dissolve, hr.poly) 
test$area<-st_area(test)
test[c("bc_habitat", "area")]
}

for.area<-rbindlist(list(for.area, data.table( herd_name= 'Hart_Ranges_South', critical_hab = c('Core', 'Matrix'), area_for = c(1865470516/10000, 3921853454/10000))))

areas<-merge(for.area, area.ice, by.x = c("herd_name", "critical_hab"), by.y =c("herd_name", "critical_hab"), all.x = TRUE )
```

### Caribou population data
Caribou surveys have been completed for a number of southern-mountain caribou herds.Some of these surveys include expert opionon, minimum counts or total counts. Here we use model corrected survey estimates which correct for sightability. 

```{r, pop}
if(TRUE){
caribou_pop<-read.csv("T:/FOR/VIC/HTS/ANA/PROJECTS/CLUS/Data/caribou/population/herd_estimates_simple_20200106.csv")
caribou_pop<-data.table(caribou_pop)
caribou_pop<-caribou_pop[,year := as.integer(year)][,herd_name:= trimws(herd_name)]

#Tyler had pers. Com biologist Mike K. North cariboo and Hart Ranges South. More surveys for North Cariboo can be added. For Hart Ranges the survey was broken into two sub-groups - Parsnip and Hart South. The Parsnip recieved pop-control (wilf,moose etc). Defining the boundary of Hart South is needed.
hart.south<-data.table(read.csv("T:/FOR/VIC/HTS/ANA/PROJECTS/CLUS/Data/caribou/population/hart_south_estimates.csv"))[!is.na(Estimate) & Type == 'Corrected Estimate',][,herd_name:= 'Hart Ranges South']
setnames(hart.south, c("Type", "Year", "Estimate"),c("estimate_type", "year", "pop_estimate"))
hart.south<-hart.south[,c("estimate_type", "year", "pop_estimate", "herd_name")]

#Added some data for North Cariboo
n.cariboo<-data.table(read.csv("T:/FOR/VIC/HTS/ANA/PROJECTS/CLUS/Data/caribou/population/NC_estimates2.csv"))[!is.na(Estimate) & Type == 'Corrected Estimate',][,herd_name:= 'North Cariboo'][Year %in% c(1999,2018,2020)]#Other years already in the caribou_pop dataset
setnames(n.cariboo, c("Type", "Year", "Estimate"),c("estimate_type", "year", "pop_estimate"))
n.cariboo<-n.cariboo[,c("estimate_type", "year", "pop_estimate", "herd_name")]
#Merge them together to one dataset
caribou_pop<-rbindlist(list(caribou_pop, hart.south, n.cariboo), use.names = TRUE)

#Export to postgres
conn<-DBI::dbConnect(dbDriver("PostgreSQL"), host=keyring::key_get('dbhost', keyring = 'postgreSQL'), dbname = keyring::key_get('dbname', keyring = 'postgreSQL'), port='5432' ,user=keyring::key_get('dbuser', keyring = 'postgreSQL') ,password= keyring::key_get('dbpass', keyring = 'postgreSQL'))

DBI::dbWriteTable(conn, c("public", "caribou_pop_simple"), value= caribou_pop, row.names = FALSE, overwrite = TRUE) 
dbDisconnect(conn)
}

caribou_pop<-data.table(getTableQuery("SELECT * FROM caribou_pop_simple;"))

```


### Predator management data

Predator management may confound the habitat-population density response. Tyler pulled this dataset together -- to determine in which years population control activities take place.

```{r, pop_control}

if(FALSE){
wolf_actions<-read.csv("T:/FOR/VIC/HTS/ANA/PROJECTS/CLUS/Data/caribou/population/table_wolf_control_20200302.csv")
colnames(wolf_actions)<-c("herd_name", "year", "type")
wolf_actions<-data.table(wolf_actions)
wolf_actions<-wolf_actions[,herd_name:= trimws(herd_name)][herd_name == 'Wells Gray', herd_name:= 'Wells Gray North'] #Determined this was WGN

conn<-DBI::dbConnect(dbDriver("PostgreSQL"), host=keyring::key_get('dbhost', keyring = 'postgreSQL'), dbname = keyring::key_get('dbname', keyring = 'postgreSQL'), port='5432' ,user=keyring::key_get('dbuser', keyring = 'postgreSQL') ,password= keyring::key_get('dbpass', keyring = 'postgreSQL'))
#data.table(wolf_actions)[,herd_name:= gsub(" ", "_", herd_name)]
DBI::dbWriteTable(conn, c("public", "wolf_control"), value= wolf_actions, row.names = FALSE, overwrite = TRUE) 
dbDisconnect(conn)
}

wolf_actions<-data.table(getTableQuery("SELECT * FROM wolf_control;"))

```

### Merge predator management and caribou population survey data
Determine the population surveys that are not confounded by predator management strategies.

```{r, final, echo=FALSE}
if(TRUE){
data_new<-data.table(merge(caribou_pop, wolf_actions, by.x = c("herd_name", "year"), by.y =c("herd_name", "year"), all.x = TRUE))
#Remove minimum counts and exper opinion estimates
data_new<-data_new[!(estimate_type %in% c("Expert Opinion", "Survey Observation","Minimum count", "Minimum Count", "Unknown"))]
#data_new<-data_new[!(estimate_type %in% c("Minimum count", "Minimum Count", "Unknown"))]

#remove dates confounded by population control responses
data_new<-data_new[is.na(type),]

#sort by herd_name and year
data_new[order(herd_name, year)]

#remove 'old' estimaste so this agrees with disturbance data
data_new<-data_new[year > 1975,]

#remove functionally extirpated populations
data_new<-data_new[pop_estimate > 0,]

#remove barkerville population after 2007 see QUESNEL HIGHLAND WOLF STERILIZATION PILOT ASSESSMENT 2012 An Independent Evaluation of the Response of Mountain Caribou
data_new<-data_new[!(herd_name == 'Barkerville' & year > 2007),]

data_new<-data_new[!(herd_name == 'Wells Gray North' & year > 2001),]

#Graham seems to have an outlier nad has a histroy of pop control and is DU7
data_new<-data_new[!(herd_name == 'Graham'),]

#Narraway in DU8
data_new<-data_new[!(herd_name == 'Narraway'),]

#remove herds with only two data point
herds_counts <- data_new[, .(rowCount = .N), by = herd_name][rowCount >= 2,]
data_new<-data_new[herd_name %in% herds_counts$herd_name,]

#calc the averaged census lambda
data_new[, pop_lag:= lapply(.SD, function(x) c(NA,x[-.N])), by = herd_name, .SDcols = "pop_estimate"]

data_new[, year_lag:= lapply(.SD, function(x) c(NA,x[-.N])), by = herd_name, .SDcols = "year"]
data_new[, lambda:= (pop_estimate/pop_lag)**(1/(year-year_lag))]
data_new[, pop.change:= (pop_estimate/pop_lag)-1]
#data_new[,c("pop_lag", "year_lag"):= list(NULL, NULL)]  

#calc the averaged census lambda
data_new[, year.0 := min(year), by=herd_name]
data_new[, pop.max := max(pop_estimate), by=herd_name]
data_new[, per.pop := pop_estimate/pop.max]

pop0<-data_new[year==year.0, c("herd_name","pop_estimate")]
setnames(pop0, "pop_estimate", "pop.0")

data_new<-merge(data_new, pop0, by.x = "herd_name", by.y = "herd_name")
data_new[, lambda.ratio:= (pop_estimate/pop.0)]
data_new[year==year.0, lambda.ratio:= NA]

data_new[, lambda.finite:= (pop_estimate/pop.0)**(1/(year-year.0))]
data_new[year==year.0, lambda.finite:= NA]

# From https://www.nature.com/scitable/knowledge/library/how-populations-grow-the-exponential-and-logistic-13240157/
data_new[, log.pop:= log(pop_estimate)]
data_new[, lambda.dif:= log(pop_estimate)-log(pop.0)]
data_new[, lambda.dift:= lambda.dif/(year-year.0)]
data_new[, lambda.dif.n0:= log(pop_estimate)-log(pop_lag)]
data_new[, lambda.dift.n0:= lambda.dif.n0/(year-year_lag)]



#rename the herds so that they link with CLUS
data_new[, herd_name:= lapply(.SD, function(x) { gsub("-", "_", x)}), .SDcols = "herd_name"]
data_new[, herd_name:= lapply(.SD, function(x) { gsub(" ", "_", x)}), .SDcols = "herd_name"]


conn<-DBI::dbConnect(dbDriver("PostgreSQL"), host=keyring::key_get('dbhost', keyring = 'postgreSQL'), dbname = keyring::key_get('dbname', keyring = 'postgreSQL'), port='5432' ,user=keyring::key_get('dbuser', keyring = 'postgreSQL') ,password= keyring::key_get('dbpass', keyring = 'postgreSQL'))

DBI::dbWriteTable(conn, c("public", "caribou_trend"), value= data_new, row.names = FALSE, overwrite = TRUE) 
dbDisconnect(conn)
}

```

#### Map of herds
Most of the DU9 herds have core and matrix habitat delinated. The exception is Hart Ranges South. This section will create a map of the herd boundaries and their corresponding critical habtiat types.

##### Hart Ranges South critical habitat
```{r, hr_crithab}

if(FALSE){
hart.south.noRR.poly<-st_read("T:/FOR/VIC/HTS/ANA/PROJECTS/CLUS/Data/caribou/caribou_herd/HartRanges_WC_Area_without_kennedy_withoutRR.shp")
hart.south.noRR.poly<-hart.south.noRR.poly[hart.south.noRR.poly$OBJECTID_1 == 1,]

herd.spat<-getSpatialQuery( "Select * from public.bc_caribou_linework_v20200507_shp_core_matrix")
herd.spat.hr<-herd.spat[herd.spat$herd_name == 'Hart_Ranges',]

hr.south.poly<-st_intersection(herd.spat.hr,hart.south.noRR.poly)
hr.south.poly <- st_zm(hr.south.poly, drop=T, what='ZM')

poly2 <-st_union(hr.south.poly, by_feature = TRUE)
poly2$OBJECTID<-NULL
poly2$objectid<-NULL
poly2$OBJECTID_1<-NULL
poly2$Shape_Leng<-NULL
poly2$study_area<-NULL
poly2$Shape_Le_1<-NULL
poly2$Shape_Area<-NULL
poly2$shape_area<-NULL
poly2$shape_leng<-NULL

st_write(poly2,"T:/FOR/VIC/HTS/ANA/PROJECTS/CLUS/Data/caribou/caribou_herd/hart_ranges_south_bnds.shp" ,append=FALSE)

#ogr2ogr -f PostgreSQL PG:"dbname=clus port = 5432 user=postgres" T:\FOR\VIC\HTS\ANA\PROJECTS\CLUS\Data\caribou\caribou_herd\hart_ranges_south_bnds.shp -overwrite -a_srs EPSG:3005 -progress --config PG_USE_COPY YES -nlt PROMOTE_TO_MULTI
}

```

#### Map critical habitat
Map of critical habitat to be used as a map of the study area.
```{r, map_figure}
herd.spat<-getSpatialQuery( "Select herd_name, bc_habitat, wkb_geometry from public.bc_caribou_linework_v20200507_shp_core_matrix where herd_name in ('Barkerville', 'Wells_Gray_South','Wells_Gray_North','Central_Selkirks','Columbia_North','Columbia_South', 'Groundhog', 'Narrow_Lake', 'North_Cariboo', 'Purcell_Central', 'Purcells_South', 'South_Selkirks')")

hr.south<-getSpatialQuery( "Select herd_name, bc_habitat, wkb_geometry from public.hart_ranges_south_bnds")

herd.spat<-rbind(herd.spat,hr.south)
herd.spat<-st_zm(herd.spat, drop=TRUE, what = 'ZM')


#Make a grouping variable
herd.spat$herd_hab<-paste(herd.spat$herd_name, herd.spat$bc_habitat)

herd.spat$herd_name2<-gsub("_", " ", herd.spat$herd_name)

#Dissolve
herd.bounds<-herd.spat %>%
   group_by(herd_name2) %>%
   summarise()
#Add XY for labels
xys<-st_coordinates(st_centroid(st_transform(herd.bounds, 4326)))
herd.bounds<-cbind(herd.bounds, xys)
herd.bounds[herd.bounds$herd_name2 == 'Hart Ranges',]$herd_name2 <- 'Hart Ranges South'
#Get the map of canada
if (!file.exists("./src/ref/ne_50m_admin_1_states_provinces_lakes/ne_50m_admin_1_states_provinces_lakes.dbf")){
  download.file(file.path('http://www.naturalearthdata.com/http/',
                          'www.naturalearthdata.com/download/50m/cultural',
                          'ne_50m_admin_1_states_provinces_lakes.zip'), 
                f <- tempfile())
  unzip(f, exdir = "./src/ref/ne_50m_admin_1_states_provinces_lakes")
  rm(f)
}

region <- readOGR("./src/ref/ne_50m_admin_1_states_provinces_lakes", 'ne_50m_admin_1_states_provinces_lakes', encoding='UTF-8')

canada = subset(region, name %in% c("British Columbia", "Alberta", "Saskatchewan", "Manitoba", "Ontario", "QuÃ©bec", "New Brunswick", "Prince Edward Island", "Nova Scotia", "Newfoundland and Labrador", "Yukon", "Northwest Territories", "Nunavut")) #notice Quebec has a problem

canada<-st_as_sf(canada)
canada$groups<-1
canada[canada$name == 'British Columbia',]$groups<-0
canada1<-canada %>%
   group_by(groups) %>%
   summarise()
canada1$prov<-''
canada1[canada1$groups == 0,]$prov<-"BC" 

#Get the bounding box of the study area
southern.mountain.bb = st_as_sfc(st_bbox(herd.spat))

inset<-ggplot() + 
  geom_sf(data = canada1,  fill = "white") + 
  geom_sf(data = southern.mountain.bb, fill = NA, color = "red", size = 1) +
  geom_label( aes(x=-100,y=70, label = "Canada"), size = 3)+
  geom_text( aes(x=-112,y=58.5, label = "BC"), size = 2) +
  theme_void()

main<-ggplot() +
    geom_sf(data = canada1, aes(alpha = 0.4), show.legend=FALSE)+
    geom_sf(data = herd.spat[herd.spat$bc_habitat=='Core',], aes(fill = "yellow"), color = NA, show.legend=FALSE )+
   geom_sf(data = herd.spat[herd.spat$bc_habitat=='Matrix',], aes(fill = "blue"), color = NA, show.legend=FALSE )+
    
    geom_sf(data = herd.bounds, aes(alpha = 0.2), show.legend=FALSE ) +
    #geom_text_repel(data = herd.spat2, aes(x=X, y=Y, label = herd_name), fontface = "bold", size = 1.5)+
  geom_text_repel(data = herd.bounds, aes(x=X, y=Y, label = herd_name2), 
        fontface = "bold", size = 3,nudge_x = c(-4,-2.25,-4,-4,-4,-3,-2,-3,-4,-3.15,-2.25,-3,-4), nudge_y = c(-0.2,0,-0.1,-0.5,-0.35,0,0,0.5,0,0.15,0.05,0,0))+
    coord_sf(xlim = c(-128,-115.2), ylim = c(48.9, 54.8), expand = FALSE) +
    theme_bw()+
    xlab("Longitude") + ylab("Latitude") +
    annotation_scale(location = "bl", width_hint = 0.4) +
    annotation_north_arrow(location = "bl", which_north = "true", 
        style = north_arrow_fancy_orienteering, pad_y = unit(0.3, "in")) 

ggdraw() +
  draw_plot(main) +
  draw_plot(inset, x = 0.63, y = 0.688, width = 0.29, height = 0.28)


```
#### Graph of population data
```{r, graph_pop}
data_new<-data.table(getTableQuery( "Select * from caribou_trend where herd_name in ('Barkerville', 'Wells_Gray_South','Wells_Gray_North','Central_Selkirks','Columbia_North','Columbia_South', 'Groundhog', 'Hart_Ranges_South', 'Narrow_Lake', 'North_Cariboo', 'Purcell_Central', 'Purcells_South', 'South_Selkirks');"))
ggplotly(ggplot(data = data_new, aes(x=year, y = pop_estimate, color = herd_name))+
  geom_point() + geom_line())
```

#### Get the disturbance information

```{r, disturbance}

conn<-DBI::dbConnect(dbDriver("PostgreSQL"), host=keyring::key_get('vmdbhost', keyring = 'postgreSQL'), dbname = keyring::key_get('vmdbname', keyring = 'postgreSQL'), port='5432' ,user=keyring::key_get('vmdbuser', keyring = 'postgreSQL') ,password= keyring::key_get('vmdbpass', keyring = 'postgreSQL'))

disturb<-data.table(dbGetQuery(conn, paste0("SELECT * from dm_all.disturbance where scenario in ('", paste(unique(data_new$herd_name), collapse = "', '"),"');")))
disturb<-disturb[,road50:=as.numeric(road50)]
#seral<-data.table(dbGetQuery(conn, paste0("SELECT * from dm_80yrs_500m.survival where scenario in ('", paste(unique(data_new$herd_name), collapse = "', '"),"');")))

dbDisconnect(conn)


fire<-data.table(getTableQuery(paste0("SELECT sumarea/10000 as area_burn, fire_year as year, herd_name, bc_habitat as critical_hab from public.fire_sum_crithab where herd_name in ('", paste(unique(data_new$herd_name), collapse = "', '"),"') order by herd_name, year;")))
fire.hr<-data.table(getTableQuery(paste0("SELECT SUM(ST_Area(ST_Intersection(y.wkb_geometry, b.wkb_geometry ))) AS area_burn, herd_name ,bc_habitat as critical_hab,fire_year as year
      FROM public.h_fire_ply_polygon b, public.hart_ranges_south_bnds y
      WHERE ST_INTERSECTS(b.wkb_geometry, y.wkb_geometry) 
      GROUP BY fire_year, herd_name, bc_habitat
      ORDER BY  fire_year, herd_name, bc_habitat;")))
fire.hr[,herd_name:='Hart_Ranges_South']
fire<-rbind(fire, fire.hr)

#fill in the years with zero
fire2<-fire %>%
  group_by(herd_name, critical_hab) %>% 
  complete(year = full_seq(year,1), fill = list(area_burn = 0))

fire3<-data.table(fire2)
fire3[, burn40 := zoo::rollapplyr(area_burn, 40, FUN = sum, fill=0), by = c("herd_name", "critical_hab")] 


disturb<-disturb[,year:=as.integer(timeperiod+1980)]
setnames(disturb, "scenario", "herd_name")

#seral<-seral[,year:=as.integer(timeperiod+1980)]
#setnames(seral, c("scenario", "herd_bounds"), c("herd_name","critical_hab"))

#merge them together
#data.1<-merge(disturb, seral, by.x = c("herd_name", "year", "critical_hab"), by.y = c("herd_name", "year", "critical_hab"))
#data.1[, early_seral:=prop_age*area]

data.1<-disturb
#rename critical_hab to either matrix or core
data.1[critical_hab %like% "Matrix",critical_hab:= 'Matrix' ]
data.1[critical_hab %like% "Core",critical_hab:= 'Core' ]

#Merge in the fire disturbance
data.2<-merge(data.1, fire3, by.x =c("herd_name", "year", "critical_hab"), by.y = c("herd_name", "year", "critical_hab"), all.x =TRUE )

data.2<-merge(data.2, areas, by.x =c("herd_name", "critical_hab"), by.y = c("herd_name", "critical_hab") )

```
### Create the linkage
```{r, linkage}

data.3<-merge(data.2, data_new, by.x = c("herd_name", "year"), by.y = c("herd_name", "year"), all.x=TRUE)

#subset by habitat type
data.core<-data.3[critical_hab== 'Core', c("herd_name", "year", "pop_estimate", "lambda", "year.0","pop.0", "lambda.ratio", "lambda.finite", "per.pop", "total_area", "pop_lag", "log.pop", "year_lag", "lambda.dift","lambda.dif", "pop.change","lambda.dift.n0","lambda.dif.n0", "area_for","burn40", "cut20", "cut40", "cut80", "road50", "road250", "road500", "road750", "c20r50", "c20r250", "c20r500", "c20r750","c40r50", "c40r250", "c40r500", "c40r750","c80r50", "c80r250", "c80r500", "c80r750")]
setnames(data.core, c("total_area", "area_for", "burn40","cut20", "cut40", "cut80", "road50", "road250", "road500", "road750", "c20r50", "c20r250", "c20r500", "c20r750","c40r50", "c40r250", "c40r500", "c40r750","c80r50", "c80r250", "c80r500", "c80r750"), 
         c("core.area", "core.area.for", "core.burn40","core.cut20", "core.cut40", "core.cut80", "core.road50", "core.road250", "core.road500", "core.road750", "core.c20r50", "core.c20r250", "core.c20r500", "core.c20r750","core.c40r50", "core.c40r250", "core.c40r500", "core.c40r750","core.c80r50", "core.c80r250", "core.c80r500", "core.c80r750"))

data.matrix<-data.3[critical_hab == 'Matrix',c("herd_name", "year","total_area","area_for","burn40", "cut20", "cut40", "cut80", "road50", "road250", "road500", "road750", "c20r50", "c20r250", "c20r500", "c20r750","c40r50", "c40r250", "c40r500", "c40r750","c80r50", "c80r250", "c80r500", "c80r750" )]
setnames(data.matrix, c("total_area", "area_for", "burn40","cut20", "cut40", "cut80", "road50", "road250", "road500", "road750", "c20r50", "c20r250", "c20r500", "c20r750","c40r50", "c40r250", "c40r500", "c40r750","c80r50", "c80r250", "c80r500", "c80r750"), c("matrix.area","matrix.area.for", "matrix.burn40","matrix.cut20", "matrix.cut40", "matrix.cut80", "matrix.road50", "matrix.road250", "matrix.road500", "matrix.road750", "matrix.c20r50", "matrix.c20r250", "matrix.c20r500", "matrix.c20r750","matrix.c40r50", "matrix.c40r250", "matrix.c40r500", "matrix.c40r750","matrix.c80r50", "matrix.c80r250", "matrix.c80r500", "matrix.c80r750"))
data.core<-data.core[,core.burn40.per:=core.burn40/core.area.for]
data.matrix<-data.matrix[,matrix.burn40.per:=matrix.burn40/matrix.area.for]

data.set<-merge(data.core, data.matrix, by.x = c("herd_name", "year"), by.y = c("herd_name", "year"))
data.set[, time:=year-year.0]
data.set[, pop.den:= pop_estimate/((core.area)*0.01)]

#Calc diturbance indicators
data.set[, core.cut20.per:= (core.cut20/core.area.for)*100]
data.set[, core.cut40.per:= (core.cut40/core.area.for)*100]
data.set[, core.cut80.per:= (core.cut80/core.area.for)*100]
data.set[, core.road50.per:= (core.road50/core.area.for)*100]
data.set[, core.road250.per:= (core.road250/core.area.for)*100]
data.set[, core.road500.per:= (core.road500/core.area.for)*100]
data.set[, core.road750.per:= (core.road750/core.area.for)*100]
data.set[, core.cut20r50.per:= (core.c20r50/core.area.for)*100]
data.set[, core.cut20r250.per:= (core.c20r250/core.area.for)*100]
data.set[, core.cut20r500.per:= (core.c20r500/core.area.for)*100]
data.set[, core.cut20r750.per:= (core.c20r750/core.area.for)*100]
data.set[, core.cut40r50.per:= (core.c40r50/core.area.for)*100]
data.set[, core.cut40r250.per:= (core.c40r250/core.area.for)*100]
data.set[, core.cut40r500.per:= (core.c40r500/core.area.for)*100]
data.set[, core.cut40r750.per:= (core.c40r750/core.area.for)*100]
data.set[, core.cut80r50.per:= (core.c80r50/core.area.for)*100]
data.set[, core.cut80r250.per:= (core.c80r250/core.area.for)*100]
data.set[, core.cut80r500.per:= (core.c80r500/core.area.for)*100]
data.set[, core.cut80r750.per:= (core.c80r750/core.area.for)*100]
data.set[, core.af.cut20:= core.area.for-core.cut20]
data.set[, core.af.cut20.per:= (core.af.cut20/core.area.for)*100]
data.set[, core.af.cut40:= core.area.for-core.cut40]
data.set[, core.af.cut40.per:= (core.af.cut40/core.area.for)*100]
data.set[, core.af.cut80:= core.area.for-core.cut80]
data.set[, core.af.cut80.per:= (core.af.cut80/core.area.for)*100]
data.set[, core.af.road50:= core.area.for-core.road50]
data.set[, core.af.road50.per:= (core.af.road50/core.area.for)*100]
data.set[, core.af.road500:= core.area.for-core.road500]
data.set[, core.af.road500.per:= (core.af.road500/core.area.for)*100]
data.set[, core.af.road750:= core.area.for-core.road750]
data.set[, core.af.road750.per:= (core.af.road750/core.area.for)*100]
data.set[, core.af.cut20r50:= core.area.for-core.c20r50]
data.set[, core.af.cut20r50.per:= (core.af.cut20r50/core.area.for)*100]
data.set[, core.af.cut20r500:= core.area.for-core.c20r500]
data.set[, core.af.cut20r500.per:= (core.af.cut20r500/core.area.for)*100]
data.set[, core.af.cut40r50:= core.area.for-core.c40r50]
data.set[, core.af.cut40r50.per:= (core.af.cut40r50/core.area.for)*100]
data.set[, core.af.cut40r500:= core.area.for-core.c40r500]
data.set[, core.af.cut40r500.per:= (core.af.cut40r500/core.area.for)*100]

#MAtrix
data.set[, matrix.cut20.per:= (matrix.cut20/matrix.area.for)*100]
data.set[, matrix.cut40.per:= (matrix.cut40/matrix.area.for)*100]
data.set[, matrix.cut80.per:= (matrix.cut80/matrix.area.for)*100]
data.set[, matrix.road50.per:= (matrix.road50/matrix.area.for)*100]
data.set[, matrix.road250.per:= (matrix.road250/matrix.area.for)*100]
data.set[, matrix.road500.per:= (matrix.road500/matrix.area.for)*100]
data.set[, matrix.road750.per:= (matrix.road750/matrix.area.for)*100]
data.set[, matrix.cut20r50.per:= (matrix.c20r50/matrix.area.for)*100]
data.set[, matrix.cut20r250.per:= (matrix.c20r250/matrix.area.for)*100]
data.set[, matrix.cut20r500.per:= (matrix.c20r500/matrix.area.for)*100]
data.set[, matrix.cut20r750.per:= (matrix.c20r750/matrix.area.for)*100]
data.set[, matrix.cut40r50.per:= (matrix.c40r50/matrix.area.for)*100]
data.set[, matrix.cut40r250.per:= (matrix.c40r250/matrix.area.for)*100]
data.set[, matrix.cut40r500.per:= (matrix.c40r500/matrix.area.for)*100]
data.set[, matrix.cut40r750.per:= (matrix.c40r750/matrix.area.for)*100]
data.set[, matrix.cut80r50.per:= (matrix.c80r50/matrix.area.for)*100]
data.set[, matrix.cut80r250.per:= (matrix.c80r250/matrix.area.for)*100]
data.set[, matrix.cut80r500.per:= (matrix.c80r500/matrix.area.for)*100]
data.set[, matrix.cut80r750.per:= (matrix.c80r750/matrix.area.for)*100]

data.set[, matrix.af.cut20:= matrix.area.for-matrix.cut20]
data.set[, matrix.af.cut20.per:= (matrix.af.cut20/matrix.area.for)*100]
data.set[, matrix.af.cut40:= matrix.area.for-matrix.cut40]
data.set[, matrix.af.cut40.per:= (matrix.af.cut40/matrix.area.for)*100]
data.set[, matrix.af.cut80:= matrix.area.for-matrix.cut80]
data.set[, matrix.af.cut80.per:= (matrix.af.cut80/matrix.area.for)*100]
data.set[, matrix.af.road50:= matrix.area.for-matrix.road50]
data.set[, matrix.af.road50.per:= (matrix.af.road50/matrix.area.for)*100]
data.set[, matrix.af.road500:= matrix.area.for-matrix.road500]
data.set[, matrix.af.road500.per:= (matrix.af.road500/matrix.area.for)*100]
data.set[, matrix.af.road750:= matrix.area.for-matrix.road750]
data.set[, matrix.af.road750.per:= (matrix.af.road750/matrix.area.for)*100]
data.set[, matrix.af.cut20r50:= matrix.area.for-matrix.c20r50]
data.set[, matrix.af.cut20r50.per:= (matrix.af.cut20r50/matrix.area.for)*100]
data.set[, matrix.af.cut40r50:= matrix.area.for-matrix.c40r50]
data.set[, matrix.af.cut40r50.per:= (matrix.af.cut40r50/matrix.area.for)*100]
data.set[, matrix.af.cut40r500:= matrix.area.for-matrix.c40r500]
data.set[, matrix.af.cut40r500.per:= (matrix.af.cut40r50/matrix.area.for)*100]
data.set[, matrix.af.cut40r500:= matrix.area.for-matrix.c40r500]
data.set[, matrix.af.cut40r500.per:= (matrix.af.cut40r500/matrix.area.for)*100]

##TOTAL
data.set[, total.cut20.per:= (matrix.cut20 + core.cut20)/(matrix.area.for+core.area.for)*100]
data.set[, total.cut40.per:= (matrix.cut40 + core.cut40)/(matrix.area.for+core.area.for)*100]
data.set[, total.cut80.per:= (matrix.cut80 + core.cut80)/(matrix.area.for+core.area.for)*100]

data.set[, total.road50.per:= (matrix.road50 + core.road50)/(matrix.area.for+core.area.for)*100]
data.set[, total.road250.per:= (matrix.road250 + core.road250)/(matrix.area.for+core.area.for)*100]
data.set[, total.road500.per:= (matrix.road500 + core.road500)/(matrix.area.for+core.area.for)*100]
data.set[, total.road750.per:= (matrix.road750 + core.road750)/(matrix.area.for+core.area.for)*100]

data.set[, total.cut40r50.per:= (matrix.c40r50 + core.c40r50)/(matrix.area+core.area)*100]
data.set[, total.cut40r500.per:= (matrix.c40r500 + core.c40r500)/(matrix.area+core.area)*100]


#RATES
##Core
if(FALSE){
data.set[, core.early.seral.lag:= lapply(.SD, function(x) c(NA,x[-.N])), by = herd_name, .SDcols = "core.early.seral"]
data.set[, core.dist.lag:= lapply(.SD, function(x) c(NA,x[-.N])), by = herd_name, .SDcols = "core.dist"]
data.set[, core.dist500.lag:= lapply(.SD, function(x) c(NA,x[-.N])), by = herd_name, .SDcols = "core.dist500"]

#Matrix
data.set[, matrix.early.seral.lag:= lapply(.SD, function(x) c(NA,x[-.N])), by = herd_name, .SDcols = "matrix.early.seral"]
data.set[, matrix.dist.lag:= lapply(.SD, function(x) c(NA,x[-.N])), by = herd_name, .SDcols = "matrix.dist"]
data.set[, matrix.dist500.lag:= lapply(.SD, function(x) c(NA,x[-.N])), by = herd_name, .SDcols = "matrix.dist500"]

#Metrics
data.set[, core.early.seral.rate:=( (core.early.seral-core.early.seral.lag)/core.area.for)*100]
data.set[, core.dist.rate:= ((core.dist-core.dist.lag)/core.area.for)*100]
data.set[, core.dist500.rate:= ((core.dist500-core.dist500.lag)/core.area.for)*100]


##Matrix
data.set[, matrix.early.seral.rate:=( (matrix.early.seral-matrix.early.seral.lag)/matrix.area.for)*100]
data.set[, matrix.dist.rate:= ((matrix.dist-matrix.dist.lag)/matrix.area.for)*100]
data.set[, matrix.dist500.rate:=( (matrix.dist500-matrix.dist500.lag)/matrix.area.for)*100]
}

#Final
data.set<-data.set[!is.na(pop.den),]
data.set<-data.set[!herd_name == 'Purcell_Central',]

#table1<- data.set[year == year.0, c("herd_name", 'core.cut40r500')]
```

# Figure of disturbance profile
```{r, dist_graph}
one0<-data.set[, c("herd_name", "year","core.cut40.per")]
setnames(one0, "core.cut40.per" , "value")
one0[, dm:='C']

one3<-data.set[, c("herd_name", "year","core.road50.per")]
setnames(one3, "core.road50.per" , "value")
one3[, dm:='R']


one2<-data.set[, c("herd_name", "year","core.cut40r500.per")]
setnames(one2, "core.cut40r500.per" , "value")
one2[, dm:='CR500']

core.graph.dist<-rbind(one0,one2,one3)
core.graph.dist[, hab:='Core']

t0<-data.set[, c("herd_name", "year","matrix.cut40.per")]
setnames(t0, "matrix.cut40.per" , "value")
t0[, dm:='C']

t3<-data.set[, c("herd_name", "year","matrix.road50.per")]
setnames(t3, "matrix.road50.per" , "value")
t3[, dm:='R']

t2<-data.set[, c("herd_name", "year","matrix.cut40r500.per")]
setnames(t2, "matrix.cut40r500.per" , "value")
t2[, dm:='CR500']

matrix.graph.dist<-rbind(t0,t2,t3)
matrix.graph.dist[,hab:='Matrix']


graph.dist<-rbind(core.graph.dist,matrix.graph.dist)
graph.dist<-graph.dist[, herd_name:=lapply(.SD, function(x) { gsub("_", " ", x)}), .SDcols = "herd_name"]

graph.dist$dm<- factor(graph.dist$dm, levels = c('R','C','CR500'))

out.graph.dist<- ggplot(data = graph.dist, aes(x = year, y =value,color = herd_name) ) +
  facet_wrap(hab~dm , scales="free_y") +
  labs(y = "Disturbance Measure (%)", x = "Year")+
  geom_point() +
  stat_smooth(method = "loess", formula = y ~ x, se = FALSE)+
  #geom_smooth(method = 'lm', se=FALSE) +
  #stat_summary(fun.data=mean_cl_boot, geom="ribbon", alpha=0.25)+
  guides(color=guide_legend(title = "Herd")) +
  theme_bw() 

out.graph.dist
```
## Population threshold
```{r, threshold_pop}
library(minpack.lm)
logistic.model <- function( a, b, c, x) {
  f <-a/(1+exp(b*(x-log(c))))
  return(f)
}
data.set[,log.core.area := log(core.area)]
pop.size <- nlsLM(pop_estimate~ logistic.model( a, b, c, log.core.area), start=list( a=201, b=-9, c=224000), data= data.set, control=c(maxiter =500))
summary(pop.size)
data.set[,herd.size:=0]
data.set[core.area >= coef(pop.size)[3],herd.size:=1]

ggplot(data = data.set, aes(x = log.core.area, y = pop_estimate)) + 
  geom_point(color='blue') +
  geom_line(color='red',data = data.table(pred=predict(pop.size), core.area = data.set$log.core.area), aes(y=pred, x= core.area))+
              geom_vline(xintercept = log(coef(pop.size)[3]))



```

## Plot between core disturbance and ratio between population estimates
```{r, pop_graph_core}
core.p0<-ggplot(data = data.set, aes(x =core.cut80.per, y =pop_estimate, color = herd_name )) +  geom_point() + geom_smooth(method = 'lm',se= FALSE) + theme(legend.position = "none")

core.p1<-ggplot(data = data.set, aes(x =core.road50.per, y =pop_estimate, color = herd_name ,  linetype = as.factor(herd.size))) +  geom_point() + geom_smooth(method = 'lm',se= FALSE) + theme(legend.position = "none")

core.p2<-ggplot(data = data.set, aes(x =core.cut40r500.per, y =pop_estimate, color = herd_name,  linetype = as.factor(herd.size)  )) +  geom_point() + geom_smooth(method = 'lm', se= FALSE) + theme(legend.position = "none")

ggplotly(core.p0)
ggplotly(core.p1)
ggplotly(core.p2)

```

## Plot between matrix disturbance and ratio between population estimates
```{r, pop_graph_core}
matrix.p0<-ggplot(data = data.set, aes(x =matrix.road50.per, y =pop_estimate, color = herd_name,  linetype = as.factor(herd.size)  )) +  geom_point() + geom_smooth(method = 'lm', se= FALSE) + theme(legend.position = "none")

matrix.p1<-ggplot(data = data.set, aes(x =matrix.cut80.per, y =pop_estimate, color = herd_name,  linetype = as.factor(herd.size)  )) +  geom_point() + geom_smooth(method = 'lm', se= FALSE) + theme(legend.position = "none")

matrix.p2<-ggplot(data = data.set, aes(x =matrix.cut40r500.per, y =pop_estimate, color = herd_name,  linetype = as.factor(herd.size)  )) +  geom_point() + geom_smooth(method = 'lm', se= FALSE) + theme(legend.position = "none")

ggplotly(matrix.p0)
ggplotly(matrix.p1)
ggplotly(matrix.p2)
```
.(count = .N, var = sum(VAR))
# Table of disturbance and population
```{r, table1}
table1<-data.set[,.(Core = mean(core.area), Matrix = mean(matrix.area),YearMin= min(year), YearMax= max(year),n = .N, popavg = round(mean(pop.den),3), popmax = max(pop.den), popmin = min(pop.den) ), by = "herd_name"]
table1
```
#DISTRUBITIONAL ASSUMPTIONS

I start with a normal distribution- since the change in population is likely symetrical distribution. This assumption does not seem valid.
```{r, assump}
library(gamlss)
data.set[, log.pop.den:=log(pop.den)]
histDist(pop_estimate,family="NO", data=data.set, nbins = 12)
histDist(pop_estimate,family="LOGNO", data=data.set, nbins = 12)
#histDist(pop_estimate,family="BE", data=data.set, nbins = 12)
histDist(pop_estimate,family="GA", data=data.set, nbins = 12)
histDist(pop_estimate,family="NBI", data=data.set, nbins = 12)
histDist(pop_estimate,family="PO", data=data.set, nbins = 12)
histDist(pop_estimate,family="LNO", data=data.set, nbins = 12)
```
#CORRELATION BETWEEN X
```{r, cor_x}
library(usdm)
vif(data.set[,c("core.cut40.per","matrix.cut40.per")])
vif(data.set[,c("core.cut40r50.per","matrix.cut40r50.per")])
vif(data.set[,c("core.cut40r500.per","matrix.cut40r500.per")])
vif(data.set[,c("core.road50.per","matrix.road50.per")])
cor(data.set[,"matrix.cut40.per"],data.set[,"core.cut40.per"])
cor(data.set[,"matrix.road50.per"],data.set[,"core.road50.per"])
cor(data.set[,"core.cut40r500.per"],data.set[,"matrix.cut40r500.per"])
cor(data.set[,"matrix.road50.per"],data.set[,"core.cut40.per"])
cor(data.set[,"matrix.cut40.per"],data.set[,"core.road50.per"])
cor(data.set[,"core.cut40.per"],data.set[,"core.road50.per"])
cor(data.set[,"matrix.cut40.per"],data.set[,"matrix.road50.per"])
```


#MODEL SETTINGS

Here the data set is cleaned up to only include those variables that are important to the modelling process. Further, the control parameters are set for the model fitting algorithums
```{r, setting}
library(gamlss)
library(nlme)

model.data<-data.set[,c("herd_name","herd.size","core.area", "pop_estimate", "pop.den",  "time", "year","core.road50.per","core.road500.per","core.road250.per","core.road750.per","core.cut40.per", "core.cut20.per", "core.cut80.per", "core.cut40r50.per", "core.cut40r500.per","core.cut80r500.per","core.cut80r50.per","core.cut20r500.per","core.af.cut40.per","core.af.cut20r500.per", "matrix.road50.per","matrix.road250.per", "matrix.road500.per","matrix.road750.per","matrix.cut40.per","matrix.cut80.per","matrix.cut20.per", "matrix.cut40r50.per", "matrix.cut40r500.per","matrix.cut80r500.per","matrix.cut80r50.per","matrix.cut20r500.per")]
con1 <- gamlss::gamlss.control(c.crit=0.001, n.cyc=5000,msMaxIter=1000000)
#xys2<-herd.bounds[,c("herd_name2", "X", "Y")]
#xys2$shape<-NULL
#xys2<-data.table(xys2)
#Add in the X and Y from the xys object
#model.data<-merge(model.data, xys2, by.x= "herd_name", by.y = "herd_name2", all.x=TRUE)
# Add the null group
model.data[,group:=1]
#model.data<-model.data[!herd_name %in% c("Purcell_Central", "Narrow_Lake"),]

```


#Linear Models
```{r, reduced_model}
m0.a.reml <- lme(pop_estimate ~ 1 , random=~ 1|group, data = model.data, method = 'REML', control = con1)
summary(m0.a.reml) #AIC:1106
plot(m0.a.reml)

#Try adding a random effect for herd. 
m0.b.reml <- lme(pop_estimate ~ 1 , random=~ 1|herd_name, data = model.data, method = 'REML', control = con1)
summary(m0.b.reml) #974

anova(m0.a.reml,m0.b.reml)

m0.b <- lme(pop_estimate ~ 1 , random=~ 1|herd_name,  correlation = corAR1(value = 0.8, form = ∼time|herd_name), data = model.data, method = 'ML', control = con1)
pacf(residuals(m0.b,type="normalized"))
summary(m0.b)#AIC:881

m0.b.reml <- lme(pop_estimate ~ 1 , random=~ 1|herd_name,  correlation = corAR1(value = 0.8, form = ∼time|herd_name), data = model.data, method = 'REML', control = con1)

m0.c <- lme(pop_estimate ~ 1 , random=~ 1|herd_name, correlation = corARMA(p=2,q=0, form = ∼time|herd_name), data = model.data, method = 'REML', control = con1)
acf(residuals(m0.c,type="normalized"))
summary(m0.c)#AIC:891
anova(m0.c, m0.b.reml)


c.0 <- lme(pop_estimate ~ core.cut40.per+matrix.cut40.per, random=~1|herd_name, correlation = corAR1(value = 0.8, form = ∼time|herd_name), data = model.data, method = 'ML', control = c(maxIter = 10000))
acf(residuals(c.0,type="normalized"), lag.max = 5)
summary(c.0) #AIC:879, Phi:0.889
plot(model.data$pop_estimate, resid(c.0))
abline(0,0)
plot(predict(c.0),model.data$pop_estimate)
abline(0,1, col = 'red')

r.0 <- lme(pop_estimate ~ core.road50.per+matrix.road50.per, random=~ 1|herd_name, correlation = corAR1(value = 0.8, form = ∼time|herd_name), data = model.data, method = 'ML', control = c(maxIter = 10000))
acf(residuals(r.0,type="normalized"), lag.max = 5)
summary(r.0)
plot(r.0)
plot(model.data$pop_estimate, resid(r.0))
abline(0,0) #AIC:874, PHI:0.88
plot(predict(r.0),model.data$pop_estimate)
abline(0,1, col = 'red')

cr500.0 <- lme(pop_estimate ~ core.cut40r500.per+matrix.cut40r500.per, random=~1|herd_name, correlation = corAR1(value = 0.8, form = ∼time|herd_name), data = model.data, method = 'ML', control = c(maxIter = 10000))
acf(residuals(cr500.0,type="normalized"), lag.max = 5)
summary(cr500.0)
plot(model.data$pop_estimate, resid(cr500.0))
abline(0,0)#AIC 875, PHI:0.874
plot(predict(cr500.0),model.data$pop_estimate)
abline(0,1, col = 'red')

lin.aic.values<-AIC(m0.b,cr500.0,r.0 ,c.0)
lin.aic.values$delta<-round(qpcR::akaike.weights(lin.aic.values$AIC)$deltaAIC, 3)
lin.aic.values$weights<-round(qpcR::akaike.weights(lin.aic.values$AIC)$weights, 3)
lin.aic.values

```

#Exponential models
```{r, nonliner}
#Models. Exponential type I: ln(Y) = b0 + b1 X
expo.model <- function(a, b, c,d,x, y,z) {
  f <- exp(a + d*z + x*b + y*c)
  return(f)
}

#CUTBLOCKS
start.c.0 <- nls(pop_estimate ~ expo.model(a,b,c,d, core.cut80.per, matrix.cut80.per, herd.size), start=list(a=5,c=0.1, b=0.1,d=0.5), data= model.data)

expo.c.0 <- nlme(pop_estimate  ~ expo.model(a,b,c,d, core.cut80.per,matrix.cut80.per,  herd.size), fixed =list(a~1,b~1,c~1,d~1), random= b~1|herd_name, correlation = corAR1(value = 0.8, form = ∼time|herd_name), start =list(fixed=coef(start.c.0)), data = model.data, method = 'ML', control = c(maxIter = 100000))
acf(residuals(expo.c.0,type="normalized"), lag.max = 10) 
pacf(residuals(expo.c.0,type="normalized"), lag.max = 10) 
summary(expo.c.0) #AIC:877 PHI:0.884
plot(expo.c.0)
plot(predict(expo.c.0),model.data$pop_estimate)
abline(0,1, col = 'red')
cor(model.data$pop_estimate, predict(expo.c.0, level=1))
newdat<-expand.grid(herd_name = 'Barkerville', core.cut80.per=seq(from = min(model.data$core.cut80.per),
                            to = max(model.data$core.cut80.per),
                            by = 0.1),
                    matrix.cut80.per= mean(model.data$matrix.cut80.per),
                    herd.size = 0)
ggplotly(ggplot(model.data, aes(x=core.cut80.per, y=pop_estimate, colour=herd_name)) +
  geom_point(size=3) +
  geom_line(aes(y=predict(expo.c.0), group=herd_name)) +
  geom_line(data=newdat, aes(y=predict(expo.c.0, level=0, newdata=newdat) ),size =1.5)) 

#ROADS
start.r.0 <- nls(pop_estimate ~ expo.model(a,b,c,d, core.road50.per,matrix.road50.per,herd.size), start=list(a=5,b=0.1,c=0.01,d=1), data= model.data)
expo.r.0 <- nlme(pop_estimate ~ expo.model(a,b,c,d, core.road50.per,matrix.road50.per, herd.size), fixed =list(a~1,b~1,c~1, d~1), random=b~1|herd_name, correlation=corAR1(value = 0.5, form = ∼time|herd_name), start =list(fixed=coef(start.r.0)), data = model.data, method = 'ML', control = c(maxIter = 10000))
acf(residuals(expo.r.0,type="normalized"), lag.max = 10)
pacf(residuals(expo.r.0,type="normalized"), lag.max = 10) 
hist(predict(expo.r.0),prob=TRUE)
curve(dnorm(x, mean=mean(predict(expo.r.0)), sd=sqrt(var(predict(expo.r.0)))), 
      col="darkblue", lwd=2, add=TRUE, yaxt="n")
summary(expo.r.0)
plot(expo.r.0)
plot(model.data$pop_estimate, predict(expo.r.0))
abline(0,1, col = 'red')
cor(model.data$pop_estimate, predict(expo.r.0, level=0))

newdat<-expand.grid(herd_name = 'Barkerville', matrix.road50.per=seq(from = min(model.data$matrix.road50.per),
                            to = max(model.data$matrix.road50.per),
                            by = 0.1),
                    core.road50.per= mean(model.data$core.road50.per),
                    herd.size =0)
newdat2<-expand.grid(herd_name = 'Barkerville', matrix.road50.per=seq(from = min(model.data$matrix.road50.per),
                            to = max(model.data$matrix.road50.per),
                            by = 0.1),
                    core.road50.per= mean(model.data$core.road50.per),
                    herd.size =1)
ggplotly(ggplot(model.data, aes(x=matrix.road50.per, y=pop_estimate, colour=herd_name)) +
  geom_point(size=3) +
  geom_line(aes(y=predict(expo.r.0), group=herd_name)) +
  geom_line(data=newdat, aes(y=predict(expo.r.0, level=0, newdata=newdat) ),size =1.5)+
   geom_line(data=newdat2, aes(y=predict(expo.r.0, level=0, newdata=newdat2) ),size =1.5) ) #AIC:859, PHI:0.77


#CUTBLOCKS + ROADS
start.cr.0 <- nls(pop_estimate ~ expo.model(a,b,c,d, core.cut80r500.per, matrix.cut80r50.per, herd.size), start=list(a=5,b=0.1, c = 0.05, d= 1), data= model.data)
expo.cr.0 <- nlme(pop_estimate ~ expo.model(a,b,c,d, core.cut80r50.per, matrix.cut80r50.per, herd.size), fixed =list(a~1,b~1, c~1, d~1), random= b~1|herd_name, correlation = corAR1(value = 0.5, form = ∼time|herd_name), start =list(fixed=coef(start.cr.0)), data = model.data, method = 'ML', control = c(maxIter = 10000))
acf(residuals(expo.cr.0,type="normalized"), lag.max = 10) 
summary(expo.cr.0)
plot(expo.cr.0)
plot(model.data$pop_estimate, predict(expo.cr.0))
abline(0,1, col = 'red')

newdat.cr<-expand.grid(herd_name = 'Barkerville', core.cut80r50.per=seq(from = min(model.data$core.cut80r50.per),
                            to = max(model.data$core.cut80r50.per),
                            by = 0.1),
                    matrix.cut80r50.per= mean(model.data$matrix.cut80r50.per),
                    herd.size =1)
ggplotly(ggplot(model.data, aes(x=core.cut80r50.per, y=pop_estimate, colour=herd_name)) +
  geom_point(size=3) +
  geom_line(aes(y=predict(expo.r.0), group=herd_name)) +
  geom_line(data=newdat.cr, aes(y=predict(expo.cr.0, level=0, newdata=newdat.cr) ),size =1.5)) #AIC:866, PHI:0.84

aic.values<-AIC(m0.b,expo.cr.0,expo.r.0 ,expo.c.0 )
aic.values$delta<-round(qpcR::akaike.weights(aic.values$AIC)$deltaAIC, 3)
aic.values$weights<-round(qpcR::akaike.weights(aic.values$AIC)$weights, 3)
aic.values

```

#GAMS
```{r, gams}
#GAMLSS
gam.null<-gamlss(pop_estimate ~ 1 + re(random=~1|herd_name, method = "ML", correlation = corAR1(form=~time|herd_name)), opt="optim",   sigma.formula = ~1 + herd.size, family = LOGNO(), data = model.data, control =gamlss.control(c.crit=0.001, n.cyc=5000,msMaxIter=1000000), method=CG())
summary(gam.null)
acf(residuals(getSmo(gam.null),type="normalized"), lag.max = 10)

gam.c<-gamlss(pop_estimate ~ core.cut80.per  +matrix.cut80.per+ re(random=~1|herd_name, method = "ML", correlation = corAR1(value =0.8, form=~time|herd_name)), opt="optim",   sigma.formula = ~1 + herd.size , family = LOGNO(), data = model.data, control =gamlss.control(c.crit=0.1, n.cyc=5000,msMaxIter=1000000), method=CG())
plot(gam.c)
summary(gam.c)
plot(model.data$pop_estimate, exp(predict(gam.c)))
abline(0,1,col='red')
acf(residuals(getSmo(gam.c),type="normalized"), lag.max = 10) 


gam.r<-gamlss(pop_estimate ~ core.road50.per+matrix.road50.per+re(random=~1|herd_name, method = 'ML',  correlation = corAR1(form = ∼time|herd_name)), opt="optim",   sigma.formula = ~1+herd.size, family = LOGNO(), data = model.data, control =gamlss.control(c.crit=0.1, n.cyc=5000,msMaxIter=1000000), method=CG())
summary(gam.r)
plot(gam.r)
plot(model.data$pop_estimate, exp(predict(gam.r)), col = as.factor(model.data$herd_name))
abline(0,1,col='red')
cor(log(model.data$pop_estimate), predict(gam.r))
wp(gam.r)
acf(residuals(getSmo(gam.r),type="normalized"), lag.max = 10)
pacf(residuals(getSmo(gam.r),type="normalized"), lag.max = 10)
hist(exp(predict(gam.r)),prob=TRUE,ylim=c(0,0.009))
curve(dlnorm(x, mean=mean((predict(gam.r))), sd=sqrt(var((predict(gam.r))))), 
      col="darkblue", lwd=2, add=TRUE, yaxt="n")

gam.cr500<-gamlss(pop_estimate ~core.cut80r50.per+matrix.cut80r50.per +re(random=~1|herd_name, method = "ML", correlation = corAR1(value = 0.8, form = ∼time|herd_name)), opt="optim",   sigma.formula = ~1 +herd.size, family = LOGNO(), data = model.data, control =gamlss.control(c.crit=0.1, n.cyc=5000,msMaxIter=1000000), method=CG())
summary(gam.cr500)
plot(model.data$pop_estimate, exp(predict(gam.cr500)))
abline(0,1)
cor(log(model.data$pop_estimate), predict(gam.cr500))
wp(gam.cr500)
acf(residuals(getSmo(gam.cr500),type="normalized"), lag.max = 10)
pacf(residuals(getSmo(gam.cr500),type="normalized"), lag.max = 10)

plot(exp(predict(gam.c)), model.data$pop_estimate, col=as.factor(model.data$herd_name))
abline(0,1, col = 'red')
plot(exp(predict(gam.r)), model.data$pop_estimate,col=as.factor(model.data$herd_name))
abline(0,1, col = 'red')
plot(exp(predict(gam.cr500)), model.data$pop_estimate,col=as.factor(model.data$herd_name)) 
abline(0,1, col = 'red')

gam.aic.values<-AIC(gam.null,gam.c,gam.r,gam.cr500)
gam.aic.values$delta<-round(qpcR::akaike.weights(gam.aic.values$AIC)$deltaAIC, 3)
gam.aic.values$weights<-round(qpcR::akaike.weights(gam.aic.values$AIC)$weights, 3)
gam.aic.values

```


#FIGURE 3: observed vs predicted
```{r, obs_pred}
dtgx<-data.table(cbind(model.data[,c("pop_estimate", "herd_name", "herd.size")],fitted = predict(gam.r)))

dtgx<-dtgx[, herd_name:=lapply(.SD, function(x) { gsub("_", " ", x)}), .SDcols = "herd_name"]

ggplot(data = dtgx, aes(y=pop_estimate, x =exp(fitted), color = herd_name)) +
  #facet_wrap(.~herd.size)+
  geom_point() +
  labs(y = "Observed", x = "Predicted")+
  geom_abline(intercept = 0, slope = 1) +
  theme_bw() +
  guides(color=guide_legend(title = "Herd")) 

a1<-ggplot(data = model.data, aes(x = core.road50.per, y = pop_estimate, colour = factor(herd_name))) +
  theme(legend.position = "none")+
    geom_point(size=3) +
    geom_line(aes(y = exp(predict(gam.r)) ) )

a2<-ggplot(data = model.data, aes(x = matrix.road50.per, y = pop_estimate, colour = factor(herd_name))) +
    theme(legend.position = "none")+
    geom_point(size=3) +
    geom_line(aes(y = exp(predict(gam.r))) )
library(gridExtra)
grid.arrange(a1, a2,nrow=1)

```

#FIGURE 4. Behaviour of the model

```{r, behave}

curves <- lapply(seq_len(NROW(df)), function(i) {
  mu <- df$y[i]
  range <- mu + c(-3, 3)
  seq <- seq(range[1], range[2], length.out = 100)
  data.frame(
    x = -1 * dnorm(seq, mean = mu) + df$x[i],
    y = seq,
    grp = i
  )
})
# Combine above densities in one data.frame
curves <- do.call(rbind, curves)
ggplot(df, aes(x, y)) +
  geom_point() +
  geom_line() +
  # The path draws the curve
  geom_path(data = curves, aes(group = grp))


```

## Thresholds
```{r, thresholds}
#get 2018 disturbance estiamtes
dist2018.core<-data.2[year == 2018 & critical_hab %like% 'Core',c("herd_name", "dist500", "area")]
setnames(dist2018.core, c("dist500", "area"), c("core.dist500.2018", "core.area"))
dist2018.matrix<-data.2[year == 2018 & critical_hab %like% 'Matrix',c("herd_name","dist500", "area")]
setnames(dist2018.matrix, c("dist500", "area"), c("matrix.dist500.2018", "matrix.area"))
dist2018<-merge(dist2018.core, dist2018.matrix, by.x = "herd_name", by.y = "herd_name")

dist.init<-data.set.0[,c("herd_name", "core.dist500.0", "matrix.dist500.0")]
#create dataset for a prestine core
trajectory <-with(dist.init, expand.grid(matrix.dist500.rate = seq(from = 0,to = 35, by =1), core.dist500.rate = -100))
trajectory <-data.table(trajectory)[,herd_id:=1]
#merge in herds
bh_herds<-data.table(herd_name=unique(model.data$herd_name), herd_id =1)
trajectory.2<-merge(bh_herds, trajectory, by.x="herd_id", by.y="herd_id", all=TRUE, allow= TRUE)
trajectory.2$pred<-predict(dist500.rate.reml, trajectory.2,level=1)


#Current level of core
dist.traj<-merge(dist.init, dist2018, by.x = "herd_name", by.y = "herd_name")
dist.traj[,core.dist500.rate:=((core.dist500.2018-core.dist500.0)/core.dist500.0)*100]
dist.traj[,matrix.dist500.rate:=((matrix.dist500.2018-matrix.dist500.0)/matrix.dist500.0)*100]
test.core<-dist.traj[,c("herd_name", "core.dist500.rate")]

trajectory <-with(dist.init, expand.grid(matrix.dist500.rate = seq(from = -20,to = 35, by =1), core.dist500.rate= test.core$core.dist500.rate))
trajectory.2<-merge(test.core, trajectory, by.x="core.dist500.rate", by.y="core.dist500.rate", all=TRUE, allow= TRUE)

trajectory.2$pred<-predict(dist500.rate.reml, trajectory.2,level=1)

#projections for 2018
dist.traj$pred<-predict(dist500.rate.reml, dist.traj,level=1)

out5<-dist.traj[, c("herd_name", "pred")]

```


