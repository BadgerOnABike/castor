---
title: "BC Caribou Population Estimates"
author: "Tyler Muhly"
date: "22/08/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(rpostgis)
library(data.table)
library(ggplot2)
library(plotly)
library(nlme)
library(ggspatial)
library(tidyr)
source(paste0(here::here(), "/R/functions/R_Postgres.R"))
```

# Background
We need data on caribou population estimates. This creates a table of that information, including source of the information, to be uploaded into our database for use in moduels or as part of information summary.

Note: currently in contact with Nicola Dodd about getting this data

### Caribou population data
```{r, pop}
caribou_pop<-read.csv("T:/FOR/VIC/HTS/ANA/PROJECTS/CLUS/Data/caribou/population/herd_estimates_simple_20200106.csv")
conn<-DBI::dbConnect(dbDriver("PostgreSQL"), host=keyring::key_get('dbhost', keyring = 'postgreSQL'), dbname = keyring::key_get('dbname', keyring = 'postgreSQL'), port='5432' ,user=keyring::key_get('dbuser', keyring = 'postgreSQL') ,password= keyring::key_get('dbpass', keyring = 'postgreSQL'))

DBI::dbWriteTable(conn, c("public", "caribou_pop_simple"), value= caribou_pop, row.names = FALSE, overwrite = TRUE) 
dbDisconnect(conn)
```


### Wolf control data

Tyler pulled this dataset together -- to determine in which years population control activities take place.

```{r, pop_control}

wolf_actions<-read.csv("T:/FOR/VIC/HTS/ANA/PROJECTS/CLUS/Data/caribou/population/table_wolf_control_20200302.csv")
colnames(wolf_actions)<-c("herd_name", "year", "type")
conn<-DBI::dbConnect(dbDriver("PostgreSQL"), host=keyring::key_get('dbhost', keyring = 'postgreSQL'), dbname = keyring::key_get('dbname', keyring = 'postgreSQL'), port='5432' ,user=keyring::key_get('dbuser', keyring = 'postgreSQL') ,password= keyring::key_get('dbpass', keyring = 'postgreSQL'))

DBI::dbWriteTable(conn, c("public", "wolf_control"), value= wolf_actions, row.names = FALSE, overwrite = TRUE) 
dbDisconnect(conn)

```

### Merge wolf and pop data

```{r, final, echo=FALSE}
data_new<-data.table(merge(caribou_pop, wolf_actions, by.x = c("herd_name", "year"), by.y =c("herd_name", "year"), all.x = TRUE))
#Remove minimum counts and exper opinion estimates
data_new<-data_new[!(estimate_type %in% c("Expert Opinion", "Survey Observation","Minimum count", "Minimum Count", "Unknown"))]
#data_new<-data_new[!(estimate_type %in% c("Minimum count", "Minimum Count", "Unknown"))]

#remove dates confounded by population control responses
data_new<-data_new[is.na(type),]

#sort by herd_name and year
data_new[order(herd_name, year)]

#remove 'old' estimaste so this agrees with disturbance data
data_new<-data_new[year > 1975,]

#remove functionally extirpated populations
data_new<-data_new[pop_estimate > 0,]

#remove barkerville population after 2007 see QUESNEL HIGHLAND WOLF STERILIZATION PILOT ASSESSMENT 2012 An Independent Evaluation of the Response of Mountain Caribou
data_new<-data_new[!(herd_name == 'Barkerville' & (year > 2007 | year < 1993)),]

#remove herds with only two data point
herds_counts <- data_new[, .(rowCount = .N), by = herd_name][rowCount > 3,]
data_new<-data_new[herd_name %in% herds_counts$herd_name,]

#calc the averaged census lambda
data_new[, pop_lag:= lapply(.SD, function(x) c(NA,x[-.N])), by = herd_name, .SDcols = "pop_estimate"]

data_new[, year_lag:= lapply(.SD, function(x) c(NA,x[-.N])), by = herd_name, .SDcols = "year"]
data_new[, lambda:= (pop_estimate/pop_lag)**(1/(year-year_lag))]
data_new[, pop.change:= (pop_estimate/pop_lag)-1]
#data_new[,c("pop_lag", "year_lag"):= list(NULL, NULL)]  

#calc the averaged census lambda
data_new[, year.0 := min(year), by=herd_name]
data_new[, pop.max := max(pop_estimate), by=herd_name]
data_new[, per.pop := pop_estimate/pop.max]

pop0<-data_new[year==year.0, c("herd_name","pop_estimate")]
setnames(pop0, "pop_estimate", "pop.0")
data_new<-merge(data_new, pop0, by.x = "herd_name", by.y = "herd_name")
data_new[, lambda.ratio:= (pop_estimate/pop.0)]
data_new[year==year.0, lambda.ratio:= NA]

data_new[, lambda.finite:= (pop_estimate/pop.0)**(1/(year-year.0))]
data_new[year==year.0, lambda.finite:= NA]

# From https://www.nature.com/scitable/knowledge/library/how-populations-grow-the-exponential-and-logistic-13240157/
data_new[, log.pop:= log(pop_estimate)]
data_new[, lambda.dif:= log(pop_estimate)-log(pop.0)]
data_new[, lambda.dift:= lambda.dif/(year-year.0)]
data_new[, lambda.dif.n0:= log(pop_estimate)-log(pop_lag)]
data_new[, lambda.dift.n0:= lambda.dif.n0/(year-year_lag)]

#rename the herds so that they link with CLUS
data_new[, herd_name:= lapply(.SD, function(x) { gsub("-", "_", x)}), .SDcols = "herd_name"]
data_new[, herd_name:= lapply(.SD, function(x) { gsub(" ", "_", x)}), .SDcols = "herd_name"]


conn<-DBI::dbConnect(dbDriver("PostgreSQL"), host=keyring::key_get('dbhost', keyring = 'postgreSQL'), dbname = keyring::key_get('dbname', keyring = 'postgreSQL'), port='5432' ,user=keyring::key_get('dbuser', keyring = 'postgreSQL') ,password= keyring::key_get('dbpass', keyring = 'postgreSQL'))

DBI::dbWriteTable(conn, c("public", "caribou_trend"), value= data_new, row.names = FALSE, overwrite = TRUE) 
dbDisconnect(conn)

```

#### Map of herds
```{r, graph_pop}
herd.spat<-getSpatialQuery( "Select * from public.bc_caribou_linework_v20200507_shp_core_matrix")

#Make a grouping variable
herd.spat$herd_hab<-herd.spat$herd_name
non.herds<-unique(data_new$herd_name)
herd.spat[herd.spat$herd_name %in% non.herds,]$herd_hab<-paste(herd.spat[herd.spat$herd_name %in% non.herds,]$herd_name,herd.spat[herd.spat$herd_name %in% non.herds,]$bc_habitat)

#Dissolve
herd.spat1<-herd.spat %>%
   group_by(herd_hab) %>%
   summarise()

#Add matrix/core and herd_name columns
herd.spat1$crit <- 0
herd.spat1[herd.spat1$herd_hab %like% "Matrix", ]$crit <- 1
herd.spat1[herd.spat1$herd_hab %like% "Core", ]$crit <- 2
string.list<-unlist(strsplit(herd.spat1$herd_hab, ' '))
herd.spat1$herd_name<-string.list[!string.list %in% c('Matrix' , 'Core')]

inset<- bc <- plot(bcmaps::bc_bound())
map<-ggplot(data = herd.spat1, aes(fill = crit )) +
    geom_sf(show.legend=FALSE )+
    geom_sf_text(aes(label = herd_name), check_overlap = TRUE, inherit.aes = TRUE)+
    theme_bw()+
    xlab("Longitude") + ylab("Latitude") +
    annotation_scale(location = "bl", width_hint = 0.3) +
    annotation_north_arrow(location = "bl", which_north = "true", height = unit(.5, "in"), width = unit(.5, "in") , 
        pad_x = unit(0.3, "in"), pad_y = unit(0.3, "in"))

map

```
#### Graph of population data
```{r, graph_pop}
conn<-DBI::dbConnect(dbDriver("PostgreSQL"), host=keyring::key_get('dbhost', keyring = 'postgreSQL'), dbname = keyring::key_get('dbname', keyring = 'postgreSQL'), port='5432' ,user=keyring::key_get('dbuser', keyring = 'postgreSQL') ,password= keyring::key_get('dbpass', keyring = 'postgreSQL'))
data_new<-dbGetQuery(conn, "Select * from caribou_trend where herd_name not in ('Muskwa', 'Pink_Mountain', 'Chase', 'Wolverine');")
dbDisconnect(conn)
ggplotly(ggplot(data = data_new, aes(x=year, y = lambda.dif, color = herd_name))+
  geom_point() + geom_line())
```

#### Get the disturbance information

```{r, disturbance}
conn<-DBI::dbConnect(dbDriver("PostgreSQL"), host=keyring::key_get('vmdbhost', keyring = 'postgreSQL'), dbname = keyring::key_get('vmdbname', keyring = 'postgreSQL'), port='5432' ,user=keyring::key_get('vmdbuser', keyring = 'postgreSQL') ,password= keyring::key_get('vmdbpass', keyring = 'postgreSQL'))

disturb<-data.table(dbGetQuery(conn, paste0("SELECT * from disturbance_measures.disturbance where scenario in ('", paste(unique(data_new$herd_name), collapse = "', '"),"');")))

seral<-data.table(dbGetQuery(conn, paste0("SELECT * from disturbance_measures.survival where scenario in ('", paste(unique(data_new$herd_name), collapse = "', '"),"');")))

rsf<-data.table(dbGetQuery(conn, paste0("SELECT * from disturbance_measures.rsf where scenario in ('", paste(unique(data_new$herd_name), collapse = "', '"),"');")))

dbDisconnect(conn)

conn<-DBI::dbConnect(dbDriver("PostgreSQL"), host=keyring::key_get('dbhost', keyring = 'postgreSQL'), dbname = keyring::key_get('dbname', keyring = 'postgreSQL'), port='5432' ,user=keyring::key_get('dbuser', keyring = 'postgreSQL') ,password= keyring::key_get('dbpass', keyring = 'postgreSQL'))
fire<-data.table(dbGetQuery(conn, paste0("SELECT sumarea/10000 as area_burn, fire_year as year, herd_name, bc_habitat as critical_hab from public.fire_sum_crithab where herd_name in ('", paste(unique(data_new$herd_name), collapse = "', '"),"') order by herd_name, year;")))
dbDisconnect(conn)

#fill in the years with zero
fire2<-fire %>%
  group_by(herd_name, critical_hab) %>% 
  complete(year = full_seq(year,1), fill = list(area_burn = 0))

fire3<-data.table(fire2)
fire3[, burn40 := zoo::rollapplyr(area_burn, 40, FUN = sum, fill=0), by = c("herd_name", "critical_hab")] 


disturb<-disturb[,year:=as.integer(timeperiod+1980)]
setnames(disturb, "scenario", "herd_name")

seral<-seral[,year:=as.integer(timeperiod+1980)]
setnames(seral, c("scenario", "herd_bounds"), c("herd_name","critical_hab"))

rsf<-rsf[,year:=as.integer(timeperiod+1980)]
setnames(rsf, "scenario", "herd_name")

#merge them together
data.0<-merge(disturb, rsf, by.x = c("herd_name", "year", "critical_hab"), by.y = c("herd_name", "year", "critical_hab"))
data.1<-merge(data.0, seral, by.x = c("herd_name", "year", "critical_hab"), by.y = c("herd_name", "year", "critical_hab"))

data.1[, early_seral:=prop_age*area]
#rename critical_hab to either matrix or core
data.1[critical_hab %like% "Matrix",critical_hab:= 'Matrix' ]
data.1[critical_hab %like% "Core",critical_hab:= 'Core' ]

#Merge in the fire disturbance
data.2<-merge(data.1, fire3, by.x =c("herd_name", "year", "critical_hab"), by.y = c("herd_name", "year", "critical_hab") )

```


### Create the linkage
```{r, linkage}

data.3<-merge(data.2, data_new, by.x = c("herd_name", "year"), by.y = c("herd_name", "year"))
data.3[, pop.den:= pop_estimate/area]

#subset by habitat type
data.core<-data.3[critical_hab== 'Core', c("herd_name", "year", "pop_estimate", "lambda", "year.0","pop.0","pop.den", "area", "lambda.ratio", "lambda.finite", "per.pop", "early_seral", "dist", "dist500", "sum_rsf_hat", "sum_rsf_hat_75","per_rsf_hat_75", "pop_lag", "log.pop", "year_lag", "burn40", "survival_rate","lambda.dift","lambda.dif", "pop.change","lambda.dift.n0","lambda.dif.n0")]
setnames(data.core, c("early_seral", "dist", "dist500", "sum_rsf_hat", "sum_rsf_hat_75", "area", "pop_lag", "year_lag","burn40","per_rsf_hat_75","survival_rate","log.pop","lambda.dift","lambda.dif","pop.change","lambda.dift.n0","lambda.dif.n0"), c("core.early.seral", "core.dist", "core.dist500", "core.sum.rsf.hat", "core.sum.rsf.hat.75", "core.area", "pop_lag", "year_lag","core.burn40","core.per.rsf.hat.75","core.survival.rate","log.pop","lambda.dift","lambda.dif","pop.change","lambda.dift.n0","lambda.dif.n0"))

data.matrix<-data.3[critical_hab == 'Matrix',c("herd_name", "year", "early_seral", "dist", "dist500", "sum_rsf_hat", "sum_rsf_hat_75", "area", "burn40", "per_rsf_hat_75", "survival_rate")]
setnames(data.matrix, c("early_seral", "dist", "dist500", "sum_rsf_hat", "sum_rsf_hat_75", "area", "burn40","per_rsf_hat_75", "survival_rate"), c("matrix.early.seral", "matrix.dist", "matrix.dist500", "matrix.sum.rsf.hat", "matrix.sum.rsf.hat.75", "matrix.area", "matrix.burn40","matrix.per.rsf.hat.75","matrix.survival.rate"))
data.core<-data.core[,core.burn40.per:=core.burn40/core.area]
data.matrix<-data.matrix[,matrix.burn40.per:=matrix.burn40/matrix.area]

data.set<-merge(data.core, data.matrix, by.x = c("herd_name", "year"), by.y = c("herd_name", "year"))
data.set[, time:=year-year.0]

#Calc diturbance indicators
data.set[, core.dist.per:= core.dist/core.area]
data.set[, core.dist500.per:= core.dist500/core.area]
data.set[, core.early.seral.per:= core.early.seral/core.area]
data.set[, core.rsf.avg:= core.sum.rsf.hat/core.area]
data.set[, matrix.dist.per:= matrix.dist/matrix.area]
data.set[, matrix.dist500.per:= matrix.dist500/matrix.area]
data.set[, matrix.early.seral.per:= core.early.seral/matrix.area]
data.set[, matrix.rsf.avg:= matrix.sum.rsf.hat/matrix.area]

#RATES
##Core
#data.set[, core.burn40.rate:= lapply(.SD, function(x) c(NA,x[-.N])), by = herd_name, .SDcols = "core.burn40"]
data.set.0<-data.set[year == year.0, c("herd_name", "core.burn40","matrix.burn40", "core.early.seral","matrix.early.seral", "core.dist", "matrix.dist", "core.dist500", "matrix.dist500", "core.sum.rsf.hat", "matrix.sum.rsf.hat")]
setnames(data.set.0,c("herd_name", "core.burn40","matrix.burn40", "core.early.seral","matrix.early.seral","core.dist", "matrix.dist", "core.dist500", "matrix.dist500", "core.sum.rsf.hat", "matrix.sum.rsf.hat"),c("herd_name", "core.burn40.0","matrix.burn40.0","core.early.seral.0","matrix.early.seral.0", "core.dist.0", "matrix.dist.0", "core.dist500.0", "matrix.dist500.0", "core.sum.rsf.hat.0", "matrix.sum.rsf.hat.0"))
data.set<-merge(data.set, data.set.0, by.x = "herd_name", by.y = "herd_name", all.x = TRUE)
data.set[, core.burn40.rate:= (core.burn40-core.burn40.0)/core.burn40.0]
data.set[, core.early.seral.rate:= (core.early.seral-core.early.seral.0)/core.early.seral.0]
data.set[, core.dist.rate:= (core.dist-core.dist.0)/core.dist.0]
data.set[, core.dist500.rate:= (core.dist500-core.dist500.0)/core.dist500.0]
data.set[, core.rsf.rate:= (core.sum.rsf.hat-core.sum.rsf.hat.0)/core.sum.rsf.hat.0]

##Matrix
data.set[, matrix.burn40.rate:= (matrix.burn40-matrix.burn40.0)/matrix.burn40.0]
data.set[, matrix.early.seral.rate:= (matrix.early.seral-matrix.early.seral.0)/matrix.early.seral.0]
data.set[, matrix.dist.rate:= (matrix.dist-matrix.dist.0)/matrix.dist.0]
data.set[, matrix.dist500.rate:= (matrix.dist500-matrix.dist500.0)/matrix.dist500.0]
data.set[, matrix.rsf.rate:= (matrix.sum.rsf.hat-matrix.sum.rsf.hat.0)/matrix.sum.rsf.hat.0]
```

## Plot between core disturbance and ratio between population estimates
```{r, pop_graph_core}
p1<-ggplot(data = data.set, aes(x =core.early.seral.rate, y =lambda.dif, color = herd_name )) +  geom_point() 

p2<-ggplot(data = data.set, aes(x =core.dist.rate, y =lambda.dif, color = herd_name  )) + geom_point() 

p3<-ggplot(data = data.set, aes(x =core.dist500.rate, y = lambda.dif, color = herd_name  )) + geom_point() 

p4<-ggplot(data = data.set, aes(x =core.burn40.rate, y = lambda.dif , color = herd_name)) + geom_point() 

gridExtra::grid.arrange(p1,p2,p3,p4)

ggplotly(p2)
```

## Plot between matrix disturbance and ratio between population estimates
```{r, pop_graph_core}
p1<-ggplot(data = data.set, aes(x =matrix.early.seral.rate, y =lambda.dif, color = herd_name )) +  geom_point() 

p2<-ggplot(data = data.set, aes(x =matrix.dist.rate, y =lambda.dif, color = herd_name  )) + geom_point() 

p3<-ggplot(data = data.set, aes(x =matrix.dist500.rate, y = lambda.dif, color = herd_name  )) + geom_point() 

p4<-ggplot(data = data.set, aes(x =matrix.rsf.rate, y = lambda.dif , color = herd_name)) + geom_point() 

p5<-ggplot(data = data.set, aes(x =matrix.burn40.rate, y = lambda.dif , color = herd_name)) + geom_point() 

gridExtra::grid.arrange(p1,p2,p3,p4,p5)

ggplotly(p3)
```


#DISTRUBITIONAL ASSUMPTIONS

I start with a normal distribution- since the change in population is likely symetrical distribution. This assumption seems valid.
```{r, assump}
histDist(lambda.dift,family="NO", data=data.set[!is.na(lambda),], nbins = 10)
histDist(lambda.ratio,family="LNO", data=data.set[!is.na(lambda),], nbins = 10)

```

#MODEL SETTINGS

Here the data set is cleaned up to only include those variables that are important to the modelling process. Further, the control parameters are set for the model fitting algorithums
```{r, setting}
model.data<-na.omit(data.set[,c("herd_name", "time", "year", "lambda.ratio","lambda", "lambda.finite", "lambda.dift", "lambda.dif", "core.early.seral.per", "core.dist.per", "core.dist500.per", "core.burn40.per","core.per.rsf.hat.75","core.sum.rsf.hat","core.rsf.avg", "core.early.seral.rate", "core.dist.rate", "core.dist500.rate", "core.rsf.rate","core.burn40.rate", "matrix.early.seral.per", "matrix.dist.per", "matrix.dist500.per", "matrix.burn40.per","matrix.per.rsf.hat.75","matrix.sum.rsf.hat","matrix.rsf.avg","matrix.early.seral.rate", "matrix.dist.rate", "matrix.dist500.rate", "matrix.rsf.rate","matrix.burn40.rate")])
con1 <- gamlss.control(c.crit=0.001, n.cyc=5000,msMaxIter=1000000)
#ignore barkerville?
#model.data<-model.data[!herd_name == 'Barkerville',]

```

#NULL Model

Note that herd_name is the identifier for each herd. This model is simply the average of the log ratio of population change by herd = exp(-0.48) = 0.619 or a decline of ~40% across the years surveyed
```{r, reduced_model}
model.data[,group:=1]
m0.a <- lme(lambda.dif ~ 1 , random=~ 1|group, data = model.data, method = 'REML', control = con1)
summary(m0.a) #AIC:273, logl:-133
plot(m0.a)

#Try adding a random effect for herd. 
m0.b <- lme(lambda.dif ~ 1 , random=~ 1|herd_name, data = model.data, method = 'REML', control = con1)
summary(m0.b)#AIC:183, logl:-88.7
plot(m0.b)# variances are different by herd

#Try adding a random effect for herd. Also, a different Variance for each herd. "The lme function allow the modeling of heteroscesdasticity of the within-error group via a weights argument. This topic will be covered in detail in § 5.2, but, for now, it suffices to know that the varIdent variance function structure allows different variances for each level of a factor and can be used to fit the heteroscedastic model [...]" Pinheiro and Bates, p. 177

m0.c <- lme(lambda.dif ~ 1 , random=~ 1|herd_name, weights = varIdent(form = ~1|herd_name), data = model.data, method = 'REML', control = con1)
summary(m0.c)#AIC: 136, logl:-52
plot(m0.c)# variances are homogenous
anova(m0.b, m0.c) # model.c is better than model.b LRT: p<0.001

acf(residuals(m0.c,type="pearson"))# Note: |r| ~ 0.2 -- issues with autocorrelation...but lags hard to fit with the limited data.
#TRY a AR1 correlation structure? Doesn't fit well --have to change residuals to normalized!!!! Too many parameters to fit....
m0.d <- lme(lambda.dif ~ 1 , random=~ 1|herd_name, correlation = corAR1(value = 0.8, form = ∼time|herd_name), data = model.data, method = 'ML', control = con1)
#anova(m0.c, m0.d) # model m0.d is better LRT: p<0.001
acf(residuals(m0.d,type="normalized")) # phi = 0.9. No significant lags
plot( fitted(m0.d, level =1),residuals(m0.d, type="normalized"))# variances are homogenous
abline(0,0, col = 'red')

m0.e <- lme(lambda.dif ~ 1 , random=~ 1|herd_name, weights = varIdent(form=~1|herd_name), correlation = corAR1(form=~time ), data = model.data, method = 'REML', control = con1)
acf(residuals(m0.e,type="normalized")) # phi = 0.9. No significant lags
plot( fitted(m0.e, level =1),residuals(m0.e, type="normalized"))# variances are homogenous
#anova(m0.e, m0.c) #Model d is better LRT: p<0.001
anova(m0.e, m0.d) 
```

#Alternative models

Comaring the use of burn40, early.seral, dist, dist500 and rsf. Null random intercept model has AIC=206, Rsq=0.586, cor = 0.76888.

## Percentage burned less 40 years (burn40)

Not significantly impating the pop change after accounting for herd level impacts

```{r, burn40}
#burn40 -- includes only fires, no human disturbances (cutblocks)
#Use ML estimation since fixed effects will change amoung models
#---PERCENTAGE---
burn.per <- lme(lambda.dif ~ 1 + core.burn40.per*matrix.burn40.per, random=~ 1|herd_name, correlation = corAR1(0.8, form = ~time|herd_name), data = model.data, method = 'ML', control = con1)
##Diagnostics
acf(residuals(burn.per, type = 'normalized'),lag.max =10) # No problem with AC
plot( fitted(burn.per),residuals(burn.per, type="normalized"))# variances are homogenous
abline(0,0, col = 'red')
cor(fitted(burn.per),model.data$lambda.dif) #0.796
plot(model.data$lambda.dif~fitted(burn.per ))
abline(0,1, col = "red")
abline(0,0, col = "yellow")
summary(burn.per)

#---RATE----
burn.rate <- lme(lambda.dif ~ 1 + core.burn40.rate*matrix.burn40.rate, random=~ 1|herd_name,  correlation = corAR1(0.8, form = ~time|herd_name), data = model.data, method = 'ML', control = con1)
##Diagnostics
acf(residuals(burn.rate, type = 'normalized'),lag.max =10) # No problem with AC
plot( fitted(burn.rate),residuals(burn.rate, type="normalized"))# variances are homogenous
abline(0,0, col = 'red')
cor(fitted(burn.rate, level= 1),model.data$lambda.dif) #0.8547
plot(model.data$lambda.dif~fitted(burn.rate ))
abline(0,1, col = "red")
abline(0,0, col = "yellow")
summary(burn.rate)

anova(burn.per,burn.rate)
#Conclusion burn40 not a signifcant disturbance measure on its own
```

#Early Seral Stage which is just clear cuts -- doesn't include burns
```{r, eary_seral}
#---Percentage---
early.seral.per<- lme(lambda.dif ~ core.early.seral.per*matrix.early.seral.per, random=~ 1|herd_name, method = 'ML', correlation = corAR1(0.3, form =~time|herd_name), data = model.data, control = con1)
##Diagnostics
acf(residuals(early.seral.per , type = 'normalized'),lag.max =10)#No issues
plot( fitted(early.seral.per),residuals(early.seral.per, type="normalized"))# variances are homogenous
abline(0,0, col = 'red')
cor(fitted(early.seral.per, level=1),model.data$lambda.dif) #0.797
plot(model.data$lambda.dif~fitted(early.seral.per))
abline(0,1, col = "red")
abline(0,0, col = "yellow")
summary(early.seral.per)


#---Rate---
early.seral.rate<- lme(lambda.dif ~  core.early.seral.rate*matrix.early.seral.rate, random=~ 1|herd_name, method = 'ML', correlation = corAR1(0.3, form =~time|herd_name), data = model.data, control = con1)
##Diagnostics
acf(residuals(early.seral.rate , type = 'normalized'),lag.max =10)#No issues
plot( fitted(early.seral.rate),residuals(early.seral.rate, type="normalized"))# variances are homogenous
abline(0,0, col = 'red')
cor(fitted(early.seral.rate, level =1),model.data$lambda.dif) #0.8767
plot(model.data$lambda.dif~fitted(early.seral.rate))
abline(0,1, col = "red")
abline(0,0, col = "yellow")
summary(early.seral.rate)

#Rate model has higher correlation
anova(early.seral.per, early.seral.rate)
```

#Percentage disturbed - includes only cutblocks and roads buffered by 50m
```{r, dist}
#---Percentage---
dist.per<- lme(lambda.dif ~ core.dist.per*matrix.dist.per, random=~ 1|herd_name, method = 'ML', correlation = corAR1(0.5, form =~time|herd_name), data = model.data, control = con1)
acf(residuals(dist.per , type = 'normalized'),lag.max =10)#No issues
plot( fitted(dist.per),residuals(dist.per, type="normalized"))# variances are homogenous
abline(0,0, col = 'red')
cor(fitted(dist.per, level =0),model.data$lambda.dif) #0.809
plot(model.data$lambda.dif~fitted(dist.per, level =0))
abline(0,1, col = "red")
abline(0,0, col = "yellow")
summary(dist.per)

#---Rate---
dist.rate<- lme(lambda.dif ~ core.dist.rate*matrix.dist.rate, random=~ 1|herd_name,method = 'ML', correlation = corAR1(0.5, form =~time|herd_name), data = model.data, control = con1)
acf(residuals(dist.rate , type = 'normalized'),lag.max =10)#No issues
plot( fitted(dist.rate),residuals(dist.rate, type="normalized"))# variances are homogenous
abline(0,0, col = 'red')
cor(fitted(dist.rate, level =0),model.data$lambda.dif) #0.876
plot(model.data$lambda.dif~fitted(dist.rate, level =0))
abline(0,1, col = "red")
abline(0,0, col = "yellow")
summary(dist.rate)

anova(dist.per, dist.rate)
```

#Disturbance including cutblocks and roads with buffering each by 500m
```{r, dist500}
#---Percentage---
dist500.per<- lme(lambda.dif ~ core.dist500.per*matrix.dist500.per, random=~ 1|herd_name, method = 'ML', correlation = corAR1(0.5, form =~time|herd_name),data = model.data, control = con1)
acf(residuals(dist500.per, type = 'normalized'),lag.max =10)#No issues
plot( fitted(dist500.per),residuals(dist500.per, type="normalized"))# variances are homogenous
abline(0,0, col = 'red')
cor(fitted(dist500.per, level =1),model.data$lambda.dif) #0.7786
plot(model.data$lambda.dif~fitted(dist500.per))
abline(0,1, col = "red")
abline(0,0, col = "yellow")
summary(dist500.per)

#---Rate---
dist500.rate<- lme(lambda.dif ~ core.dist500.rate*matrix.dist500.rate,random=~ 1|herd_name, method = 'ML', correlation = corAR1(0.5, form =~time|herd_name), data = model.data, control = con1)
acf(residuals(dist500.rate , type = 'normalized'),lag.max =10)#No issues
plot( fitted(dist500.rate),residuals(dist500.rate, type="normalized"))# variances are homogenous
abline(0,0, col = 'red')
cor(fitted(dist500.rate, level =1),model.data$lambda.dif) #0.86
plot(model.data$lambda.dif~fitted(dist500.rate))
abline(0,1, col = "red")
abline(0,0, col = "yellow")
summary(dist500.rate)

anova(dist500.per, dist500.rate)
```

#Resource Selection Function (TBD)
To be determined later
```{r, rsf, echo=FALSE, eval=FALE}
rsf.rate<- lme(lambda.dif~ core.rsf.rate*matrix.rsf.rate,random=~ 1|herd_name, correlation = corAR1(form=~time|herd_name) ,
                  data = model.data, method = 'REML', control = con1)
summary(rsf.rate)
```

## OVERALL
```{r, overall}
aic.values<-AIC(m0.d,
                burn.per, burn.rate,early.seral.per,early.seral.rate,dist.per, dist.rate, dist500.per, dist500.rate)
aic.values$weights<-round(qpcR::akaike.weights(aic.values$AIC)$weights, 3)
aic.values
```

