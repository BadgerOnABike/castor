---
title: "Scripts for creating parameters to run Castor model for Fort Nelson timber supply area for comparison to SELES/STSM"
output: html_document
---

All data comes from Qinglin Li, and is the data used to complete the timber supply review in 2020-21.


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
source (here::here("R/functions/R_Postgres.R"))
library (data.table)
library (sf)
library (tidyverse)
library (raster)
library (fasterize)

data.dir <- "D:\\clus_data\\castor_stsm\\FN_data\\"

#Create a provincial raster
layeraoi <- getSpatialQuery ("SELECT * FROM study_area_compart limit 1")
prov.rast <- raster::raster(
  nrows = 15744, ncols = 17216, xmn = 159587.5, xmx = 1881187.5, ymn = 173787.5, ymx = 1748187.5, 
  crs = st_crs(layeraoi)$proj4string, resolution = c(100, 100), vals = 0)
```

## Fort Nelson TSA - Area of Interest
```{r Fort Nelson TSA}

fn.tsa <- st_make_valid (st_read (dsn = paste0 (data.dir, "fn_spatial.gdb"),
                                  layer = "bnd"))
fn.tsa$tsa_name <- "Fort_Nelson_TSA"
fn.tsa$value <- as.integer (1)
fn.tsa$included <- NULL
fn.tsa$bnd_fid <- NULL
fn.tsa$ORIG_FID <- NULL
fn.tsa$Shape_Length <- NULL
fn.tsa$Shape_Area <- NULL

st_write (fn.tsa, paste0 (data.dir, "bounds_fort_nelson_tsa.shp"))
# ogr2ogr -f PostgreSQL PG:"dbname=clus port=5432 user= password= host=" SCHEMA=fort_nelson_tsa D:\clus_data\castor_stsm\FN_data\bounds_fort_nelson_tsa.shp bounds_fort_nelson_tsa -a_srs EPSG:3005 -progress --config PG_USE_COPY YES -nlt PROMOTE_TO_MULTI -lco 

fn.tsa.vat <- as.data.table (unique (fn.tsa$tsa_name))
fn.tsa.vat [, value := seq_len(.N)]

# Rasterize 
ras.fn.tsa <-fasterize::fasterize (st_cast (fn.tsa, "MULTIPOLYGON"), prov.rast, field = "value")
writeRaster (ras.fn.tsa, paste0 (data.dir, "bounds_fort_nelson_tsa.tif"), overwrite = T)

# write data
conn<-DBI::dbConnect(dbDriver("PostgreSQL"), host=keyring::key_get('dbhost', keyring = 'postgreSQL'), dbname = keyring::key_get('dbname', keyring = 'postgreSQL'), port='5432' ,user=keyring::key_get('dbuser', keyring = 'postgreSQL') ,password= keyring::key_get('dbpass', keyring = 'postgreSQL'))

setnames (fn.tsa.vat, c ("attribute", "value")) # Note use convention; always name these value and attribute
DBI::dbWriteTable(conn, c("fort_nelson_tsa", "vat_bounds_fort_nelson_tsa"), value = fn.tsa.vat, row.names = FALSE, overwrite = TRUE)

system("cmd.exe", input = paste0('raster2pgsql -s 3005 -d -I -C -M -N 2147483648  ', data.dir, 'bounds_fort_nelson_tsa.tif -t 100x100 fort_nelson_tsa.rast_bounds_fort_nelson_tsa | psql postgres://', keyring::key_get('dbuser', keyring = 'postgreSQL'), ':', keyring::key_get('dbpass', keyring = 'postgreSQL'), '@', keyring::key_get('dbhost', keyring = 'postgreSQL'), ':5432/clus'), show.output.on.console = FALSE, invisible = TRUE)

dbDisconnect(conn)
```

## Inventory
```{r, inventory data}

fn.vri <- st_make_valid (st_read (dsn = paste0 (data.dir, "fn_spatial.gdb"),
                                  layer = "vri"))
fn.vri$Shape_Length <- NULL
fn.vri$Shape_Area <- NULL
st_write (fn.vri, paste0 (data.dir, "vri_fort_nelson_tsa.shp"))
# ogr2ogr -f PostgreSQL PG:"dbname=clus port=5432 user= password= host=" SCHEMA=fort_nelson_tsa D:\clus_data\castor_stsm\FN_data\vri_fort_nelson_tsa.shp vri_fort_nelson_tsa -a_srs EPSG:3005 -progress --config PG_USE_COPY YES -nlt PROMOTE_TO_MULTI -lco 

# Rasterize 
ras.fn.vri <-fasterize::fasterize (st_cast (fn.vri, "MULTIPOLYGON"), prov.rast, field = "vri_fid")
writeRaster (ras.fn.vri, paste0 (data.dir, "vri_fort_nelson_tsa.tif"), overwrite = T)

# write data
system("cmd.exe", input = paste0('raster2pgsql -s 3005 -d -I -C -M -N 2147483648  ', data.dir, 'vri_fort_nelson_tsa.tif -t 100x100 fort_nelson_tsa.rast_vri_id_fort_nelson_tsa | psql postgres://', keyring::key_get('dbuser', keyring = 'postgreSQL'), ':', keyring::key_get('dbpass', keyring = 'postgreSQL'), '@', keyring::key_get('dbhost', keyring = 'postgreSQL'), ':5432/clus'), show.output.on.console = FALSE, invisible = TRUE)

```

## Growth and Yield
```{r, g and y data}
## TABLES
tab.au.info <- data.table (read.table (paste0 (data.dir, "AUInfo.txt"), header = T, sep = '\t'))
tab.mgd.vol <- data.table (read.table (paste0 (data.dir, "MgdVolumeTables.txt"), header = T, sep = '\t')) # use this for both 'natural' and 'managed' stands 
tab.height <- data.table (read.table (paste0 (data.dir, "HeightTables.txt"), header = T, sep = '\t'))

# Check for dupes 
# tab.count <- tab.mgd.vol %>%
#               group_by (au) %>%
#                tally ()
# check <- tab.count %>%
#           dplyr::filter (n > 1)

# Format
colnames (tab.mgd.vol) <- c('ycid', "0", "10", "20", "30", "40", "50", "60", "70", "80", "90", "100", "110", "120", "130", "140", "150", "160", "170", "180", "190", "200", "210", "220", "230", "240", "250", "260", "270", "280", "290", "300")
colnames (tab.height) <- c('ycid', "0", "10", "20", "30", "40", "50", "60", "70", "80", "90", "100", "110", "120", "130", "140", "150", "160", "170", "180", "190", "200", "210", "220", "230", "240", "250", "260", "270", "280", "290", "300")
tab.au.info <- tab.au.info [, c ("AU", "Auid")]
colnames (tab.au.info) <- c ("ycid", "yc_grp")
# reshape the table to long form
tab.vol <- melt (tab.mgd.vol, 
                 id.vars = "ycid",
                 measure.vars = list (age = c ("0", "10", "20", "30", "40", "50", "60", "70", "80", "90", "100", "110", "120", "130", "140", "150", "160", "170", "180", "190", "200", "210", "220", "230", "240", "250", "260", "270", "280", "290", "300")),
                  value.name = "tvol",
                  variable.name = "age")
tab.hgt <- melt (tab.height, 
                 id.vars = "ycid",
                 measure.vars = list (age = c ("0", "10", "20", "30", "40", "50", "60", "70", "80", "90", "100", "110", "120", "130", "140", "150", "160", "170", "180", "190", "200", "210", "220", "230", "240", "250", "260", "270", "280", "290", "300")),
                  value.name = "height",
                  variable.name = "age")

# join the tables
tab.yields <- merge (tab.vol,
                     tab.hgt, 
                     by.x = c ("ycid", "age"),
                     by.y = c ("ycid", "age"),
                     all.x = T)
tab.gy <- merge (tab.au.info,
                 tab.yields, 
                 by.x = "ycid",
                 by.y = "ycid",
                 all.x = T)

# write table
conn<-DBI::dbConnect(dbDriver("PostgreSQL"), host=keyring::key_get('dbhost', keyring = 'postgreSQL'), dbname = keyring::key_get('dbname', keyring = 'postgreSQL'), port='5432' ,user=keyring::key_get('dbuser', keyring = 'postgreSQL') ,password= keyring::key_get('dbpass', keyring = 'postgreSQL'))

DBI::dbWriteTable (conn, c("fort_nelson_tsa", "yc_table"), value = tab.gy, row.names = FALSE, overwrite = TRUE)

## RASTERS
# analysis unit raster
rast.yield.id <- raster::raster (paste0 (data.dir, "tsa08_au2016.tif")) 
writeRaster (rast.yield.id, paste0 (data.dir, "rast_ycid_fort_nelson_tsa.tif"), overwrite = T)
system ("cmd.exe", input = paste0('raster2pgsql -s 3005 -d -I -C -M -N 2147483648  ', data.dir, 'rast_ycid_fort_nelson_tsa.tif -t 100x100 fort_nelson_tsa.rast_ycid_fort_nelson_tsa | psql postgres://', keyring::key_get('dbuser', keyring = 'postgreSQL'), ':', keyring::key_get('dbpass', keyring = 'postgreSQL'), '@', keyring::key_get('dbhost', keyring = 'postgreSQL'), ':5432/clus'), show.output.on.console = FALSE, invisible = TRUE)

```

## THLB
```{r thlb}

thlb <- raster::raster (paste0 (data.dir, "tsa08_thlb_fact_nov2019.tif")) 
# values have been multiplied to make them 0 to 10,000; divide by 10,000 to make it a value 0 to 1
thlb <- thlb / 10000
## Upload data to db
crs(thlb) <- "+proj=aea +lat_0=45 +lon_0=-126 +lat_1=50 +lat_2=58.5 +x_0=1000000 +y_0=0 +datum=NAD83 +units=m +no_defs"
writeRaster (thlb, file = paste0 (data.dir, "thlb.tif"), format = "GTiff", overwrite = TRUE)
system ("cmd.exe", input = paste0 ('raster2pgsql -s 3005 -d -I -C -M -N 2147483648  ', data.dir, 'thlb.tif -t 100x100 fort_nelson_tsa.rast_thlb | psql postgres://', keyring::key_get('dbuser', keyring = 'postgreSQL'), ':', keyring::key_get('dbpass', keyring = 'postgreSQL'), '@', keyring::key_get('dbhost', keyring = 'postgreSQL'), ':5432/clus'), show.output.on.console = FALSE, invisible = TRUE)

```

## Harvest Constraint Zones
```{r harvest constraints}

conn <- DBI::dbConnect(dbDriver("PostgreSQL"), host=keyring::key_get('dbhost', keyring = 'postgreSQL'), dbname = keyring::key_get('dbname', keyring = 'postgreSQL'), port='5432' ,user=keyring::key_get('dbuser', keyring = 'postgreSQL') ,password= keyring::key_get('dbpass', keyring = 'postgreSQL'))

# constraints table
tab.constraints <- data.table (read.table (paste0 (data.dir, "CoverConstraints.txt"), header = T, sep = '\t'))
tab.og.constraints <- tab.constraints [Layer == "rlu_oldgrw", ]

# raster data
rast.og <- raster::raster (paste0 (data.dir, "tsa08_lu_oldgrw_number.tif")) # old growth zones
rast.prod <- raster::raster (paste0 (data.dir, "tsa08_prod_for_change.tif")) # productive forest

# multiply rasters together to get area of productive forest, by zone
rast.og.prod <- rast.og * rast.prod

# write raster data to db
writeRaster (rast.og.prod, paste0 (data.dir, "lu_oldgrw_prod.tif"), overwrite = T)
system ("cmd.exe", input = paste0('raster2pgsql -s 3005 -d -I -C -M -N 2147483648  ', data.dir, 'lu_oldgrw_prod.tif -t 100x100 fort_nelson_tsa.rast_oldgrw_prod | psql postgres://', keyring::key_get ('dbuser', keyring = 'postgreSQL'), ':', keyring::key_get ('dbpass', keyring = 'postgreSQL'), '@', keyring::key_get ('dbhost', keyring = 'postgreSQL'), ':5432/clus'), show.output.on.console = FALSE, invisible = TRUE)


# og raster vat
og.vat <- data.table (value = as.integer (c(1:5)),
                      attribute = c ('alluvial_con', 'alluvial_decid', 'mountains', 'upland_con', 'upland_decid')                                 )
DBI::dbWriteTable (conn, c("fort_nelson_tsa", "vat_old_growth_zone_names"), value = og.vat, row.names = FALSE, overwrite = TRUE)

# constraints table
zone_og <- data.table (zoneid = as.integer (c(1:5)), # check these.....
                       type = 'ge',
                       variable = 'age', 
                       threshold = as.numeric (c (140, 100, 140, 140, 100)), 
                       reference_zone = 'fort_nelson_tsa.rast_oldgrw_prod', 
                       percentage = as.numeric (c (44, 44, 37, 17, 17)), 
                       ndt = as.integer (0), 
                       label = c ('alluvial_con', 'alluvial_decid', 'mountains',
                                  'upland_con', 'upland_decid'), 
                       multi_condition = as.character (''), 
                       denom = as.character (''), 
                       start = as.integer (0), 
                       stop = as.integer (250))
DBI::dbWriteTable (conn, c("fort_nelson_tsa", "constraints"), value = zone_og, row.names = FALSE, overwrite = TRUE)

dbDisconnect (conn)
```

## Analysis Units
```{r analysis units}

system ("cmd.exe", input = paste0('raster2pgsql -s 3005 -d -I -C -M -N 2147483648  ', data.dir, 'tsa08_au2016.tif -t 100x100 fort_nelson_tsa.rast_au | psql postgres://', keyring::key_get ('dbuser', keyring = 'postgreSQL'), ':', keyring::key_get ('dbpass', keyring = 'postgreSQL'), '@', keyring::key_get ('dbhost', keyring = 'postgreSQL'), ':5432/clus'), show.output.on.console = FALSE, invisible = TRUE)



### use script below if you want to replicate the STSM approach of not creating 'blocks' (i.e., each pixel is a block) to the castor db
castordb <- dbConnect(RSQLite::SQLite(), dbname = paste0(here::here(), "/R/scenarios/comparison_ft_nelson/ftnelson_stsmcompare_noroads_noblocks_castordb.sqlite"))
# update pixels table 
dbExecute (castordb, "ALTER TABLE pixels ADD COLUMN blockid integer DEFAULT 0")
dbBegin (castordb)
rs <- dbSendQuery (castordb, "UPDATE pixels SET blockid = pixelid;")
dbClearResult (rs)
dbCommit (castordb)

# create blocks table
dbExecute (castordb, "CREATE TABLE IF NOT EXISTS blocks ( blockid integer DEFAULT 0, age integer, height numeric, vol numeric, salvage_vol numeric, dist numeric DEFAULT 0, landing integer)")  
dbExecute (castordb, paste0("UPDATE blocks SET vol = 0 WHERE vol IS NULL")) 
dbExecute (castordb, paste0("UPDATE blocks SET dist = 0 WHERE dist is NULL"))
dbExecute (castordb, paste0("INSERT INTO blocks (blockid, age, height,  vol, salvage_vol, dist, landing)  
                    SELECT blockid, round(AVG(age),0) as age, AVG(height) as height, AVG(vol) as vol, AVG(salvage_vol) as salvage_vol, AVG(dist) as dist, (CASE WHEN min(dist) = dist THEN pixelid ELSE pixelid END) as landing
                                       FROM pixels WHERE blockid > 0 AND thlb > 0 GROUP BY blockid "))  
dbExecute (castordb, "CREATE INDEX index_blockid on blocks (blockid)")

# create adjacent blocks table
ras <- terra::rast (ncol = 5223, nrow = 2947, xmin = 830187.5, 
			              xmax = 1352488, ymin = 1388088, ymax = 1682788,)  
terra::crs(ras)  <- "+proj=aea +lat_0=45 +lon_0=-126 +lat_1=50 +lat_2=58.5 +x_0=1000000 +y_0=0 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs +type=crs"  
edgesAdj <- data.table(SpaDES.tools::adj(returnDT= TRUE, 
                                         directions = 8, numCol = ncol(ras), numCell=ncol(ras)*nrow(ras),
                                         cells = 1:as.integer(ncol(ras)*nrow(ras)))) 
blockids <- data.table (dbGetQuery (castordb, "SELECT blockid, pixelid FROM pixels WHERE blockid > 0"))
setkey (blockids, pixelid)  
edgesAdj <- merge (edgesAdj, blockids, by.x = "to", by.y = "pixelid" )  
edgesAdj <- merge (edgesAdj, blockids, by.x = "from", by.y ="pixelid" )
edgesAdj <- data.table (edgesAdj[, c ("blockid.x", "blockid.y")])
edgesAdj <- edgesAdj[blockid.x  != blockid.y]
edgesAdj <- edgesAdj[blockid.x  > 0 & blockid.y  > 0]
edgesAdj <- unique (edgesAdj)
setnames(edgesAdj, c ("blockid", "adjblockid")) 
  
dbExecute(castordb, "CREATE TABLE IF NOT EXISTS adjacentBlocks (id integer PRIMARY KEY, adjblockid integer, blockid integer)")  
dbBegin(castordb)  
rs <- dbSendQuery (castordb, "INSERT INTO adjacentBlocks (blockid , adjblockid) VALUES (:blockid, :adjblockid)", edgesAdj)  
dbClearResult(rs)
dbCommit(castordb) 
dbExecute(castordb, "CREATE INDEX index_adjblockid on adjacentBlocks (adjblockid)")


### use script below if you want to add analysis units (AU's) as blocks to the castor db
castordb <- dbConnect(RSQLite::SQLite(), dbname = paste0(here::here(), "/R/scenarios/comparison_ft_nelson/ftnelson_stsmcompare_noroads_noblocks_castordb.sqlite"))

tab.au <- data.table (blockid = as.integer (RASTER_CLIP2 (tmpRast = paste0('temp_', sample(1:10000, 1)), 
								                                          srcRaster = "fort_nelson_tsa.rast_au" , # 
                                                          clipper = "fort_nelson_tsa.bounds_fort_nelson_tsa", 
								                                          geom = "wkb_geometry", 
                                                          where_clause = " tsa_name in (''Fort_Nelson_TSA'')",
                                            conn = NULL)[]))
tab.au [, pixelid := seq_len(.N)][, blockid := as.integer(blockid)]
tab.au <- tab.au[blockid > 0, ]  
	 
# update pixels table 
dbExecute (castordb, "ALTER TABLE pixels ADD COLUMN blockid integer DEFAULT 0")
dbBegin (castordb)
rs <- dbSendQuery (castordb, "Update pixels set blockid = :blockid where pixelid = :pixelid", tab.au)
dbClearResult (rs)
dbCommit (castordb)

# create blocks table
dbExecute(castordb, "CREATE TABLE IF NOT EXISTS blocks ( blockid integer DEFAULT 0, age integer, height numeric, vol numeric, salvage_vol numeric, dist numeric DEFAULT 0, landing integer)")  
dbExecute(castordb, paste0("UPDATE blocks SET vol = 0 WHERE vol IS NULL")) 
dbExecute(castordb, paste0("UPDATE blocks SET dist = 0 WHERE dist is NULL"))
dbExecute(castordb, paste0("INSERT INTO blocks (blockid, age, height,  vol, salvage_vol, dist, landing)  
                    SELECT blockid, round(AVG(age),0) as age, AVG(height) as height, AVG(vol) as vol, AVG(salvage_vol) as salvage_vol, AVG(dist) as dist, (CASE WHEN min(dist) = dist THEN pixelid ELSE pixelid END) as landing
                                       FROM pixels WHERE blockid > 0 AND thlb > 0 GROUP BY blockid "))  
dbExecute(castordb, "CREATE INDEX index_blockid on blocks (blockid)")

# create adjacent blocks table
ras <- terra::rast (ncol = 5223, nrow = 2947, xmin=830187.5, 
			        xmax=1352488, ymin=1388088, ymax=1682788,)  
terra::crs(ras)  <- "+proj=aea +lat_0=45 +lon_0=-126 +lat_1=50 +lat_2=58.5 +x_0=1000000 +y_0=0 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs +type=crs"  
edgesAdj <- data.table(SpaDES.tools::adj(returnDT= TRUE, 
directions = 8, numCol = ncol(ras), numCell=ncol(ras)*nrow(ras),
                                             cells = 1:as.integer(ncol(ras)*nrow(ras)))) 
blockids <- data.table (dbGetQuery (castordb, "SELECT blockid, pixelid FROM pixels WHERE blockid > 0"))
setkey (blockids, pixelid)  
edgesAdj <- merge (edgesAdj, blockids, by.x = "to", by.y = "pixelid" )  
edgesAdj <- merge (edgesAdj, blockids, by.x = "from", by.y ="pixelid" )
edgesAdj <- data.table (edgesAdj[, c ("blockid.x", "blockid.y")])
edgesAdj <- edgesAdj[blockid.x  != blockid.y]
edgesAdj <- edgesAdj[blockid.x  > 0 & blockid.y  > 0]
edgesAdj <- unique (edgesAdj)
setnames(edgesAdj, c ("blockid", "adjblockid")) 
  
dbExecute(castordb, "CREATE TABLE IF NOT EXISTS adjacentBlocks (id integer PRIMARY KEY, adjblockid integer, blockid integer)")  
dbBegin(castordb)  
rs <- dbSendQuery (castordb, "INSERT INTO adjacentBlocks (blockid , adjblockid) VALUES (:blockid, :adjblockid)", edgesAdj)  
dbClearResult(rs)
dbCommit(castordb) 
dbExecute(castordb, "CREATE INDEX index_adjblockid on adjacentBlocks (adjblockid)")
  
```


