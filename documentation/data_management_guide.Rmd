---
title: "Data Management Guidelines"
author: "Tyler Muhly"
date: "02/11/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library (DBI)
library (here)
library (data.table)

source (here ("R/functions/R_Postgres.R"))

```

## Data Management Guidelines for the Caribou and Land Use Simulator
The caribou and land use simulator (CLUS) has a specific framework for using datasets and parameters. For details on the framework, see the 'Getting Started with CLUS' documentation. Here we describe how to document and manage datasets used within this framework. 

### Data Tracking Table
Spatial and aspatial data and parameters used in CLUS are stored in postgres databases. We uploaded a data table called 'pgdbs_data_list' to the DC052586 CLUS postgres database that describes each table in the databases used by CLUS and CLUS applications. This table is intended to simplify CLUS users ability to understand the origin and appropriate end-use of datasets used in the CLUS model.  

```{r, write original spreadsheet to postgres, eval = F, echo = T, warning = F, message = F}
pgdbs_data_list <- read.table ("C:\\Work\\pgdbs_data_list.csv",
                               header = T,
                               sep = ",") 
conn <- DBI::dbConnect(dbDriver("PostgreSQL"), 
                       host = keyring::key_get('dbhost', keyring = 'postgreSQL'), 
                       dbname = keyring::key_get('dbname', keyring = 'postgreSQL'), 
                       port='5432' ,
                       user=keyring::key_get('dbuser', keyring = 'postgreSQL') ,
                       password= keyring::key_get('dbpass', keyring = 'postgreSQL'))
DBI::dbWriteTable(conn, c("public", "pgdbs_data_list"), 
                  value = pgdbs_data_list, row.names = FALSE, overwrite = TRUE)
```

The data tracking table (pgdbs_data_list) consists of 11 fields. Each row represents a unique table in a postgres database. The *computer*, *database* and *schema* fields identify where the table is stored, and the *table_name* field identifies the name of the table in the database. The *type* field identifies whether the data table is one of three types: a simple 'table', spatial 'polygon' or 'raster'.  The *script* field identifies where in the CLUS repository the data was documented and created. For example, many of the rasters and tables used to define provincial management objectives, such as visual quality objectives, are documented and created in *clus\R\Params\prov_manage_objs.Rmd*. The *source* field describes where the original data were obtained, and the *public* field describes whether the data can be shared with the public ('Yes') or must be kept internal and confidential ('No'). The *last_updated* field documents the year the data was added to the database or last modified, and the *next_update* field documents the year the data should ideally be updated. For example, the consolidated cutblocks data should ideally be updated annually. If the data is not going to be updated and the data should be maintained long-term in the database the *next_update* field can be set to 'NA'. When it is not clear when an update is needed but we anticipate that a dataset will be updated periodically the *next_update* field can be set to 'as needed'. Finally, the *where_used* field documents where in the CLUS model the table is used, for example, in the dataLoaderCLUS module, or the CLUS scenario application. If the data are no longer used anywhere, but you don't want to delete it, the *where_used* field  can be set to 'archive'. If the data are no longer used anywhere, but you think it should be deleted the *where_used* field can be set to 'deprecated'. 

### Updating the Tracking Table
The data tracking table (pgdbs_data_list) should be updated whenever a new dataset is added or modified in the CLUS model. For example, if a new management area with a new management objective is defined and created in the database it should be documented by adding new row to the tracking table. 

When adding new data that you anticipate will be updated on a annual basis, include the year it was uploaded to the end of the table name, e.g., 'new_table_2020'. If you anticipate the data will be updated monthly, include the year and month at the end of the table name, e.g., 'new_table_202011'. 

```{r, add new row (new data) to the table, eval = F, echo = T, warning = F, message = F}
# load the existing data tracking table
pgdbs_data_list <- getTableQuery("SELECT * from public.pgdbs_data_list;")

#Create new row for table
new_data <- data.table (computer = 'test', # e.g., 206.12.91.188 or DC052586 
                        database = 'test', # clus
                        schema = 'test', # caribou, public or rast
                        table_name = 'test', # add year adn month if relevant
                        type = 'test', # polygon, raster or table
                        script = 'test', # name and location of script to produce the data
                        source = 'test', # description of data source
                        public = 'test', # Yes, if can be shared with public, otherwise No
                        last_updated = 'test', # year when data added
                        next_update = 'test', # year when data should ideally be updated
                        where_used = 'test' # name of module of application where data used
                        )

# merge tables
pgdbs_data_list_new <- merge (pgdbs_data_list, new_data, all = T)

# re-upload data to postgres
DBI::dbWriteTable(conn, c("public", "pgdbs_data_list"), value= pgdbs_data_list_new, row.names = FALSE, overwrite = TRUE)
```

If an existing table is updated in the data tracking table (pgdbs_data_list), the modifications to the data should be documented.  

```{r, modify an existing row (table), eval = F, echo = T, warning = F, message = F}
# load the existing data tracking table
pgdbs_data_list <- getTableQuery("SELECT * from public.pgdbs_data_list;")




# edit table

# re-upload data to postgres
```



### Replacing Exidting Datasets


-	If data is no longer needed label it as ‘deprecated’ or 'archive' and check with other team members to ensure they no longer needed
o	If consensus is that the data is no longer needed, delete it from the data





### Archiving Data


